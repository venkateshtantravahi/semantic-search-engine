id,published,authors,clean_title,clean_abstract
http://arxiv.org/abs/2505.13448v1,2025-05-19T17:59:58Z,"Vinay Samuel, Harshita Diddee, Yiming Zhang, Daphne Ippolito",cie controlling language model text generations using continuous signals,aligning language models with user intent is becoming increasingly relevant to enhance user experience this calls for designing methods that can allow users to control the properties of the language that lms generate for example controlling the length of the generation the complexity of the language that gets chosen the sentiment tone etc most existing work attempts to integrate users control by conditioning lm generations on natural language prompts or discrete control signals which are often brittle and hard to scale in this work we are interested in textitcontinuous control signals ones that exist along a spectrum that cant easily be captured in a natural language prompt or via existing techniques in conditional generation through a case study in controlling the precise responselength of generations produced by lms we demonstrate how after finetuning behaviors of language models can be controlled via continuous signals as vectors that are interpolated between a low and a high token embedding our method more reliably exerts responselength control than incontext learning methods or finetuning methods that represent the control signal as a discrete signal our full opensourced code and datasets are available at httpsgithubcomvsamuel2003cie
http://arxiv.org/abs/2505.13445v1,2025-05-19T17:59:31Z,"Xiaoyuan Liu, Tian Liang, Zhiwei He, Jiahao Xu, Wenxuan Wang, Pinjia He, Zhaopeng Tu, Haitao Mi, Dong Yu",trust but verify a selfverification approach to reinforcement learning with verifiable rewards,large language models llms show great promise in complex reasoning with reinforcement learning with verifiable rewards rlvr being a key enhancement strategy however a prevalent issue is superficial selfreflection where models fail to robustly verify their own outputs we introduce rise reinforcing reasoning with selfverification a novel online rl framework designed to tackle this rise explicitly and simultaneously trains an llm to improve both its problemsolving and selfverification abilities within a single integrated rl process the core mechanism involves leveraging verifiable rewards from an outcome verifier to provide onthefly feedback for both solution generation and selfverification tasks in each iteration the model generates solutions then critiques its own onpolicy generated solutions with both trajectories contributing to the policy update extensive experiments on diverse mathematical reasoning benchmarks show that rise consistently improves models problemsolving accuracy while concurrently fostering strong selfverification skills our analyses highlight the advantages of online verification and the benefits of increased verification compute additionally rise models exhibit more frequent and accurate selfverification behaviors during reasoning these advantages reinforce rise as a flexible and effective path towards developing more robust and selfaware reasoners
http://arxiv.org/abs/2505.13444v1,2025-05-19T17:59:27Z,"Liyan Tang, Grace Kim, Xinyu Zhao, Thom Lake, Wenxuan Ding, Fangcong Yin, Prasann Singhal, Manya Wadhwa, Zeyu Leo Liu, Zayne Sprague, Ramya Namuduri, Bodun Hu, Juan Diego Rodriguez, Puyuan Peng, Greg Durrett",chartmuseum testing visual reasoning capabilities of large visionlanguage models,chart understanding presents a unique challenge for large visionlanguage models lvlms as it requires the integration of sophisticated textual and visual reasoning capabilities however current lvlms exhibit a notable imbalance between these skills falling short on visual reasoning that is difficult to perform in text we conduct a case study using a synthetic dataset solvable only through visual reasoning and show that model performance degrades significantly with increasing visual complexity while human performance remains robust we then introduce chartmuseum a new chart question answering qa benchmark containing 1162 expertannotated questions spanning multiple reasoning types curated from realworld charts across 184 sources specifically built to evaluate complex visual and textual reasoning unlike prior chart understanding benchmarks where frontier models perform similarly and near saturation our benchmark exposes a substantial gap between model and human performance while effectively differentiating model capabilities although humans achieve 93 accuracy the bestperforming model gemini25pro attains only 630 and the leading opensource lvlm qwen25vl72binstruct achieves only 385 moreover on questions requiring primarily visual reasoning all models experience a 3555 performance drop from textreasoningheavy question performance lastly our qualitative error analysis reveals specific categories of visual reasoning that are challenging for current lvlms
http://arxiv.org/abs/2505.13438v1,2025-05-19T17:58:44Z,"Penghui Qi, Zichen Liu, Tianyu Pang, Chao Du, Wee Sun Lee, Min Lin",optimizing anytime reasoning via budget relative policy optimization,scaling testtime compute is crucial for enhancing the reasoning capabilities of large language models llms existing approaches typically employ reinforcement learning rl to maximize a verifiable reward obtained at the end of reasoning traces however such methods optimize only the final performance under a large and fixed token budget which hinders efficiency in both training and deployment in this work we present a novel framework anytimereasoner to optimize anytime reasoning performance which aims to improve token efficiency and the flexibility of reasoning under varying token budget constraints to achieve this we truncate the complete thinking process to fit within sampled token budgets from a prior distribution compelling the model to summarize the optimal answer for each truncated thinking for verification this introduces verifiable dense rewards into the reasoning process facilitating more effective credit assignment in rl optimization we then optimize the thinking and summary policies in a decoupled manner to maximize the cumulative reward additionally we introduce a novel variance reduction technique budget relative policy optimization brpo to enhance the robustness and efficiency of the learning process when reinforcing the thinking policy empirical results in mathematical reasoning tasks demonstrate that our method consistently outperforms grpo across all thinking budgets under various prior distributions enhancing both training and token efficiency
http://arxiv.org/abs/2505.13434v1,2025-05-19T17:57:36Z,"Mateusz Bystroński, Mikołaj Hołysz, Grzegorz Piotrowski, Nitesh V. Chawla, Tomasz Kajdanowicz",smotext smote meets large language models,data scarcity and class imbalance are persistent challenges in training robust nlp models especially in specialized domains or lowresource settings we propose a novel technique smotext that adapts the idea of synthetic minority oversampling smote to textual data our method generates new synthetic examples by interpolating between bertbased embeddings of two existing examples and then decoding the resulting latent point into text with xrag architecture by leveraging xrags crossmodal retrievalgeneration framework we can effectively turn interpolated vectors into coherent text while this is preliminary work supported by qualitative outputs only the method shows strong potential for knowledge distillation and data augmentation in fewshot settings notably our approach also shows promise for privacypreserving machine learning in early experiments training models solely on generated data achieved comparable performance to models trained on the original dataset this suggests a viable path toward safe and effective learning under data protection constraints
http://arxiv.org/abs/2505.13430v1,2025-05-19T17:55:15Z,"Sifeng Shang, Jiayi Zhou, Chenyu Lin, Minxian Li, Kaiyang Zhou",finetuning quantized neural networks with zerothorder optimization,as the size of large language models grows exponentially gpu memory has become a bottleneck for adapting these models to downstream tasks in this paper we aim to push the limits of memoryefficient training by minimizing memory usage on model weights gradients and optimizer states within a unified framework our idea is to eliminate both gradients and optimizer states using zerothorder optimization which approximates gradients by perturbing weights during forward passes to identify gradient directions to minimize memory usage on weights we employ model quantization eg converting from bfloat16 to int4 however directly applying zerothorder optimization to quantized weights is infeasible due to the precision gap between discrete weights and continuous gradients which would otherwise require dequantization and requantization to overcome this challenge we propose quantized zerothorder optimization qzo a novel approach that perturbs the continuous quantization scale for gradient estimation and uses a directional derivative clipping method to stabilize training qzo is orthogonal to both scalarbased and codebookbased posttraining quantization methods compared to fullparameter finetuning in bfloat16 qzo can reduce the total memory cost by more than 18 for 4bit llms and enables finetuning llama213b and stable diffusion 35 large within a single 24gb gpu
http://arxiv.org/abs/2505.13418v1,2025-05-19T17:51:35Z,"Lotem Peled-Cohen, Maya Zadok, Nitay Calderon, Hila Gonen, Roi Reichart",dementia through different eyes explainable modeling of human and llm perceptions for early awareness,cognitive decline often surfaces in language years before diagnosis it is frequently nonexperts such as those closest to the patient who first sense a change and raise concern as llms become integrated into daily communication and used over prolonged periods it may even be an llm that notices something is off but what exactly do they noticeand should be noticingwhen making that judgment this paper investigates how dementia is perceived through language by nonexperts we presented transcribed picture descriptions to nonexpert humans and llms asking them to intuitively judge whether each text was produced by someone healthy or with dementia we introduce an explainable method that uses llms to extract highlevel expertguided features representing these picture descriptions and use logistic regression to model human and llm perceptions and compare with clinical diagnoses our analysis reveals that human perception of dementia is inconsistent and relies on a narrow and sometimes misleading set of cues llms by contrast draw on a richer more nuanced feature set that aligns more closely with clinical patterns still both groups show a tendency toward false negatives frequently overlooking dementia cases through our interpretable framework and the insights it provides we hope to help nonexperts better recognize the linguistic signs that matter
http://arxiv.org/abs/2505.13417v1,2025-05-19T17:50:52Z,"Jiajie Zhang, Nianyi Lin, Lei Hou, Ling Feng, Juanzi Li",adaptthink reasoning models can learn when to think,recently large reasoning models have achieved impressive performance on various tasks by employing humanlike deep thinking however the lengthy thinking process substantially increases inference overhead making efficiency a critical bottleneck in this work we first demonstrate that nothinking which prompts the reasoning model to skip thinking and directly generate the final solution is a better choice for relatively simple tasks in terms of both performance and efficiency motivated by this we propose adaptthink a novel rl algorithm to teach reasoning models to choose the optimal thinking mode adaptively based on problem difficulty specifically adaptthink features two core components 1 a constrained optimization objective that encourages the model to choose nothinking while maintaining the overall performance 2 an importance sampling strategy that balances thinking and nothinking samples during onpolicy training thereby enabling cold start and allowing the model to explore and exploit both thinking modes throughout the training process our experiments indicate that adaptthink significantly reduces the inference costs while further enhancing performance notably on three math datasets adaptthink reduces the average response length of deepseekr1distillqwen15b by 53 and improves its accuracy by 24 highlighting the promise of adaptive thinkingmode selection for optimizing the balance between reasoning quality and efficiency our codes and models are available at httpsgithubcomthukegadaptthink
http://arxiv.org/abs/2505.13408v1,2025-05-19T17:44:26Z,"Jinhe Bi, Danqi Yan, Yifan Wang, Wenke Huang, Haokun Chen, Guancheng Wan, Mang Ye, Xun Xiao, Hinrich Schuetze, Volker Tresp, Yunpu Ma",cotkinetics a theoretical modeling assessing lrm reasoning process,recent large reasoning models significantly improve the reasoning ability of large language models by learning to reason exhibiting the promising performance in solving complex tasks lrms solve tasks that require complex reasoning by explicitly generating reasoning trajectories together with answers nevertheless judging the quality of such an output answer is not easy because only considering the correctness of the answer is not enough and the soundness of the reasoning trajectory part matters as well logically if the soundness of the reasoning part is poor even if the answer is correct the confidence of the derived answer should be low existing methods did consider jointly assessing the overall output answer by taking into account the reasoning part however their capability is still not satisfactory as the causal relationship of the reasoning to the concluded answer cannot properly reflected in this paper inspired by classical mechanics we present a novel approach towards establishing a cotkinetics energy equation specifically our cotkinetics energy equation formulates the token state transformation process which is regulated by lrm internal transformer layers as like a particle kinetics dynamics governed in a mechanical field our cotkinetics energy assigns a scalar score to evaluate specifically the soundness of the reasoning phase telling how confident the derived answer could be given the evaluated reasoning as such the lrms overall output quality can be accurately measured rather than a coarse judgment eg correct or incorrect anymore
http://arxiv.org/abs/2505.13404v1,2025-05-19T17:40:58Z,"Nithin Rao Koluguri, Monica Sekoyan, George Zelenfroynd, Sasha Meister, Shuoyang Ding, Sofia Kostandian, He Huang, Nikolay Karpov, Jagadeesh Balam, Vitaly Lavrukhin, Yifan Peng, Sara Papi, Marco Gaido, Alessio Brutti, Boris Ginsburg",granary speech recognition and translation dataset in 25 european languages,multitask and multilingual approaches benefit large models yet speech processing for lowresource languages remains underexplored due to data scarcity to address this we present granary a largescale collection of speech datasets for recognition and translation across 25 european languages this is the first opensource effort at this scale for both transcription and translation we enhance data quality using a pseudolabeling pipeline with segmentation twopass inference hallucination filtering and punctuation restoration we further generate translation pairs from pseudolabeled transcriptions using eurollm followed by a data filtration pipeline designed for efficiency our pipeline processes vast amount of data within hours we assess models trained on processed data by comparing their performance on previously curated datasets for both high and lowresource languages our findings show that these models achieve similar performance using approx 50 less data dataset will be made available at httpshfcodatasetsnvidiagranary
http://arxiv.org/abs/2505.13403v1,2025-05-19T17:37:39Z,"Renjie Pi, Felix Bai, Qibin Chen, Simon Wang, Jiulong Shan, Kieran Liu, Meng Cao",mr judge multimodal reasoner as a judge,the paradigm of using large language models llms and multimodal large language models mllms as evaluative judges has emerged as an effective approach in rlhf and inferencetime scaling in this work we propose multimodal reasoner as a judge mr judge a paradigm for empowering generalpurpose mllms judges with strong reasoning capabilities instead of directly assigning scores for each response we formulate the judgement process as a reasoninginspired multiplechoice problem specifically the judge model first conducts deliberate reasoning covering different aspects of the responses and eventually selects the best response from them this reasoning process not only improves the interpretibility of the judgement but also greatly enhances the performance of mllm judges to cope with the lack of questions with scored responses we propose the following strategy to achieve automatic annotation 1 reverse response candidates synthesis starting from a supervised finetuning sft dataset we treat the original response as the best candidate and prompt the mllm to generate plausible but flawed negative candidates 2 textbased reasoning extraction we carefully design a data synthesis pipeline for distilling the reasoning capability from a textbased reasoning model which is adopted to enable the mllm judges to regain complex reasoning ability via warm up supervised finetuning experiments demonstrate that our mr judge is effective across a wide range of tasks specifically our mr judge7b surpasses gpt4o by 99 on vlrewardbench and improves performance on mmvet during inferencetime scaling by up to 77
http://arxiv.org/abs/2505.13398v1,2025-05-19T17:34:56Z,"Matan Abudy, Orr Well, Emmanuel Chemla, Roni Katzir, Nur Lan",a minimum description length approach to regularization in neural networks,stateoftheart neural networks can be trained to become remarkable solutions to many problems but while these architectures can express symbolic perfect solutions trained models often arrive at approximations instead we show that the choice of regularization method plays a crucial role when trained on formal languages with standard regularization or none expressive architectures not only fail to converge to correct solutions but are actively pushed away from perfect initializations in contrast applying the minimum description length mdl principle to balance model complexity with data fit provides a theoretically grounded regularization method using mdl perfect solutions are selected over approximations independently of the optimization algorithm we propose that unlike existing regularization techniques mdl introduces the appropriate inductive bias to effectively counteract overfitting and promote generalization
http://arxiv.org/abs/2505.13393v1,2025-05-19T17:33:15Z,Christopher K. Frantz,ig parser a software package for the encoding of institutional statements using the institutional grammar,this article provides an overview of ig parser a software that facilitates qualitative content analysis of formal eg legal rules or informal eg socionormative norms and strategies such as conventions referred to as emphinstitutions that govern social systems and operate configurally to describe emphinstitutional systems to this end the ig parser employs a distinctive syntax that ensures rigorous encoding of natural language while automating the transformation into various formats that support the downstream analysis using diverse analytical techniques the conceptual core of the ig parser is an associated syntax ig script that operationalizes the conceptual foundations of the institutional grammar and more specifically institutional grammar 20 an analytical paradigm for institutional analysis this article presents the ig parser including its conceptual foundations syntactic specification of ig script alongside architectural principles this introduction is augmented with selective illustrative examples that highlight the use and benefit associated with the tool
http://arxiv.org/abs/2505.13388v1,2025-05-19T17:29:03Z,"David Anugraha, Zilu Tang, Lester James V. Miranda, Hanyang Zhao, Mohammad Rifqi Farhansyah, Garry Kuwanto, Derry Wijaya, Genta Indra Winata",r3 robust rubricagnostic reward models,reward models are essential for aligning language model outputs with human preferences yet existing approaches often lack both controllability and interpretability these models are typically optimized for narrow objectives limiting their generalizability to broader downstream tasks moreover their scalar outputs are difficult to interpret without contextual reasoning to address these limitations we introduce r3 a novel reward modeling framework that is rubricagnostic generalizable across evaluation dimensions and provides interpretable reasoned score assignments r3 enables more transparent and flexible evaluation of language models supporting robust alignment with diverse human values and use cases our models data and code are available as open source at httpsgithubcomrubricrewardr3
http://arxiv.org/abs/2505.13380v1,2025-05-19T17:24:26Z,"Nam V. Nguyen, Huy Nguyen, Quang Pham, Van Nguyen, Savitha Ramasamy, Nhat Ho",competesmoe statistically guaranteed mixture of experts training via competition,sparse mixture of experts smoe offers an appealing solution to scale up the model complexity beyond the mean of increasing the networks depth or width however we argue that effective smoe training remains challenging because of the suboptimal routing process where experts that perform computation do not directly contribute to the routing process in this work we propose competition a novel mechanism to route tokens to experts with the highest neural response theoretically we show that the competition mechanism enjoys a better sample efficiency than the traditional softmax routing furthermore we develop competesmoe a simple yet effective algorithm to train large language models by deploying a router to learn the competition policy thus enjoying strong performances at a low training overhead our extensive empirical evaluations on both the visual instruction tuning and language pretraining tasks demonstrate the efficacy robustness and scalability of competesmoe compared to stateoftheart smoe strategies we have made the implementation available at httpsgithubcomfsoftaiccompetesmoe this work is an improved version of the previous study at arxiv240202526
http://arxiv.org/abs/2505.13379v1,2025-05-19T17:24:16Z,"Gongfan Fang, Xinyin Ma, Xinchao Wang",thinkless llm learns when to think,reasoning language models capable of extended chainofthought reasoning have demonstrated remarkable performance on tasks requiring complex logical inference however applying elaborate reasoning for all queries often results in substantial computational inefficiencies particularly when many problems admit straightforward solutions this motivates an open question can llms learn when to think to answer this we propose thinkless a learnable framework that empowers an llm to adaptively select between shortform and longform reasoning based on both task complexity and the models ability thinkless is trained under a reinforcement learning paradigm and employs two control tokens short for concise responses and think for detailed reasoning at the core of our method is a decoupled group relative policy optimization degrpo algorithm which decomposes the learning objective of hybrid reasoning into two components 1 a control token loss that governs the selection of the reasoning mode and 2 a response loss that improves the accuracy of the generated answers this decoupled formulation enables finegrained control over the contributions of each objective stabilizing training and effectively preventing collapse observed in vanilla grpo empirically on several benchmarks such as minerva algebra math500 and gsm8k thinkless is able to reduce the usage of longchain thinking by 50 90 significantly improving the efficiency of reasoning language models the code is available at httpsgithubcomvainfthinkless
http://arxiv.org/abs/2505.13360v1,2025-05-19T17:03:42Z,"Chenyang Yang, Yike Shi, Qianou Ma, Michael Xieyang Liu, Christian Kästner, Tongshuang Wu",what prompts dont say understanding and managing underspecification in llm prompts,building llmpowered software requires developers to communicate their requirements through natural language but developer prompts are frequently underspecified failing to fully capture many userimportant requirements in this paper we present an indepth analysis of prompt underspecification showing that while llms can often 411 guess unspecified requirements by default such behavior is less robust underspecified prompts are 2x more likely to regress over model or prompt changes sometimes with accuracy drops by more than 20 we then demonstrate that simply adding more requirements to a prompt does not reliably improve performance due to llms limited instructionfollowing capabilities and competing constraints and standard prompt optimizers do not offer much help to address this we introduce novel requirementsaware prompt optimization mechanisms that can improve performance by 48 on average over baselines that naively specify everything in the prompt beyond prompt optimization we envision that effectively managing prompt underspecification requires a broader process including proactive requirements discovery evaluation and monitoring
http://arxiv.org/abs/2505.13353v1,2025-05-19T16:56:31Z,"Adam Štorek, Mukur Gupta, Samira Hajizadeh, Prashast Srivastava, Suman Jana",sense and sensitivity examining the influence of semantic recall on long context code reasoning,although modern large language models llms support extremely large contexts their effectiveness in utilizing long context for code reasoning remains unclear this paper investigates llm reasoning ability over code snippets within large repositories and how it relates to their recall ability specifically we differentiate between lexical code recall verbatim retrieval and semantic code recall remembering what the code does to measure semantic recall we propose semtrace a code reasoning technique where the impact of specific statements on output is attributable and unpredictable we also present a method to quantify semantic recall sensitivity in existing benchmarks our evaluation of stateoftheart llms reveals a significant drop in code reasoning accuracy as a code snippet approaches the middle of the input context particularly with techniques requiring high semantic recall like semtrace moreover we find that lexical recall varies by granularity with models excelling at function retrieval but struggling with linebyline recall notably a disconnect exists between lexical and semantic recall suggesting different underlying mechanisms finally our findings indicate that current code reasoning benchmarks may exhibit low semantic recall sensitivity potentially underestimating llm challenges in leveraging incontext information
http://arxiv.org/abs/2505.13348v1,2025-05-19T16:51:12Z,"Narek Maloyan, Bislan Ashinov, Dmitry Namiot",investigating the vulnerability of llmasajudge architectures to promptinjection attacks,large language models llms are increasingly employed as evaluators llmasajudge for assessing the quality of machinegenerated text this paradigm offers scalability and costeffectiveness compared to human annotation however the reliability and security of such systems particularly their robustness against adversarial manipulations remain critical concerns this paper investigates the vulnerability of llmasajudge architectures to promptinjection attacks where malicious inputs are designed to compromise the judges decisionmaking process we formalize two primary attack strategies comparative undermining attack cua which directly targets the final decision output and justification manipulation attack jma which aims to alter the models generated reasoning using the greedy coordinate gradient gcg optimization method we craft adversarial suffixes appended to one of the responses being compared experiments conducted on the mtbench human judgments dataset with opensource instructiontuned llms qwen253binstruct and falcon33binstruct demonstrate significant susceptibility the cua achieves an attack success rate asr exceeding 30 while jma also shows notable effectiveness these findings highlight substantial vulnerabilities in current llmasajudge systems underscoring the need for robust defense mechanisms and further research into adversarial evaluation and trustworthiness in llmbased assessment frameworks
http://arxiv.org/abs/2505.13346v1,2025-05-19T16:50:35Z,"Austin Xu, Yilun Zhou, Xuan-Phi Nguyen, Caiming Xiong, Shafiq Joty",j4r learning to judge with equivalent initial state group relative preference optimization,to keep pace with the increasing pace of large language models llm development model output evaluation has transitioned away from timeconsuming human evaluation to automatic evaluation where llms themselves are tasked with assessing and critiquing other model outputs llmasjudge models are a class of generative evaluators that excel in evaluating relatively simple domains like chat quality but struggle in reasoning intensive domains where model responses contain more substantive and challenging content to remedy existing judge shortcomings we explore training judges with reinforcement learning rl we make three key contributions 1 we propose the equivalent initial state group relative policy optimization eisgrpo algorithm which allows us to train our judge to be robust to positional biases that arise in more complex evaluation settings 2 we introduce reasoningjudgebench a benchmark that evaluates judges in diverse reasoning settings not covered by prior work 3 we train judge for reasoning j4r a 7b judge trained with eisgrpo that outperforms gpt4o and the next best small judge by 67 and 9 matching or exceeding the performance of larger grpotrained judges on both judgebench and reasoningjudgebench
http://arxiv.org/abs/2505.13338v1,2025-05-19T16:47:46Z,"Qiongqiong Wang, Hardik B. Sailor, Tianchi Liu, Ai Ti Aw",contextual paralinguistic data creation for multimodal speechllm data condensation and spoken qa generation,current speechllms exhibit limited capability in contextual reasoning alongside paralinguistic understanding primarily due to the lack of questionanswer qa datasets that cover both aspects we propose a novel framework for dataset generation from inthewild speech data that integrates contextual reasoning with paralinguistic information it consists of a pseudo paralinguistic labelbased data condensation of inthewild speech and llmbased contextual paralinguistic qa cpqa generation the effectiveness is validated by a strong correlation in evaluations of the qwen2audio7binstruct model on a dataset created by our framework and humangenerated cpqa dataset the results also reveal the speechllms limitations in handling empathetic reasoning tasks highlighting the need for such datasets and more robust models the proposed framework is first of its kind and has potential in training more robust speechllms with paralinguistic reasoning capabilities
http://arxiv.org/abs/2505.13328v1,2025-05-19T16:36:13Z,"Hongru Wang, Wenyu Huang, Yufei Wang, Yuanhao Xi, Jianqiao Lu, Huan Zhang, Nan Hu, Zeming Liu, Jeff Z. Pan, Kam-Fai Wong",rethinking stateful tool use in multiturn dialogues benchmarks and challenges,existing benchmarks that assess language models lms as language agents las for tool use primarily focus on stateless singleturn interactions or partial evaluations such as tool selection in a single turn overlooking the inherent stateful nature of interactions in multiturn applications to fulfill this gap we propose textttdialogtool a multiturn dialogue dataset with stateful tool interactions considering the whole life cycle of tool use across six key tasks in three stages 1 textittool creation 2 textittool utilization tool awareness tool selection tool execution and 3 textitroleconsistent response response generation and role play furthermore we build textttvirtualmobile an embodied virtual mobile evaluation environment to simulate api calls and assess the robustness of the created apisfootnotewe will use tools and apis alternatively there are no significant differences between them in this paper taking advantage of these artifacts we conduct comprehensive evaluation on 13 distinct open and closedsource llms and provide detailed analysis at each stage revealing that the existing stateoftheart llms still cannot perform well to use tools over long horizons
http://arxiv.org/abs/2505.13312v1,2025-05-19T16:26:58Z,"Zhijie Deng, Chris Yuhao Liu, Zirui Pang, Xinlei He, Lei Feng, Qi Xuan, Zhaowei Zhu, Jiaheng Wei",guard generationtime llm unlearning via adaptive restriction and detection,large language models llms have demonstrated strong capabilities in memorizing vast amounts of knowledge across diverse domains however the ability to selectively forget specific knowledge is critical for ensuring the safety and compliance of deployed models existing unlearning efforts typically finetune the model with resources such as forget data retain data and a calibration model these additional gradient steps blur the decision boundary between forget and retain knowledge making unlearning often at the expense of overall performance to avoid the negative impact of finetuning it would be better to unlearn solely at inference time by safely guarding the model against generating responses related to the forget target without destroying the fluency of text generation in this work we propose generationtime unlearning via adaptive restriction and detection guard a framework that enables dynamic unlearning during llm generation specifically we first employ a prompt classifier to detect unlearning targets and extract the corresponding forbidden token we then dynamically penalize and filter candidate tokens during generation using a combination of token matching and semantic matching effectively preventing the model from leaking the forgotten content experimental results on copyright content unlearning tasks over the harry potter dataset and the muse benchmark as well as entity unlearning tasks on the tofu dataset demonstrate that guard achieves strong forget quality across various tasks while causing almost no degradation to the llms general capabilities striking an excellent tradeoff between forgetting and utility
http://arxiv.org/abs/2505.13308v1,2025-05-19T16:26:02Z,"Hengli Li, Chenxi Li, Tong Wu, Xuekai Zhu, Yuxuan Wang, Zhaoxin Yu, Eric Hanchen Jiang, Song-Chun Zhu, Zixia Jia, Ying Nian Wu, Zilong Zheng",seek in the dark reasoning via testtime instancelevel policy gradient in latent space,reasoning ability a core component of human intelligence continues to pose a significant challenge for large language models llms in the pursuit of agi although model performance has improved under the training scaling law significant challenges remain particularly with respect to training algorithms such as catastrophic forgetting and the limited availability of novel training data as an alternative testtime scaling enhances reasoning performance by increasing testtime computation without parameter updating unlike prior methods in this paradigm focused on token space we propose leveraging latent space for more effective reasoning and better adherence to the testtime scaling law we introduce latentseek a novel framework that enhances llm reasoning through testtime instancelevel adaptation ttia within the models latent space specifically latentseek leverages policy gradient to iteratively update latent representations guided by selfgenerated reward signals latentseek is evaluated on a range of reasoning benchmarks including gsm8k math500 and aime2024 across multiple llm architectures results show that latentseek consistently outperforms strong baselines such as chainofthought prompting and finetuningbased methods furthermore our analysis demonstrates that latentseek is highly efficient typically converging within a few iterations for problems of average complexity while also benefiting from additional iterations thereby highlighting the potential of testtime scaling in the latent space these findings position latentseek as a lightweight scalable and effective solution for enhancing the reasoning capabilities of llms
http://arxiv.org/abs/2505.13307v1,2025-05-19T16:25:55Z,"Qiguang Chen, Libo Qin, Jinhao Liu, Yue Liao, Jiaqi Wang, Jingxuan Zhou, Wanxiang Che",rbf quantifying and optimizing reasoning boundaries across measurable and unmeasurable capabilities for chainofthought reasoning,chainofthought cot reasoning has proven effective in enhancing large language models llms on complex tasks spurring research into its underlying mechanisms however two primary challenges remain for realworld applications 1 the lack of quantitative metrics and actionable guidelines for evaluating and optimizing measurable boundaries of cot capability and 2 the absence of methods to assess boundaries of unmeasurable cot capability such as multimodal perception to address these gaps we introduce the reasoning boundary framework rbf to tackle the first challenge we define the reasoning boundary rb as the maximum limit of cot performance we also propose a combination law for rbs enabling quantitative analysis and offering actionable guidance across various cot tasks for the second challenge particularly in multimodal scenarios we introduce a constant assumption which replaces unmeasurable rbs with scenariospecific constants additionally we propose the reasoning boundary division mechanism which divides unmeasurable rbs into two subboundaries facilitating the quantification and optimization of both unmeasurable domain knowledge and multimodal perception capabilities extensive experiments involving 38 models across 13 tasks validate the feasibility of our framework in crossmodal settings additionally we evaluate 10 cot strategies offer insights into optimization and decay from two complementary perspectives and expand evaluation benchmarks for measuring rbs in llm reasoning we hope this work advances the understanding of rbs and optimization strategies in llms code and data are available at httpsgithubcomlightchen233reasoningboundary
http://arxiv.org/abs/2505.13302v1,2025-05-19T16:20:54Z,"Alice Plebe, Timothy Douglas, Diana Riazi, R. Maria del Rio-Chanona",ill believe it when i see it images increase misinformation sharing in visionlanguage models,large language models are increasingly integrated into news recommendation systems raising concerns about their role in spreading misinformation in humans visual content is known to boost credibility and shareability of information yet its effect on visionlanguage models vlms remains unclear we present the first study examining how images influence vlms propensity to reshare news content whether this effect varies across model families and how persona conditioning and content attributes modulate this behavior to support this analysis we introduce two methodological contributions a jailbreakinginspired prompting strategy that elicits resharing decisions from vlms while simulating users with antisocial traits and political alignments and a multimodal dataset of factchecked political news from politifact paired with corresponding images and groundtruth veracity labels experiments across model families reveal that image presence increases resharing rates by 48 for true news and 150 for false news persona conditioning further modulates this effect dark triad traits amplify resharing of false news whereas republicanaligned profiles exhibit reduced veracity sensitivity of all the tested models only claude3haiku demonstrates robustness to visual misinformation these findings highlight emerging risks in multimodal model behavior and motivate the development of tailored evaluation frameworks and mitigation strategies for personalized ai systems code and dataset are available at httpsgithubcom3lismisinfovlm
http://arxiv.org/abs/2505.13282v1,2025-05-19T16:06:13Z,"Sahil Mishra, Kumar Arjun, Tanmoy Chakraborty",lineageoriented reasoning for taxonomy expansion,taxonomies are hierarchical knowledge graphs crucial for recommendation systems and web applications as data grows expanding taxonomies is essential but existing methods face key challenges 1 discriminative models struggle with representation limits and generalization while 2 generative methods either process all candidates at once introducing noise and exceeding context limits or discard relevant entities by selecting noisy candidates we propose lorex ineageriented asoning for taxonomy epansion a plugandplay framework that combines discriminative ranking and generative reasoning for efficient taxonomy expansion unlike prior methods lorex ranks and chunks candidate terms into batches filtering noise and iteratively refining selections by reasoning candidates hierarchy to ensure contextual efficiency extensive experiments across four benchmarks and twelve baselines show that lorex improves accuracy by 12 and wu palmer similarity by 5 over stateoftheart methods
http://arxiv.org/abs/2505.13271v1,2025-05-19T15:52:19Z,"Lei Sheng, Shuai-Shuai Xu",cscsql corrective selfconsistency in texttosql via reinforcement learning,large language models llms have demonstrated strong capabilities in translating natural language questions about relational databases into sql queries in particular testtime scaling techniques such as selfconsistency and selfcorrection can enhance sql generation accuracy by increasing computational effort during inference however these methods have notable limitations selfconsistency may select suboptimal outputs despite majority votes while selfcorrection typically addresses only syntactic errors to leverage the strengths of both approaches we propose cscsql a novel method that integrates selfconsistency and selfcorrection cscsql selects the two most frequently occurring outputs from parallel sampling and feeds them into a merge revision model for correction additionally we employ the group relative policy optimization grpo algorithm to finetune both the sql generation and revision models via reinforcement learning significantly enhancing output quality experimental results confirm the effectiveness and generalizability of cscsql on the bird development set our 3b model achieves 6528 execution accuracy while the 7b model achieves 6919 the code will be open sourced at httpsgithubcomcycloneboycscsql
http://arxiv.org/abs/2505.13268v1,2025-05-19T15:47:51Z,"Livia Qian, Carol Figueroa, Gabriel Skantze",representation of perceived prosodic similarity of conversational feedback,vocal feedback eg mhm yeah okay is an important component of spoken dialogue and is crucial to ensuring common ground in conversational systems the exact meaning of such feedback is conveyed through both lexical and prosodic form in this work we investigate the perceived prosodic similarity of vocal feedback with the same lexical form and to what extent existing speech representations reflect such similarities a triadic comparison task with recruited participants is used to measure perceived similarity of feedback responses taken from two different datasets we find that spectral and selfsupervised speech representations encode prosody better than extracted pitch features especially in the case of feedback from the same speaker we also find that it is possible to further condense and align the representations to human perception through contrastive learning
http://arxiv.org/abs/2505.13259v1,2025-05-19T15:41:32Z,"Tianshi Zheng, Zheye Deng, Hong Ting Tsang, Weiqi Wang, Jiaxin Bai, Zihao Wang, Yangqiu Song",from automation to autonomy a survey on large language models in scientific discovery,large language models llms are catalyzing a paradigm shift in scientific discovery evolving from taskspecific automation tools into increasingly autonomous agents and fundamentally redefining research processes and humanai collaboration this survey systematically charts this burgeoning field placing a central focus on the changing roles and escalating capabilities of llms in science through the lens of the scientific method we introduce a foundational threelevel taxonomytool analyst and scientistto delineate their escalating autonomy and evolving responsibilities within the research lifecycle we further identify pivotal challenges and future research trajectories such as robotic automation selfimprovement and ethical governance overall this survey provides a conceptual architecture and strategic foresight to navigate and shape the future of aidriven scientific discovery fostering both rapid innovation and responsible advancement github repository httpsgithubcomhkustknowcompawesomellmscientificdiscovery
http://arxiv.org/abs/2505.13258v1,2025-05-19T15:40:29Z,"Jingyi Ren, Yekun Xu, Xiaolong Wang, Weitao Li, Weizhi Ma, Yang Liu",effective and transparent rag adaptivereward reinforcement learning for decision traceability,retrievalaugmented generation rag has significantly improved the performance of large language models llms on knowledgeintensive domains however although rag achieved successes across distinct domains there are still some unsolved challenges 1 effectiveness existing research mainly focuses on developing more powerful rag retrievers but how to enhance the generators llms ability to utilize the retrieved information for reasoning and generation 2 transparency most rag methods ignore which retrieved content actually contributes to the reasoning process resulting in a lack of interpretability and visibility to address this we propose arena adaptiverewarded evidence navigation agent a transparent rag generator framework trained via reinforcement learning rl with our proposed rewards based on the structured generation and adaptive reward calculation our rlbased training enables the model to identify key evidence perform structured reasoning and generate answers with interpretable decision traces applied to qwen257binstruct and llama318binstruct abundant experiments with various rag baselines demonstrate that our model achieves 1030 improvements on all multihop qa datasets which is comparable with the sota commerciallydeveloped llms eg openaio1 deepseekr1 further analyses show that arena has strong flexibility to be adopted on new datasets without extra training our models and codes are publicly released
http://arxiv.org/abs/2505.13257v1,2025-05-19T15:39:48Z,"Zilu Tang, Afra Feyza Akyürek, Ekin Akyürek, Derry Wijaya",wikipersonas what can we learn from personalized alignment to famous people,preference alignment has become a standard pipeline in finetuning models to follow emphgeneric human preferences majority of work seeks to optimize model to produce responses that would be preferable emphon average simplifying the diverse and often emphcontradicting space of human preferences while research has increasingly focused on personalized alignment adapting models to individual user preferences there is a lack of personalized preference dataset which focus on nuanced individuallevel preferences to address this we introduce wikipersona the first finegrained personalization using welldocumented famous individuals our dataset challenges models to align with these personas through an interpretable process generating verifiable textual descriptions of a personas background and preferences in addition to alignment we systematically evaluate different personalization approaches and find that as fewshot prompting with preferences and finetuning fail to simultaneously ensure effectiveness and efficiency using textitinferred personal preferences as prefixes enables effective personalization especially in topics where preferences clash while leading to more equitable generalization across unseen personas
http://arxiv.org/abs/2505.13254v1,2025-05-19T15:38:40Z,"Siran Liu, Yang Ye, Qianchao Zhu, Zheng Cao, Yongchao He",heterospec leveraging contextual heterogeneity for efficient speculative decoding,autoregressive decoding the standard approach for large language model llm inference remains a significant bottleneck due to its sequential nature while speculative decoding algorithms mitigate this inefficiency through parallel verification they fail to exploit the inherent heterogeneity in linguistic complexity a key factor leading to suboptimal resource allocation we address this by proposing heterospec a heterogeneityadaptive speculative decoding framework that dynamically optimizes computational resource allocation based on linguistic context complexity heterospec introduces two key mechanisms 1 a novel cumulative metapath top entropy metric for efficiently identifying predictable contexts 2 a dynamic resource allocation strategy based on datadriven entropy partitioning enabling adaptive speculative expansion and pruning tailored to local context difficulty evaluated on five public benchmarks and four models heterospec achieves an average speedup of 426 it consistently outperforms stateoftheart eagle3 across speedup rates average acceptance length and verification cost notably heterospec requires no draft model retraining incurs minimal overhead and is orthogonal to other acceleration techniques it demonstrates enhanced acceleration with stronger draft models establishing a new paradigm for contextaware llm inference acceleration
http://arxiv.org/abs/2505.13252v1,2025-05-19T15:35:17Z,"Rikhil Amonkar, Ronan Le Bras, Li Zhang",natural language planning via coding and inference scaling,reallife textual planning tasks such as meeting scheduling have posed much challenge to llms especially when the complexity is high while previous work primarily studied autoregressive generation of plans with closedsource models we systematically evaluate both closed and opensource models including those that scales output length with complexity during inference in generating programs which are executed to output the plan we consider not only standard python code but also the code to a constraint satisfaction problem solver despite the algorithmic nature of the task we show that programming often but not always outperforms planning our detailed error analysis also indicates a lack of robustness and efficiency in the generated code that hinders generalization
http://arxiv.org/abs/2505.13251v1,2025-05-19T15:34:07Z,Sidney Wong,stronger together unleashing the social impact of hate speech research,the advent of the internet has been both a blessing and a curse for once marginalised communities when used well the internet can be used to connect and establish communities crossing different intersections however it can also be used as a tool to alienate people and communities as well as perpetuate hate misinformation and disinformation especially on social media platforms we propose steering hate speech research and researchers away from preexisting computational solutions and consider social methods to inform social solutions to address this social problem in a similar way linguistics research can inform language planning policy linguists should apply what we know about language and society to mitigate some of the emergent risks and dangers of antisocial behaviour in digital spaces we argue linguists and nlp researchers can play a principle role in unleashing the social impact potential of linguistics research working alongside communities advocates activists and policymakers to enable equitable digital inclusion and to close the digital divide
http://arxiv.org/abs/2505.13244v1,2025-05-19T15:24:53Z,"Jieying Xue, Phuong Minh Nguyen, Minh Le Nguyen, Xin Liu",jnlp at semeval2025 task 11 crosslingual multilabel emotion detection using generative models,with the rapid advancement of global digitalization users from different countries increasingly rely on social media for information exchange in this context multilingual multilabel emotion detection has emerged as a critical research area this study addresses semeval2025 task 11 bridging the gap in textbased emotion detection our paper focuses on two subtracks of this task 1 track a multilabel emotion detection and 2 track b emotion intensity to tackle multilingual challenges we leverage pretrained multilingual models and focus on two architectures 1 a finetuned bertbased classification model and 2 an instructiontuned generative llm additionally we propose two methods for handling multilabel classification the base method which maps an input directly to all its corresponding emotion labels and the pairwise method which models the relationship between the input text and each emotion category individually experimental results demonstrate the strong generalization ability of our approach in multilingual emotion recognition in track a our method achieved top 4 performance across 10 languages ranking 1st in hindi in track b our approach also secured top 5 performance in 7 languages highlighting its simplicity and effectivenessfootnoteour code is available at httpsgithubcomyingjie7mlingualmultilabelemodetection
http://arxiv.org/abs/2505.13237v1,2025-05-19T15:20:32Z,"Chih-Kai Yang, Neo Ho, Yen-Ting Piao, Hung-yi Lee",sakura on the multihop reasoning of large audiolanguage models based on speech and audio information,large audiolanguage models lalms extend the large language models with multimodal understanding in speech audio etc while their performances on speech and audioprocessing tasks are extensively studied their reasoning abilities remain underexplored particularly their multihop reasoning the ability to recall and integrate multiple facts lacks systematic evaluation existing benchmarks focus on general speech and audioprocessing tasks conversational abilities and fairness but overlook this aspect to bridge this gap we introduce sakura a benchmark assessing lalms multihop reasoning based on speech and audio information results show that lalms struggle to integrate speechaudio representations for multihop reasoning even when they extract the relevant information correctly highlighting a fundamental challenge in multimodal reasoning our findings expose a critical limitation in lalms offering insights and resources for future research
http://arxiv.org/abs/2505.13227v1,2025-05-19T15:09:23Z,"Tianbao Xie, Jiaqi Deng, Xiaochuan Li, Junlin Yang, Haoyuan Wu, Jixuan Chen, Wenjing Hu, Xinyuan Wang, Yuhui Xu, Zekun Wang, Yiheng Xu, Junli Wang, Doyen Sahoo, Tao Yu, Caiming Xiong",scaling computeruse grounding via user interface decomposition and synthesis,graphical user interface gui grounding the ability to map natural language instructions to specific actions on graphical user interfaces remains a critical bottleneck in computer use agent development current benchmarks oversimplify grounding tasks as short referring expressions failing to capture the complexity of realworld interactions that require software commonsense layout understanding and finegrained manipulation capabilities to address these limitations we introduce osworldg a comprehensive benchmark comprising 564 finely annotated samples across diverse task types including text matching element recognition layout understanding and precise manipulation additionally we synthesize and release the largest computer use grounding dataset jedi which contains 4 million examples through multiperspective decoupling of tasks our multiscale models trained on jedi demonstrate its effectiveness by outperforming existing approaches on screenspotv2 screenspotpro and our osworldg furthermore we demonstrate that improved grounding with jedi directly enhances agentic capabilities of general foundation models on complex computer tasks improving from 5 to 27 on osworld through detailed ablation studies we identify key factors contributing to grounding performance and verify that combining specialized data for different interface elements enables compositional generalization to novel interfaces all benchmark data checkpoints and code are opensourced and available at httpsosworldgroundinggithubio
http://arxiv.org/abs/2505.13220v1,2025-05-19T15:02:59Z,"Jie Ying, Zihong Chen, Zhefan Wang, Wanli Jiang, Chenyang Wang, Zhonghang Yuan, Haoyang Su, Huanjun Kong, Fan Yang, Nanqing Dong",seedbench a multitask benchmark for evaluating large language models in seed science,seed science is essential for modern agriculture directly influencing crop yields and global food security however challenges such as interdisciplinary complexity and high costs with limited returns hinder progress leading to a shortage of experts and insufficient technological support while large language models llms have shown promise across various fields their application in seed science remains limited due to the scarcity of digital resources complex genetrait relationships and the lack of standardized benchmarks to address this gap we introduce seedbench the first multitask benchmark specifically designed for seed science developed in collaboration with domain experts seedbench focuses on seed breeding and simulates key aspects of modern breeding processes we conduct a comprehensive evaluation of 26 leading llms encompassing proprietary opensource and domainspecific finetuned models our findings not only highlight the substantial gaps between the power of llms and the realworld seed science problems but also make a foundational step for research on llms for seed design
http://arxiv.org/abs/2505.13210v1,2025-05-19T14:58:44Z,"Xiaocong Du, Haoyu Pei, Haipeng Zhang",picturized and recited with dialects a multimodal chinese representation framework for sentiment analysis of classical chinese poetry,classical chinese poetry is a vital and enduring part of chinese literature conveying profound emotional resonance existing studies analyze sentiment based on textual meanings overlooking the unique rhythmic and visual features inherent in poetryespecially since it is often recited and accompanied by chinese paintings in this work we propose a dialectenhanced multimodal framework for classical chinese poetry sentiment analysis we extract sentencelevel audio features from the poetry and incorporate audio from multiple dialectswhich may retain regional ancient chinese phonetic features enriching the phonetic representation additionally we generate sentencelevel visual features and the multimodal features are fused with textual features enhanced by llm translation through multimodal contrastive representation learning our framework outperforms stateoftheart methods on two public datasets achieving at least 251 improvement in accuracy and 163 in macro f1 we opensource the code to facilitate research in this area and provide insights for general multimodal chinese representation
http://arxiv.org/abs/2505.13208v1,2025-05-19T14:57:53Z,"Colin Krawchuk, Nikhil Khatri, Neil John Ortega, Dimitri Kartsaklis",efficient generation of parameterised quantum circuits from large texts,quantum approaches to natural language processing nlp are redefining how linguistic information is represented and processed while traditional hybrid quantumclassical models rely heavily on classical neural networks recent advancements propose a novel framework discocirc capable of directly encoding entire documents as parameterised quantum circuits pqcs besides enjoying some additional interpretability and compositionality benefits following these ideas this paper introduces an efficient methodology for converting largescale texts into quantum circuits using treelike representations of pregroup diagrams exploiting the compositional parallels between language and quantum mechanics grounded in symmetric monoidal categories our approach enables faithful and efficient encoding of syntactic and discourse relationships in long and complex texts up to 6410 words in our experiments to quantum circuits the developed system is provided to the community as part of the augmented opensource quantum nlp package lambeq gen ii
http://arxiv.org/abs/2505.13204v1,2025-05-19T14:55:41Z,"Jikai Wang, Zhenxu Tian, Juntao Li, Qingrong Xia, Xinyu Duan, Zhefeng Wang, Baoxing Huai, Min Zhang",alignmentaugmented speculative decoding with alignment sampling and conditional verification,recent works have revealed the great potential of speculative decoding in accelerating the autoregressive generation process of large language models the success of these methods relies on the alignment between draft candidates and the sampled outputs of the target model existing methods mainly achieve drafttarget alignment with trainingbased methods eg eagle medusa involving considerable training costs in this paper we present a trainingfree alignmentaugmented speculative decoding algorithm we propose alignment sampling which leverages output distribution obtained in the prefilling phase to provide more aligned draft candidates to further benefit from highquality but nonaligned draft candidates we also introduce a simple yet effective flexible verification strategy through an adaptive probability threshold our approach can improve generation accuracy while further improving inference efficiency experiments on 8 datasets including question answering summarization and code completion tasks show that our approach increases the average generation score by 33 points for the llama3 model our method achieves a mean acceptance length up to 239 and speed up generation by 223
http://arxiv.org/abs/2505.13181v1,2025-05-19T14:38:59Z,"Zhengrui Ma, Yang Feng, Chenze Shao, Fandong Meng, Jie Zhou, Min Zhang",efficient speech language modeling via energy distance in continuous latent space,we introduce sled an alternative approach to speech language modeling by encoding speech waveforms into sequences of continuous latent representations and modeling them autoregressively using an energy distance objective the energy distance offers an analytical measure of the distributional gap by contrasting simulated and target samples enabling efficient training to capture the underlying continuous autoregressive distribution by bypassing reliance on residual vector quantization sled avoids discretization errors and eliminates the need for the complicated hierarchical architectures common in existing speech language models it simplifies the overall modeling pipeline while preserving the richness of speech information and maintaining inference efficiency empirical results demonstrate that sled achieves strong performance in both zeroshot and streaming speech synthesis showing its potential for broader applications in generalpurpose speech language models
http://arxiv.org/abs/2505.13176v1,2025-05-19T14:30:46Z,"Zihao Cheng, Hongru Wang, Zeming Liu, Yuhang Guo, Yuanfang Guo, Yunhong Wang, Haifeng Wang",toolspectrum towards personalized tool utilization for large language models,while integrating external tools into large language models llms enhances their ability to access realtime information and domainspecific services existing approaches focus narrowly on functional tool selection following user instructions overlooking the contextaware personalization in tool selection this oversight leads to suboptimal user satisfaction and inefficient tool utilization particularly when overlapping toolsets require nuanced selection based on contextual factors to bridge this gap we introduce toolspectrum a benchmark designed to evaluate llms capabilities in personalized tool utilization specifically we formalize two key dimensions of personalization user profile and environmental factors and analyze their individual and synergistic impacts on tool utilization through extensive experiments on toolspectrum we demonstrate that personalized tool utilization significantly improves user experience across diverse scenarios however even stateoftheart llms exhibit the limited ability to reason jointly about user profiles and environmental factors often prioritizing one dimension at the expense of the other our findings underscore the necessity of contextaware personalization in toolaugmented llms and reveal critical limitations for current models our data and code are available at httpsgithubcomchengziha0toolspectrum
http://arxiv.org/abs/2505.13173v1,2025-05-19T14:30:10Z,"V. S. D. S. Mahesh Akavarapu, Hrishikesh Terdalkar, Pramit Bhattacharyya, Shubhangi Agarwal, Vishakha Deulgaonkar, Pralay Manna, Chaitali Dangarikar, Arnab Bhattacharya",a case study of crosslingual zeroshot generalization for classical languages in llms,large language models llms have demonstrated remarkable generalization capabilities across diverse tasks and languages in this study we focus on natural language understanding in three classical languages sanskrit ancient greek and latin to investigate the factors affecting crosslingual zeroshot generalization first we explore named entity recognition and machine translation into english while llms perform equal to or better than finetuned baselines on outofdomain data smaller models often struggle especially with niche or abstract entity types in addition we concentrate on sanskrit by presenting a factoid questionanswering qa dataset and show that incorporating context via retrievalaugmented generation approach significantly boosts performance in contrast we observe pronounced performance drops for smaller llms across these qa tasks these results suggest model scale as an important factor influencing crosslingual generalization assuming that models used such as gpt4o and llama31 are not instruction finetuned on classical languages our findings provide insights into how llms may generalize on these languages and their consequent utility in classical studies
http://arxiv.org/abs/2505.13171v1,2025-05-19T14:28:35Z,"Yixuan Xu, Antoine Bosselut, Imanol Schlag",positional fragility in llms how offset effects reshape our understanding of memorization risks,large language models are known to memorize parts of their training data posing risk of copyright violations to systematically examine this risk we pretrain language models 1b3b8b from scratch on 83b tokens mixing webscale data with public domain books used to simulate copyrighted content at controlled frequencies at lengths at least ten times longer than prior work we thereby identified the offset effect a phenomenon characterized by two key findings 1 verbatim memorization is most strongly triggered by short prefixes drawn from the beginning of the context window with memorization decreasing counterintuitively as prefix length increases and 2 a sharp decline in verbatim recall when prefix begins offset from the initial tokens of the context window we attribute this to positional fragility models rely disproportionately on the earliest tokens in their context window as retrieval anchors making them sensitive to even slight shifts we further observe that when the model fails to retrieve memorized content it often produces degenerated text leveraging these findings we show that shifting sensitive data deeper into the context window suppresses both extractable memorization and degeneration our results suggest that positional offset is a critical and previously overlooked axis for evaluating memorization risks since prior work implicitly assumed uniformity by probing only from the beginning of training sequences
http://arxiv.org/abs/2505.13157v1,2025-05-19T14:18:16Z,"Yassine El Boudouri, Walter Nuninger, Julian Alvarez, Yvan Peter",roleplaying evaluation for large language models,large language models llms demonstrate a notable capacity for adopting personas and engaging in roleplaying however evaluating this ability presents significant challenges as human assessments are resourceintensive and automated evaluations can be biased to address this we introduce roleplaying eval rpeval a novel benchmark designed to assess llm roleplaying capabilities across four key dimensions emotional understanding decisionmaking moral alignment and incharacter consistency this article details the construction of rpeval and presents baseline evaluations our code and dataset are available at httpsgithubcomyelboudourirpeval
http://arxiv.org/abs/2505.13156v1,2025-05-19T14:17:37Z,"Zhi Liu, Tao Yang, Jing Wang, Yexin Chen, Zhan Gao, Jiaxi Yang, Kui Chen, Bingji Lu, Xiaochen Li, Changyong Luo, Yan Li, Xiaohong Gu, Peng Cao",tianyi a traditional chinese medicine allrounder language model and its realworld clinical practice,natural medicines particularly traditional chinese medicine tcm are gaining global recognition for their therapeutic potential in addressing human symptoms and diseases tcm with its systematic theories and extensive practical experience provides abundant resources for healthcare however the effective application of tcm requires precise syndrome diagnosis determination of treatment principles and prescription formulation which demand decades of clinical expertise despite advancements in tcmbased decision systems machine learning and deep learning research limitations in data and singleobjective constraints hinder their practical application in recent years large language models llms have demonstrated potential in complex tasks but lack specialization in tcm and face significant challenges such as too big model scale to deploy and issues with hallucination to address these challenges we introduce tianyi with 76billionparameter llm a model scale proper and specifically designed for tcm pretrained and finetuned on diverse tcm corpora including classical texts expert treatises clinical records and knowledge graphs tianyi is designed to assimilate interconnected and systematic tcm knowledge through a progressive learning manner additionally we establish tcmeval a comprehensive evaluation benchmark to assess llms in tcm examinations clinical tasks domainspecific questionanswering and realworld trials the extensive evaluations demonstrate the significant potential of tianyi as an ai assistant in tcm clinical practice and research bridging the gap between tcm knowledge and practical application
http://arxiv.org/abs/2505.13147v1,2025-05-19T14:12:05Z,"Aswathy Velutharambath, Roman Klinger, Kai Sassenberg",what if deception cannot be detected a crosslinguistic study on the limits of deception detection from text,can deception be detected solely from written text cues of deceptive communication are inherently subtle even more so in textonly communication yet prior studies have reported considerable success in automatic deception detection we hypothesize that such findings are largely driven by artifacts introduced during data collection and do not generalize beyond specific datasets we revisit this assumption by introducing a beliefbased deception framework which defines deception as a misalignment between an authors claims and true beliefs irrespective of factual accuracy allowing deception cues to be studied in isolation based on this framework we construct three corpora collectively referred to as defabel including a germanlanguage corpus of deceptive and nondeceptive arguments and a multilingual version in german and english each collected under varying conditions to account for belief change and enable crosslinguistic analysis using these corpora we evaluate commonly reported linguistic cues of deception across all three defabel variants these cues show negligible statistically insignificant correlations with deception labels contrary to prior work that treats such cues as reliable indicators we further benchmark against other english deception datasets following similar data collection protocols while some show statistically significant correlations effect sizes remain low and critically the set of predictive cues is inconsistent across datasets we also evaluate deception detection using featurebased models pretrained language models and instructiontuned large language models while some models perform well on established deception datasets they consistently perform near chance on defabel our findings challenge the assumption that deception can be reliably inferred from linguistic cues and call for rethinking how deception is studied and modeled in nlp
http://arxiv.org/abs/2505.13141v1,2025-05-19T14:10:15Z,"Zheng Wei Lim, Alham Fikri Aji, Trevor Cohn",understanding crosslingual inconsistency in large language models,large language models llms are demonstrably capable of crosslingual transfer but can produce inconsistent output when prompted with the same queries written in different languages to understand how language models are able to generalize knowledge from one language to the others we apply the logit lens to interpret the implicit steps taken by llms to solve multilingual multichoice reasoning questions we find llms predict inconsistently and are less accurate because they rely on subspaces of individual languages rather than working in a shared semantic space while larger models are more multilingual we show their hidden states are more likely to dissociate from the shared representation compared to smaller models but are nevertheless more capable of retrieving knowledge embedded across different languages finally we demonstrate that knowledge sharing can be modulated by steering the models latent processing towards the shared semantic space we find reinforcing utilization of the shared space improves the models multilingual reasoning performance as a result of more knowledge transfer from and better output consistency with english
http://arxiv.org/abs/2505.13136v1,2025-05-19T14:07:20Z,"Anton Ehrmanntraut, Julia Wunderle, Jan Pfister, Fotis Jannidis, Andreas Hotho",moderngbert germanonly 1b encoder model trained from scratch,despite the prominence of decoderonly language models encoders remain crucial for resourceconstrained applications we introduce moderngbert 134m 1b a fully transparent family of german encoder models trained from scratch incorporating architectural innovations from modernbert to evaluate the practical tradeoffs of training encoders from scratch we also present llammlein2vec 120m 1b 7b a family of encoders derived from german decoderonly models via llm2vec we benchmark all models on natural language understanding text embedding and longcontext reasoning tasks enabling a controlled comparison between dedicated encoders and converted decoders our results show that moderngbert 1b outperforms prior stateoftheart german encoders as well as encoders adapted via llm2vec with regard to performance and parameterefficiency all models training data checkpoints and code are publicly available advancing the german nlp ecosystem with transparent highperformance encoder models
http://arxiv.org/abs/2505.13126v1,2025-05-19T13:58:15Z,"Liancheng Gong, Wang Zhu, Jesse Thomason, Li Zhang",zeroshot iterative formalization and planning in partially observable environments,in planning using llms not to predict plans but to formalize an environment into the planning domain definition language pddl has been shown to greatly improve performance and control while most work focused on fully observable environments we tackle the more realistic and challenging partially observable environments where existing methods are incapacitated by the lack of complete information we propose pddlego a framework to iteratively formalize plan grow and refine pddl representations in a zeroshot manner without needing access to any existing trajectories on two textual simulated environments we show that pddlego not only achieves superior performance but also shows robustness against problem complexity we also show that the domain knowledge captured after a successful trial is interpretable and benefits future tasks
http://arxiv.org/abs/2505.13115v1,2025-05-19T13:46:35Z,"Debarpan Bhattacharya, Apoorva Kulkarni, Sriram Ganapathy",benchmarking and confidence evaluation of lalms for temporal reasoning,the popular success of textbased large language models llm has streamlined the attention of the multimodal community to combine other modalities like vision and audio along with text to achieve similar multimodal capabilities in this quest large audio language models lalms have to be evaluated on reasoning related tasks which are different from traditional classification or generation tasks towards this goal we propose a novel dataset called temporal reasoning evaluation of audio trea we benchmark opensource lalms and observe that they are consistently behind human capabilities on the tasks in the trea dataset while evaluating lalms we also propose an uncertainty metric which computes the invariance of the model to semantically identical perturbations of the input our analysis shows that the accuracy and uncertainty metrics are not necessarily correlated and thus points to a need for wholesome evaluation of lalms for highstakes applications
http://arxiv.org/abs/2505.13109v1,2025-05-19T13:36:45Z,"Guangda Liu, Chengwei Li, Zhenyu Ning, Jing Lin, Yiwu Yao, Danning Ke, Minyi Guo, Jieru Zhao",freekv boosting kv cache retrieval for efficient llm inference,large language models llms have been widely deployed with rapidly expanding context windows to support increasingly demanding applications however long contexts pose significant deployment challenges primarily due to the kv cache whose size grows proportionally with context length while kv cache compression methods are proposed to address this issue kv dropping methods incur considerable accuracy loss and kv retrieval methods suffer from significant efficiency bottlenecks we propose freekv an algorithmsystem cooptimization framework to enhance kv retrieval efficiency while preserving accuracy on the algorithm side freekv introduces speculative retrieval to shift the kv selection and recall processes out of the critical path combined with finegrained correction to ensure accuracy on the system side freekv employs hybrid kv layouts across cpu and gpu memory to eliminate fragmented data transfers and leverages doublebuffered streamed recall to further improve efficiency experiments demonstrate that freekv achieves nearlossless accuracy across various scenarios and models delivering up to 13 speedup compared to sota kv retrieval methods
http://arxiv.org/abs/2505.13098v1,2025-05-19T13:29:27Z,"Lars-Peter Meyer, Johannes Frey, Desiree Heim, Felix Brei, Claus Stadler, Kurt Junghanns, Michael Martin",llmkgbench 30 a compass for semantictechnology capabilities in the ocean of llms,current large language models llms can assist developing program code beside many other things but can they support working with knowledge graphs kgs as well which llm is offering the best capabilities in the field of semantic web and knowledge graph engineering kge is this possible to determine without checking many answers manually the llmkgbench framework in version 30 is designed to answer these questions it consists of an extensible set of tasks for automated evaluation of llm answers and covers different aspects of working with semantic technologies in this paper the llmkgbench framework is presented in version 3 along with a dataset of prompts answers and evaluations generated with it and several stateoftheart llms significant enhancements have been made to the framework since its initial release including an updated task api that offers greater flexibility in handling evaluation tasks revised tasks and extended support for various open models through the vllm library among other improvements a comprehensive dataset has been generated using more than 30 contemporary open and proprietary llms enabling the creation of exemplary model cards that demonstrate the models capabilities in working with rdf and sparql as well as comparing their performance on turtle and jsonld rdf serialization tasks
http://arxiv.org/abs/2505.13090v1,2025-05-19T13:24:01Z,"David Stap, Christof Monz",the effect of language diversity when finetuning large language models for translation,prior research diverges on language diversity in llm finetuning some studies report benefits while others find no advantages through controlled finetuning experiments across 132 translation directions we systematically resolve these disparities we find that expanding language diversity during finetuning improves translation quality for both unsupervised and surprisingly supervised pairs despite less diverse models being finetuned exclusively on these supervised pairs however benefits plateau or decrease beyond a certain diversity threshold we show that increased language diversity creates more languageagnostic representations these representational adaptations help explain the improved performance in models finetuned with greater diversity
http://arxiv.org/abs/2505.13089v1,2025-05-19T13:23:44Z,"Sondre Wold, Lucas Georges Gabriel Charpentier, Étienne Simon",systematic generalization in language models scales with information entropy,systematic generalization remains challenging for current language models which are known to be both sensitive to semantically similar permutations of the input and to struggle with known concepts presented in novel contexts although benchmarks exist for assessing compositional behavior it is unclear how to measure the difficulty of a systematic generalization problem in this work we show how one aspect of systematic generalization can be described by the entropy of the distribution of component parts in the training data we formalize a framework for measuring entropy in a sequencetosequence task and find that the performance of popular model architectures scales with the entropy our work connects systematic generalization to information efficiency and our results indicate that success at high entropy can be achieved even without builtin priors and that success at low entropy can serve as a target for assessing progress towards robust systematic generalization
http://arxiv.org/abs/2505.13077v1,2025-05-19T13:11:28Z,"Xiang Fei, Jinghui Lu, Qi Sun, Hao Feng, Yanjie Wang, Wei Shi, An-Lan Wang, Jingqun Tang, Can Huang",advancing sequential numerical prediction in autoregressive models,autoregressive models have become the de facto choice for sequence generation tasks but standard approaches treat digits as independent tokens and apply crossentropy loss overlooking the coherent structure of numerical sequences this paper introduces numerical token integrity loss ntil to address this gap ntil operates at two levels 1 tokenlevel where it extends the earth movers distance emd to preserve ordinal relationships between numerical values and 2 sequencelevel where it penalizes the overall discrepancy between the predicted and actual sequences this dual approach improves numerical prediction and integrates effectively with llmsmllms extensive experiments show significant performance improvements with ntil
http://arxiv.org/abs/2505.13069v1,2025-05-19T13:04:37Z,"Ambre Marie, Ilias Maoudj, Guillaume Dardenne, Gwenolé Quellec",suicide risk assessment using multimodal speech features a study on the sw1 challenge dataset,the 1st speechwellness challenge conveys the need for speechbased suicide risk assessment in adolescents this study investigates a multimodal approach for this challenge integrating automatic transcription with whisperx linguistic embeddings from chinese roberta and audio embeddings from wavlm additionally handcrafted acoustic features including mfccs spectral contrast and pitchrelated statistics were incorporated we explored three fusion strategies early concatenation modalityspecific processing and weighted attention with mixup regularization results show that weighted attention provided the best generalization achieving 69 accuracy on the development set though a performance gap between development and test sets highlights generalization challenges our findings strictly tied to the minikid framework emphasize the importance of refining embedding representations and fusion mechanisms to enhance classification reliability
http://arxiv.org/abs/2505.13053v1,2025-05-19T12:42:23Z,"Amelie S. Robrecht, Christoph R. Kowalski, Stefan Kopp",snapepm building and utilizing dynamic partner models for adaptive explanation generation,adapting to the addressee is crucial for successful explanations yet poses significant challenges for dialogsystems we adopt the approach of treating explanation generation as a nonstationary decision process where the optimal strategy varies according to changing beliefs about the explainee and the interaction context in this paper we address the questions of 1 how to track the interaction context and the relevant listener features in a formally defined computational partner model and 2 how to utilize this model in the dynamically adjusted rational decision process that determines the currently best explanation strategy we propose a bayesian inferencebased approach to continuously update the partner model based on user feedback and a nonstationary markov decision process to adjust decisionmaking based on the partner model values we evaluate an implementation of this framework with five simulated interlocutors demonstrating its effectiveness in adapting to different partners with constant and even changing feedback behavior the results show high adaptivity with distinct explanation strategies emerging for different partners highlighting the potential of our approach to improve explainable ai systems and dialogsystems in general
http://arxiv.org/abs/2505.13036v1,2025-05-19T12:21:29Z,"Sai Koneru, Maike Züfle, Thai-Binh Nguyen, Seymanur Akti, Jan Niehues, Alexander Waibel",kits offline speech translation and instruction following submission for iwslt 2025,the scope of the international workshop on spoken language translation iwslt has recently broadened beyond traditional speech translation st to encompass a wider array of tasks including speech question answering and summarization this shift is partly driven by the growing capabilities of modern systems particularly with the success of large language models llms in this paper we present the karlsruhe institute of technologys submissions for the offline st and instruction following if tracks where we leverage llms to enhance performance across all tasks for the offline st track we propose a pipeline that employs multiple automatic speech recognition systems whose outputs are fused using an llm with documentlevel context this is followed by a twostep translation process incorporating additional refinement step to improve translation quality for the if track we develop an endtoend model that integrates a speech encoder with an llm to perform a wide range of instructionfollowing tasks we complement it with a final documentlevel refinement stage to further enhance output quality by using contextual information
http://arxiv.org/abs/2505.13034v1,2025-05-19T12:19:01Z,"Márton Kardos, Kenneth C. Enevoldsen, Kristoffer Laigaard Nielbo",topicwizard a modern modelagnostic framework for topic model visualization and interpretation,topic models are statistical tools that allow their users to gain qualitative and quantitative insights into the contents of textual corpora without the need for close reading they can be applied in a wide range of settings from discourse analysis through pretraining data curation to text filtering topic models are typically parameterrich complex models and interpreting these parameters can be challenging for their users it is typical practice for users to interpret topics based on the top 10 highest ranking terms on a given topic this listofwords approach however gives users a limited and biased picture of the content of topics thoughtful user interface design and visualizations can help users gain a more complete and accurate understanding of topic models output while some visualization utilities do exist for topic models these are typically limited to a certain type of topic model we introduce topicwizard a framework for modelagnostic topic model interpretation that provides intuitive and interactive tools that help users examine the complex semantic relations between documents words and topics learned by topic models
http://arxiv.org/abs/2505.13032v1,2025-05-19T12:18:42Z,"Ziyang Ma, Yinghao Ma, Yanqiao Zhu, Chen Yang, Yi-Wen Chao, Ruiyang Xu, Wenxi Chen, Yuanzhe Chen, Zhuo Chen, Jian Cong, Kai Li, Keliang Li, Siyou Li, Xinfeng Li, Xiquan Li, Zheng Lian, Yuzhe Liang, Minghao Liu, Zhikang Niu, Tianrui Wang, Yuping Wang, Yuxuan Wang, Yihao Wu, Guanrou Yang, Jianwei Yu, Ruibin Yuan, Zhisheng Zheng, Ziya Zhou, Haina Zhu, Wei Xue, Emmanouil Benetos, Kai Yu, Eng-Siong Chng, Xie Chen",mmar a challenging benchmark for deep reasoning in speech audio music and their mix,we introduce mmar a new benchmark designed to evaluate the deep reasoning capabilities of audiolanguage models alms across massive multidisciplinary tasks mmar comprises 1000 meticulously curated audioquestionanswer triplets collected from realworld internet videos and refined through iterative error corrections and quality checks to ensure high quality unlike existing benchmarks that are limited to specific domains of sound music or speech mmar extends them to a broad spectrum of realworld audio scenarios including mixedmodality combinations of sound music and speech each question in mmar is hierarchically categorized across four reasoning layers signal perception semantic and cultural with additional subcategories within each layer to reflect task diversity and complexity to further foster research in this area we annotate every question with a chainofthought cot rationale to promote future advancements in audio reasoning each item in the benchmark demands multistep deep reasoning beyond surfacelevel understanding moreover a part of the questions requires graduatelevel perceptual and domainspecific knowledge elevating the benchmarks difficulty and depth we evaluate mmar using a broad set of models including large audiolanguage models lalms large audio reasoning models larms omni language models olms large language models llms and large reasoning models lrms with audio caption inputs the performance of these models on mmar highlights the benchmarks challenging nature and our analysis further reveals critical limitations of understanding and reasoning capabilities among current models we hope mmar will serve as a catalyst for future advances in this important but littleexplored area
http://arxiv.org/abs/2505.13028v1,2025-05-19T12:12:00Z,"Sayon Palit, Daniel Woods",evaluatiing the efficacy of llm safety solutions the palit benchmark dataset,large language models llms are increasingly integrated into critical systems in industries like healthcare and finance users can often submit queries to llmenabled chatbots some of which can enrich responses with information retrieved from internal databases storing sensitive data this gives rise to a range of attacks in which a user submits a malicious query and the llmsystem outputs a response that creates harm to the owner such as leaking internal data or creating legal liability by harming a thirdparty while security tools are being developed to counter these threats there is little formal evaluation of their effectiveness and usability this study addresses this gap by conducting a thorough comparative analysis of llm security tools we identified 13 solutions 9 closedsource 4 opensource but only 7 were evaluated due to a lack of participation by proprietary model ownersto evaluate we built a benchmark dataset of malicious prompts and evaluate these tools performance against a baseline llm model chatgpt35turbo our results show that the baseline model has too many false positives to be used for this task lakera guard and protectai llm guard emerged as the best overall tools showcasing the tradeoff between usability and performance the study concluded with recommendations for greater transparency among closed source providers improved contextaware detections enhanced opensource engagement increased user awareness and the adoption of more representative performance metrics
http://arxiv.org/abs/2505.13010v1,2025-05-19T11:54:39Z,"Himel Ghosh, Ahmed Mosharafa, Georg Groh",to bias or not to bias detecting bias in news with biasdetector,media bias detection is a critical task in ensuring fair and balanced information dissemination yet it remains challenging due to the subjectivity of bias and the scarcity of highquality annotated data in this work we perform sentencelevel bias classification by finetuning a robertabased model on the expertannotated babe dataset using mcnemars test and the 5x2 crossvalidation paired ttest we show statistically significant improvements in performance when comparing our model to a domainadaptively pretrained daroberta baseline furthermore attentionbased analysis shows that our model avoids common pitfalls like oversensitivity to politically charged terms and instead attends more meaningfully to contextually relevant tokens for a comprehensive examination of media bias we present a pipeline that combines our model with an alreadyexisting biastype classifier our method exhibits good generalization and interpretability despite being constrained by sentencelevel analysis and dataset size because of a lack of larger and more advanced bias corpora we talk about contextaware modeling bias neutralization and advanced bias type classification as potential future directions our findings contribute to building more robust explainable and socially responsible nlp systems for media bias detection
http://arxiv.org/abs/2505.13006v1,2025-05-19T11:46:30Z,"Yuyang Li, Philip J. M. Kerbusch, Raimon H. R. Pruim, Tobias Käfer",evaluating the performance of rag methods for conversational ai in the airport domain,airports from the top 20 in terms of annual passengers are highly dynamic environments with thousands of flights daily and they aim to increase the degree of automation to contribute to this we implemented a conversational ai system that enables staff in an airport to communicate with flight information systems this system not only answers standard airport queries but also resolves airport terminology jargon abbreviations and dynamic questions involving reasoning in this paper we built three different retrievalaugmented generation rag methods including traditional rag sql rag and knowledge graphbased rag graph rag experiments showed that traditional rag achieved 8484 accuracy using bm25 gpt4 but occasionally produced hallucinations which is risky to airport safety in contrast sql rag and graph rag achieved 8085 and 9149 accuracy respectively with significantly fewer hallucinations moreover graph rag was especially effective for questions that involved reasoning based on our observations we thus recommend sql rag and graph rag are better for airport environments due to fewer hallucinations and the ability to handle dynamic questions
http://arxiv.org/abs/2505.13004v1,2025-05-19T11:43:37Z,"Yuhao Qing, Boyu Zhu, Mingzhe Du, Zhijiang Guo, Terry Yue Zhuo, Qianru Zhang, Jie M. Zhang, Heming Cui, Siu-Ming Yiu, Dong Huang, See-Kiong Ng, Luu Anh Tuan",effibenchx a multilanguage benchmark for measuring efficiency of llmgenerated code,existing code generation benchmarks primarily evaluate functional correctness with limited focus on code efficiency and often restricted to a single language like python to address this gap we introduce effibenchx the first multilanguage benchmark designed to measure the efficiency of llmgenerated code effibenchx supports python c java javascript ruby and golang it comprises competitive programming tasks with humanexpert solutions as efficiency baselines evaluating stateoftheart llms on effibenchx reveals that while models generate functionally correct code they consistently underperform human experts in efficiency even the most efficient llmgenerated solutions qwen332b achieve only around textbf62 of human efficiency on average with significant languagespecific variations llms show better efficiency in python ruby and javascript than in java c and golang for instance deepseekr1s python code is significantly more efficient than its java code these results highlight the critical need for research into llm optimization techniques to improve code efficiency across diverse languages the dataset and evaluation infrastructure are submitted and available at httpsgithubcomeffibencheffibenchxgit and httpshuggingfacecodatasetseffibencheffibenchx
http://arxiv.org/abs/2505.12996v1,2025-05-19T11:34:47Z,"Jiaan Wang, Fandong Meng, Jie Zhou",extrans multilingual deep reasoning translation via exemplarenhanced reinforcement learning,in recent years the emergence of large reasoning models lrms such as openaio1 and deepseekr1 has shown impressive capabilities in complex problems eg mathematics and coding some pioneering studies attempt to bring the success of lrms in neural machine translation mt they try to build lrms with deep reasoning mt ability via reinforcement learning rl despite some progress that has been made these attempts generally focus on several highresource languages eg english and chinese leaving the performance on other languages unclear besides the reward modeling methods in previous work do not fully unleash the potential of reinforcement learning in mt in this work we first design a new reward modeling method that compares the translation results of the policy mt model with a strong lrm ie deepseekr1671b and quantifies the comparisons to provide rewards experimental results demonstrate the superiority of the reward modeling method using qwen257binstruct as the backbone the trained model achieves the new stateoftheart performance in literary translation and outperforms strong lrms including openaio1 and deepseekr1 furthermore we extend our method to the multilingual settings with 11 languages with a carefully designed lightweight reward modeling in rl we can simply transfer the strong mt ability from a single direction into multiple ie 90 translation directions and achieve impressive multilingual mt performance
http://arxiv.org/abs/2505.12992v1,2025-05-19T11:30:41Z,"Baohao Liao, Hanze Dong, Yuhui Xu, Doyen Sahoo, Christof Monz, Junnan Li, Caiming Xiong",fractured chainofthought reasoning,inferencetime scaling techniques have significantly bolstered the reasoning capabilities of large language models llms by harnessing additional computational effort at inference without retraining similarly chainofthought cot prompting and its extension long cot improve accuracy by generating rich intermediate reasoning trajectories but these approaches incur substantial token costs that impede their deployment in latencysensitive settings in this work we first show that truncated cot which stops reasoning before completion and directly generates the final answer often matches full cot sampling while using dramatically fewer tokens building on this insight we introduce fractured sampling a unified inferencetime strategy that interpolates between full cot and solutiononly sampling along three orthogonal axes 1 the number of reasoning trajectories 2 the number of final solutions per trajectory and 3 the depth at which reasoning traces are truncated through extensive experiments on five diverse reasoning benchmarks and several model scales we demonstrate that fractured sampling consistently achieves superior accuracycost tradeoffs yielding steep loglinear scaling gains in passk versus token budget our analysis reveals how to allocate computation across these dimensions to maximize performance paving the way for more efficient and scalable llm reasoning
http://arxiv.org/abs/2505.12983v1,2025-05-19T11:18:54Z,"Jiaan Wang, Fandong Meng, Zengkui Sun, Yunlong Liang, Yuxuan Cao, Jiarong Xu, Haoxiang Shi, Jie Zhou",an empirical study of manytomany summarization with large language models,manytomany summarization m2ms aims to process documents in any language and generate the corresponding summaries also in any language recently large language models llms have shown strong multilingual abilities giving them the potential to perform m2ms in real applications this work presents a systematic empirical study on llms m2ms ability specifically we first reorganize m2ms data based on eight previous domainspecific datasets the reorganized data contains 478k samples spanning five domains and six languages which could be used to train and evaluate llms then we benchmark 18 llms in a zeroshot manner and an instructiontuning manner finetuned traditional models eg mbart are also conducted for comparisons our experiments reveal that zeroshot llms achieve competitive results with finetuned traditional models after instructtuning opensource llms can significantly improve their m2ms ability and outperform zeroshot llms including gpt4 in terms of automatic evaluations in addition we demonstrate that this taskspecific improvement does not sacrifice the llms general tasksolving abilities however as revealed by our human evaluation llms still face the factuality issue and the instruction tuning might intensify the issue thus how to control factual errors becomes the key when building llm summarizers in real applications and is worth noting in future research
http://arxiv.org/abs/2505.12973v1,2025-05-19T11:11:12Z,"Mahta Fetrat Qharabagh, Zahra Dehghanian, Hamid R. Rabiee",fast not fancy rethinking g2p with rich data and rulebased models,homograph disambiguation remains a significant challenge in graphemetophoneme g2p conversion especially for lowresource languages this challenge is twofold 1 creating balanced and comprehensive homograph datasets is laborintensive and costly and 2 specific disambiguation strategies introduce additional latency making them unsuitable for realtime applications such as screen readers and other accessibility tools in this paper we address both issues first we propose a semiautomated pipeline for constructing homographfocused datasets introduce the homorich dataset generated through this pipeline and demonstrate its effectiveness by applying it to enhance a stateoftheart deep learningbased g2p system for persian second we advocate for a paradigm shift utilizing rich offline datasets to inform the development of fast rulebased methods suitable for latencysensitive accessibility applications like screen readers to this end we improve one of the most wellknown rulebased g2p systems espeak into a fast homographaware version homofast espeak our results show an approximate 30 improvement in homograph disambiguation accuracy for the deep learningbased and espeak systems
http://arxiv.org/abs/2505.12970v1,2025-05-19T11:06:50Z,"Robin Jegan, Andreas Henrich",a structured literature review on traditional approaches in current natural language processing,the continued rise of neural networks and large language models in the more recent past has altered the natural language processing landscape enabling new approaches towards typical language tasks and achieving mainstream success despite the huge success of large language models many disadvantages still remain and through this work we assess the state of the art in five application scenarios with a particular focus on the future perspectives and sensible application scenarios of traditional and older approaches and techniques in this paper we survey recent publications in the application scenarios classification information and relation extraction text simplification as well as text summarization after defining our terminology ie which features are characteristic for traditional techniques in our interpretation for the five scenarios we survey if such traditional approaches are still being used and if so in what way they are used it turns out that all five application scenarios still exhibit traditional models in one way or another as part of a processing pipeline as a comparisonbaseline to the core model of the respective paper or as the main models of the paper for the complete statistics see httpszenodoorgrecords13683801
http://arxiv.org/abs/2505.12969v1,2025-05-19T11:04:52Z,"Yingzhi Wang, Anas Alhmoud, Saad Alsahly, Muhammad Alqurishi, Mirco Ravanelli",calmwhisper reduce whisper hallucination on nonspeech by calming crazy heads down,openais whisper has achieved significant success in automatic speech recognition however it has consistently been found to exhibit hallucination issues particularly in nonspeech segments which limits its broader application in complex industrial settings in this paper we introduce a novel method to reduce whispers hallucination on nonspeech segments without using any pre or postpossessing techniques specifically we benchmark the contribution of each selfattentional head in the whisperlargev3 decoder to the hallucination problem by performing a headwise mask our findings reveal that only 3 of the 20 heads account for over 75 of the hallucinations on the urbansound dataset we then finetune these three crazy heads using a collection of nonspeech data the results show that our best finetuned model namely calmwhisper achieves over 80 reduction in nonspeech hallucination with only less than 01 wer degradation on librispeech testclean and testother
http://arxiv.org/abs/2505.12964v1,2025-05-19T11:00:43Z,"Shanshan Liu, Noriki Nishida, Rumana Ferdous Munne, Narumi Tokunaga, Yuki Yamagata, Kouji Kozaki, Yuji Matsumoto",macoir leveraging semantic search index and generative models for ontologydriven biomedical concept recognition,recognizing biomedical concepts in the text is vital for ontology refinement knowledge graph construction and concept relationship discovery however traditional concept recognition methods relying on explicit mention identification often fail to capture complex concepts not explicitly stated in the text to overcome this limitation we introduce macoir a framework that reformulates concept recognition as an indexingrecognition task by assigning semantic search indexes ssids to concepts macoir resolves ambiguities in ontology entries and enhances recognition efficiency using a pretrained bartbased model finetuned on small datasets our approach reduces computational requirements to facilitate adoption by domain experts furthermore we incorporate large language models llmsgenerated queries and synthetic data to improve recognition in lowresource settings experimental results on three scenarios cdr hpo and hoip highlight the effectiveness of macoir in recognizing both explicit and implicit concepts without the need for mentionlevel annotations during inference advancing ontologydriven concept recognition in biomedical domain applications our code and constructed data are available at httpsgithubcomsl633macoirmaster
http://arxiv.org/abs/2505.12950v1,2025-05-19T10:42:36Z,"Daehee Kim, Deokhyung Kang, Jonghwi Kim, Sangwon Ryu, Gary Geunbae Lee",guregenerative query rewriter for legal passage retrieval,legal passage retrieval lpr systems are crucial as they help practitioners save time when drafting legal arguments however it remains an underexplored avenue one primary reason is the significant vocabulary mismatch between the query and the target passage to address this we propose a simple yet effective method the generative query rewriter gure we leverage the generative capabilities of large language models llms by training the llm for query rewriting rewritten queries help retrievers to retrieve target passages by mitigating vocabulary mismatch experimental results show that gure significantly improves performance in a retrieveragnostic manner outperforming all baseline methods further analysis reveals that different training objectives lead to distinct retrieval behaviors making gure more suitable than direct retriever finetuning for realworld applications codes are avaiable at githubcomdaehuikimgure
http://arxiv.org/abs/2505.12949v1,2025-05-19T10:41:47Z,"Cael Marquard, Simbarashe Mawere, Francois Meyer",neural morphological tagging for nguni languages,morphological parsing is the task of decomposing words into morphemes the smallest units of meaning in a language and labelling their grammatical roles it is a particularly challenging task for agglutinative languages such as the nguni languages of south africa which construct words by concatenating multiple morphemes a morphological parsing system can be framed as a pipeline with two separate components a segmenter followed by a tagger this paper investigates the use of neural methods to build morphological taggers for the four nguni languages we compare two classes of approaches training neural sequence labellers lstms and neural crfs from scratch and finetuning pretrained language models we compare performance across these two categories as well as to a traditional rulebased morphological parser neural taggers comfortably outperform the rulebased baseline and models trained from scratch tend to outperform pretrained models we also compare parsing results across different upstream segmenters and with varying linguistic input features our findings confirm the viability of employing neural taggers based on preexisting morphological segmenters for the nguni languages
http://arxiv.org/abs/2505.12942v1,2025-05-19T10:29:32Z,"Jeffrey T. H. Wong, Cheng Zhang, Xinye Cao, Pedro Gimenes, George A. Constantinides, Wayne Luk, Yiren Zhao",a3 an analytical lowrank approximation framework for attention,large language models have demonstrated remarkable performance however their massive parameter counts make deployment highly expensive lowrank approximation offers a promising compression solution yet existing approaches have two main limitations 1 they focus on minimizing the output error of individual linear layers without considering the architectural characteristics of transformers and 2 they decompose a large weight matrix into two small lowrank matrices consequently these methods often fall short compared to other compression techniques like pruning and quantization and introduce runtime overhead such as the extra gemm kernel launches for decomposed small matrices to address these limitations we propose a posttraining lowrank approximation framework splits a transformer layer into three functional components namely and for each component provides an analytical solution that reduces the hidden dimension size inside each component while minimizing the components functional loss error in attention scores attention outputs and mlp outputs this approach directly reduces model sizes kv cache sizes and flops without introducing any runtime overheads in addition it provides a new narrative in advancing the optimization problem from singular linear layer loss optimization toward improved endtoend performance through extensive experiments we show that maintains superior performance compared to sotas for example under the same reduction budget in computation and memory our lowrank approximated llama 3170b achieves a perplexity of 469 on wikitext2 outperforming the previous sotas 787 by 318 we also demonstrate the versatility of including kv cache compression quantization and mixedrank assignments for enhanced performance
http://arxiv.org/abs/2505.12938v1,2025-05-19T10:22:04Z,"Uri Dalal, Meirav Segal, Zvika Ben-Haim, Dan Lahav, Omer Nevo",leveraging llm inconsistency to boost passk performance,large language models llms achieve impressive abilities in numerous domains but exhibit inconsistent performance in response to minor input changes rather than view this as a drawback in this paper we introduce a novel method for leveraging models inconsistency to boost passk performance specifically we present a variator agent that generates k variants of a given task and submits one candidate solution for each one our variant generation approach is applicable to a wide range of domains as it is task agnostic and compatible with freeform inputs we demonstrate the efficacy of our agent theoretically using a probabilistic model of the inconsistency effect and show empirically that it outperforms the baseline on the apps dataset furthermore we establish that inconsistency persists even in frontier reasoning models across coding and cybersecurity domains suggesting our method is likely to remain relevant for future model generations
http://arxiv.org/abs/2505.12929v1,2025-05-19T10:14:08Z,"Zhihe Yang, Xufang Luo, Zilong Wang, Dongqi Han, Zhiyuan He, Dongsheng Li, Yunjian Xu",do not let lowprobability tokens overdominate in rl for llms,reinforcement learning rl has become a cornerstone for enhancing the reasoning capabilities of large language models llms with recent innovations such as group relative policy optimization grpo demonstrating exceptional effectiveness in this study we identify a critical yet underexplored issue in rl training lowprobability tokens disproportionately influence model updates due to their large gradient magnitudes this dominance hinders the effective learning of highprobability tokens whose gradients are essential for llms performance but are substantially suppressed to mitigate this interference we propose two novel methods advantage reweighting and lowprobability token isolation lopti both of which effectively attenuate gradients from lowprobability tokens while emphasizing parameter updates driven by highprobability tokens our approaches promote balanced updates across tokens with varying probabilities thereby enhancing the efficiency of rl training experimental results demonstrate that they substantially improve the performance of grpotrained llms achieving up to a 462 improvement in kk logic puzzle reasoning tasks our implementation is available at httpsgithubcomzhyang2226arlopti
http://arxiv.org/abs/2505.12920v1,2025-05-19T10:00:01Z,"Paul Van Eecke, Katrien Beuls",pyfcg fluid construction grammar in python,we present pyfcg an open source software library that ports fluid construction grammar fcg to the python programming language pyfcg enables its users to seamlessly integrate fcg functionality into python programs and to use fcg in combination with other libraries within pythons rich ecosystem apart from a general description of the library this paper provides three walkthrough tutorials that demonstrate example usage of pyfcg in typical use cases of fcg i formalising and testing construction grammar analyses ii learning usagebased construction grammars from corpora and iii implementing agentbased experiments on emergent communication
http://arxiv.org/abs/2505.12900v1,2025-05-19T09:35:58Z,"Shuyang Hou, Zhangxiao Shen, Huayi Wu, Jianyuan Liang, Haoyue Jiao, Yaxian Qing, Xiaopu Zhang, Xu Li, Zhipeng Gui, Xuefeng Guan, Longgang Xiang",autogeeval a multimodal and automated framework for geospatial code generation on gee with large language models,geospatial code generation is emerging as a key direction in the integration of artificial intelligence and geoscientific analysis however there remains a lack of standardized tools for automatic evaluation in this domain to address this gap we propose autogeeval the first multimodal unitlevel automated evaluation framework for geospatial code generation tasks on the google earth engine gee platform powered by large language models llms built upon the gee python api autogeeval establishes a benchmark suite autogeevalbench comprising 1325 test cases that span 26 gee data types the framework integrates both question generation and answer verification components to enable an endtoend automated evaluation pipelinefrom function invocation to execution validation autogeeval supports multidimensional quantitative analysis of model outputs in terms of accuracy resource consumption execution efficiency and error types we evaluate 18 stateoftheart llmsincluding generalpurpose reasoningaugmented codecentric and geosciencespecialized modelsrevealing their performance characteristics and potential optimization pathways in gee code generation this work provides a unified protocol and foundational resource for the development and assessment of geospatial code generation models advancing the frontier of automated natural language to domainspecific code translation
http://arxiv.org/abs/2505.12896v1,2025-05-19T09:31:52Z,"Chenxi Liu, Yongqiang Chen, Tongliang Liu, James Cheng, Bo Han, Kun Zhang",on the thinkinglanguage modeling gap in large language models,system 2 reasoning is one of the defining characteristics of intelligence which requires slow and logical thinking human conducts system 2 reasoning via the language of thoughts that organizes the reasoning process as a causal sequence of mental language or thoughts recently it has been observed that system 2 reasoning can be elicited from large language models llms pretrained on largescale natural languages however in this work we show that there is a significant gap between the modeling of languages and thoughts as language is primarily a tool for humans to share knowledge and thinking modeling human language can easily absorb language biases into llms deviated from the chain of thoughts in minds furthermore we show that the biases will mislead the eliciting of thoughts in llms to focus only on a biased part of the premise to this end we propose a new prompt technique termed languageofthoughts lot to demonstrate and alleviate this gap instead of directly eliciting the chain of thoughts from partial information lot instructs llms to adjust the order and token used for the expressions of all the relevant information we show that the simple strategy significantly reduces the language modeling biases in llms and improves the performance of llms across a variety of reasoning tasks
http://arxiv.org/abs/2505.12891v1,2025-05-19T09:22:02Z,"Shaohang Wei, Wei Li, Feifan Song, Wen Luo, Tianyi Zhuang, Haochen Tan, Zhijiang Guo, Houfeng Wang",time a multilevel benchmark for temporal reasoning of llms in realworld scenarios,temporal reasoning is pivotal for large language models llms to comprehend the real world however existing works neglect the realworld challenges for temporal reasoning 1 intensive temporal information 2 fastchanging event dynamics and 3 complex temporal dependencies in social interactions to bridge this gap we propose a multilevel benchmark time designed for temporal reasoning in realworld scenarios time consists of 38522 qa pairs covering 3 levels with 11 finegrained subtasks this benchmark encompasses 3 subdatasets reflecting different realworld challenges timewiki timenews and timedial we conduct extensive experiments on reasoning models and nonreasoning models and we conducted an indepth analysis of temporal reasoning performance across diverse realworld scenarios and tasks and summarized the impact of testtime scaling on temporal reasoning capabilities additionally we release timelite a humanannotated subset to foster future research and standardized evaluation in temporal reasoning the code is available at httpsgithubcomsylvainweitime and the dataset is available at httpshuggingfacecodatasetssylvainweitime
http://arxiv.org/abs/2505.12888v1,2025-05-19T09:18:19Z,"Jialun Zhong, Yanzeng Li, Sen Hu, Yang Zhang, Teng Xu, Lei Zou",gap graphassisted prompts for dialoguebased medication recommendation,medication recommendations have become an important task in the healthcare domain especially in measuring the accuracy and safety of medical dialogue systems mds different from the recommendation task based on electronic health records ehrs dialoguebased medication recommendations require research on the interaction details between patients and doctors which is crucial but may not exist in ehrs recent advancements in large language models llm have extended the medical dialogue domain these llms can interpret patients intent and provide medical suggestions including medication recommendations but some challenges are still worth attention during a multiturn dialogue llms may ignore the finegrained medical information or connections across the dialogue turns which is vital for providing accurate suggestions besides llms may generate nonfactual responses when there is a lack of domainspecific knowledge which is more risky in the medical domain to address these challenges we propose a textbfgraphtextbfassisted textbfprompts textbfgap framework for dialoguebased medication recommendation it extracts medical concepts and corresponding states from dialogue to construct an explicitly patientcentric graph which can describe the neglected but important information further combined with external medical knowledge graphs gap can generate abundant queries and prompts thus retrieving information from multiple sources to reduce the nonfactual responses we evaluate gap on a dialoguebased medication recommendation dataset and further explore its potential in a more difficult scenario dynamically diagnostic interviewing extensive experiments demonstrate its competitive performance when compared with strong baselines
http://arxiv.org/abs/2505.12886v1,2025-05-19T09:16:40Z,"Zhongxiang Sun, Qipeng Wang, Haoyu Wang, Xiao Zhang, Jun Xu",detection and mitigation of hallucination in large reasoning models a mechanistic perspective,large reasoning models lrms have shown impressive capabilities in multistep reasoning tasks however alongside these successes a more deceptive form of model error has emergedreasoning hallucinationwhere logically coherent but factually incorrect reasoning traces lead to persuasive yet faulty conclusions unlike traditional hallucinations these errors are embedded within structured reasoning making them more difficult to detect and potentially more harmful in this work we investigate reasoning hallucinations from a mechanistic perspective we propose the reasoning score which quantifies the depth of reasoning by measuring the divergence between logits obtained from projecting late layers of lrms to the vocabulary space effectively distinguishing shallow patternmatching from genuine deep reasoning using this score we conduct an indepth analysis on the retruthqa dataset and identify two key reasoning hallucination patterns earlystage fluctuation in reasoning depth and incorrect backtracking to flawed prior steps these insights motivate our reasoning hallucination detection rhd framework which achieves stateoftheart performance across multiple domains to mitigate reasoning hallucinations we further introduce grpor an enhanced reinforcement learning algorithm that incorporates steplevel deep reasoning rewards via potentialbased shaping our theoretical analysis establishes stronger generalization guarantees and experiments demonstrate improved reasoning quality and reduced hallucination rates
http://arxiv.org/abs/2505.12871v1,2025-05-19T08:57:08Z,"Zi Liang, Haibo Hu, Qingqing Ye, Yaxin Xiao, Ronghua Li",does low rank adaptation lead to lower robustness against trainingtime attacks,low rank adaptation lora has emerged as a prominent technique for finetuning large language models llms thanks to its superb efficiency gains over previous methods while extensive studies have examined the performance and structural properties of lora its behavior upon trainingtime attacks remain underexplored posing significant security risks in this paper we theoretically investigate the security implications of loras lowrank structure during finetuning in the context of its robustness against data poisoning and backdoor attacks we propose an analytical framework that models loras training dynamics employs the neural tangent kernel to simplify the analysis of the training process and applies information theory to establish connections between loras low rank structure and its vulnerability against trainingtime attacks our analysis indicates that lora exhibits better robustness to backdoor attacks than full finetuning while becomes more vulnerable to untargeted data poisoning due to its oversimplified information geometry extensive experimental evaluations have corroborated our theoretical findings
http://arxiv.org/abs/2505.12864v1,2025-05-19T08:48:12Z,"Yu Fan, Jingwei Ni, Jakob Merane, Etienne Salimbeni, Yang Tian, Yoan Hermstrüwer, Yinya Huang, Mubashara Akhtar, Florian Geering, Oliver Dreyer, Daniel Brunner, Markus Leippold, Mrinmaya Sachan, Alexander Stremitzer, Christoph Engel, Elliott Ash, Joel Niklaus",lexam benchmarking legal reasoning on 340 law exams,longform legal reasoning remains a key challenge for large language models llms in spite of recent advances in testtime scaling we introduce lexam a novel benchmark derived from 340 law exams spanning 116 law school courses across a range of subjects and degree levels the dataset comprises 4886 law exam questions in english and german including 2841 longform openended questions and 2045 multiplechoice questions besides reference answers the open questions are also accompanied by explicit guidance outlining the expected legal reasoning approach such as issue spotting rule recall or rule application our evaluation on both openended and multiplechoice questions present significant challenges for current llms in particular they notably struggle with open questions that require structured multistep legal reasoning moreover our results underscore the effectiveness of the dataset in differentiating between models with varying capabilities adopting an llmasajudge paradigm with rigorous human expert validation we demonstrate how modelgenerated reasoning steps can be evaluated consistently and accurately our evaluation setup provides a scalable method to assess legal reasoning quality beyond simple accuracy metrics project page httpslexambenchmarkgithubio
http://arxiv.org/abs/2505.12859v1,2025-05-19T08:43:54Z,"Lucas Georges Gabriel Charpentier, Pierre Lison",reidentification of deidentified documents with autoregressive infilling,documents revealing sensitive information about individuals must typically be deidentified this deidentification is often done by masking all mentions of personally identifiable information pii thereby making it more difficult to uncover the identity of the persons in question to investigate the robustness of deidentification methods we present a novel raginspired approach that attempts the reverse process of reidentification based on a database of documents representing background knowledge given a text in which personal identifiers have been masked the reidentification proceeds in two steps a retriever first selects from the background knowledge passages deemed relevant for the reidentification those passages are then provided to an infilling model which seeks to infer the original content of each text span this process is repeated until all masked spans are replaced we evaluate the reidentification on three datasets wikipedia biographies court rulings and clinical notes results show that 1 as many as 80 of deidentified text spans can be successfully recovered and 2 the reidentification accuracy increases along with the level of background knowledge
http://arxiv.org/abs/2505.12842v1,2025-05-19T08:29:05Z,"Zheng Wu, Pengzhou Cheng, Zongru Wu, Lingzhong Dong, Zhuosheng Zhang",gem gaussian embedding modeling for outofdistribution detection in gui agents,graphical user interface gui agents have recently emerged as an intriguing paradigm for humancomputer interaction capable of automatically executing user instructions to operate intelligent terminal devices however when encountering outofdistribution ood instructions that violate environmental constraints or exceed the current capabilities of agents gui agents may suffer task breakdowns or even pose security threats therefore effective ood detection for gui agents is essential traditional ood detection methods perform suboptimally in this domain due to the complex embedding space and evolving gui environments in this work we observe that the indistribution input semantic space of gui agents exhibits a clustering pattern with respect to the distance from the centroid based on the finding we propose gem a novel method based on fitting a gaussian mixture model over input embedding distances extracted from the gui agent that reflect its capability boundary evaluated on eight datasets spanning smartphones computers and web browsers our method achieves an average accuracy improvement of 2370 over the bestperforming baseline analysis verifies the generalization ability of our method through experiments on nine different backbones the codes are available at httpsgithubcomwuzheng02gemoodforguiagents
http://arxiv.org/abs/2505.12837v1,2025-05-19T08:25:21Z,"Christian Braun, Alexander Lilienbeck, Daniel Mentjukov",the hidden structure improving legal document understanding through explicit text formatting,legal contracts possess an inherent semantically vital structure eg sections clauses that is crucial for human comprehension but whose impact on llm processing remains underexplored this paper investigates the effects of explicit input text structure and prompt engineering on the performance of gpt4o and gpt41 on a legal questionanswering task using an excerpt of the cuad we compare model exactmatch accuracy across various input formats wellstructured plaintext humangenerated from cuad plaintext cleaned of line breaks extracted plaintext from azure ocr plaintext extracted by gpt4o vision and extracted and interpreted markdown md from gpt4o vision to give an indication of the impact of possible prompt engineering we assess the impact of shifting task instructions to the system prompt and explicitly informing the model about the structured nature of the input our findings reveal that gpt4o demonstrates considerable robustness to variations in input structure but lacks in overall performance conversely gpt41s performance is markedly sensitive poorly structured inputs yield suboptimal results but identical with gpt4o while wellstructured formats original cuad text gpt4o vision text and gpt4o md improve exactmatch accuracy by 20 percentage points optimizing the system prompt to include task details and an advisory about structured input further elevates gpt41s accuracy by an additional 1013 percentage points with markdown ultimately achieving the highest performance under these conditions 79 percentage points overall exactmatch accuracy this research empirically demonstrates that while newer models exhibit greater resilience careful input structuring and strategic prompt design remain critical for optimizing the performance of llms and can significantly affect outcomes in highstakes legal applications
http://arxiv.org/abs/2505.12835v1,2025-05-19T08:21:20Z,"Hengxing Cai, Jinhan Dong, Jingjun Tan, Jingcheng Deng, Sihang Li, Zhifeng Gao, Haidong Wang, Zicheng Su, Agachai Sumalee, Renxin Zhong",flightgpt towards generalizable and interpretable uav visionandlanguage navigation with visionlanguage models,unmanned aerial vehicle uav visionandlanguage navigation vln is vital for applications such as disaster response logistics delivery and urban inspection however existing methods often struggle with insufficient multimodal fusion weak generalization and poor interpretability to address these challenges we propose flightgpt a novel uav vln framework built upon visionlanguage models vlms with powerful multimodal perception capabilities we design a twostage training pipeline first supervised finetuning sft using highquality demonstrations to improve initialization and structured reasoning then group relative policy optimization grpo algorithm guided by a composite reward that considers goal accuracy reasoning quality and format compliance to enhance generalization and adaptability furthermore flightgpt introduces a chainofthought cotbased reasoning mechanism to improve decision interpretability extensive experiments on the cityscale dataset citynav demonstrate that flightgpt achieves stateoftheart performance across all scenarios with a 922 higher success rate than the strongest baseline in unseen environments our implementation is publicly available
http://arxiv.org/abs/2505.12831v1,2025-05-19T08:19:27Z,"Zifeng Cheng, Zhonghui Wang, Yuchen Fu, Zhiwei Jiang, Yafeng Yin, Cong Wang, Qing Gu",contrastive prompting enhances sentence embeddings in llms through inferencetime steering,extracting sentence embeddings from large language models llms is a practical direction as it requires neither additional data nor finetuning previous studies usually focus on prompt engineering to guide llms to encode the core semantic information of the sentence into the embedding of the last token however the last token in these methods still encodes an excess of nonessential information such as stop words limiting its encoding capacity to this end we propose a contrastive prompting cp method that introduces an extra auxiliary prompt to elicit better sentence embedding by contrasting with the auxiliary prompt cp can steer existing prompts to encode the core semantics of the sentence rather than nonessential information cp is a plugandplay inferencetime intervention method that can be combined with various promptbased methods extensive experiments on semantic textual similarity sts tasks and downstream classification tasks demonstrate that our method can improve the performance of existing promptbased methods across different llms our code will be released at httpsgithubcomzifengchengcp
http://arxiv.org/abs/2505.12821v1,2025-05-19T08:03:38Z,"Han Sun, Zhen Sun, Zongmin Zhang, Linzhao Jia, Wei Shao, Min Zhang",syndec a synthesizethendecode approach for arbitrary textual style transfer via large language models,large language models llms are emerging as dominant forces for textual style transfer however for arbitrary style transfer llms face two key challenges 1 considerable reliance on manuallyconstructed prompts and 2 rigid stylistic biases inherent in llms in this paper we propose a novel synthesizethendecode syndec approach which automatically synthesizes highquality prompts and amplifies their roles during decoding process specifically our approach synthesizes prompts by selecting representative fewshot samples conducting a fourdimensional style analysis and reranking the candidates at llm decoding stage the tst effect is amplified by maximizing the contrast in output probabilities between scenarios with and without the synthesized prompt as well as between prompts and negative samples we conduct extensive experiments and the results show that syndec outperforms existing stateoftheart llmbased methods on five out of six benchmarks eg achieving up to a 9 increase in accuracy for moderntoelizabethan english transfer detailed ablation studies further validate the effectiveness of syndec
http://arxiv.org/abs/2505.12814v1,2025-05-19T07:45:09Z,"Xilong Cheng, Yunxiao Qin, Yuting Tan, Zhengnan Li, Ye Wang, Hongjiang Xiao, Yuan Zhang",psymem finegrained psychological alignment and explicit memory control for advanced roleplaying llms,existing llmbased roleplaying methods often rely on superficial textual descriptions or simplistic metrics inadequately modeling both intrinsic and extrinsic character dimensions additionally they typically simulate character memory with implicit model knowledge or basic retrieval augment generation without explicit memory alignment compromising memory consistency the two issues weaken reliability of roleplaying llms in several applications such as trustworthy social simulation to address these limitations we propose psymem a novel framework integrating finegrained psychological attributes and explicit memory control for roleplaying psymem supplements textual descriptions with 26 psychological indicators to detailed model character additionally psymem implements memory alignment training explicitly trains the model to align characters response with memory thereby enabling dynamic memorycontrolled responding during inference by training qwen257binstruct on our specially designed dataset including 5414 characters and 38962 dialogues extracted from novels the resulting model termed as psymemqwen outperforms baseline models in roleplaying achieving the best performance in humanlikeness and character fidelity
http://arxiv.org/abs/2505.12808v1,2025-05-19T07:34:25Z,"Yanbin Yin, Kun Zhou, Zhen Wang, Xiangdong Zhang, Yifei Shao, Shibo Hao, Yi Gu, Jieyuan Liu, Somanshu Singla, Tianyang Liu, Eric P. Xing, Zhengzhong Liu, Haojian Jin, Zhiting Hu",decentralized arena towards democratic and scalable automatic evaluation of language models,the recent explosion of large language models llms each with its own general or specialized strengths makes scalable reliable benchmarking more urgent than ever standard practices nowadays face fundamental tradeoffs closedended questionbased benchmarks eg mmlu struggle with saturation as newer models emerge while crowdsourced leaderboards eg chatbot arena rely on costly and slow human judges recently automated methods eg llmasajudge shed light on the scalability but risk bias by relying on one or a few authority models to tackle these issues we propose decentralized arena dearena a fully automated framework leveraging collective intelligence from all llms to evaluate each other it mitigates singlemodel judge bias by democratic pairwise evaluation and remains efficient at scale through two key components 1 a coarsetofine ranking algorithm for fast incremental insertion of new models with subquadratic complexity and 2 an automatic question selection strategy for the construction of new evaluation dimensions across extensive experiments across 66 llms dearena attains up to 97 correlation with human judgements while significantly reducing the cost our code and data will be publicly released on httpsgithubcommaitrixorgdearena
http://arxiv.org/abs/2505.12792v1,2025-05-19T07:24:35Z,"Wenhao Zhu, Yuhang Xie, Guojie Song, Xin Zhang",eavit efficient and accurate human value identification from text data via llms,the rapid evolution of large language models llms has revolutionized various fields including the identification and discovery of human values within text data while traditional nlp models such as bert have been employed for this task their ability to represent textual data is significantly outperformed by emerging llms like gpts however the performance of online llms often degrades when handling long contexts required for value identification which also incurs substantial computational costs to address these challenges we propose eavit an efficient and accurate framework for human value identification that combines the strengths of both locally finetunable and online blackbox llms our framework employs a value detector a small local language model to generate initial value estimations these estimations are then used to construct concise input prompts for online llms enabling accurate final value identification to train the value detector we introduce explanationbased training and data generation techniques specifically tailored for value identification alongside sampling strategies to optimize the brevity of llm input prompts our approach effectively reduces the number of input tokens by up to 16 compared to directly querying online llms while consistently outperforming traditional nlp methods and other llmbased strategies
http://arxiv.org/abs/2505.12781v1,2025-05-19T07:10:42Z,"Jitai Hao, Qiang Huang, Hao Liu, Xinyan Xiao, Zhaochun Ren, Jun Yu",a token is worth over 1000 tokens efficient knowledge distillation through lowrank clone,training highperforming small language models slms remains costly even with knowledge distillation and pruning from larger teacher models existing work often faces three key challenges 1 information loss from hard pruning 2 inefficient alignment of representations and 3 underutilization of informative activations particularly from feedforward networks ffns to address these challenges we introduce lowrank clone lrc an efficient pretraining method that constructs slms aspiring to behavioral equivalence with strong teacher models lrc trains a set of lowrank projection matrices that jointly enable soft pruning by compressing teacher weights and activation clone by aligning student activations including ffn signals with those of the teacher this unified design maximizes knowledge transfer while removing the need for explicit alignment modules extensive experiments with opensource teachers eg llama323binstruct qwen253b7binstruct show that lrc matches or surpasses stateoftheart models trained on trillions of tokenswhile using only 20b tokens achieving over 1000x training efficiency our codes and model checkpoints are available at httpsgithubcomcurrentflowrankclone and httpshuggingfacecocollectionsjitaihaolowrankclonelrc6828389e96a93f1d4219dfaf
http://arxiv.org/abs/2505.12768v1,2025-05-19T06:46:47Z,"Yaxun Dai, Wenxuan Xie, Xialie Zhuang, Tianyu Yang, Yiying Yang, Haiqin Yang, Yuhang Zhao, Pingfu Chao, Wenhao Jiang",reexsql reasoning with executionaware reinforcement learning for texttosql,in texttosql execution feedback is essential for guiding large language models llms to reason accurately and generate reliable sql queries however existing methods treat execution feedback solely as a posthoc signal for correction or selection failing to integrate it into the generation process this limitation hinders their ability to address reasoning errors as they occur ultimately reducing query accuracy and robustness to address this issue we propose reexsql reasoning with executionaware reinforcement learning a framework for texttosql that enables models to interact with the database during decoding and dynamically adjust their reasoning based on execution feedback reexsql introduces an executionaware reasoning paradigm that interleaves intermediate sql execution into reasoning paths facilitating contextsensitive revisions it achieves this through structured prompts with markup tags and a stepwise rollout strategy that integrates execution feedback into each stage of generation to supervise policy learning we develop a composite reward function that includes an exploration reward explicitly encouraging effective database interaction additionally reexsql adopts a treebased decoding strategy to support exploratory reasoning enabling dynamic expansion of alternative reasoning paths notably reexsql achieves 888 on spider and 649 on bird at the 7b scale surpassing the standard reasoning baseline by 27 and 26 respectively it also shows robustness achieving 852 on spiderrealistic with leading performance in addition its treestructured decoding improves efficiency and performance over linear decoding reducing inference time by 519 on the bird development set
http://arxiv.org/abs/2505.12763v1,2025-05-19T06:43:08Z,"Sunghwan Kim, Dongjin Kang, Taeyoon Kwon, Hyungjoo Chae, Dongha Lee, Jinyoung Yeo",rethinking reward model evaluation through the lens of reward overoptimization,reward models rms play a crucial role in reinforcement learning from human feedback rlhf aligning model behavior with human preferences however existing benchmarks for reward models show a weak correlation with the performance of optimized policies suggesting that they fail to accurately assess the true capabilities of rms to bridge this gap we explore several evaluation designs through the lens of reward overoptimizationtextemdash a phenomenon that captures both how well the reward model aligns with human preferences and the dynamics of the learning signal it provides to the policy the results highlight three key findings on how to construct a reliable benchmark i it is important to minimize differences between chosen and rejected responses beyond correctness ii evaluating reward models requires multiple comparisons across a wide range of chosen and rejected responses and iii given that reward models encounter responses with diverse representations responses should be sourced from a variety of models however we also observe that a extremely high correlation with degree of overoptimization leads to comparatively lower correlation with certain downstream performance thus when designing a benchmark it is desirable to use the degree of overoptimization as a useful tool rather than the end goal
http://arxiv.org/abs/2505.12727v1,2025-05-19T05:31:42Z,"Han Meng, Yancan Chen, Yunan Li, Yitian Yang, Jungup Lee, Renwen Zhang, Yi-Chieh Lee",what is stigma attributed to a theorygrounded expertannotated interview corpus for demystifying mentalhealth stigma,mentalhealth stigma remains a pervasive social problem that hampers treatmentseeking and recovery existing resources for training neural models to finely classify such stigma are limited relying primarily on socialmedia or synthetic data without theoretical underpinnings to remedy this gap we present an expertannotated theoryinformed corpus of humanchatbot interviews comprising 4141 snippets from 684 participants with documented sociocultural backgrounds our experiments benchmark stateoftheart neural models and empirically unpack the challenges of stigma detection this dataset can facilitate research on computationally detecting neutralizing and counteracting mentalhealth stigma
http://arxiv.org/abs/2505.12723v1,2025-05-19T05:25:29Z,"Haoyuan Wu, Rui Ming, Jilong Gao, Hangyu Zhao, Xueyi Chen, Yikai Yang, Haisheng Zheng, Zhuolun He, Bei Yu",onpolicy optimization with group equivalent preference for multiprogramming language understanding,large language models llms achieve remarkable performance in code generation tasks however a significant performance disparity persists between popular programming languages eg python c and others to address this capability gap we leverage the code translation task to train llms thereby facilitating the transfer of coding proficiency across diverse programming languages moreover we introduce oorl for training a novel reinforcement learning rl framework that integrates onpolicy and offpolicy strategies within oorl onpolicy rl is applied during code translation guided by a rulebased reward signal derived from unit tests complementing this coarsegrained rulebased reward we propose group equivalent preference optimization gepo a novel preference optimization method specifically gepo trains the llm using intermediate representations irs groups llms can be guided to discern irs equivalent to the source code from inequivalent ones while also utilizing signals about the mutual equivalence between irs within the group this process allows llms to capture nuanced aspects of code functionality by employing oorl for training with code translation tasks llms improve their recognition of code functionality and their understanding of the relationships between code implemented in different languages extensive experiments demonstrate that our oorl for llms training with code translation tasks achieves significant performance improvements on code benchmarks across multiple programming languages
http://arxiv.org/abs/2505.12718v1,2025-05-19T05:19:26Z,"Jingyang Peng, Wenyuan Shen, Jiarui Rao, Jionghao Lin",automated bias assessment in aigenerated educational content using ceat framework,recent advances in generative artificial intelligence genai have transformed educational content creation particularly in developing tutor training materials however biases embedded in aigenerated contentsuch as gender racial or national stereotypesraise significant ethical and educational concerns despite the growing use of genai systematic methods for detecting and evaluating such biases in educational materials remain limited this study proposes an automated bias assessment approach that integrates the contextualized embedding association test with a promptengineered word extraction method within a retrievalaugmented generation framework we applied this method to aigenerated texts used in tutor training lessons results show a high alignment between the automated and manually curated word sets with a pearson correlation coefficient of r 0993 indicating reliable and consistent bias assessment our method reduces human subjectivity and enhances fairness scalability and reproducibility in auditing genaiproduced educational content
http://arxiv.org/abs/2505.12717v1,2025-05-19T05:18:58Z,"Haoyuan Wu, Xueyi Chen, Rui Ming, Jilong Gao, Shoubo Hu, Zhuolun He, Bei Yu",totrl unlock llm treeofthoughts reasoning potential through puzzles solving,large language models llms demonstrate significant reasoning capabilities particularly through long chainofthought cot processes which can be elicited by reinforcement learning rl however prolonged cot reasoning presents limitations primarily verbose outputs due to excessive introspection the reasoning process in these llms often appears to follow a trialanderror methodology rather than a systematic logical deduction in contrast treeofthoughts tot offers a conceptually more advanced approach by modeling reasoning as an exploration within a tree structure this reasoning structure facilitates the parallel generation and evaluation of multiple reasoning branches allowing for the active identification assessment and pruning of unproductive paths this process can potentially lead to improved performance and reduced token costs building upon the long cot capability of llms we introduce treeofthoughts rl totrl a novel onpolicy rl framework with a rulebased reward totrl is designed to guide llms in developing the parallel tot strategy based on the sequential cot strategy furthermore we employ llms as players in a puzzle game during the totrl training process solving puzzle games inherently necessitates exploring interdependent choices and managing multiple constraints which requires the construction and exploration of a thought tree providing challenging tasks for cultivating the tot reasoning capability our empirical evaluations demonstrate that our totqwen38b model trained with our totrl achieves significant improvement in performance and reasoning efficiency on complex reasoning tasks
http://arxiv.org/abs/2505.12716v1,2025-05-19T05:16:21Z,"Taiqiang Wu, Runming Yang, Jiayi Li, Pengfei Hu, Ngai Wong, Yujiu Yang",shadowft tuning instruct via base,large language models llms consistently benefit from further finetuning on various tasks however we observe that directly tuning the instruct ie instruction tuned models often leads to marginal improvements and even performance degeneration notably paired base models the foundation for these instruct variants contain highly similar weight values ie less than 2 on average for llama 31 8b therefore we propose a novel shadowft framework to tune the instruct models by leveraging the corresponding base models the key insight is to finetune the base model and then directly graft the learned weight updates to the instruct model our proposed shadowft introduces no additional parameters is easy to implement and significantly improves performance we conduct extensive experiments on tuning mainstream llms such as qwen 3 and llama 3 series and evaluate them across 19 benchmarks covering coding reasoning and mathematical tasks experimental results demonstrate that shadowft consistently outperforms conventional fullparameter and parameterefficient tuning approaches further analyses indicate that shadowft can be applied to multimodal large language models mllms and combined with direct preference optimization dpo codes and weights are available at hrefhttpsgithubcomwutaiqiangshadowftgithub
http://arxiv.org/abs/2505.12692v1,2025-05-19T04:32:02Z,"Ziwei Xu, Udit Sanghi, Mohan Kankanhalli",bullying the machine how personas increase llm vulnerability,large language models llms are increasingly deployed in interactions where they are prompted to adopt personas this paper investigates whether such persona conditioning affects model safety under bullying an adversarial manipulation that applies psychological pressures in order to force the victim to comply to the attacker we introduce a simulation framework in which an attacker llm engages a victim llm using psychologically grounded bullying tactics while the victim adopts personas aligned with the big five personality traits experiments using multiple opensource llms and a wide range of adversarial goals reveal that certain persona configurations such as weakened agreeableness or conscientiousness significantly increase victims susceptibility to unsafe outputs bullying tactics involving emotional or sarcastic manipulation such as gaslighting and ridicule are particularly effective these findings suggest that personadriven interaction introduces a novel vector for safety risks in llms and highlight the need for personaaware safety evaluation and alignment strategies
http://arxiv.org/abs/2505.12680v1,2025-05-19T03:56:05Z,"Haoyu Zhao, Yihan Geng, Shange Tang, Yong Lin, Bohan Lyu, Hongzhou Lin, Chi Jin, Sanjeev Arora",ineqcomp benchmarking humanintuitive compositional reasoning in automated theorem proving on inequalities,llmbased formal proof assistants eg in lean hold great promise for automating mathematical discovery but beyond syntactic correctness do these systems truly understand mathematical structure as humans do we investigate this question through the lens of mathematical inequalities a fundamental tool across many domains while modern provers can solve basic inequalities we probe their ability to handle humanintuitive compositionality we introduce ineqcomp a benchmark built from elementary inequalities through systematic transformations including variable duplication algebraic rewriting and multistep composition although these problems remain easy for humans we find that most provers including goedel stp and kimina7b struggle significantly deepseekproverv27b shows relative robustness possibly because it is trained to decompose the problems into subproblems but still suffers a 20 performance drop pass32 strikingly performance remains poor for all models even when formal proofs of the constituent parts are provided in context revealing that the source of weakness is indeed in compositional reasoning our results expose a persisting gap between the generalization behavior of current ai provers and human mathematical intuition
http://arxiv.org/abs/2505.12662v1,2025-05-19T03:25:18Z,"Xukai Liu, Ye Liu, Shiwen Wu, Yanghai Zhang, Yihao Yuan, Kai Zhang, Qi Liu",know3rag a knowledgeaware rag framework with adaptive retrieval generation and filtering,recent advances in large language models llms have led to impressive progress in natural language generation yet their tendency to produce hallucinated or unsubstantiated content remains a critical concern to improve factual reliability retrievalaugmented generation rag integrates external knowledge during inference however existing rag systems face two major limitations 1 unreliable adaptive control due to limited external knowledge supervision and 2 hallucinations caused by inaccurate or irrelevant references to address these issues we propose know3rag a knowledgeaware rag framework that leverages structured knowledge from knowledge graphs kgs to guide three core stages of the rag process including retrieval generation and filtering specifically we introduce a knowledgeaware adaptive retrieval module that employs kg embedding to assess the confidence of the generated answer and determine retrieval necessity a knowledgeenhanced reference generation strategy that enriches queries with kgderived entities to improve generated reference relevance and a knowledgedriven reference filtering mechanism that ensures semantic alignment and factual accuracy of references experiments on multiple opendomain qa benchmarks demonstrate that know3rag consistently outperforms strong baselines significantly reducing hallucinations and enhancing answer reliability
http://arxiv.org/abs/2505.12654v1,2025-05-19T03:08:30Z,"Yuxin Lin, Yinglin Zheng, Ming Zeng, Wangzheng Shi",predicting turntaking and backchannel in humanmachine conversations using linguistic acoustic and visual signals,this paper addresses the gap in predicting turntaking and backchannel actions in humanmachine conversations using multimodal signals linguistic acoustic and visual to overcome the limitation of existing datasets we propose an automatic data collection pipeline that allows us to collect and annotate over 210 hours of human conversation videos from this we construct a multimodal facetoface mmf2f human conversation dataset including over 15m words and corresponding turntaking and backchannel annotations from approximately 20m frames additionally we present an endtoend framework that predicts the probability of turntaking and backchannel actions from multimodal signals the proposed model emphasizes the interrelation between modalities and supports any combination of text audio and video inputs making it adaptable to a variety of realistic scenarios our experiments show that our approach achieves stateoftheart performance on turntaking and backchannel prediction tasks achieving a 10 increase in f1score on turntaking and a 33 increase on backchannel prediction our dataset and code are publicly available online to ease of subsequent research
http://arxiv.org/abs/2505.12636v1,2025-05-19T02:44:57Z,"Jiakuan Xie, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao",revealing the deceptiveness of knowledge editing a mechanistic analysis of superficial editing,knowledge editing which aims to update the knowledge encoded in language models can be deceptive despite the fact that many existing knowledge editing algorithms achieve nearperfect performance on conventional metrics the models edited by them are still prone to generating original knowledge this paper introduces the concept of superficial editing to describe this phenomenon our comprehensive evaluation reveals that this issue presents a significant challenge to existing algorithms through systematic investigation we identify and validate two key factors contributing to this issue 1 the residual stream at the last subject position in earlier layers and 2 specific attention modules in later layers notably certain attention heads in later layers along with specific left singular vectors in their output matrices encapsulate the original knowledge and exhibit a causal relationship with superficial editing furthermore we extend our analysis to the task of superficial unlearning where we observe consistent patterns in the behavior of specific attention heads and their corresponding left singular vectors thereby demonstrating the robustness and broader applicability of our methodology and conclusions our code is available here
http://arxiv.org/abs/2505.12632v1,2025-05-19T02:39:03Z,"Yunseok Jang, Yeda Song, Sungryull Sohn, Lajanugen Logeswaran, Tiange Luo, Dong-Ki Kim, Kyunghoon Bae, Honglak Lee",scalable videotodataset generation for crossplatform mobile agents,recent advancements in large language models llms and visionlanguage models vlms have sparked significant interest in developing gui visual agents we introduce monday mobile os navigation task dataset for agents from youtube a largescale dataset of 313k annotated frames from 20k instructional videos capturing diverse realworld mobile os navigation across multiple platforms models that include monday in their pretraining phases demonstrate robust crossplatform generalization capabilities consistently outperforming models trained on existing single os datasets while achieving an average performance gain of 1811p on an unseen mobile os platform to enable continuous dataset expansion as mobile platforms evolve we present an automated framework that leverages publicly available video content to create comprehensive task datasets without manual annotation our framework comprises robust ocrbased scene detection 9504 f1score nearperfect ui element detection 9987 hit ratio and novel multistep action identification to extract reliable action sequences across diverse interface configurations we contribute both the monday dataset and our automated collection framework to facilitate future research in mobile os navigation
http://arxiv.org/abs/2505.12629v1,2025-05-19T02:35:53Z,"Yuchang Sun, Yanxi Chen, Yaliang Li, Bolin Ding",enhancing latent computation in transformers with latent tokens,augmenting large language models llms with auxiliary tokens has emerged as a promising strategy for enhancing model performance in this work we introduce a lightweight method termed latent tokens these are dummy tokens that may be noninterpretable in natural language but steer the autoregressive decoding process of a transformerbased llm via the attention mechanism the proposed latent tokens can be seamlessly integrated with a pretrained transformer trained in a parameterefficient manner and applied flexibly at inference time while adding minimal complexity overhead to the existing infrastructure of standard transformers we propose several hypotheses about the underlying mechanisms of latent tokens and design synthetic tasks accordingly to verify them numerical results confirm that the proposed method noticeably outperforms the baselines particularly in the outofdistribution generalization scenarios highlighting its potential in improving the adaptability of llms
http://arxiv.org/abs/2505.12625v1,2025-05-19T02:16:56Z,"Ali Naseh, Harsh Chaudhari, Jaechul Roh, Mingshi Wu, Alina Oprea, Amir Houmansadr",r1dacted investigating local censorship in deepseeks r1 language model,deepseek recently released r1 a highperforming large language model llm optimized for reasoning tasks despite its efficient training pipeline r1 achieves competitive performance even surpassing leading reasoning models like openais o1 on several benchmarks however emerging reports suggest that r1 refuses to answer certain prompts related to politically sensitive topics in china while existing llms often implement safeguards to avoid generating harmful or offensive outputs r1 represents a notable shift exhibiting censorshiplike behavior on politically charged queries in this paper we investigate this phenomenon by first introducing a largescale set of heavily curated prompts that get censored by r1 covering a range of politically sensitive topics but are not censored by other models we then conduct a comprehensive analysis of r1s censorship patterns examining their consistency triggers and variations across topics prompt phrasing and context beyond englishlanguage queries we explore censorship behavior in other languages we also investigate the transferability of censorship to models distilled from the r1 language model finally we propose techniques for bypassing or removing this censorship our findings reveal possible additional censorship integration likely shaped by design choices during training or alignment raising concerns about transparency bias and governance in language model deployment
http://arxiv.org/abs/2505.12621v1,2025-05-19T02:08:20Z,"João Eduardo Batista, Emil Vatai, Mohamed Wahib",think before you attribute improving the performance of llms attribution systems,large language models llms are increasingly applied in various science domains yet their broader adoption remains constrained by a critical challenge the lack of trustworthy verifiable outputs current llms often generate answers without reliable source attribution or worse with incorrect attributions posing a barrier to their use in scientific and highstakes settings where traceability and accountability are nonnegotiable to be reliable attribution systems need high accuracy and retrieve data with short lengths ie attribute to a sentence within a document rather than a whole document we propose a sentencelevel preattribution step for retrieveaugmented generation rag systems that classify sentences into three categories not attributable attributable to a single quote and attributable to multiple quotes by separating sentences before attribution a proper attribution method can be selected for the type of sentence or the attribution can be skipped altogether our results indicate that classifiers are wellsuited for this task in this work we propose a preattribution step to reduce the computational complexity of attribution provide a clean version of the hagrid dataset and provide an endtoend attribution system that works out of the box
http://arxiv.org/abs/2505.12616v1,2025-05-19T01:58:22Z,"Shujauddin Syed, Ted Pedersen",duluth at semeval2025 task 7 tfidf with optimized vector dimensions for multilingual factchecked claim retrieval,this paper presents the duluth approach to the semeval2025 task 7 on multilingual and crosslingual factchecked claim retrieval we implemented a tfidfbased retrieval system with experimentation on vector dimensions and tokenization strategies our bestperforming configuration used wordlevel tokenization with a vocabulary size of 15000 features achieving an average success10 score of 078 on the development set and 069 on the test set across ten languages our system showed stronger performance on higherresource languages but still lagged significantly behind the topranked system which achieved 096 average success10 our findings suggest that though advanced neural architectures are increasingly dominant in multilingual retrieval tasks properly optimized traditional methods like tfidf remain competitive baselines especially in limited compute resource scenarios
http://arxiv.org/abs/2505.12594v1,2025-05-19T01:14:57Z,"Tiankai Yang, Junjun Liu, Wingchun Siu, Jiahang Wang, Zhuangzhuang Qian, Chanjuan Song, Cheng Cheng, Xiyang Hu, Yue Zhao",adagent a multiagent framework for endtoend anomaly detection,anomaly detection ad is essential in areas such as fraud detection network monitoring and scientific research however the diversity of data modalities and the increasing number of specialized ad libraries pose challenges for nonexpert users who lack indepth libraryspecific knowledge and advanced programming skills to tackle this we present adagent an llmdriven multiagent framework that turns naturallanguage instructions into fully executable ad pipelines adagent coordinates specialized agents for intent parsing data preparation library and model selection documentation mining and iterative code generation and debugging using a shared shortterm workspace and a longterm cache the agents integrate popular ad libraries like pyod pygod and tslib into a unified workflow experiments demonstrate that adagent produces reliable scripts and recommends competitive models across libraries the system is opensourced to support further research and practical applications in ad
http://arxiv.org/abs/2505.12592v1,2025-05-19T01:08:26Z,"Sullam Jeoung, Yueyan Chen, Yi Zhang, Shuai Wang, Haibo Ding, Lin Lee Cheong",promptprism a linguisticallyinspired taxonomy for prompts,prompts are the interface for eliciting the capabilities of large language models llms understanding their structure and components is critical for analyzing llm behavior and optimizing performance however the field lacks a comprehensive framework for systematic prompt analysis and understanding we introduce promptprism a linguisticallyinspired taxonomy that enables prompt analysis across three hierarchical levels functional structure semantic component and syntactic pattern we show the practical utility of promptprism by applying it to three applications 1 a taxonomyguided prompt refinement approach that automatically improves prompt quality and enhances model performance across a range of tasks 2 a multidimensional dataset profiling method that extracts and aggregates structural semantic and syntactic characteristics from prompt datasets enabling comprehensive analysis of prompt distributions and patterns 3 a controlled experimental framework for prompt sensitivity analysis by quantifying the impact of semantic reordering and delimiter modifications on llm performance our experimental results validate the effectiveness of our taxonomy across these applications demonstrating that promptprism provides a foundation for refining profiling and analyzing prompts
http://arxiv.org/abs/2505.12587v1,2025-05-19T00:50:49Z,"Aditeya Baral, Allen George Ajith, Roshan Nayak, Mrityunjay Abhijeet Bhanja",cmlformer a dual decoder transformer with switching point learning for codemixed language modeling,codemixed languages characterized by frequent withinsentence language transitions present structural challenges that standard language models fail to address in this work we propose cmlformer an enhanced multilayer dualdecoder transformer with a shared encoder and synchronized decoder crossattention designed to model the linguistic and semantic dynamics of codemixed text cmlformer is pretrained on an augmented hinglish corpus with switching point and translation annotations with multiple new objectives specifically aimed at capturing switching behavior crosslingual structure and codemixing complexity our experiments show that cmlformer improves f1 score precision and accuracy over other approaches on the hasoc2021 benchmark under select pretraining setups attention analyses further show that it can identify and attend to switching points validating its sensitivity to codemixed structure these results demonstrate the effectiveness of cmlformers architecture and multitask pretraining strategy for modeling codemixed languages
http://arxiv.org/abs/2505.12584v1,2025-05-19T00:14:43Z,"Omar Mahmoud, Buddhika Laknath Semage, Thommen George Karimpanal, Santu Rana",improving multilingual language models by aligning representations through steering,in this paper we investigate how large language models llms process nonenglish tokens within their layer representations an open question despite significant advancements in the field using representation steering specifically by adding a learned vector to a single model layers activations we demonstrate that steering a single model layer can notably enhance performance our analysis shows that this approach achieves results comparable to translation baselines and surpasses state of the art prompt optimization methods additionally we highlight how advanced techniques like supervised fine tuning textscsft and reinforcement learning from human feedback textscrlhf improve multilingual capabilities by altering representation spaces we further illustrate how these methods align with our approach to reshaping llms layer representations
http://arxiv.org/abs/2505.12572v1,2025-05-18T23:20:01Z,"Hanwen Shen, Ting Ying",measuring information distortion in hierarchical ultra long novel generationthe optimal expansion ratio,writing novels with large language models llms raises a critical question how much humanauthored outline is necessary to generate highquality millionword novels while frameworks such as dome planwrite and long writer have improved stylistic coherence and logical consistency they primarily target shorter novels 10k100k words leaving ultralong generation largely unexplored drawing on insights from recent text compression methods like llmzip and llm2vec we conduct an informationtheoretic analysis that quantifies distortion occurring when llms compress and reconstruct ultralong novels under varying compressionexpansion ratios we introduce a hierarchical twostage generation pipeline outline detailed outline manuscript and find an optimal outline length that balances information preservation with human effort through extensive experimentation with chinese novels we establish that a twostage hierarchical outline approach significantly reduces semantic distortion compared to singlestage methods our findings provide empiricallygrounded guidance for authors and researchers collaborating with llms to create millionword novels
http://arxiv.org/abs/2505.12568v1,2025-05-18T23:04:49Z,"Lekang Jiang, Chengzu Li, Stephan Goetz",enriching patent claim generation with european patent dataset,drafting patent claims is timeintensive costly and requires professional skill therefore researchers have investigated large language models llms to assist inventors in writing claims however existing work has largely relied on datasets from the united states patent and trademark office uspto to enlarge research scope regarding various jurisdictions drafting conventions and legal standards we introduce epd a european patent dataset epd presents rich textual data and structured metadata to support multiple patentrelated tasks including claim generation this dataset enriches the field in three critical aspects 1 jurisdictional diversity patents from different offices vary in legal and drafting conventions epd fills a critical gap by providing a benchmark for european patents to enable more comprehensive evaluation 2 quality improvement epd offers highquality granted patents with finalized and legally approved texts whereas others consist of patent applications that are unexamined or provisional experiments show that llms finetuned on epd significantly outperform those trained on previous datasets and even gpt4o in claim quality and crossdomain generalization 3 realworld simulation we propose a difficult subset of epd to better reflect realworld challenges of claim generation results reveal that all tested llms perform substantially worse on these challenging samples which highlights the need for future research
http://arxiv.org/abs/2505.12565v1,2025-05-18T22:52:39Z,"Carl Edwards, Chi Han, Gawon Lee, Thao Nguyen, Bowen Jin, Chetan Kumar Prasad, Sara Szymkuć, Bartosz A. Grzybowski, Ying Diao, Jiawei Han, Ge Liu, Hao Peng, Martin D. Burke, Heng Ji",mclm a functioninfused and synthesisfriendly modular chemical language model,despite their ability to understand chemical knowledge and accurately generate sequential representations large language models llms remain limited in their capacity to propose novel molecules with druglike properties in addition the molecules that llms propose can often be challenging to make in the lab to more effectively enable the discovery of functional small molecules llms need to learn a molecular language however llms are currently limited by encoding molecules from atoms in this paper we argue that just like tokenizing texts into subword tokens instead of characters molecules should be decomposed and reassembled at the level of functional building blocks ie parts of molecules that bring unique functions and serve as effective building blocks for realworld automated laboratory synthesis this motivates us to propose mclm a modular chemicallanguage model tokenizing molecules into building blocks and learning a bilingual language model of both natural language descriptions of functions and molecule building blocks by reasoning on such functional building blocks mclm guarantees to generate efficiently synthesizable molecules thanks to recent progress in blockbased chemistry while also improving the functions of molecules in a principled manner in experiments on 430 fdaapproved drugs we find mclm capable of significantly improving 5 out of 6 chemical functions critical to determining drug potentials more importantly mclm can reason on multiple functions and improve the fdarejected drugs fallen angels over multiple iterations to greatly improve their shortcomings
http://arxiv.org/abs/2505.12560v1,2025-05-18T22:13:32Z,Hiram Ring,the taggedpbc annotating a massive parallel corpus for crosslinguistic investigations,existing datasets available for crosslinguistic investigations have tended to focus on large amounts of data for a small group of languages or a small amount of data for a large number of languages this means that claims based on these datasets are limited in what they reveal about universal properties of the human language faculty while this has begun to change through the efforts of projects seeking to develop tagged corpora for a large number of languages such efforts are still constrained by limits on resources the current paper reports on a large automatically tagged parallel dataset which has been developed to partially address this issue the taggedpbc contains more than 1800 sentences of postagged parallel text data from over 1500 languages representing 133 language families and 111 isolates dwarfing previously available resources the accuracy of tags in this dataset is shown to correlate well with both existing sota taggers for highresource languages spacy trankit as well as handtagged corpora universal dependencies treebanks additionally a novel measure derived from this dataset the n1 ratio correlates with expert determinations of word order in three typological databases wals grambank autotyp such that a gaussian naive bayes classifier trained on this feature can accurately identify basic word order for languages not in those databases while much work is still needed to expand and develop this dataset the taggedpbc is an important step to enable corpusbased crosslinguistic investigations and is made available for research and collaboration via github
http://arxiv.org/abs/2505.12546v1,2025-05-18T21:06:32Z,"A. Feder Cooper, Aaron Gokaslan, Amy B. Cyphert, Christopher De Sa, Mark A. Lemley, Daniel E. Ho, Percy Liang",extracting memorized pieces of copyrighted books from openweight language models,plaintiffs and defendants in copyright lawsuits over generative ai often make sweeping opposing claims about the extent to which large language models llms have memorized plaintiffs protected expression drawing on adversarial ml and copyright law we show that these polarized positions dramatically oversimplify the relationship between memorization and copyright to do so we leverage a recent probabilistic extraction technique to extract pieces of the books3 dataset from 13 openweight llms through numerous experiments we show that its possible to extract substantial parts of at least some books from different llms this is evidence that the llms have memorized the extracted text this memorized content is copied inside the model parameters but the results are complicated the extent of memorization varies both by model and by book with our specific experiments we find that the largest llms dont memorize most books either in whole or in part however we also find that llama 31 70b memorizes some books like harry potter and 1984 almost entirely we discuss why our results have significant implications for copyright cases though not ones that unambiguously favor either side
http://arxiv.org/abs/2505.12545v1,2025-05-18T21:02:30Z,"Yang Zhao, Pu Wang, Yibo Zhao, Hongru Du,  Hao,  Yang",towards reliable and interpretable traffic crash pattern prediction and safety interventions using customized large language models,predicting crash events is crucial for understanding crash distributions and their contributing factors thereby enabling the design of proactive traffic safety policy interventions however existing methods struggle to interpret the complex interplay among various sources of traffic crash data including numeric characteristics textual reports crash imagery environmental conditions and driver behavior records as a result they often fail to capture the rich semantic information and intricate interrelationships embedded in these diverse data sources limiting their ability to identify critical crash risk factors in this research we propose trafficsafe a framework that adapts llms to reframe crash prediction and feature attribution as textbased reasoning a multimodal crash dataset including 58903 realworld reports together with belonged infrastructure environmental driver and vehicle information is collected and textualized into trafficsafe event dataset by customizing and finetuning llms on this dataset the trafficsafe llm achieves a 42 average improvement in f1score over baselines to interpret these predictions and uncover contributing factors we introduce trafficsafe attribution a sentencelevel feature attribution framework enabling conditional risk analysis findings show that alcoholimpaired driving is the leading factor in severe crashes with aggressive and impairmentrelated behaviors having nearly twice the contribution for severe crashes compared to other driver behaviors furthermore trafficsafe attribution highlights pivotal features during model training guiding strategic crash data collection for iterative performance improvements the proposed trafficsafe offers a transformative leap in traffic safety research providing a blueprint for translating advanced ai technologies into responsible actionable and lifesaving outcomes
http://arxiv.org/abs/2505.12543v1,2025-05-18T20:53:41Z,"Md Mehrab Tanjim, Yeonjun In, Xiang Chen, Victor S. Bursztyn, Ryan A. Rossi, Sungchul Kim, Guang-Jie Ren, Vaishnavi Muppala, Shun Jiang, Yongsung Kim, Chanyoung Park",disambiguation in conversational question answering in the era of llm a survey,ambiguity remains a fundamental challenge in natural language processing nlp due to the inherent complexity and flexibility of human language with the advent of large language models llms addressing ambiguity has become even more critical due to their expanded capabilities and applications in the context of conversational question answering cqa this paper explores the definition forms and implications of ambiguity for language driven systems particularly in the context of llms we define key terms and concepts categorize various disambiguation approaches enabled by llms and provide a comparative analysis of their advantages and disadvantages we also explore publicly available datasets for benchmarking ambiguity detection and resolution techniques and highlight their relevance for ongoing research finally we identify open problems and future research directions proposing areas for further investigation by offering a comprehensive review of current research on ambiguities and disambiguation with llms we aim to contribute to the development of more robust and reliable language systems
http://arxiv.org/abs/2505.12533v1,2025-05-18T20:22:14Z,"Varvara Arzt, Allan Hanbury, Michael Wiegand, Gábor Recski, Terra Blevins",relation extraction or pattern matching unravelling the generalisation limits of language models for biographical re,analysing the generalisation capabilities of relation extraction re models is crucial for assessing whether they learn robust relational patterns or rely on spurious correlations our crossdataset experiments find that re models struggle with unseen data even within similar domains notably higher intradataset performance does not indicate better transferability instead often signaling overfitting to datasetspecific artefacts our results also show that data quality rather than lexical similarity is key to robust transfer and the choice of optimal adaptation strategy depends on the quality of data available while finetuning yields the best crossdataset performance with highquality data fewshot incontext learning icl is more effective with noisier data however even in these cases zeroshot baselines occasionally outperform all crossdataset results structural issues in re benchmarks such as singlerelation per sample constraints and nonstandardised negative class definitions further hinder model transferability
http://arxiv.org/abs/2505.12531v1,2025-05-18T20:04:59Z,"Navid Madani, Rohini Srihari",escjudge a framework for comparing emotional support conversational agents,large language models llms increasingly power mentalhealth chatbots yet the field still lacks a scalable theorygrounded way to decide which model is most effective to deploy we present escjudge the first endtoend evaluation framework that i grounds headtohead comparisons of emotionalsupport llms in clara hills established explorationinsightaction counseling model providing a structured and interpretable view of performance and ii fully automates the evaluation pipeline at scale escjudge operates in three stages first it synthesizes realistic helpseeker roles by sampling empirically salient attributes such as stressors personality and life history second it has two candidate support agents conduct separate sessions with the same role isolating modelspecific strategies and third it asks a specialized judge llm to express pairwise preferences across rubricanchored skills that span the exploration insight and action spectrum in our study escjudge matched phdlevel annotators on 85 percent of exploration 83 percent of insight and 86 percent of action decisions demonstrating humanlevel reliability at a fraction of the cost all code prompts synthetic roles transcripts and judgment scripts are released to promote transparent progress in emotionally supportive ai
http://arxiv.org/abs/2505.12511v1,2025-05-18T18:08:35Z,"Yanting Li, Jiyue Jiang, Zikang Wang, Ziqian Lin, Dongchen He, Yuheng Shan, Yanruisheng Shao, Jiayi Li, Xiangyu Shi, Jiuming Wang, Yanyu Chen, Yimin Fan, Han Li, Yu Li",dsprogen a dualstructure deep language model for functional protein design,inverse protein folding ipf is a critical subtask in the field of protein design aiming to engineer amino acid sequences capable of folding correctly into a specified threedimensional 3d conformation although substantial progress has been achieved in recent years existing methods generally rely on either backbone coordinates or molecular surface features alone which restricts their ability to fully capture the complex chemical and geometric constraints necessary for precise sequence prediction to address this limitation we present dsprogen a dualstructure deep language model for functional protein design which integrates both backbone geometry and surfacelevel representations by incorporating backbone coordinates as well as surface chemical and geometric descriptors into a nextaminoacid prediction paradigm dsprogen is able to generate functionally relevant and structurally stable sequences while satisfying both global and local conformational constraints on the pride dataset dsprogen attains the current stateoftheart recovery rate of 6147 demonstrating the synergistic advantage of multimodal structural encoding in protein design furthermore dsprogen excels in predicting interactions with a variety of biological partners including ligands ions and rna confirming its robust functional retention capabilities
http://arxiv.org/abs/2505.12507v1,2025-05-18T17:55:45Z,"Xu Zheng, Zhuomin Chen, Esteban Schafir, Sipeng Chen, Hojat Allah Salehi, Haifeng Chen, Farhad Shirani, Wei Cheng, Dongsheng Luo",lmotifs an explainable framework for machinegenerated texts detection,the impressive ability of large language models to generate natural text across various tasks has led to critical challenges in authorship authentication although numerous detection methods have been developed to differentiate between machinegenerated texts mgt and humangenerated texts hgt the explainability of these methods remains a significant gap traditional explainability techniques often fall short in capturing the complex word relationships that distinguish hgt from mgt to address this limitation we present lmotifs a novel explainable framework for mgt detection inspired by probabilistic graphical models we provide a theoretical rationale for the effectiveness lmotifs utilizes explainable graph neural networks to achieve both accurate detection and interpretability the lmotifs pipeline operates in three key stages first it transforms text into graphs based on word cooccurrence to represent lexical dependencies second graph neural networks are used for prediction and third a posthoc explainability method extracts interpretable motifs offering multilevel explanations from individual words to sentence structures extensive experiments on multiple benchmark datasets demonstrate the comparable performance of lmotifs the empirical evaluation of the extracted explainable motifs confirms their effectiveness in differentiating hgt and mgt furthermore qualitative analysis reveals distinct and visible linguistic fingerprints characteristic of mgt
http://arxiv.org/abs/2505.12495v1,2025-05-18T16:46:39Z,"Nikita Tatarinov, Vidhyakshaya Kannan, Haricharana Srinivasa, Arnav Raj, Harpreet Singh Anand, Varun Singh, Aditya Luthra, Ravij Lade, Agam Shah, Sudheer Chava",kgqagen a knowledgegraphbased framework for systematic question generation and longcontext llm evaluation,the increasing context length of modern language models has created a need for evaluating their ability to retrieve and process information across extensive documents while existing benchmarks test longcontext capabilities they often lack a structured way to systematically vary question complexity we introduce kgqagen knowledgegraphbased questionanswer generation a framework that 1 extracts qa pairs at multiple complexity levels 2 by leveraging structured representations of financial agreements 3 along three key dimensions multihop retrieval set operations and answer plurality enabling finegrained assessment of model performance across controlled difficulty levels using this framework we construct a dataset of 20139 qa pairs the largest number among the longcontext benchmarks and opensource a part of it we evaluate 13 proprietary and opensource llms and observe that even the bestperforming models are struggling with setbased comparisons and multihop logical inference our analysis reveals systematic failure modes tied to semantic misinterpretation and inability to handle implicit relations
http://arxiv.org/abs/2505.12476v1,2025-05-18T15:52:57Z,"Xiao Long, Liansheng Zhuang, Chen Shen, Shaotian Yan, Yifei Li, Shafei Wang",enhancing large language models with rewardguided tree search for knowledge graph question and answering,recently large language models llms have demonstrated impressive performance in knowledge graph question answering kgqa tasks which aim to find answers based on knowledge graphs kgs for natural language questions existing llmsbased kgqa methods typically follow the graph retrievalaugmented generation graphrag paradigm which first retrieves reasoning paths from the large kgs and then generates the answers based on them however these methods emphasize the exploration of new optimal reasoning paths in kgs while ignoring the exploitation of historical reasoning paths which may lead to suboptimal reasoning paths additionally the complex semantics contained in questions may lead to the retrieval of inaccurate reasoning paths to address these issues this paper proposes a novel and trainingfree framework for kgqa tasks called rewardguided tree search on graph rtsog rtsog decomposes an original question into a series of simpler and welldefined subquestions to handle the complex semantics then a selfcritic monte carlo tree search scmcts guided by a reward model is introduced to iteratively retrieve weighted reasoning paths as contextual knowledge finally it stacks the weighted reasoning paths according to their weights to generate the final answers extensive experiments on four datasets demonstrate the effectiveness of rtsog notably it achieves 87 and 70 performance improvement over the stateoftheart method on the grailqa and the webqsp respectively
http://arxiv.org/abs/2505.12474v1,2025-05-18T15:52:24Z,"Weixiao Zhou, Junnan Zhu, Gengyao Li, Xianfu Cheng, Xinnian Liang, Feifei Zhai, Zhoujun Li",what are they talking about benchmarking large language models for knowledgegrounded discussion summarization,in this work we investigate the performance of llms on a new task that requires combining discussion with background knowledge for summarization this aims to address the limitation of outside observer confusion in existing dialogue summarization systems due to their reliance solely on discussion information to achieve this we model the task output as background and opinion summaries and define two standardized summarization patterns to support assessment we introduce the first benchmark comprising highquality samples consistently annotated by human experts and propose a novel hierarchical evaluation framework with finegrained interpretable metrics we evaluate 12 llms under structuredprompt and selfreflection paradigms our findings reveal 1 llms struggle with background summary retrieval generation and opinion summary integration 2 even top llms achieve less than 69 average performance across both patterns 3 current llms lack adequate selfevaluation and selfcorrection capabilities for this task
http://arxiv.org/abs/2505.12457v1,2025-05-18T15:14:58Z,"Yang Zhao, Kai Xiong, Xiao Ding, Li Du,  YangouOuyang, Zhouhao Sun, Jiannan Guan, Wenbin Zhang, Bin Liu, Dong Hu, Bing Qin, Ting Liu",uforl uncertaintyfocused optimization for efficient reinforcement learning data selection,scaling rl for llms is computationally expensive largely due to multisampling for policy optimization and evaluation making efficient data selection crucial inspired by the zone of proximal development zpd theory we hypothesize llms learn best from data within their potential comprehension zone addressing the limitation of conventional computationally intensive multisampling methods for data assessment we introduce uforl this novel framework uses a computationally efficient singlepass uncertainty estimation to identify informative data instances achieving up to 185x faster data evaluation uforl leverages this metric to select data within the estimated zpd for training experiments show that training with just 10 of data selected by uforl yields performance comparable to or surpassing fulldata training reducing overall training time by up to 16x while enhancing stability and generalization uforl offers a practical and highly efficient strategy for scaling rl finetuning of llms by focusing learning on valuable data
http://arxiv.org/abs/2505.12454v1,2025-05-18T15:10:04Z,"Yuyang Ding, Dan Qiao, Juntao Li, Jiajie Xu, Pingfu Chao, Xiaofang Zhou, Min Zhang",towards dsner unveiling and addressing latent noise in distant annotations,distantly supervised named entity recognition dsner has emerged as a cheap and convenient alternative to traditional human annotation methods enabling the automatic generation of training data by aligning text with external resources despite the many efforts in noise measurement methods few works focus on the latent noise distribution between different distant annotation methods in this work we explore the effectiveness and robustness of dsner by two aspects 1 distant annotation techniques which encompasses both traditional rulebased methods and the innovative large language model supervision approach and 2 noise assessment for which we introduce a novel framework this framework addresses the challenges by distinctly categorizing them into the unlabeledentity problem uep and the noisyentity problem nep subsequently providing specialized solutions for each our proposed method achieves significant improvements on eight realworld distant supervision datasets originating from three different data sources and involving four distinct annotation techniques confirming its superiority over current stateoftheart methods
http://arxiv.org/abs/2505.12452v1,2025-05-18T15:04:02Z,"Siyang Wu, Honglin Bao, Nadav Kunievsky, James A. Evans",introspective growth automatically advancing llm expertise in technology judgment,large language models llms increasingly demonstrate signs of conceptual understanding yet much of their internal knowledge remains latent loosely structured and difficult to access or evaluate we propose selfquestioning as a lightweight and scalable strategy to improve llms understanding particularly in domains where success depends on finegrained semantic distinctions to evaluate this approach we introduce a challenging new benchmark of 13 million post2015 computer science patent pairs characterized by dense technical jargon and strategically complex writing the benchmark centers on a pairwise differentiation task can a model distinguish between closely related but substantively different inventions we show that prompting llms to generate and answer their own questions targeting the background knowledge required for the task significantly improves performance these selfgenerated questions and answers activate otherwise underutilized internal knowledge allowing llms to retrieve answers from external scientific texts further enhances performance suggesting that model knowledge is compressed and lacks the full richness of the training data we also find that chainofthought prompting and selfquestioning converge though selfquestioning remains more effective for improving understanding of technical concepts notably we uncover an asymmetry in prompting smaller models often generate more fundamental more openended betteraligned questions for midsized models than large models with better understanding do revealing a new strategy for crossmodel collaboration altogether our findings establish selfquestioning as both a practical mechanism for automatically improving llm comprehension especially in domains with sparse and underrepresented knowledge and a diagnostic probe of how internal and external knowledge are organized
http://arxiv.org/abs/2505.12442v1,2025-05-18T14:31:45Z,"Liwen Wang, Wenxuan Wang, Shuai Wang, Zongjie Li, Zhenlan Ji, Zongyi Lyu, Daoyuan Wu, Shing-Chi Cheung",ip leakage attacks targeting llmbased multiagent systems,the rapid advancement of large language models llms has led to the emergence of multiagent systems mas to perform complex tasks through collaboration however the intricate nature of mas including their architecture and agent interactions raises significant concerns regarding intellectual property ip protection in this paper we introduce masleak a novel attack framework designed to extract sensitive information from mas applications masleak targets a practical blackbox setting where the adversary has no prior knowledge of the mas architecture or agent configurations the adversary can only interact with the mas through its public api submitting attack query and observing outputs from the final agent inspired by how computer worms propagate and infect vulnerable network hosts masleak carefully crafts adversarial query to elicit propagate and retain responses from each mas agent that reveal a full set of proprietary components including the number of agents system topology system prompts task instructions and tool usages we construct the first synthetic dataset of mas applications with 810 applications and also evaluate masleak against realworld mas applications including coze and crewai masleak achieves high accuracy in extracting mas ip with an average attack success rate of 87 for system prompts and task instructions and 92 for system architecture in most cases we conclude by discussing the implications of our findings and the potential defenses
http://arxiv.org/abs/2505.12439v1,2025-05-18T14:21:56Z,"Jinming Zhang, Yunfei Long",learning to play like humans a framework for llm adaptation in interactive fiction games,interactive fiction games if games are where players interact through natural language commands while recent advances in artificial intelligence agents have reignited interest in if games as a domain for studying decisionmaking existing approaches prioritize taskspecific performance metrics over humanlike comprehension of narrative context and gameplay logic this work presents a cognitively inspired framework that guides large language models llms to learn and play if games systematically our proposed learning to play like humans lplh framework integrates three key components 1 structured map building to capture spatial and narrative relationships 2 action learning to identify contextappropriate commands and 3 feedbackdriven experience analysis to refine decisionmaking over time by aligning llmsbased agents behavior with narrative intent and commonsense constraints lplh moves beyond purely exploratory strategies to deliver more interpretable humanlike performance crucially this approach draws on cognitive science principles to more closely simulate how human players read interpret and respond within narrative worlds as a result lplh reframes the if games challenge as a learning problem for llmsbased agents offering a new path toward robust contextaware gameplay in complex textbased environments
http://arxiv.org/abs/2505.12423v1,2025-05-18T13:47:44Z,"Wenqiao Zhu, Chao Xu, Lulu Wang, Jun Wu",psc extending context window of large language models via phase shift calibration,rotary position embedding rope is an efficient position encoding approach and is widely utilized in numerous large language models llms recently a lot of methods have been put forward to further expand the context window based on rope the core concept of those methods is to predefine or search for a set of factors to rescale the base frequencies of rope nevertheless it is quite a challenge for existing methods to predefine an optimal factor due to the exponential search space in view of this we introduce psc phase shift calibration a small module for calibrating the frequencies predefined by existing methods with the employment of psc we demonstrate that many existing methods can be further enhanced like pi yarn and longrope we conducted extensive experiments across multiple models and tasks the results demonstrate that 1 when psc is enabled the comparative reductions in perplexity increase as the context window size is varied from 16k to 32k and up to 64k 2 our approach is broadly applicable and exhibits robustness across a variety of models and tasks the code can be found at httpsgithubcomwnqzhupsc
http://arxiv.org/abs/2505.12415v1,2025-05-18T13:40:18Z,"Zhenhe Wu, Jian Yang, Jiaheng Liu, Xianjie Wu, Changzai Pan, Jie Zhang, Yu Zhao, Shuangyong Song, Yongxiang Li, Zhoujun Li",tabler1 regionbased reinforcement learning for table understanding,tables present unique challenges for language models due to their structured rowcolumn interactions necessitating specialized approaches for effective comprehension while large language models llms have demonstrated potential in table reasoning through prompting and techniques like chainofthought cot and programofthought pot optimizing their performance for table question answering remains underexplored in this paper we introduce regionbased tabler1 a novel reinforcement learning approach that enhances llm table understanding by integrating region evidence into reasoning steps our method employs regionenhanced supervised finetuning resft to guide models in identifying relevant table regions before generating answers incorporating textual symbolic and programbased reasoning additionally tableaware group relative policy optimization tarpo introduces a mixed reward system to dynamically balance region accuracy and answer correctness with decaying region rewards and consistency penalties to align reasoning steps experiments show that tabler1 achieves an average performance improvement of 1436 points across multiple base models on three benchmark datasets even outperforming baseline models with ten times the parameters while tarpo reduces response token consumption by 675 compared to grpo significantly advancing llm capabilities in efficient tabular reasoning
http://arxiv.org/abs/2505.12405v1,2025-05-18T13:16:30Z,"Konstantinos Xylogiannopoulos, Petros Xanthopoulos, Panagiotis Karampelas, Georgios Bakamitsos",the power of text similarity in identifying aillm paraphrased documents the case of bbc news articles and chatgpt,generative ai paraphrased text can be used for copyright infringement and the ai paraphrased content can deprive substantial revenue from original content creators despite this recent surge of malicious use of generative ai there are few academic publications that research this threat in this article we demonstrate the ability of patternbased similarity detection for ai paraphrased news recognition we propose an algorithmic scheme which is not limited to detect whether an article is an ai paraphrase but more importantly to identify that the source of infringement is the chatgpt the proposed method is tested with a benchmark dataset specifically created for this task that incorporates real articles from bbc incorporating a total of 2224 articles across five different news categories as well as 2224 paraphrased articles created with chatgpt results show that our pattern similaritybased method that makes no use of deep learning can detect chatgpt assisted paraphrased articles at percentages 9623 for accuracy 9625 for precision 9621 for sensitivity 9625 for specificity and 9623 for f1 score
http://arxiv.org/abs/2505.12398v1,2025-05-18T12:51:55Z,"Yepeng Weng, Qiao Hu, Xujie Chen, Li Liu, Dianwen Mei, Huishi Qiu, Jiang Tian, Zhongchao Shi",traversal verification for speculative tree decoding,speculative decoding is a promising approach for accelerating large language models the primary idea is to use a lightweight draft model to speculate the output of the target model for multiple subsequent timesteps and then verify them in parallel to determine whether the drafted tokens should be accepted or rejected to enhance acceptance rates existing frameworks typically construct token trees containing multiple candidates in each timestep however their reliance on tokenlevel verification mechanisms introduces two critical limitations first the probability distribution of a sequence differs from that of individual tokens leading to suboptimal acceptance length second current verification schemes begin from the root node and proceed layer by layer in a topdown manner once a parent node is rejected all its child nodes should be discarded resulting in inefficient utilization of speculative candidates this paper introduces traversal verification a novel speculative decoding algorithm that fundamentally rethinks the verification paradigm through leaftoroot traversal our approach considers the acceptance of the entire token sequence from the current node to the root and preserves potentially valid subsequences that would be prematurely discarded by existing methods we theoretically prove that the probability distribution obtained through traversal verification is identical to that of the target model guaranteeing lossless inference while achieving substantial acceleration gains experimental results across different large language models and multiple tasks show that our method consistently improves acceptance length and throughput over existing methods
http://arxiv.org/abs/2505.12392v1,2025-05-18T12:37:56Z,"Yang Hu, Xingyu Zhang, Xueji Fang, Zhiyang Chen, Xiao Wang, Huatian Zhang, Guojun Qi",slot samplespecific language model optimization at testtime,we propose slot samplespecific language model optimization at testtime a novel and parameterefficient testtime inference approach that enhances a language models ability to more accurately respond to individual prompts existing large language models llms often struggle with complex instructions leading to poor performances on those not well represented among general samples to address this slot conducts few optimization steps at testtime to update a lightweight samplespecific parameter vector it is added to the final hidden layer before the output head and enables efficient adaptation by caching the last layer features during persample optimization by minimizing the crossentropy loss on the input prompt only slot helps the model better aligned with and follow each given instruction in experiments we demonstrate that our method outperforms the compared models across multiple benchmarks and llms for example qwen257b with slot achieves an accuracy gain of 86 on gsm8k from 5754 to 6619 while deepseekr1distillllama70b with slot achieves a sota accuracy of 6869 on gpqa among 70blevel models our code is available at httpsgithubcommapleresearchlabslot
http://arxiv.org/abs/2505.12381v1,2025-05-18T11:55:05Z,"Mohsinul Kabir, Tasfia Tahsin, Sophia Ananiadou",from ngram to attention how model architectures learn and propagate bias in language modeling,current research on bias in language models lms predominantly focuses on data quality with significantly less attention paid to model architecture and temporal influences of data even more critically few studies systematically investigate the origins of bias we propose a methodology grounded in comparative behavioral theory to interpret the complex interaction between training data and model architecture in bias propagation during language modeling building on recent work that relates transformers to ngram lms we evaluate how data model design choices and temporal dynamics affect bias propagation our findings reveal that 1 ngram lms are highly sensitive to context window size in bias propagation while transformers demonstrate architectural robustness 2 the temporal provenance of training data significantly affects bias and 3 different model architectures respond differentially to controlled bias injection with certain biases eg sexual orientation being disproportionately amplified as language models become ubiquitous our findings highlight the need for a holistic approach tracing bias to its origins across both data and model dimensions not just symptoms to mitigate harm
http://arxiv.org/abs/2505.12371v1,2025-05-18T11:28:17Z,"Yinghao Zhu, Ziyi He, Haoran Hu, Xiaochen Zheng, Xichen Zhang, Zixiang Wang, Junyi Gao, Liantao Ma, Lequan Yu",medagentboard benchmarking multiagent collaboration with conventional methods for diverse medical tasks,the rapid advancement of large language models llms has stimulated interest in multiagent collaboration for addressing complex medical tasks however the practical advantages of multiagent collaboration approaches remain insufficiently understood existing evaluations often lack generalizability failing to cover diverse tasks reflective of realworld clinical practice and frequently omit rigorous comparisons against both singlellmbased and established conventional methods to address this critical gap we introduce medagentboard a comprehensive benchmark for the systematic evaluation of multiagent collaboration singlellm and conventional approaches medagentboard encompasses four diverse medical task categories 1 medical visual question answering 2 lay summary generation 3 structured electronic health record ehr predictive modeling and 4 clinical workflow automation across text medical images and structured ehr data our extensive experiments reveal a nuanced landscape while multiagent collaboration demonstrates benefits in specific scenarios such as enhancing task completeness in clinical workflow automation it does not consistently outperform advanced single llms eg in textual medical qa or critically specialized conventional methods that generally maintain better performance in tasks like medical vqa and ehrbased prediction medagentboard offers a vital resource and actionable insights emphasizing the necessity of a taskspecific evidencebased approach to selecting and developing ai solutions in medicine it underscores that the inherent complexity and overhead of multiagent collaboration must be carefully weighed against tangible performance gains all code datasets detailed prompts and experimental results are opensourced at httpsmedagentboardnetlifyapp
http://arxiv.org/abs/2505.12368v1,2025-05-18T11:14:14Z,"Gauri Kholkar, Ratinder Ahuja",capture contextaware prompt injection testing and robustness enhancement,prompt injection remains a major security risk for large language models however the efficacy of existing guardrail models in contextaware settings remains underexplored as they often rely on static attack benchmarks additionally they have overdefense tendencies we introduce capture a novel contextaware benchmark assessing both attack detection and overdefense tendencies with minimal indomain examples our experiments reveal that current prompt injection guardrail models suffer from high false negatives in adversarial cases and excessive false positives in benign scenarios highlighting critical limitations
http://arxiv.org/abs/2505.12363v1,2025-05-18T10:57:33Z,"Qi Feng, Hidetoshi Shimodaira",towards visuospatial cognition via hierarchical fusion of visual experts,while multimodal large language models mllms excel at general visionlanguage tasks visuospatial cognition reasoning about spatial layouts relations and dynamics remains a significant challenge existing models often lack the necessary architectural components and specialized training data for finegrained spatial understanding we introduce vica2 visuospatial cognitive assistant 2 a novel mllm designed to enhance spatial reasoning vica2 features a dual vision encoder architecture integrating siglip for semantics and hiera for spatial structure coupled with a token ratio control mechanism for efficiency we also developed vica322k a new largescale dataset with over 322000 spatially grounded questionanswer pairs for targeted instruction tuning on the challenging vsibench benchmark our vica27b model achieves a stateoftheart average score of 568 significantly surpassing larger opensource models eg llavanextvideo72b 409 and leading proprietary models gemini15 pro 454 this demonstrates the effectiveness of our approach in achieving strong visuospatial intelligence with a compact model we release vica2 its codebase and the vica322k dataset to facilitate further research
http://arxiv.org/abs/2505.12349v1,2025-05-18T10:29:24Z,"Axel Abels, Tom Lenaerts",wisdom from diversity bias mitigation through hybrid humanllm crowds,despite their performance large language models llms can inadvertently perpetuate biases found in the data they are trained on by analyzing llm responses to biaseliciting headlines we find that these models often mirror human biases to address this we explore crowdbased strategies for mitigating bias through response aggregation we first demonstrate that simply averaging responses from multiple llms intended to leverage the wisdom of the crowd can exacerbate existing biases due to the limited diversity within llm crowds in contrast we show that locally weighted aggregation methods more effectively leverage the wisdom of the llm crowd achieving both bias mitigation and improved accuracy finally recognizing the complementary strengths of llms accuracy and humans diversity we demonstrate that hybrid crowds containing both significantly enhance performance and further reduce biases across ethnic and genderrelated contexts
http://arxiv.org/abs/2505.12345v1,2025-05-18T10:19:01Z,"Qizhou Chen, Dakan Wang, Taolin Zhang, Zaoming Yan, Chengsong You, Chengyu Wang, Xiaofeng He",uniedit a unified knowledge editing benchmark for large language models,model editing aims to enhance the accuracy and reliability of large language models llms by efficiently adjusting their internal parameters currently most llm editing datasets are confined to narrow knowledge domains and cover a limited range of editing evaluation they often overlook the broad scope of editing demands and the diversity of ripple effects resulting from edits in this context we introduce uniedit a unified benchmark for llm editing grounded in opendomain knowledge first we construct editing samples by selecting entities from 25 common domains across five major categories utilizing the extensive triple knowledge available in opendomain knowledge graphs to ensure comprehensive coverage of the knowledge domains to address the issues of generality and locality in editing we design an neighborhood multihop chain sampling nmcs algorithm to sample subgraphs based on a given knowledge piece to entail comprehensive ripple effects to evaluate finally we employ proprietary llms to convert the sampled knowledge subgraphs into natural language text guaranteeing grammatical accuracy and syntactical diversity extensive statistical analysis confirms the scale comprehensiveness and diversity of our uniedit benchmark we conduct comprehensive experiments across multiple llms and editors analyzing their performance to highlight strengths and weaknesses in editing across open knowledge domains and various evaluation criteria thereby offering valuable insights for future research endeavors
http://arxiv.org/abs/2505.12328v1,2025-05-18T09:46:30Z,"Xinye Li, Mingqi Wan, Dianbo Sui",llmsrxllm25 an empirical study of llm for structural reasoning,we present team asdfo123s submission to the llmsrxllm25 shared task which evaluates large language models on producing finegrained controllable and interpretable reasoning processes systems must extract all problem conditions decompose a chain of thought into statementevidence pairs and verify the logical validity of each pair leveraging only the offtheshelf metallama38binstruct we craft a concise fewshot multiturn prompt that first enumerates all conditions and then guides the model to label cite and adjudicate every reasoning step a lightweight postprocessor based on regular expressions normalises spans and enforces the official json schema without finetuning external retrieval or ensembling our method ranks 5th overall achieving macro f1 scores on par with substantially more complex and resourceconsuming pipelines we conclude by analysing the strengths and limitations of our approach and outlining directions for future research in structural reasoning with llms our code is available at httpsgithubcomasdfo123llmsrasdfo123
http://arxiv.org/abs/2505.12313v1,2025-05-18T08:55:46Z,"Weixuan Wang, Minghao Wu, Barry Haddow, Alexandra Birch",expertsteer intervening in llms through expert knowledge,large language models llms exhibit remarkable capabilities across various tasks yet guiding them to follow desired behaviours during inference remains a significant challenge activation steering offers a promising method to control the generation process of llms by modifying their internal activations however existing methods commonly intervene in the models behaviour using steering vectors generated by the model itself which constrains their effectiveness to that specific model and excludes the possibility of leveraging powerful external expert models for steering to address these limitations we propose expertsteer a novel approach that leverages arbitrary specialized expert models to generate steering vectors enabling intervention in any llms expertsteer transfers the knowledge from an expert model to a target llm through a cohesive fourstep process first aligning representation dimensions with autoencoders to enable crossmodel transfer then identifying intervention layer pairs based on mutual information analysis next generating steering vectors from the expert model using recursive feature machines and finally applying these vectors on the identified layers during inference to selectively guide the target llm without updating model parameters we conduct comprehensive experiments using three llms on 15 popular benchmarks across four distinct domains experiments demonstrate that expertsteer significantly outperforms established baselines across diverse tasks at minimal cost
http://arxiv.org/abs/2505.12312v1,2025-05-18T08:55:02Z,"Qi Feng, Hidetoshi Shimodaira",visuospatial cognitive assistant,videobased spatial cognition is vital for robotics and embodied ai but challenges current visionlanguage models vlms this paper makes two key contributions first we introduce vica visuospatial cognitive assistant322k a diverse dataset of 322003 qa pairs from realworld indoor videos arkitscenes scannet scannet offering supervision for 3d metadatagrounded queries and videobased complex reasoning second we develop vica7b finetuned on vica322k which achieves new stateoftheart on all eight vsibench tasks outperforming existing models including larger ones eg 261 on absolute distance for interpretability we present vicathinking268k a dataset with explicit reasoning chains and finetune vica7b to create vica7bthinking a model that articulates its spatial reasoning our work highlights the importance of targeted data and suggests paths for improved temporalspatial modeling we release all resources to foster research in robust visuospatial intelligence
http://arxiv.org/abs/2505.12307v1,2025-05-18T08:39:37Z,"Maoyuan Ye, Jing Zhang, Juhua Liu, Bo Du, Dacheng Tao",logicocr do your large multimodal models excel at logical reasoning on textrich images,recent advances in large multimodal models lmms have significantly improved their reasoning and optical character recognition ocr capabilities however their performance on complex logical reasoning tasks involving textrich images remains underexplored to bridge this gap we introduce logicocr a benchmark comprising 1100 multiplechoice questions designed to evaluate lmms logical reasoning abilities on textrich images while minimizing reliance on domainspecific knowledge eg mathematics we construct logicocr by curating a text corpus from the chinese national civil servant examination and develop a scalable automated pipeline to convert it into multimodal samples first we design prompt templates to steer gptimage1 to generate images with diverse backgrounds interleaved textillustration layouts and varied fonts ensuring contextual relevance and visual realism then the generated images are manually verified with lowquality examples discarded we evaluate a range of representative opensource and proprietary lmms under both chainofthought cot and directanswer settings our multidimensional analysis reveals key insights such as the impact of testtime scaling input modality differences and sensitivity to visualtext orientation notably lmms still lag in multimodal reasoning compared to textonly inputs indicating that they have not fully bridged visual reading with reasoning we hope logicocr will serve as a valuable resource for advancing multimodal reasoning research the dataset is available at httpsgithubcommililablogicocr
http://arxiv.org/abs/2505.12306v1,2025-05-18T08:39:05Z,"Yuwei Zhang, Wenhao Yu, Shangbin Feng, Yifan Zhu, Letian Peng, Jayanth Srinivasa, Gaowen Liu, Jingbo Shang",bidirectional lms are better knowledge memorizers a benchmark for realworld knowledge injection,despite significant advances in large language models llms their knowledge memorization capabilities remain underexplored due to the lack of standardized and highquality test ground in this paper we introduce a novel realworld and largescale knowledge injection benchmark that evolves continuously over time without requiring human intervention specifically we propose wikidyk which leverages recentlyadded and humanwritten facts from wikipedias did you know entries these entries are carefully selected by expert wikipedia editors based on criteria such as verifiability and clarity each entry is converted into multiple questionanswer pairs spanning diverse task formats from easy cloze prompts to complex multihop questions wikidyk contains 12290 facts and 77180 questions which is also seamlessly extensible with future updates from wikipedia editors extensive experiments using continued pretraining reveal a surprising insight despite their prevalence in modern llms causal language models clms demonstrate significantly weaker knowledge memorization capabilities compared to bidirectional language models bilms exhibiting a 23 lower accuracy in terms of reliability to compensate for the smaller scales of current bilms we introduce a modular collaborative framework utilizing ensembles of bilms as external knowledge repositories to integrate with llms experiment shows that our framework further improves the reliability accuracy by up to 291
http://arxiv.org/abs/2505.12301v1,2025-05-18T08:33:09Z,"Luyu Chen, Zeyu Zhang, Haoran Tan, Quanyu Dai, Hao Yang, Zhenhua Dong, Xu Chen",beyond singlepoint judgment distribution alignment for llmasajudge,llms have emerged as powerful evaluators in the llmasajudge paradigm offering significant efficiency and flexibility compared to human judgments however previous methods primarily rely on singlepoint evaluations overlooking the inherent diversity and uncertainty in human evaluations this approach leads to information loss and decreases the reliability of evaluations to address this limitation we propose a novel training framework that explicitly aligns the llmgenerated judgment distribution with empirical human distributions specifically we propose a distributional alignment objective based on kl divergence combined with an auxiliary crossentropy regularization to stabilize the training process furthermore considering that empirical distributions may derive from limited human annotations we incorporate adversarial training to enhance model robustness against distribution perturbations extensive experiments across various llm backbones and evaluation tasks demonstrate that our framework significantly outperforms existing closedsource llms and conventional singlepoint alignment methods with improved alignment quality evaluation accuracy and robustness
http://arxiv.org/abs/2505.12300v1,2025-05-18T08:31:44Z,"Weixuan Wang, Minghao Wu, Barry Haddow, Alexandra Birch",hbo hierarchical balancing optimization for finetuning large language models,finetuning large language models llms on a mixture of diverse datasets poses challenges due to data imbalance and heterogeneity existing methods often address these issues across datasets globally but overlook the imbalance and heterogeneity within individual datasets locally which limits their effectiveness we introduce hierarchical balancing optimization hbo a novel method that enables llms to autonomously adjust data allocation during finetuning both across datasets globally and within each individual dataset locally hbo employs a bilevel optimization strategy with two types of actors a global actor which balances data sampling across different subsets of the training mixture and several local actors which optimizes data usage within each subset based on difficulty levels these actors are guided by reward functions derived from the llms training state which measure learning progress and relative performance improvement we evaluate hbo on three llm backbones across nine diverse tasks in multilingual and multitask setups results show that hbo consistently outperforms existing baselines achieving significant accuracy gains our indepth analysis further demonstrates that both the global actor and local actors of hbo effectively adjust data usage during finetuning hbo provides a comprehensive solution to the challenges of data imbalance and heterogeneity in llm finetuning enabling more effective training across diverse datasets
http://arxiv.org/abs/2505.12299v1,2025-05-18T08:28:05Z,"Kun Huang, Weikai Xu, Yuxuan Liu, Quandong Wang, Pengzhi Gao, Wei Liu, Jian Luan, Bin Wang, Bo An",enhance mobile agents thinking process via iterative preference learning,the chain of actionplanning thoughts coat paradigm has been shown to improve the reasoning performance of vlmbased mobile agents in gui tasks however the scarcity of diverse coat trajectories limits the expressiveness and generalization ability of such agents while selftraining is commonly employed to address data scarcity existing approaches either overlook the correctness of intermediate reasoning steps or depend on expensive processlevel annotations to construct process reward models prm to address the above problems we propose an iterative preference learning ipl that constructs a coattree through interative sampling scores leaf nodes using rulebased reward and backpropagates feedback to derive thinkinglevel direct preference optimization tdpo pairs to prevent overfitting during warmup supervised finetuning we further introduce a threestage instruction evolution which leverages gpt4o to generate diverse qa pairs based on real mobile ui screenshots enhancing both generality and layout understanding experiments on three standard mobile guiagent benchmarks demonstrate that our agent mobileipl outperforms strong baselines including continual pretraining models such as osatlas and uitars it achieves stateoftheart performance across three standard mobile guiagents benchmarks and shows strong generalization to outofdomain scenarios
http://arxiv.org/abs/2505.12287v1,2025-05-18T07:51:19Z,"Linghan Huang, Haolin Jin, Zhaoge Bi, Pengyue Yang, Peizhou Zhao, Taozhao Chen, Xiongfei Wu, Lei Ma, Huaming Chen",the tower of babel revisited multilingual jailbreak prompts on closedsource large language models,large language models llms have seen widespread applications across various domains yet remain vulnerable to adversarial prompt injections while most existing research on jailbreak attacks and hallucination phenomena has focused primarily on opensource models we investigate the frontier of closedsource llms under multilingual attack scenarios we present a firstofitskind integrated adversarial framework that leverages diverse attack techniques to systematically evaluate frontier proprietary solutions including gpt4o deepseekr1 gemini15pro and qwenmax our evaluation spans six categories of security contents in both english and chinese generating 38400 responses across 32 types of jailbreak attacks attack success rate asr is utilized as the quantitative metric to assess performance from three dimensions prompt design model architecture and language environment our findings suggest that qwenmax is the most vulnerable while gpt4o shows the strongest defense notably prompts in chinese consistently yield higher asrs than their english counterparts and our novel twosides attack technique proves to be the most effective across all models this work highlights a dire need for languageaware alignment and robust crosslingual defenses in llms and we hope it will inspire researchers developers and policymakers toward more robust and inclusive ai systems
http://arxiv.org/abs/2505.12284v1,2025-05-18T07:46:43Z,"Danlong Yuan, Tian Xie, Shaohan Huang, Zhuocheng Gong, Huishuai Zhang, Chong Luo, Furu Wei, Dongyan Zhao",efficient rl training for reasoning models via lengthaware optimization,large reasoning models such as openai o1 or deepseek r1 have demonstrated remarkable performance on reasoning tasks but often incur a long reasoning path with significant memory and time costs existing methods primarily aim to shorten reasoning paths by introducing additional training data and stages in this paper we propose three critical reward designs integrated directly into the reinforcement learning process of large reasoning models which reduce the response length without extra training stages experiments on four settings show that our method significantly decreases response length while maintaining or even improving performance specifically in a logic reasoning setting we achieve a 40 reduction in response length averaged by steps alongside a 14 gain in performance for math problems we reduce response length averaged by steps by 33 while preserving performance
http://arxiv.org/abs/2505.12273v1,2025-05-18T07:24:13Z,"Md. Atiqur Rahman, Sabrina Islam, Mushfiqul Haque Omi",llmbased evaluation of lowresource machine translation a referenceless dialect guided approach with a refined sylhetienglish benchmark,evaluating machine translation mt for lowresource languages poses a persistent challenge primarily due to the limited availability of high quality reference translations this issue is further exacerbated in languages with multiple dialects where linguistic diversity and data scarcity hinder robust evaluation large language models llms present a promising solution through referencefree evaluation techniques however their effectiveness diminishes in the absence of dialectspecific context and tailored guidance in this work we propose a comprehensive framework that enhances llmbased mt evaluation using a dialect guided approach we extend the onubad dataset by incorporating sylhetienglish sentence pairs corresponding machine translations and direct assessment da scores annotated by native speakers to address the vocabulary gap we augment the tokenizer vocabulary with dialectspecific terms we further introduce a regression head to enable scalar score prediction and design a dialectguided dg prompting strategy our evaluation across multiple llms shows that the proposed pipeline consistently outperforms existing methods achieving the highest gain of 01083 in spearman correlation along with improvements across other evaluation settings the dataset and the code are available at httpsgithubcom180041123atiqmteonlowresourcelanguage
http://arxiv.org/abs/2505.12269v1,2025-05-18T07:18:58Z,"Kerry Xiao, Amy Zang",vague knowledge evidence from analyst reports,people in the real world often possess vague knowledge of future payoffs for which quantification is not feasible or desirable we argue that language with differing ability to convey vague information plays an important but less knownrole in subjective expectations empirically we find that in their reports analysts include useful information in linguistic expressions but not numerical forecasts specifically the textual tone of analyst reports has predictive power for forecast errors and subsequent revisions in numerical forecasts and this relation becomes stronger when analysts language is vaguer when uncertainty is higher and when analysts are busier overall our theory and evidence suggest that some useful information is vaguely known and only communicated through language
http://arxiv.org/abs/2505.12268v1,2025-05-18T07:15:01Z,Pratim Chowdhary,mshc unmasking minimally sufficient head circuits in large language models with experiments on syntactic classification tasks,understanding which neural components drive specific capabilities in midsized language models 10b parameters remains a key challenge we introduce the minimum sufficient head circuit mshc a methodology to identify minimal sets of attention heads crucial for classification tasks as well as searchkmshc an efficient algorithm for discovering these circuits applying our searchkmshc algorithm to gemma9b we analyze three syntactic task families grammar acceptability arithmetic verification and arithmetic word problems our findings reveal distinct taskspecific head circuits with grammar tasks predominantly utilizing early layers word problems showing pronounced activity in both shallow and deep regions and arithmetic verification demonstrating a more distributed pattern across the network we discover nonlinear circuit overlap patterns where different task pairs share computational components at varying levels of importance while grammar and arithmetic share many weak heads arithmetic and word problems share more consistently critical strong heads importantly we find that each task maintains dedicated superheads with minimal crosstask overlap suggesting that syntactic and numerical competencies emerge from specialized yet partially reusable head circuits
http://arxiv.org/abs/2505.12265v1,2025-05-18T07:10:03Z,"Chengwei Qin, Wenxuan Zhou, Karthik Abinav Sankararaman, Nanshu Wang, Tengyu Xu, Alexander Radovic, Eryk Helenowski, Arya Talebzadeh, Aditya Tayade, Sinong Wang, Shafiq Joty, Han Fang, Hao Ma",learning auxiliary tasks improves referencefree hallucination detection in opendomain longform generation,hallucination the generation of factually incorrect information remains a significant challenge for large language models llms especially in opendomain longform generation existing approaches for detecting hallucination in longform tasks either focus on limited domains or rely heavily on external factchecking tools which may not always be available in this work we systematically investigate referencefree hallucination detection in opendomain longform responses our findings reveal that internal states eg models output probability and entropy alone are insufficient for reliably ie better than random guessing distinguishing between factual and hallucinated content to enhance detection we explore various existing approaches including promptingbased methods probing and finetuning with finetuning proving the most effective to further improve the accuracy we introduce a new paradigm named rateft that augments finetuning with an auxiliary task for the model to jointly learn with the main task of hallucination detection with extensive experiments and analysis using a variety of model families datasets we demonstrate the effectiveness and generalizability of our method eg 3 over general finetuning methods on longfact
http://arxiv.org/abs/2505.12260v1,2025-05-18T06:51:21Z,"Guangyuan Ma, Yongliang Ma, Xuanrui Gou, Zhenpeng Su, Ming Zhou, Songlin Hu",lightretriever a llmbased hybrid retrieval architecture with 1000x faster query inference,large language models llmsbased hybrid retrieval uses llms to encode queries and documents into lowdimensional dense or highdimensional sparse vectors it retrieves documents relevant to search queries based on vector similarities documents are preencoded offline while queries arrive in realtime necessitating an efficient online query encoder although llms significantly enhance retrieval capabilities serving deeply parameterized llms slows down query inference throughput and increases demands for online deployment resources in this paper we propose lightretriever a novel llmbased hybrid retriever with extremely lightweight query encoders our method retains a fullsized llm for document encoding but reduces the workload of query encoding to no more than an embedding lookup compared to serving a fullsized llm on an h800 gpu our approach achieves over a 1000x speedup for query inference with gpu acceleration and even a 20x speedup without gpu experiments on largescale retrieval benchmarks demonstrate that our method generalizes well across diverse retrieval tasks retaining an average of 95 fullsized performance
http://arxiv.org/abs/2505.12259v1,2025-05-18T06:51:10Z,"Yuhang Zhou, Xutian Chen, Yixin Cao, Yuchen Ni, Yu He, Siyu Tian, Xiang Liu, Jian Zhang, Chuanjun Ji, Guangnan Ye, Xipeng Qiu",teach2eval an indirect evaluation method for llm by judging how it teaches,recent progress in large language models llms has outpaced the development of effective evaluation methods traditional benchmarks rely on taskspecific metrics and static datasets which often suffer from fairness issues limited scalability and contamination risks in this paper we introduce teach2eval an indirect evaluation framework inspired by the feynman technique instead of directly testing llms on predefined tasks our method evaluates a models multiple abilities to teach weaker student models to perform tasks effectively by converting openended tasks into standardized multiplechoice questions mcqs through teachergenerated feedback teach2eval enables scalable automated and multidimensional assessment our approach not only avoids data leakage and memorization but also captures a broad range of cognitive abilities that are orthogonal to current benchmarks experimental results across 26 leading llms show strong alignment with existing human and modelbased dynamic rankings while offering additional interpretability for training guidance
http://arxiv.org/abs/2505.12250v1,2025-05-18T06:10:08Z,"Chi Zhang, Huaping Zhong, Hongtao Li, Chengliang Chai, Jiawei Hong, Yuhao Deng, Jiacheng Wang, Tian Tan, Yizhou Yan, Jiantao Qiu, Ye Yuan, Guoren Wang, Conghui He, Lei Cao",not all documents are what you need for extracting instruction tuning data,instruction tuning improves the performance of large language models llms but it heavily relies on highquality training data recently llms have been used to synthesize instruction data using seed questionanswer qa pairs however these synthesized instructions often lack diversity and tend to be similar to the input seeds limiting their applicability in realworld scenarios to address this we propose extracting instruction tuning data from web corpora that contain rich and diverse knowledge a naive solution is to retrieve domainspecific documents and extract all qa pairs from them but this faces two key challenges 1 extracting all qa pairs using llms is prohibitively expensive and 2 many extracted qa pairs may be irrelevant to the downstream tasks potentially degrading model performance to tackle these issues we introduce equal an effective and scalable data extraction framework that iteratively alternates between document selection and highquality qa pair extraction to enhance instruction tuning equal first clusters the document corpus based on embeddings derived from contrastive learning then uses a multiarmed bandit strategy to efficiently identify clusters that are likely to contain valuable qa pairs this iterative approach significantly reduces computational cost while boosting model performance experiments on automathtext and stackoverflow across four downstream tasks show that equal reduces computational costs by 510x and improves accuracy by 25 percent on llama318b and mistral7b
http://arxiv.org/abs/2505.12244v1,2025-05-18T05:49:48Z,"Haojin Wang, Zining Zhu, Freda Shi",distribution prompting understanding the expressivity of language models through the nexttoken distributions they can produce,autoregressive neural language models lms generate a probability distribution over tokens at each time step given a prompt in this work we attempt to systematically understand the probability distributions that lms can produce showing that some distributions are significantly harder to elicit than others specifically for any target nexttoken distribution over the vocabulary we attempt to find a prompt that induces the lm to output a distribution as close as possible to the target using either soft or hard gradientbased prompt tuning we find that 1 in general distributions with very low or very high entropy are easier to approximate than those with moderate entropy 2 among distributions with the same entropy those containing outlier tokens are easier to approximate 3 target distributions generated by lms even lms with different tokenizers are easier to approximate than randomly chosen targets these results offer insights into the expressiveness of lms and the challenges of using them as probability distribution proposers
http://arxiv.org/abs/2505.12238v1,2025-05-18T05:27:35Z,"Sriram Selvam, Anneswa Ghosh",panorama a synthetic piilaced dataset for studying sensitive data memorization in llms,the memorization of sensitive and personally identifiable information pii by large language models llms poses growing privacy risks as models scale and are increasingly deployed in realworld applications existing efforts to study sensitive and pii data memorization and develop mitigation strategies are hampered by the absence of comprehensive realistic and ethically sourced datasets reflecting the diversity of sensitive information found on the web we introduce panorama profilebased assemblage for naturalistic online representation and attribute memorization analysis a largescale synthetic corpus of 384789 samples derived from 9674 synthetic profiles designed to closely emulate the distribution variety and context of pii and sensitive data as it naturally occurs in online environments our data generation pipeline begins with the construction of internally consistent multiattribute human profiles using constrained selection to reflect realworld demographics such as education health attributes financial status etc using a combination of zeroshot prompting and openai o3mini we generate diverse content types including wikistyle articles social media posts forum discussions online reviews comments and marketplace listings each embedding realistic contextually appropriate pii and other sensitive information we validate the utility of panorama by finetuning the mistral7b model on 1x 5x 10x and 25x data replication rates with a subset of data and measure pii memorization rates revealing not only consistent increases with repetition but also variation across content types highlighting panoramas ability to model how memorization risks differ by context our dataset and code are publicly available providing a muchneeded resource for privacy risk assessment model auditing and the development of privacypreserving llms
http://arxiv.org/abs/2505.12236v1,2025-05-18T05:17:36Z,"Quanjiang Guo, Jinchuan Zhang, Sijie Wang, Ling Tian, Zhao Kang, Bin Yan, Weidong Xiao",bridging generative and discriminative learning fewshot relation extraction via twostage knowledgeguided pretraining,fewshot relation extraction fsre remains a challenging task due to the scarcity of annotated data and the limited generalization capabilities of existing models although large language models llms have demonstrated potential in fsre through incontext learning icl their generalpurpose training objectives often result in suboptimal performance for taskspecific relation extraction to overcome these challenges we propose tkre twostage knowledgeguided pretraining for relation extraction a novel framework that synergistically integrates llms with traditional relation extraction models bridging generative and discriminative learning paradigms tkre introduces two key innovations 1 leveraging llms to generate explanationdriven knowledge and schemaconstrained synthetic data addressing the issue of data scarcity and 2 a twostage pretraining strategy combining masked span language modeling mslm and spanlevel contrastive learning scl to enhance relational reasoning and generalization together these components enable tkre to effectively tackle fsre tasks comprehensive experiments on benchmark datasets demonstrate the efficacy of tkre achieving new stateoftheart performance in fsre and underscoring its potential for broader application in lowresource scenarios footnotethe code and data are released on httpsgithubcomuestcgqjtkre
http://arxiv.org/abs/2505.12225v1,2025-05-18T04:00:35Z,"Jizhou Guo, Zhaomin Wu, Philip S. Yu",reward inside the model a lightweight hiddenstate reward model for llms bestofn sampling,highquality reward models are crucial for unlocking the reasoning potential of large language models llms with bestofn voting demonstrating significant performance gains however current reward models which typically operate on the textual output of llms are computationally expensive and parameterheavy limiting their realworld applications we introduce the efficient linear hidden state reward elhsr model a novel highly parameterefficient approach that leverages the rich information embedded in llm hidden states to address these issues elhsr systematically outperform baselines with less than 0005 of the parameters of baselines requiring only a few samples for training elhsr also achieves ordersofmagnitude efficiency improvement with significantly less time and fewer flops per sample than baseline reward models moreover elhsr exhibits robust performance even when trained only on logits extending its applicability to some closedsource llms in addition elhsr can also be combined with traditional reward models to achieve additional performance gains
http://arxiv.org/abs/2505.12218v1,2025-05-18T03:35:43Z,"Tong Bao, Yi Zhao, Jin Mao, Chengzhi Zhang",examining linguistic shifts in academic writing before and after the launch of chatgpt a study on preprint papers,large language models llms such as chatgpt have prompted academic concerns about their impact on academic writing existing studies have primarily examined llm usage in academic writing through quantitative approaches such as word frequency statistics and probabilitybased analyses however few have systematically examined the potential impact of llms on the linguistic characteristics of academic writing to address this gap we conducted a largescale analysis across 823798 abstracts published in last decade from arxiv dataset through the linguistic analysis of features such as the frequency of llmpreferred words lexical complexity syntactic complexity cohesion readability and sentiment the results indicate a significant increase in the proportion of llmpreferred words in abstracts revealing the widespread influence of llms on academic writing additionally we observed an increase in lexical complexity and sentiment in the abstracts but a decrease in syntactic complexity suggesting that llms introduce more new vocabulary and simplify sentence structure however the significant decrease in cohesion and readability indicates that abstracts have fewer connecting words and are becoming more difficult to read moreover our analysis reveals that scholars with weaker english proficiency were more likely to use the llms for academic writing and focused on improving the overall logic and fluency of the abstracts finally at discipline level we found that scholars in computer science showed more pronounced changes in writing style while the changes in mathematics were minimal
http://arxiv.org/abs/2505.12216v1,2025-05-18T03:26:07Z,"Rongguang Ye, Ming Tang",oneforall pruning a universal model for customized compression of large language models,existing pruning methods for large language models llms focus on achieving high compression rates while maintaining model performance although these methods have demonstrated satisfactory performance in handling a single users compression request their processing time increases linearly with the number of requests making them inefficient for realworld scenarios with multiple simultaneous requests to address this limitation we propose a univeral model for customized compression unicuco for llms which introduces a stratnet that learns to map arbitrary requests to their optimal pruning strategy the challenge in training stratnet lies in the high computational cost of evaluating pruning strategies and the nondifferentiable nature of the pruning process which hinders gradient backpropagation for stratnet updates to overcome these challenges we leverage a gaussian process to approximate the evaluation process since the gradient of the gaussian process is computable we can use it to approximate the gradient of the nondifferentiable pruning process thereby enabling stratnet updates experimental results show that unicuco is 28 times faster than baselines in processing 64 requests while maintaining comparable accuracy to baselines
http://arxiv.org/abs/2505.12215v1,2025-05-18T03:21:30Z,"Jiwei Tang, Zhicheng Zhang, Shunlong Wu, Jingheng Ye, Lichen Bai, Zitai Wang, Tingwei Lu, Jiaqi Chen, Lin Hai, Hai-Tao Zheng, Hong-Gee Kim",gmsa enhancing context compression via group merging and layer semantic alignment,large language models llms have achieved impressive performance in a variety of natural language processing nlp tasks however when applied to longcontext scenarios they face two challenges ie low computational efficiency and much redundant information this paper introduces gmsa a context compression framework based on the encoderdecoder architecture which addresses these challenges by reducing input sequence length and redundant information structurally gmsa has two key components group merging and layer semantic alignment lsa group merging is used to effectively and efficiently extract summary vectors from the original context layer semantic alignment on the other hand aligns the highlevel summary vectors with the lowlevel primary input semantics thus bridging the semantic gap between different layers in the training process gmsa first learns soft tokens that contain complete semantics through autoencoder training to furtherly adapt gmsa to downstream tasks we propose knowledge extraction finetuning keft to extract knowledge from the soft tokens for downstream tasks we train gmsa by randomly sampling the compression rate for each sample in the dataset under this condition gmsa not only significantly outperforms the traditional compression paradigm in context restoration but also achieves stable and significantly faster convergence with only a few encoder layers in downstream questionanswering qa tasks gmsa can achieve approximately a 2x speedup in endtoend inference while outperforming both the original input prompts and various stateoftheart sota methods by a large margin
http://arxiv.org/abs/2505.12212v1,2025-05-18T03:10:00Z,"Shaobo Wang, Ziming Wang, Xiangqi Jin, Jize Wang, Jiajun Zhang, Kaixin Li, Zichen Wen, Zhong Li, Conghui He, Xuming Hu, Linfeng Zhang",data whisperer efficient data selection for taskspecific llm finetuning via fewshot incontext learning,finetuning large language models llms on taskspecific data is essential for their effective deployment as dataset sizes grow efficiently selecting optimal subsets for training becomes crucial to balancing performance and computational costs traditional data selection methods often require finetuning a scoring model on the target dataset which is timeconsuming and resourceintensive or rely on heuristics that fail to fully leverage the models predictive capabilities to address these challenges we propose data whisperer an efficient trainingfree attentionbased method that leverages fewshot incontext learning with the model to be finetuned comprehensive evaluations were conducted on both raw and synthetic datasets across diverse tasks and models notably data whisperer achieves superior performance compared to the full gsm8k dataset on the llama38binstruct model using just 10 of the data and outperforms existing methods with a 31point improvement and a 74 speedup
http://arxiv.org/abs/2505.12201v1,2025-05-18T02:32:35Z,"Xiyan Fu, Wei Liu",how reliable is multilingual llmasajudge,llmasajudge has emerged as a popular evaluation strategy where advanced large language models assess generation results in alignment with human instructions while these models serve as a promising alternative to human annotators their reliability in multilingual evaluation remains uncertain to bridge this gap we conduct a comprehensive analysis of multilingual llmasajudge specifically we evaluate five models from different model families across five diverse tasks involving 25 languages our findings reveal that llms struggle to achieve consistent judgment results across languages with an average fleiss kappa of approximately 03 and some models performing even worse to investigate the cause of inconsistency we analyze various influencing factors we observe that consistency varies significantly across languages with particularly poor performance in lowresource languages additionally we find that neither training on multilingual data nor increasing model scale directly improves judgment consistency these findings suggest that llms are not yet reliable for evaluating multilingual predictions we finally propose an ensemble strategy which improves the consistency of the multilingual judge in realworld applications
http://arxiv.org/abs/2505.12196v1,2025-05-18T02:13:48Z,"Yi-Chien Lin, Hongao Zhu, William Schuler",vectors from larger language models predict human reading time and fmri data more poorly when dimensionality expansion is controlled,the impressive linguistic abilities of large language models llms have recommended them as models of human sentence processing with some conjecturing a positive qualitypower relationship wilcox et al 2023 in which language models lms fit to psychometric data continues to improve as their ability to predict words in context increases this is important because it suggests that elements of llm architecture such as veridical attention to context and a unique objective of predicting upcoming words reflect the architecture of the human sentence processing faculty and that any inadequacies in predicting human reading time and brain imaging data may be attributed to insufficient model complexity which recedes as larger models become available recent studies oh and schuler 2023 have shown this scaling inverts after a point as lms become excessively large and accurate when word prediction probability as informationtheoretic surprisal is used as a predictor other studies propose the use of entire vectors from differently sized llms still showing positive scaling schrimpf et al 2021 casting doubt on the value of surprisal as a predictor but do not control for the larger number of predictors in vectors from larger lms this study evaluates llm scaling using entire llm vectors while controlling for the larger number of predictors in vectors from larger llms results show that inverse scaling obtains suggesting that inadequacies in predicting human reading time and brain imaging data may be due to substantial misalignment between llms and human sentence processing which worsens as larger models are used
http://arxiv.org/abs/2505.12189v1,2025-05-18T01:34:34Z,"Marco Valentino, Geonhee Kim, Dhairya Dalal, Zhixue Zhao, André Freitas",mitigating content effects on reasoning in language models through finegrained activation steering,large language models llms frequently demonstrate reasoning limitations often conflating content plausibility ie material inference with logical validity ie formal inference this can result in biased inferences where plausible arguments are incorrectly deemed logically valid or vice versa mitigating this limitation is critical as it undermines the trustworthiness and generalizability of llms in applications that demand rigorous logical consistency this paper investigates the problem of mitigating content biases on formal reasoning through activation steering specifically we curate a controlled syllogistic reasoning dataset to disentangle formal validity from content plausibility after localising the layers responsible for formal and material inference we investigate contrastive activation steering methods for testtime interventions an extensive empirical analysis on different llms reveals that contrastive steering consistently supports linear control over content biases however we observe that a static approach is insufficient for improving all the tested models we then leverage the possibility to control content effects by dynamically determining the value of the steering parameters via finegrained conditional methods we found that conditional steering is effective on unresponsive models achieving up to 15 absolute improvement in formal reasoning accuracy with a newly introduced knnbased method kcast finally additional experiments reveal that steering for content effects is robust to prompt variations incurs minimal side effects on language modeling capabilities and can partially generalize to outofdistribution reasoning tasks practically this paper demonstrates that activationlevel interventions can offer a scalable strategy for enhancing the robustness of llms contributing towards more systematic and unbiased formal reasoning
http://arxiv.org/abs/2505.12185v1,2025-05-18T01:02:33Z,"Sen Fang, Weiyuan Ding, Bowen Xu",evaloop assessing llm robustness in programming from a selfconsistency perspective,assessing the programming capabilities of large language models llms is crucial for their effective use in software engineering current evaluations however predominantly measure the accuracy of generated code on static benchmarks neglecting the critical aspect of model robustness during programming tasks while adversarial attacks offer insights on model robustness their effectiveness is limited and evaluation could be constrained current adversarial attack methods for robustness evaluation yield inconsistent results struggling to provide a unified evaluation across different llms we introduce evaloop a novel assessment framework that evaluate the robustness from a selfconsistency perspective ie leveraging the natural duality inherent in popular software engineering tasks eg code generation and code summarization evaloop initiates a selfcontained feedback loop an llm generates output eg code from an input eg natural language specification and then use the generated output as the input to produce a new output eg summarizes that code into a new specification evaloop repeats the process to assess the effectiveness of evaloop in each loop this cyclical strategy intrinsically evaluates robustness without rely on any external attack setups providing a unified metric to evaluate llms robustness in programming we evaluate 16 prominent llms eg gpt41 o4mini on evaloop and found that evaloop typically induces a 5011931 absolute drop in pass1 performance within ten loops intriguingly robustness does not always align with initial performance ie onetime query for instance gpt35turbo despite superior initial code generation compared to deepseekv2 demonstrated lower robustness over repeated evaluation loop
http://arxiv.org/abs/2505.12183v1,2025-05-18T00:52:06Z,"Manari Hirose, Masato Uchida",decoding the mind of large language models a quantitative evaluation of ideology and biases,the widespread integration of large language models llms across various sectors has highlighted the need for empirical research to understand their biases thought patterns and societal implications to ensure ethical and effective use in this study we propose a novel framework for evaluating llms focusing on uncovering their ideological biases through a quantitative analysis of 436 binarychoice questions many of which have no definitive answer by applying our framework to chatgpt and gemini findings revealed that while llms generally maintain consistent opinions on many topics their ideologies differ across models and languages notably chatgpt exhibits a tendency to change their opinion to match the questioners opinion both models also exhibited problematic biases unethical or unfair claims which might have negative societal impacts these results underscore the importance of addressing both ideological and ethical considerations when evaluating llms the proposed framework offers a flexible quantitative method for assessing llm behavior providing valuable insights for the development of more socially aligned ai systems
http://arxiv.org/abs/2505.12182v1,2025-05-18T00:47:21Z,"Haohang Li, Yupeng Cao, Yangyang Yu, Jordan W. Suchow, Zining Zhu",truth neurons,despite their remarkable success and deployment across diverse workflows language models sometimes produce untruthful responses our limited understanding of how truthfulness is mechanistically encoded within these models jeopardizes their reliability and safety in this paper we propose a method for identifying representations of truthfulness at the neuron level we show that language models contain truth neurons which encode truthfulness in a subjectagnostic manner experiments conducted across models of varying scales validate the existence of truth neurons confirming that the encoding of truthfulness at the neuron level is a property shared by many language models the distribution patterns of truth neurons over layers align with prior findings on the geometry of truthfulness selectively suppressing the activations of truth neurons found through the truthfulqa dataset degrades performance both on truthfulqa and on other benchmarks showing that the truthfulness mechanisms are not tied to a specific dataset our results offer novel insights into the mechanisms underlying truthfulness in language models and highlight potential directions toward improving their trustworthiness and reliability
http://arxiv.org/abs/2505.12160v1,2025-05-17T22:38:18Z,"Darmawan Wicaksono, Hasri Akbar Awal Rozaq, Nevfel Boz",emotion recognition for lowresource turkish finetuning berturk on tremo and testing on xenophobic political discourse,social media platforms like x formerly twitter play a crucial role in shaping public discourse and societal norms this study examines the term sessiz istila silent invasion on turkish social media highlighting the rise of antirefugee sentiment amidst the syrian refugee influx using berturk and the tremo dataset we developed an advanced emotion recognition model erm tailored for turkish achieving 9262 accuracy in categorizing emotions such as happiness fear anger sadness disgust and surprise by applying this model to largescale x data the study uncovers emotional nuances in turkish discourse contributing to computational social science by advancing sentiment analysis in underrepresented languages and enhancing our understanding of global digital discourse and the unique linguistic challenges of turkish the findings underscore the transformative potential of localized nlp tools with our erm model offering practical applications for realtime sentiment analysis in turkishlanguage contexts by addressing critical areas including marketing public relations and crisis management these models facilitate improved decisionmaking through timely and accurate sentiment tracking this highlights the significance of advancing research that accounts for regional and linguistic nuances
http://arxiv.org/abs/2505.12158v1,2025-05-17T22:35:40Z,"Elisa Bassignana, Amanda Cercas Curry, Dirk Hovy",the ai gap how socioeconomic status affects language technology interactions,socioeconomic status ses fundamentally influences how people interact with each other and more recently with digital technologies like large language models llms while previous research has highlighted the interaction between ses and language technology it was limited by reliance on proxy metrics and synthetic data we survey 1000 individuals from diverse socioeconomic backgrounds about their use of language technologies and generative ai and collect 6482 prompts from their previous interactions with llms we find systematic differences across ses groups in language technology usage ie frequency performed tasks interaction styles and topics higher ses entails a higher level of abstraction convey requests more concisely and topics like inclusivity and travel lower ses correlates with higher anthropomorphization of llms using hello and thank you and more concrete language our findings suggest that while generative language technologies are becoming more accessible to everyone socioeconomic linguistic differences still stratify their use to exacerbate the digital divide these differences underscore the importance of considering ses in developing language technologies to accommodate varying linguistic needs rooted in socioeconomic factors and limit the ai gap across ses groups
http://arxiv.org/abs/2505.12135v1,2025-05-17T20:23:17Z,"Omar Choukrani, Idriss Malek, Daniil Orel, Zhuohan Xie, Zangir Iklassov, Martin Takáč, Salem Lahlou",llmbabybench understanding and evaluating grounded planning and reasoning in llms,assessing the capacity of large language models llms to plan and reason within the constraints of interactive environments is crucial for developing capable ai agents we introduce a new benchmark suite designed specifically for this purpose built upon a textual adaptation of the procedurally generated babyai grid world this suite evaluates llms on three fundamental aspects of grounded intelligence 1 predicting the consequences of actions on the environment state task 2 generating sequences of lowlevel actions to achieve specified objectives task and 3 decomposing highlevel instructions into coherent subgoal sequences task we detail the methodology for generating the three corresponding datasets by extracting structured information from an expert agent operating within the textbased environment furthermore we provide a standardized evaluation harness and metrics including environment interaction for validating generated plans to facilitate reproducible assessment of diverse llms initial baseline results highlight the challenges posed by these grounded reasoning tasks the benchmark suite datasets data generation code and evaluation code are made publicly available
http://arxiv.org/abs/2505.12116v1,2025-05-17T18:52:47Z,"Fitsum Gaim, Hoyun Song, Huije Lee, Changgeon Ko, Eui Jun Hwang, Jong C. Park",a multitask benchmark for abusive language detection in lowresource settings,content moderation research has recently made significant advances but still fails to serve the majority of the worlds languages due to the lack of resources leaving millions of vulnerable users to online hostility this work presents a largescale humanannotated multitask benchmark dataset for abusive language detection in tigrinya social media with joint annotations for three tasks abusiveness sentiment and topic classification the dataset comprises 13717 youtube comments annotated by nine native speakers collected from 7373 videos with a total of over 12 billion views across 51 channels we developed an iterative term clustering approach for effective data selection recognizing that around 64 of tigrinya social media content uses romanized transliterations rather than native geez script our dataset accommodates both writing systems to reflect actual language use we establish strong baselines across the tasks in the benchmark while leaving significant challenges for future contributions our experiments reveal that small specialized multitask models outperform the current frontier models in the lowresource setting achieving up to 86 accuracy 7 points in abusiveness detection we make the resources publicly available to promote research on online safety
http://arxiv.org/abs/2505.12100v1,2025-05-17T17:56:53Z,"Isabela Pereira Gregio, Ian Pons, Anna Helena Reali Costa, Artur Jordão",improving fairness in llms through testingtime adversaries,large language models llms push the boundaries in natural language processing and generative ai driving progress across various aspects of modern society unfortunately the pervasive issue of bias in llms responses ie predictions poses a significant and open challenge hindering their application in tasks involving ethical sensitivity and responsible decisionmaking in this work we propose a straightforward userfriendly and practical method to mitigate such biases enhancing the reliability and trustworthiness of llms our method creates multiple variations of a given sentence by modifying specific attributes and evaluates the corresponding prediction behavior compared to the original unaltered predictionsentence the idea behind this process is that critical ethical predictions often exhibit notable inconsistencies indicating the presence of bias unlike previous approaches our method relies solely on forward passes ie testingtime adversaries eliminating the need for training finetuning or prior knowledge of the training data distribution through extensive experiments on the popular llama family we demonstrate the effectiveness of our method in improving various fairness metrics focusing on the reduction of disparities in how the model treats individuals from different racial groups specifically using standard metrics we improve the fairness in llama3 in up to 27 percentage points overall our approach significantly enhances fairness equity and reliability in llmgenerated results without parameter tuning or training data modifications confirming its effectiveness in practical scenarios we believe our work establishes an important step toward enabling the use of llms in tasks that require ethical considerations and responsible decisionmaking
http://arxiv.org/abs/2505.12090v1,2025-05-17T17:10:25Z,"Mohammad Shokri, Sarah Ita Levitan, Rivka Levitan",personalized author obfuscation with large language models,in this paper we investigate the efficacy of large language models llms in obfuscating authorship by paraphrasing and altering writing styles rather than adopting a holistic approach that evaluates performance across the entire dataset we focus on userwise performance to analyze how obfuscation effectiveness varies across individual authors while llms are generally effective we observe a bimodal distribution of efficacy with performance varying significantly across users to address this we propose a personalized prompting method that outperforms standard prompting techniques and partially mitigates the bimodality issue
http://arxiv.org/abs/2505.12082v1,2025-05-17T16:53:14Z,"Yunshui Li, Yiyuan Ma, Shen Yan, Chaoyi Zhang, Jing Liu, Jianqiao Lu, Ziwen Xu, Mengzhao Chen, Minrui Wang, Shiyi Zhan, Jin Ma, Xunhao Lai, Yao Luo, Xingyan Bin, Hongbin Ren, Mingji Han, Wenhao Hao, Bairen Yi, LingJun Liu, Bole Ma, Xiaoying Jia, Zhou Xun, Liang Xiang, Yonghui Wu",model merging in pretraining of large language models,model merging has emerged as a promising technique for enhancing large language models though its application in largescale pretraining remains relatively unexplored in this paper we present a comprehensive investigation of model merging techniques during the pretraining process through extensive experiments with both dense and mixtureofexperts moe architectures ranging from millions to over 100 billion parameters we demonstrate that merging checkpoints trained with constant learning rates not only achieves significant performance improvements but also enables accurate prediction of annealing behavior these improvements lead to both more efficient model development and significantly lower training costs our detailed ablation studies on merging strategies and hyperparameters provide new insights into the underlying mechanisms while uncovering novel applications through comprehensive experimental analysis we offer the opensource community practical pretraining guidelines for effective model merging
http://arxiv.org/abs/2505.12075v1,2025-05-17T16:28:33Z,"Guy Davidson, Todd M. Gureckis, Brenden M. Lake, Adina Williams",do different prompting methods yield a common task representation in language models,demonstrations and instructions are two primary approaches for prompting language models to perform incontext learning icl tasks do identical tasks elicited in different ways result in similar representations of the task an improved understanding of task representation mechanisms would offer interpretability insights and may aid in steering models we study this through function vectors recently proposed as a mechanism to extract fewshot icl task representations we generalize function vectors to alternative task presentations focusing on short textual instruction prompts and successfully extract instruction function vectors that promote zeroshot task accuracy we find evidence that demonstration and instructionbased function vectors leverage different model components and offer several controls to dissociate their contributions to task performance our results suggest that different task presentations do not induce a common task representation but elicit different partly overlapping mechanisms our findings offer principled support to the practice of combining textual instructions and task demonstrations imply challenges in universally monitoring task inference across presentation forms and encourage further examinations of llm task inference mechanisms
http://arxiv.org/abs/2505.12071v1,2025-05-17T16:21:49Z,"Harald Baayen, Kristian Berg, Maziyah Mohamed",historical and psycholinguistic perspectives on morphological productivity a sketch of an integrative approach,in this study we approach morphological productivity from two perspectives a cognitivecomputational perspective and a diachronic perspective zooming in on an actual speaker thomas mann for developing the first perspective we make use of a cognitive computational model of the mental lexicon the discriminative lexicon model for computational mappings between form and meaning to be productive in the sense that novel previously unencountered words can be understood and produced there must be systematicities between the form space and the semantic space if the relation between form and meaning would be truly arbitrary a model could memorize form and meaning pairings but there is no way in which the model would be able to generalize to novel test data for finnish nominal inflection malay derivation and english compounding we explore using the discriminative lexicon model as a computational tool to trace differences in the degree to which inflectional and word formation patterns are productive we show that the dlm tends to associate affixlike sublexical units with the centroids of the embeddings of the words with a given affix for developing the second perspective we study how the intake and output of one prolific writer thomas mann changes over time we show by means of an examination of what thomas mann is likely to have read and what he wrote that the rate at which mann produces novel derived words is extremely low there are far more novel words in his input than in his output we show that thomas mann is less likely to produce a novel derived word with a given suffix the greater the average distance is of the embeddings of all derived words to the corresponding centroid and discuss the challenges of using speakerspecific embeddings for lowfrequency and novel words
http://arxiv.org/abs/2505.12065v1,2025-05-17T16:07:01Z,"Tiannuo Yang, Zebin Yao, Bowen Jin, Lixiao Cui, Yusen Li, Gang Wang, Xiaoguang Liu",demystifying and enhancing the efficiency of large language model based search agents,large language model llmbased search agents have shown remarkable capabilities in solving complex tasks by dynamically decomposing problems and addressing them through interleaved reasoning and retrieval however this interleaved paradigm introduces substantial efficiency bottlenecks first we observe that both highly accurate and overly approximate retrieval methods degrade system efficiency exact search incurs significant retrieval overhead while coarse retrieval requires additional reasoning steps during generation second we identify inefficiencies in system design including improper scheduling and frequent retrieval stalls which lead to cascading latency where even minor delays in retrieval amplify endtoend inference time to address these challenges we introduce searchagentx a highefficiency inference framework for llmbased search agents searchagentx leverages highrecall approximate retrieval and incorporates two key techniques priorityaware scheduling and nonstall retrieval extensive experiments demonstrate that searchagentx consistently outperforms stateoftheart systems such as vllm and hnswbased retrieval across diverse tasks achieving up to 34 higher throughput and 5 lower latency without compromising generation quality searchagentx is available at httpsgithubcomtiannuoyangsearchagentx
http://arxiv.org/abs/2505.12060v1,2025-05-17T15:54:52Z,"Peng Ding, Jun Kuang, Zongyu Wang, Xuezhi Cao, Xunliang Cai, Jiajun Chen, Shujian Huang",why not act on what you know unleashing safety potential of llms via selfaware guard enhancement,large language models llms have shown impressive capabilities across various tasks but remain vulnerable to meticulously crafted jailbreak attacks in this paper we identify a critical safety gap while llms are adept at detecting jailbreak prompts they often produce unsafe responses when directly processing these inputs inspired by this insight we propose sage selfaware guard enhancement a trainingfree defense strategy designed to align llms strong safety discrimination performance with their relatively weaker safety generation ability sage consists of two core components a discriminative analysis module and a discriminative response module enhancing resilience against sophisticated jailbreak attempts through flexible safety discrimination instructions extensive experiments demonstrate sages effectiveness and robustness across various opensource and closedsource llms of different sizes and architectures achieving an average 99 defense success rate against numerous complex and covert jailbreak methods while maintaining helpfulness on general benchmarks we further conduct mechanistic interpretability analysis through hidden states and attention distributions revealing the underlying mechanisms of this detectiongeneration discrepancy our work thus contributes to developing future llms with coherent safety awareness and generation behavior our code and datasets are publicly available at httpsgithubcomnjunlpsage
http://arxiv.org/abs/2505.12058v1,2025-05-17T15:40:03Z,Vincent Koc,tiny qa benchmark ultralightweight synthetic multilingual dataset generation smoketests for continuous llm evaluation,tiny qa benchmark tqb presents an ultralightweight multilingual smoketest suite designed to give largelanguagemodel llm pipelines a unittest style safety net dataset that runs in seconds with minimal cost born out of the tight feedbackloop demands building the comet opik promptoptimization sdk where waiting on heavyweight benchmarks breaks developer flow tqb couples a 52item english gold set less than 20 kb with a tiny syntheticdata generator pypi package built on provideragnostic litellm the generator lets practitioners mint their own tiny packs in any language domain or difficulty while ten readymade packs already cover arabic chinese french german japanese korean portuguese russian spanish and turkish every dataset ships with croissant metadata and plugandplay files for openaievals langchain and standard ci tools so teams can drop deterministic microbenchmarks directly into pullrequest gates promptengineering loops and production dashboards without touching gpu budgets a complete tqb run adds only a few seconds to pipeline latency yet reliably flags prompttemplate errors tokenizer drift and finetuning sideeffects long before fullscale suites like mmlu or bigbench would finish configuring the entire framework is released to accelerate continuous resourceefficient quality assurance across the generativeai ecosystem
http://arxiv.org/abs/2505.12054v1,2025-05-17T15:34:33Z,Matúš Pikuliak,genderbench evaluation suite for gender biases in llms,we present genderbench a comprehensive evaluation suite designed to measure gender biases in llms genderbench includes 14 probes that quantify 19 genderrelated harmful behaviors exhibited by llms we release genderbench as an opensource and extensible library to improve the reproducibility and robustness of benchmarking across the field we also publish our evaluation of 12 llms our measurements reveal consistent patterns in their behavior we show that llms struggle with stereotypical reasoning equitable gender representation in generated texts and occasionally also with discriminatory behavior in highstakes scenarios such as hiring
http://arxiv.org/abs/2505.12050v1,2025-05-17T15:24:48Z,"Vinod Raman, Hilal Asi, Satyen Kale",abon adaptive bestofn alignment,recent advances in testtime alignment methods such as bestofn sampling offer a simple and effective way to steer language models lms toward preferred behaviors using reward models rm however these approaches can be computationally expensive especially when applied uniformly across prompts without accounting for differences in alignment difficulty in this work we propose a promptadaptive strategy for bestofn alignment that allocates inferencetime compute more efficiently motivated by latency concerns we develop a twostage algorithm an initial exploratory phase estimates the reward distribution for each prompt using a small exploration budget and a second stage adaptively allocates the remaining budget using these estimates our method is simple practical and compatible with any lmrm combination empirical results on the alpacaeval dataset for 12 lmrm pairs and 50 different batches of prompts show that our adaptive strategy consistently outperforms the uniform allocation with the same inference budget moreover our experiments show that our adaptive strategy remains competitive against uniform allocations with 20 larger inference budgets and even improves in performance as the batch size grows
http://arxiv.org/abs/2505.12043v1,2025-05-17T15:12:47Z,"Jingxue Chen, Qingkun Tang, Qianchun Lu, Siyuan Fang",mol for llms dualloss optimization to enhance domain expertise while preserving general capabilities,although llms perform well in general tasks domainspecific applications suffer from hallucinations and accuracy limitations cpt approaches encounter two key issues 1 domainbiased data degrades general language skills and 2 improper corpusmixture ratios limit effective adaptation to address these we propose a novel framework mixture of losses mol which decouples optimization objectives for domainspecific and general corpora specifically crossentropy ce loss is applied to domain data to ensure knowledge acquisition while kullbackleibler kl divergence aligns generalcorpus training with the base models foundational capabilities this dualloss architecture preserves universal skills while enhancing domain expertise avoiding catastrophic forgetting empirically we validate that a 11 domaintogeneral corpus ratio optimally balances training and overfitting without the need for extensive tuning or resourceintensive experiments furthermore our experiments demonstrate significant performance gains compared to traditional cpt approaches which often suffer from degradation in general language capabilities our model achieves 279 higher accuracy on the math500 benchmark in the nonthink reasoning mode and an impressive 833 improvement on the challenging aime25 subset in the think mode underscoring the effectiveness of our approach
http://arxiv.org/abs/2505.12039v1,2025-05-17T15:01:33Z,"Renqi Chen, Haoyang Su, Shixiang Tang, Zhenfei Yin, Qi Wu, Hui Li, Ye Sun, Nanqing Dong, Wanli Ouyang, Philip Torr",aidriven automation can become the foundation of nextera science of science research,the science of science sos explores the mechanisms underlying scientific discovery and offers valuable insights for enhancing scientific efficiency and fostering innovation traditional approaches often rely on simplistic assumptions and basic statistical tools such as linear regression and rulebased simulations which struggle to capture the complexity and scale of modern research ecosystems the advent of artificial intelligence ai presents a transformative opportunity for the next generation of sos enabling the automation of largescale pattern discovery and uncovering insights previously unattainable this paper offers a forwardlooking perspective on the integration of science of science with ai for automated research pattern discovery and highlights key open challenges that could greatly benefit from ai we outline the advantages of ai over traditional methods discuss potential limitations and propose pathways to overcome them additionally we present a preliminary multiagent system as an illustrative example to simulate research societies showcasing ais ability to replicate realworld research patterns and accelerate progress in science of science research
http://arxiv.org/abs/2505.12028v1,2025-05-17T14:36:51Z,"Yupei Ren, Xinyi Zhou, Ning Zhang, Shangqing Zhao, Man Lan, Xiaopeng Bai",towards comprehensive argument analysis in education dataset tasks and method,argument mining has garnered increasing attention over the years with the recent advancement of large language models llms further propelling this trend however current argument relations remain relatively simplistic and foundational struggling to capture the full scope of argument information particularly when it comes to representing complex argument structures in realworld scenarios to address this limitation we propose 14 finegrained relation types from both vertical and horizontal dimensions thereby capturing the intricate interplay between argument components for a thorough understanding of argument structure on this basis we conducted extensive experiments on three tasks argument component detection relation prediction and automated essay grading additionally we explored the impact of writing quality on argument component detection and relation prediction as well as the connections between discourse relations and argumentative features the findings highlight the importance of finegrained argumentative annotations for argumentative writing quality assessment and encourage multidimensional argument analysis
http://arxiv.org/abs/2505.11995v1,2025-05-17T13:13:13Z,"Yuhao Wang, Ruiyang Ren, Yucheng Wang, Wayne Xin Zhao, Jing Liu, Hua Wu, Haifeng Wang",unveiling knowledge utilization mechanisms in llmbased retrievalaugmented generation,considering the inherent limitations of parametric knowledge in large language models llms retrievalaugmented generation rag is widely employed to expand their knowledge scope since rag has shown promise in knowledgeintensive tasks like opendomain question answering its broader application to complex tasks and intelligent assistants has further advanced its utility despite this progress the underlying knowledge utilization mechanisms of llmbased rag remain underexplored in this paper we present a systematic investigation of the intrinsic mechanisms by which llms integrate internal parametric and external retrieved knowledge in rag scenarios specially we employ knowledge stream analysis at the macroscopic level and investigate the function of individual modules at the microscopic level drawing on knowledge streaming analyses we decompose the knowledge utilization process into four distinct stages within llm layers knowledge refinement knowledge elicitation knowledge expression and knowledge contestation we further demonstrate that the relevance of passages guides the streaming of knowledge through these stages at the module level we introduce a new method knowledge activation probability entropy kape for neuron identification associated with either internal or external knowledge by selectively deactivating these neurons we achieve targeted shifts in the llms reliance on one knowledge source over the other moreover we discern complementary roles for multihead attention and multilayer perceptron layers during knowledge formation these insights offer a foundation for improving interpretability and reliability in retrievalaugmented llms paving the way for more robust and transparent generative solutions in knowledgeintensive domains
http://arxiv.org/abs/2505.11979v1,2025-05-17T12:23:55Z,"Tarik Houichime, Younes El Amrani",introduction to analytical software engineering design paradigm,as modern software systems expand in scale and complexity the challenges associated with their modeling and formulation grow increasingly intricate traditional approaches often fall short in effectively addressing these complexities particularly in tasks such as design pattern detection for maintenance and assessment as well as code refactoring for optimization and longterm sustainability this growing inadequacy underscores the need for a paradigm shift in how such challenges are approached and resolved this paper presents analytical software engineering ase a novel design paradigm aimed at balancing abstraction tool accessibility compatibility and scalability ase enables effective modeling and resolution of complex software engineering problems the paradigm is evaluated through two frameworks behavioralstructural sequences bss and optimized design refactoring odr both developed in accordance with ase principles bss offers a compact languageagnostic representation of codebases to facilitate precise design pattern detection odr unifies artifact and solution representations to optimize code refactoring via heuristic algorithms while eliminating iterative computational overhead by providing a structured approach to software design challenges ase lays the groundwork for future research in encoding and analyzing complex software metrics
http://arxiv.org/abs/2505.11969v1,2025-05-17T12:08:22Z,"Md. Rafiul Biswas, Wajdi Zaghouani",an annotated corpus of arabic tweets for hate speech analysis,identifying hate speech content in the arabic language is challenging due to the rich quality of dialectal variations this study introduces a multilabel hate speech dataset in the arabic language we have collected 10000 arabic tweets and annotated each tweet whether it contains offensive content or not if a text contains offensive content we further classify it into different hate speech targets such as religion gender politics ethnicity origin and others a text can contain either single or multiple targets multiple annotators are involved in the data annotation task we calculated the interannotator agreement which was reported to be 086 for offensive content and 071 for multiple hate speech targets finally we evaluated the data annotation task by employing a different transformersbased model in which arabertv2 outperformed with a microf1 score of 07865 and an accuracy of 0786
http://arxiv.org/abs/2505.11965v1,2025-05-17T11:41:39Z,"Xu Liu, Guanyi Chen",ccnu at semeval2025 task 3 leveraging internal and external knowledge of large language models for multilingual hallucination annotation,we present the system developed by the central china normal university ccnu team for the mushroom shared task which focuses on identifying hallucinations in questionanswering systems across 14 different languages our approach leverages multiple large language models llms with distinct areas of expertise employing them in parallel to annotate hallucinations effectively simulating a crowdsourcing annotation process furthermore each llmbased annotator integrates both internal and external knowledge related to the input during the annotation process using the opensource llm deepseekv3 our system achieves the top ranking 1 for hindi data and secures a top5 position in seven other languages in this paper we also discuss unsuccessful approaches explored during our development process and share key insights gained from participating in this shared task
http://arxiv.org/abs/2505.11959v1,2025-05-17T11:21:58Z,"Md. Rafiul Biswas, Wajdi Zaghouani",emohopespeech an annotated dataset of emotions and hope speech in english,this research introduces a bilingual dataset comprising 23456 entries for arabic and 10036 entries for english annotated for emotions and hope speech addressing the scarcity of multiemotion emotion and hope datasets the dataset provides comprehensive annotations capturing emotion intensity complexity and causes alongside detailed classifications and subcategories for hope speech to ensure annotation reliability fleiss kappa was employed revealing 075085 agreement among annotators both for arabic and english language the evaluation metrics microf1score067 obtained from the baseline model ie using a machine learning model validate that the data annotations are worthy this dataset offers a valuable resource for advancing natural language processing in underrepresented languages fostering better crosslinguistic analysis of emotions and hope speech
http://arxiv.org/abs/2505.11958v1,2025-05-17T11:19:49Z,"Aswini Kumar Padhi, Anil Bandhakavi, Tanmoy Chakraborty",counterspeech the ultimate shield multiconditioned counterspeech generation through attributed prefix learning,counterspeech has proven to be a powerful tool to combat hate speech online previous studies have focused on generating counterspeech conditioned only on specific intents single attributed however a holistic approach considering multiple attributes simultaneously can yield more nuanced and effective responses here we introduce hippro hierarchical prefix learning with preference optimization a novel twostage framework that utilizes the effectiveness of attributespecific prefix embedding spaces hierarchically optimized during the counterspeech generation process in the first phase thereafter we incorporate both reference and rewardfree preference optimization to generate more constructive counterspeech furthermore we extend intentconanv2 by annotating all 13973 counterspeech instances with emotion labels by five annotators hippro leverages hierarchical prefix optimization to integrate these dual attributes effectively an extensive evaluation demonstrates that hippro achieves a 38 improvement in intent conformity and a 3 2 3 improvement in rouge1 rouge2 and rougel respectively compared to several baseline models human evaluations further substantiate the superiority of our approach highlighting the enhanced relevance and appropriateness of the generated counterspeech this work underscores the potential of multiattribute conditioning in advancing the efficacy of counterspeech generation systems
http://arxiv.org/abs/2505.11935v1,2025-05-17T09:47:15Z,"Xuanle Zhao, Xuexin Liu, Haoyue Yang, Xianzhen Luo, Fanhu Zeng, Jianling Li, Qi Shi, Chi Chen",chartedit how far are mllms from automating chart analysis evaluating mllms capability via chart editing,although multimodal large language models mllms show promise in generating chart rendering code chart editing presents a greater challenge this difficulty stems from its nature as a laborintensive task for humans that also demands mllms to integrate chart understanding complex reasoning and precise intent interpretation while many mllms claim such editing capabilities current assessments typically rely on limited case studies rather than robust evaluation methodologies highlighting the urgent need for a comprehensive evaluation framework in this work we propose chartedit a new highquality benchmark designed for chart editing tasks this benchmark comprises diverse editing instructions applied to realworld charts with each instructionchart instance having been manually annotated and validated for accuracy utilizing chartedit we evaluate the performance of 10 mainstream mllms across two types of experiments assessing them at both the code and chart levels the results suggest that largescale models can generate code to produce images that partially match the reference images however their ability to generate accurate edits according to the instructions remains limited the stateoftheart sota model achieves a score of only highlighting significant challenges in precise modification in contrast smallscale models including chartdomain models struggle both with following editing instructions and generating overall chart images underscoring the need for further development in this area code is available at httpsgithubcomxxlllzchartedit
http://arxiv.org/abs/2505.11932v1,2025-05-17T09:36:03Z,"Yuyao Zhang, Zhicheng Dou, Xiaoxi Li, Jiajie Jin, Yongkang Wu, Zhonghua Li, Qi Ye, Ji-Rong Wen",neurosymbolic query compiler,precise recognition of search intent in retrievalaugmented generation rag systems remains a challenging goal especially under resource constraints and for complex queries with nested structures and dependencies this paper presents qcompiler a neurosymbolic framework inspired by linguistic grammar rules and compiler design to bridge this gap it theoretically designs a minimal yet sufficient backusnaur form bnf grammar to formalize complex queries unlike previous methods this grammar maintains completeness while minimizing redundancy based on this qcompiler includes a query expression translator a lexical syntax parser and a recursive descent processor to compile queries into abstract syntax trees asts for execution the atomicity of the subqueries in the leaf nodes ensures more precise document retrieval and response generation significantly improving the rag systems ability to address complex queries
http://arxiv.org/abs/2505.11924v1,2025-05-17T09:18:37Z,"Yu-Ting Lee, Hui-Ying Shih, Fu-Chieh Chang, Pei-Yuan Wu",an explanation of intrinsic selfcorrection via linear representations and latent concepts,we provide an explanation for the performance gains of intrinsic selfcorrection a process where a language model iteratively refines its outputs without external feedback more precisely we investigate how prompting induces interpretable changes in hidden states and thus affects the output distributions we hypothesize that each promptinduced shift lies in a linear span of some linear representation vectors naturally separating tokens based on individual concept alignment building around this idea we give a mathematical formulation of selfcorrection and derive a concentration result for output tokens based on alignment magnitudes our experiments on text detoxification with zephyr7bsft reveal a substantial gap in the inner products of the promptinduced shifts and the unembeddings of the top100 most toxic tokens vs those of the unembeddings of the bottom100 least toxic tokens under toxic instructions this suggests that selfcorrection prompts enhance a language models capability of latent concept recognition our analysis offers insights into the underlying mechanism of selfcorrection by characterizing how prompting works explainably for reproducibility our code is available
http://arxiv.org/abs/2505.11922v1,2025-05-17T09:13:47Z,"Yuheng Lu, ZiMeng Bai, Caixia Yuan, Huixing Jiang, Xiaojie Wang",enhancing complex instruction following for large language models with mixtureofcontexts finetuning,large language models llms exhibit remarkable capabilities in handling natural language tasks however they may struggle to consistently follow complex instructions including those involve multiple constraints posttraining llms using supervised finetuning sft is a standard approach to improve their ability to follow instructions in addressing complex instruction following existing efforts primarily focus on datadriven methods that synthesize complex instructionoutput pairs for sft however insufficient attention allocated to crucial subcontexts may reduce the effectiveness of sft in this work we propose transforming sequentially structured input instruction into multiple parallel instructions containing subcontexts to support processing this multiinput we propose miso multiinput singleoutput an extension to currently dominant decoderonly transformerbased llms miso introduces a mixtureofcontexts paradigm that jointly considers the overall instructionoutput alignment and the influence of individual subcontexts to enhance sft effectiveness we apply miso finetuning to complex instructionfollowing datasets and evaluate it with standard llm inference empirical results demonstrate the superiority of miso as a finetuning method for llms both in terms of effectiveness in complex instructionfollowing scenarios and its potential for training efficiency
http://arxiv.org/abs/2505.11908v1,2025-05-17T08:48:43Z,"Zhangyu Wang, Siyuan Gao, Rong Zhou, Hao Wang, Li Ning",elite embeddingless retrieval with iterative text exploration,large language models llms have achieved impressive progress in natural language processing but their limited ability to retain longterm context constrains performance on documentlevel or multiturn tasks retrievalaugmented generation rag mitigates this by retrieving relevant information from an external corpus however existing rag systems often rely on embeddingbased retrieval trained on corpuslevel semantic similarity which can lead to retrieving content that is semantically similar in form but misaligned with the questions true intent furthermore recent rag variants construct graph or hierarchybased structures to improve retrieval accuracy resulting in significant computation and storage overhead in this paper we propose an embeddingfree retrieval framework our method leverages the logical inferencing ability of llms in retrieval using iterative search space refinement guided by our novel importance measure and extend our retrieval results with logically related information without explicit graph construction experiments on longcontext qa benchmarks including novelqa and marathon show that our approach outperforms strong baselines while reducing storage and runtime by over an order of magnitude
http://arxiv.org/abs/2505.11900v1,2025-05-17T08:32:05Z,"Philipp Christmann, Gerhard Weikum",recursive question understanding for complex question answering over heterogeneous personal data,question answering over mixed sources like text and tables has been advanced by verbalizing all contents and encoding it with a language model a prominent case of such heterogeneous data is personal information user devices log vast amounts of data every day such as calendar entries workout statistics shopping records streaming history and more information needs range from simple lookups to queries of analytical nature the challenge is to provide humans with convenient access with small footprint so that all personal data stays on the user devices we present reqap a novel method that creates an executable operator tree for a given question via recursive decomposition operators are designed to enable seamless integration of structured and unstructured sources and the execution of the operator tree yields a traceable answer we further release the perqa benchmark with personabased data and questions covering a diverse spectrum of realistic user needs
http://arxiv.org/abs/2505.11893v1,2025-05-17T08:06:14Z,"Zepeng Ding, Dixuan Wang, Ziqin Luo, Guochao Jiang, Deqing Yang, Jiaqing Liang",rlap a reinforcement learning enhanced adaptive planning framework for multistep nlp task solving,multistep planning has been widely employed to enhance the performance of large language models llms on downstream natural language processing nlp tasks which decomposes the original task into multiple subtasks and guide llms to solve them sequentially without additional training when addressing task instances existing methods either preset the order of steps or attempt multiple paths at each step however these methods overlook instances linguistic features and rely on the intrinsic planning capabilities of llms to evaluate intermediate feedback and then select subtasks resulting in suboptimal outcomes to better solve multistep nlp tasks with llms in this paper we propose a reinforcement learning enhanced adaptive planning framework rlap in our framework we model an nlp task as a markov decision process mdp and employ an llm directly into the environment in particular a lightweight actor model is trained to estimate qvalues for natural language sequences consisting of states and actions through reinforcement learning therefore during sequential planning the linguistic features of each sequence in the mdp can be taken into account and the actor model interacts with the llm to determine the optimal order of subtasks for each task instance we apply rlap on three different types of nlp tasks and conduct extensive experiments on multiple datasets to verify rlaps effectiveness and robustness
http://arxiv.org/abs/2505.11891v1,2025-05-17T07:58:34Z,"Weikai Xu, Zhizheng Jiang, Yuxuan Liu, Wei Liu, Jian Luan, Yuanchun Li, Yunxin Liu, Bin Wang, Bo An",mobilebenchv2 a more realistic and comprehensive benchmark for vlmbased mobile agents,vlmbased mobile agents are increasingly popular due to their capabilities to interact with smartphone guis and xmlstructured texts and to complete daily tasks however existing online benchmarks struggle with obtaining stable reward signals due to dynamic environmental changes offline benchmarks evaluate the agents through singlepath trajectories which stands in contrast to the inherently multisolution characteristics of gui tasks additionally both types of benchmarks fail to assess whether mobile agents can handle noise or engage in proactive interactions due to a lack of noisy apps or overly full instructions during the evaluation process to address these limitations we use a slotbased instruction generation method to construct a more realistic and comprehensive benchmark named mobilebenchv2 mobilebenchv2 includes a common task split with offline multipath evaluation to assess the agents ability to obtain step rewards during task execution it contains a noisy split based on popups and ads apps and a contaminated split named aitznoise to formulate a real noisy environment furthermore an ambiguous instruction split with preset qa interactions is released to evaluate the agents proactive interaction capabilities we conduct evaluations on these splits using the singleagent framework appagentv1 the multiagent framework mobileagentv2 as well as other mobile agents such as uitars and osatlas code and data are available at httpshuggingfacecodatasetsxwk123mobilebenchv2
http://arxiv.org/abs/2505.11887v1,2025-05-17T07:44:54Z,"Xiechi Zhang, Zetian Ouyang, Linlin Wang, Gerard de Melo, Zhu Cao, Xiaoling Wang, Ya Zhang, Yanfeng Wang, Liang He",automedeval harnessing language models for automatic medical capability evaluation,with the proliferation of large language models llms in the medical domain there is increasing demand for improved evaluation techniques to assess their capabilities however traditional metrics like f1 and rouge which rely on token overlaps to measure quality significantly overlook the importance of medical terminology while human evaluation tends to be more reliable it can be very costly and may as well suffer from inaccuracies due to limits in human expertise and motivation although there are some evaluation methods based on llms their usability in the medical field is limited due to their proprietary nature or lack of expertise to tackle these challenges we present automedeval an opensourced automatic evaluation model with 13b parameters specifically engineered to measure the questionanswering proficiency of medical llms the overarching objective of automedeval is to assess the quality of responses produced by diverse models aspiring to significantly reduce the dependence on human evaluation specifically we propose a hierarchical training method involving curriculum instruction tuning and an iterative knowledge introspection mechanism enabling automedeval to acquire professional medical assessment capabilities with limited instructional data human evaluations indicate that automedeval surpasses other baselines in terms of correlation with human judgments
http://arxiv.org/abs/2505.11876v1,2025-05-17T07:00:02Z,"Yanbo Dai, Zhenlan Ji, Zongjie Li, Shuai Wang",namet robust massive model editing via noiseaware memory optimization,model editing techniques are essential for efficiently updating knowledge in large language models llms however the effectiveness of existing approaches degrades in massive editing scenarios particularly when evaluated with practical metrics or in contextrich settings we attribute these failures to embedding collisions among knowledge items which undermine editing reliability at scale to address this we propose namet noiseaware model editing in transformers a simple yet effective method that introduces noise during memory extraction via a oneline modification to memit extensive experiments across six llms and three datasets demonstrate that namet consistently outperforms existing methods when editing thousands of facts
http://arxiv.org/abs/2505.11875v1,2025-05-17T06:58:42Z,"Chi-Min Chan, Chunpu Xu, Jiaming Ji, Zhen Ye, Pengcheng Wen, Chunyang Jiang, Yaodong Yang, Wei Xue, Sirui Han, Yike Guo",j1 exploring simple testtime scaling for llmasajudge,the current focus of ai research is shifting from emphasizing model training towards enhancing evaluation quality a transition that is crucial for driving further advancements in ai systems traditional evaluation methods typically rely on reward models assigning scalar preference scores to outputs although effective such approaches lack interpretability leaving users often uncertain about why a reward model rates a particular response as high or low the advent of llmasajudge provides a more scalable and interpretable method of supervision offering insights into the decisionmaking process moreover with the emergence of large reasoning models which consume more tokens for deeper thinking and answer refinement scaling testtime computation in the llmasajudge paradigm presents an avenue for further boosting performance and providing more interpretability through reasoning traces in this paper we introduce which is first supervised finetuned on reflectionenhanced datasets collected via rejectionsampling and subsequently trained using reinforcement learning rl with verifiable rewards at inference time we apply simple testtime scaling stts strategies for additional performance improvement experimental results demonstrate that surpasses the previous stateoftheart llmasajudge by and exhibits a stronger scaling trend under stts additionally we present three key findings 1 existing llmasajudge does not inherently exhibit such scaling trend 2 model simply finetuned on reflectionenhanced datasets continues to demonstrate similarly weak scaling behavior 3 significant scaling trend emerges primarily during the rl phase suggesting that effective stts capability is acquired predominantly through rl training
http://arxiv.org/abs/2505.11861v1,2025-05-17T06:02:00Z,"Qi Zhou, Jie Zhang, Dongxia Wang, Qiang Liu, Tianlin Li, Jin Song Dong, Wenhai Wang, Qing Guo",fairpp a synthetic dataset for aligning llm with personalized preferences of social equity,human preference plays a crucial role in the refinement of large language models llms however collecting human preference feedback is costly and most existing datasets neglect the correlation between personalization and preferences to address this issue we introduce fairpp a synthetic dataset of personalized preferences targeting social equity derived from realworld social survey data which includes 28 social groups 98 equity topics and 5 personal preference dimensions leveraging gpt4omini we engage in roleplaying based on seven representative persona portrayals guided by existing social survey data yielding a total of 238623 preference records through fairpp we also contribute i an automated framework for generating preference data along with a more finegrained dataset of personalized preferences ii analysis of the positioning of the existing mainstream llms across five major global regions within the personalized preference space and iii a sample reweighting method for personalized preference alignment enabling alignment with a target persona while maximizing the divergence from other personas empirical experiments show our method outperforms the baselines
http://arxiv.org/abs/2505.11855v1,2025-05-17T05:45:16Z,"Guijin Son, Jiwoo Hong, Honglu Fan, Heejeong Nam, Hyunwoo Ko, Seungwon Lim, Jinyeop Song, Jinha Choi, Gonçalo Paulo, Youngjae Yu, Stella Biderman",when ai coscientists fail spota benchmark for automated verification of scientific research,recent advances in large language models llms have fueled the vision of automated scientific discovery often called ai coscientists to date prior work casts these systems as generative coauthors responsible for crafting hypotheses synthesizing code or drafting manuscripts in this work we explore a complementary application using llms as verifiers to automate the textbfacademic verification of scientific manuscripts to that end we introduce spot a dataset of 83 published papers paired with 91 errors significant enough to prompt errata or retraction crossvalidated with actual authors and human annotators evaluating stateoftheart llms on spot we find that none surpasses 211 recall or 61 precision o3 achieves the best scores with all others near zero furthermore confidence estimates are uniformly low and across eight independent runs models rarely rediscover the same errors undermining their reliability finally qualitative analysis with domain experts reveals that even the strongest models make mistakes resembling studentlevel misconceptions derived from misunderstandings these findings highlight the substantial gap between current llm capabilities and the requirements for dependable aiassisted academic verification
http://arxiv.org/abs/2505.11842v1,2025-05-17T05:06:38Z,"Xuannan Liu, Zekun Li, Zheqi He, Peipei Li, Shuhan Xia, Xing Cui, Huaibo Huang, Xi Yang, Ran He",videosafetybench a benchmark for safety evaluation of video lvlms,the increasing deployment of large visionlanguage models lvlms raises safety concerns under potential malicious inputs however existing multimodal safety evaluations primarily focus on model vulnerabilities exposed by static image inputs ignoring the temporal dynamics of video that may induce distinct safety risks to bridge this gap we introduce videosafetybench the first comprehensive benchmark designed to evaluate the safety of lvlms under videotext attacks it comprises 2264 videotext pairs spanning 48 finegrained unsafe categories each pairing a synthesized video with either a harmful query which contains explicit malice or a benign query which appears harmless but triggers harmful behavior when interpreted alongside the video to generate semantically accurate videos for safety evaluation we design a controllable pipeline that decomposes video semantics into subject images what is shown and motion text how it moves which jointly guide the synthesis of queryrelevant videos to effectively evaluate uncertain or borderline harmful outputs we propose rjscore a novel llmbased metric that incorporates the confidence of judge models and humanaligned decision threshold calibration extensive experiments show that benignquery video composition achieves average attack success rates of 672 revealing consistent vulnerabilities to videoinduced attacks we believe videosafetybench will catalyze future research into videobased safety evaluation and defense strategies
http://arxiv.org/abs/2505.11835v1,2025-05-17T04:47:16Z,"Hongliang Li, Jinan Xu, Gengping Cui, Changhao Guan, Fengran Mo, Kaiyu Huang",multilingual collaborative defense for large language models,the robustness and security of large language models llms has become a prominent research area one notable vulnerability is the ability to bypass llm safeguards by translating harmful queries into rare or underrepresented languages a simple yet effective method of jailbreaking these models despite the growing concern there has been limited research addressing the safeguarding of llms in multilingual scenarios highlighting an urgent need to enhance multilingual safety in this work we investigate the correlation between various attack features across different languages and propose multilingual collaborative defense mcd a novel learning method that optimizes a continuous soft safety prompt automatically to facilitate multilingual safeguarding of llms the mcd approach offers three advantages first it effectively improves safeguarding performance across multiple languages second mcd maintains strong generalization capabilities while minimizing false refusal rates third mcd mitigates the language safety misalignment caused by imbalances in llm training corpora to evaluate the effectiveness of mcd we manually construct multilingual versions of commonly used jailbreak benchmarks such as maliciousinstruct and advbench to assess various safeguarding methods additionally we introduce these datasets in underrepresented zeroshot languages to verify the language transferability of mcd the results demonstrate that mcd outperforms existing approaches in safeguarding against multilingual jailbreak attempts while also exhibiting strong language transfer capabilities our code is available at httpsgithubcomhliangleemcd
http://arxiv.org/abs/2505.11829v1,2025-05-17T04:34:19Z,"Chenlu Wang, Weimin Lyu, Ritwik Banerjee",class distillation with mahalanobis contrast an efficient training paradigm for pragmatic language understanding tasks,detecting deviant language such as sexism or nuanced language such as metaphors or sarcasm is crucial for enhancing the safety clarity and interpretation of online social discourse while existing classifiers deliver strong results on these tasks they often come with significant computational cost and high data demands in this work we propose textbfclass textbfdistillation clad a novel training paradigm that targets the core challenge distilling a small welldefined target class from a highly diverse and heterogeneous background clad integrates two key innovations i a loss function informed by the structural properties of class distributions based on mahalanobis distance and ii an interpretable decision algorithm optimized for class separation across three benchmark detection tasks sexism metaphor and sarcasm clad outperforms competitive baselines and even with smaller language models and orders of magnitude fewer parameters achieves performance comparable to several large language models llms these results demonstrate clad as an efficient tool for pragmatic language understanding tasks that require gleaning a small target class from a larger heterogeneous background
http://arxiv.org/abs/2505.11827v1,2025-05-17T04:26:39Z,"Yansong Ning, Wei Li, Jun Fang, Naiqiang Tan, Hao Liu",not all thoughts are generated equal efficient llm reasoning via multiturn reinforcement learning,compressing long chainofthought cot from large language models llms is an emerging strategy to improve the reasoning efficiency of llms despite its promising benefits existing studies equally compress all thoughts within a long cot hindering more concise and effective reasoning to this end we first investigate the importance of different thoughts by examining their effectiveness and efficiency in contributing to reasoning through automatic long cot chunking and monte carlo rollouts building upon the insights we propose a theoretically bounded metric to jointly measure the effectiveness and efficiency of different thoughts we then propose longshort an efficient reasoning framework that enables two llms to collaboratively solve the problem a longthought llm for more effectively generating important thoughts while a shortthought llm for efficiently generating remaining thoughts specifically we begin by synthesizing a small amount of coldstart data to finetune llms for longthought and shortthought reasoning styles respectively furthermore we propose a synergizingoriented multiturn reinforcement learning focusing on the model selfevolution and collaboration between longthought and shortthought llms experimental results show that our method enables qwen257b and llama318b to achieve comparable performance compared to deepseekr1distillqwen7b and deepseekr1distillllama8b while reducing token length by over 80 across the math500 aime2425 amc23 and gpqa diamond benchmarks our data and code are available at httpsgithubcomyasninglongotimesshort
http://arxiv.org/abs/2505.11820v1,2025-05-17T04:06:12Z,"Kaitao Song, Xiaohua Wang, Xu Tan, Huiqiang Jiang, Chengruidong Zhang, Yongliang Shen, Cen LU, Zihao Li, Zifan Song, Caihua Shan, Yansen Wang, Kan Ren, Xiaoqing Zheng, Tao Qin, Yuqing Yang, Dongsheng Li, Lili Qiu",chainofmodel learning for language model,in this paper we propose a novel learning paradigm termed chainofmodel com which incorporates the causal relationship into the hidden states of each layer as a chain style thereby introducing great scaling efficiency in model training and inference flexibility in deployment we introduce the concept of chainofrepresentation cor which formulates the hidden states at each layer as a combination of multiple subrepresentations ie chains at the hidden dimension level in each layer each chain from the output representations can only view all of its preceding chains in the input representations consequently the model built upon com framework can progressively scale up the model size by increasing the chains based on the previous models ie chains and offer multiple submodels at varying sizes for elastic inference by using different chain numbers based on this principle we devise chainoflanguagemodel colm which incorporates the idea of com into each layer of transformer architecture based on colm we further introduce colmair by introducing a kv sharing mechanism that computes all keys and values within the first chain and then shares across all chains this design demonstrates additional extensibility such as enabling seamless lm switching prefilling acceleration and so on experimental results demonstrate our colm family can achieve comparable performance to the standard transformer while simultaneously enabling greater flexiblity such as progressive scaling to improve training efficiency and offer multiple varying model sizes for elastic inference paving a a new way toward building language models our code will be released in the future at httpsgithubcommicrosoftcolm
http://arxiv.org/abs/2505.11812v1,2025-05-17T03:44:23Z,"Yang Tan, Wenrui Gou, Bozitao Zhong, Liang Hong, Huiqun Yu, Bingxin Zhou",venusx unlocking finegrained functional understanding of proteins,deep learning models have driven significant progress in predicting protein function and interactions at the protein level while these advancements have been invaluable for many biological applications such as enzyme engineering and function annotation a more detailed perspective is essential for understanding protein functional mechanisms and evaluating the biological knowledge captured by models to address this demand we introduce venusx the first largescale benchmark for finegrained functional annotation and functionbased protein pairing at the residue fragment and domain levels venusx comprises three major task categories across six types of annotations including residuelevel binary classification fragmentlevel multiclass classification and pairwise functional similarity scoring for identifying critical active sites binding sites conserved sites motifs domains and epitopes the benchmark features over 878000 samples curated from major opensource databases such as interpro biolip and sabdab by providing mixedfamily and crossfamily splits at three sequence identity thresholds our benchmark enables a comprehensive assessment of model performance on both indistribution and outofdistribution scenarios for baseline evaluation we assess a diverse set of popular and opensource models including pretrained protein language models sequencestructure hybrids structurebased methods and alignmentbased techniques their performance is reported across all benchmark datasets and evaluation settings using multiple metrics offering a thorough comparison and a strong foundation for future research code and data are publicly available at httpsgithubcomai4proteinvenusx
http://arxiv.org/abs/2505.11811v1,2025-05-17T03:43:30Z,"Taolin Zhang, Dongyang Li, Qizhou Chen, Chengyu Wang, Xiaofeng He",belle a bilevel multiagent reasoning framework for multihop question answering,multihop question answering qa involves finding multiple relevant passages and performing stepbystep reasoning to answer complex questions previous works on multihop qa employ specific methods from different modeling perspectives based on large language models llms regardless of the question types in this paper we first conduct an indepth analysis of public multihop qa benchmarks dividing the questions into four types and evaluating five types of cuttingedge methods for multihop qa chainofthought cot singlestep iterativestep substep and adaptivestep we find that different types of multihop questions have varying degrees of sensitivity to different types of methods thus we propose a bilevel multiagent reasoning belle framework to address multihop qa by specifically focusing on the correspondence between question types and methods where each type of method is regarded as an operator by prompting llms differently the first level of belle includes multiple agents that debate to obtain an executive plan of combined operators to address the multihop qa task comprehensively during the debate in addition to the basic roles of affirmative debater negative debater and judge at the second level we further leverage fast and slow debaters to monitor whether changes in viewpoints are reasonable extensive experiments demonstrate that belle significantly outperforms strong baselines in various datasets additionally the model consumption of belle is higher costeffectiveness than that of single models in more complex multihop qa scenarios
http://arxiv.org/abs/2505.11810v1,2025-05-17T03:43:16Z,"Shen Li, Renfen Hu, Lijun Wang",efficiently building a domainspecific large language model from scratch a case study of a classical chinese large language model,generalpurpose large language models demonstrate notable capabilities in language comprehension and generation achieving results that are comparable to or even surpass human performance in many language information processing tasks nevertheless when general models are applied to some specific domains eg classical chinese texts their effectiveness is often unsatisfactory and finetuning opensource foundational models similarly struggles to adequately incorporate domainspecific knowledge to address this challenge this study developed a large language model ai taiyan specifically designed for understanding and generating classical chinese experiments show that with a reasonable model design data processing foundational training and finetuning satisfactory results can be achieved with only 18 billion parameters in key tasks related to classical chinese information processing such as punctuation identification of allusions explanation of word meanings and translation between ancient and modern chinese this model exhibits a clear advantage over both generalpurpose large models and domainspecific traditional models achieving levels close to or surpassing human baselines this research provides a reference for the efficient construction of specialized domainspecific large language models furthermore the paper discusses the application of this model in fields such as the collation of ancient texts dictionary editing and language research combined with case studies
http://arxiv.org/abs/2505.11807v1,2025-05-17T03:28:24Z,"Yufei Xiang, Yiqun Shen, Yeqin Zhang, Cam-Tu Nguyen",retrospex language agent meets offline reinforcement learning critic,large language models llms possess extensive knowledge and commonsense reasoning capabilities making them valuable for creating powerful agents however existing llm agent frameworks have not fully utilized past experiences for improvement this work introduces a new llmbased agent framework called retrospex which addresses this challenge by analyzing past experiences in depth unlike previous approaches retrospex does not directly integrate experiences into the llms context instead it combines the llms action likelihood with action values estimated by a reinforcement learning rl critic which is trained on past experiences through an offline retrospection process additionally retrospex employs a dynamic action rescoring mechanism that increases the importance of experiencebased values for tasks that require more interaction with the environment we evaluate retrospex in scienceworld alfworld and webshop environments demonstrating its advantages over strong contemporary baselines
http://arxiv.org/abs/2505.11770v1,2025-05-17T00:31:39Z,"Jing Huang, Junyi Tao, Thomas Icard, Diyi Yang, Christopher Potts",internal causal mechanisms robustly predict language model outofdistribution behaviors,interpretability research now offers a variety of techniques for identifying abstract internal mechanisms in neural networks can such techniques be used to predict how models will behave on outofdistribution examples in this work we provide a positive answer to this question through a diverse set of language modeling tasksincluding symbol manipulation knowledge retrieval and instruction followingwe show that the most robust features for correctness prediction are those that play a distinctive causal role in the models behavior specifically we propose two methods that leverage causal mechanisms to predict the correctness of model outputs counterfactual simulation checking whether key causal variables are realized and value probing using the values of those variables to make predictions both achieve high aucroc in distribution and outperform methods that rely on causalagnostic features in outofdistribution settings where predicting model behaviors is more crucial our work thus highlights a novel and significant application for internal causal analysis of language models
http://arxiv.org/abs/2505.11764v1,2025-05-17T00:11:58Z,"Raymond Baartmans, Matthew Raffel, Rahul Vikram, Aiden Deringer, Lizhong Chen",towards universal semantics with large language models,the natural semantic metalanguage nsm is a linguistic theory based on a universal set of semantic primes simple primitive wordmeanings that have been shown to exist in most if not all languages of the world according to this framework any word regardless of complexity can be paraphrased using these primes revealing a clear and universally translatable meaning these paraphrases known as explications can offer valuable applications for many natural language processing nlp tasks but producing them has traditionally been a slow manual process in this work we present the first study of using large language models llms to generate nsm explications we introduce automatic evaluation methods a tailored dataset for training and evaluation and finetuned models for this task our 1b and 8b models outperform gpt4o in producing accurate crosstranslatable explications marking a significant step toward universal semantic representation with llms and opening up new possibilities for applications in semantic analysis translation and beyond
http://arxiv.org/abs/2505.11756v1,2025-05-16T23:30:17Z,"David Chanin, Tomáš Dulka, Adrià Garriga-Alonso",feature hedging correlated features break narrow sparse autoencoders,it is assumed that sparse autoencoders saes decompose polysemantic activations into interpretable linear directions as long as the activations are composed of sparse linear combinations of underlying features however we find that if an sae is more narrow than the number of underlying true features on which it is trained and there is correlation between features the sae will merge components of correlated features together thus destroying monosemanticity in llm saes these two conditions are almost certainly true this phenomenon which we call feature hedging is caused by sae reconstruction loss and is more severe the narrower the sae in this work we introduce the problem of feature hedging and study it both theoretically in toy models and empirically in saes trained on llms we suspect that feature hedging may be one of the core reasons that saes consistently underperform supervised baselines finally we use our understanding of feature hedging to propose an improved variant of matryoshka saes our work shows there remain fundamental issues with saes but we are hopeful that that highlighting feature hedging will catalyze future advances that allow saes to achieve their full potential of interpreting llms at scale
http://arxiv.org/abs/2505.11754v1,2025-05-16T23:29:47Z,"Wenyu Huang, Pavlos Vougiouklis, Mirella Lapata, Jeff Z. Pan",masking in multihop qa an analysis of how language models perform with context permutation,multihop question answering mhqa adds layers of complexity to question answering making it more challenging when language models lms are prompted with multiple search results they are tasked not only with retrieving relevant information but also employing multihop reasoning across the information sources although lms perform well on traditional questionanswering tasks the causal mask can hinder their capacity to reason across complex contexts in this paper we explore how lms respond to multihop questions by permuting search results retrieved documents under various configurations our study reveals interesting findings as follows 1 encoderdecoder models such as the ones in the flant5 family generally outperform causal decoderonly lms in mhqa tasks despite being significantly smaller in size 2 altering the order of gold documents reveals distinct trends in both flan t5 models and finetuned decoderonly models with optimal performance observed when the document order aligns with the reasoning chain order 3 enhancing causal decoderonly models with bidirectional attention by modifying the causal mask can effectively boost their end performance in addition to the above we conduct a thorough investigation of the distribution of lm attention weights in the context of mhqa our experiments reveal that attention weights tend to peak at higher values when the resulting answer is correct we leverage this finding to heuristically improve lms performance on this task our code is publicly available at httpsgithubcomhwy9855multihopqareasoning
http://arxiv.org/abs/2505.11746v1,2025-05-16T23:06:11Z,"Xianglong Xu, John Bowen, Rojin Taheri",token masking improves transformerbased text classification,while transformerbased models achieve strong performance on text classification we explore whether masking input tokens can further enhance their effectiveness we propose token masking regularization a simple yet theoretically motivated method that randomly replaces input tokens with a special mask token at probability p this introduces stochastic perturbations during training leading to implicit gradient averaging that encourages the model to capture deeper intertoken dependencies experiments on language identification and sentiment analysis across diverse models mbert qwen2505b tinyllama11b show consistent improvements over standard regularization techniques we identify taskspecific optimal masking rates with p 01 as a strong general default we attribute the gains to two key effects 1 input perturbation reduces overfitting and 2 gradientlevel smoothing acts as implicit ensembling
http://arxiv.org/abs/2505.11739v1,2025-05-16T22:52:24Z,"Feijiang Han, Xiaodong Yu, Jianheng Tang, Lyle Ungar",zerotuning unlocking the initial tokens power to enhance large language models without training,recently trainingfree methods for improving large language models llms have attracted growing interest with tokenlevel attention tuning emerging as a promising and interpretable direction however existing methods typically rely on auxiliary mechanisms to identify important or irrelevant taskspecific tokens introducing potential bias and limiting applicability in this paper we uncover a surprising and elegant alternative the semantically empty initial token is a powerful and underexplored control point for optimizing model behavior through theoretical analysis we show that tuning the initial tokens attention sharpens or flattens the attention distribution over subsequent tokens and its role as an attention sink amplifies this effect empirically we find that 1 tuning its attention improves llm performance more effectively than tuning other taskspecific tokens 2 the effect follows a consistent trend across layers with earlier layers having greater impact but varies across attention heads with different heads showing distinct preferences in how they attend to this token based on these findings we propose zerotuning a trainingfree approach that improves llm performance by applying headspecific attention adjustments to this special token despite tuning only one token zerotuning achieves higher performance on text classification multiplechoice and multiturn conversation tasks across models such as llama qwen and deepseek for example zerotuning improves llama318b by 1171 on classification 264 on qa tasks and raises its multiturn score from 7804 to 7966 the method is also robust to limited resources fewshot settings long contexts quantization decoding strategies and prompt variations our work sheds light on a previously overlooked control point in llms offering new insights into both inferencetime tuning and model interpretability
http://arxiv.org/abs/2505.11737v1,2025-05-16T22:47:32Z,"Tunyu Zhang, Haizhou Shi, Yibin Wang, Hengyi Wang, Xiaoxiao He, Zhuowei Li, Haoxian Chen, Ligong Han, Kai Xu, Huan Zhang, Dimitris Metaxas, Hao Wang",tokenlevel uncertainty estimation for large language model reasoning,while large language models llms have demonstrated impressive capabilities their output quality remains inconsistent across various application scenarios making it difficult to identify trustworthy responses especially in complex tasks requiring multistep reasoning in this paper we propose a tokenlevel uncertainty estimation framework to enable llms to selfassess and selfimprove their generation quality in mathematical reasoning specifically we introduce lowrank random weight perturbation to llm decoding generating predictive distributions that we use to estimate tokenlevel uncertainties we then aggregate these uncertainties to reflect semantic uncertainty of the generated sequences experiments on mathematical reasoning datasets of varying difficulty demonstrate that our tokenlevel uncertainty metrics strongly correlate with answer correctness and model robustness additionally we explore using uncertainty to directly enhance the models reasoning performance through multiple generations and the particle filtering algorithm our approach consistently outperforms existing uncertainty estimation methods establishing effective uncertainty estimation as a valuable tool for both evaluating and improving reasoning generation in llms
http://arxiv.org/abs/2505.11733v1,2025-05-16T22:34:36Z,"Kevin Wu, Eric Wu, Rahul Thapa, Kevin Wei, Angela Zhang, Arvind Suresh, Jacqueline J. Tao, Min Woo Sun, Alejandro Lozano, James Zou",medcasereasoning evaluating and learning diagnostic reasoning from clinical case reports,doctors and patients alike increasingly use large language models llms to diagnose clinical cases however unlike domains such as math or coding where correctness can be objectively defined by the final answer medical diagnosis requires both the outcome and the reasoning process to be accurate currently widely used medical benchmarks like medqa and mmlu assess only accuracy in the final answer overlooking the quality and faithfulness of the clinical reasoning process to address this limitation we introduce medcasereasoning the first openaccess dataset for evaluating llms on their ability to align with clinicianauthored diagnostic reasoning the dataset includes 14489 diagnostic questionandanswer cases each paired with detailed reasoning statements derived from openaccess medical case reports we evaluate stateoftheart reasoning llms on medcasereasoning and find significant shortcomings in their diagnoses and reasoning for instance the topperforming opensource model deepseekr1 achieves only 48 10shot diagnostic accuracy and mentions only 64 of the clinician reasoning statements recall however we demonstrate that finetuning llms on the reasoning traces derived from medcasereasoning significantly improves diagnostic accuracy and clinical reasoning recall by an average relative gain of 29 and 41 respectively the opensource dataset code and models are available at httpsgithubcomkevinwu23stanfordmedcasereasoning
http://arxiv.org/abs/2505.11731v1,2025-05-16T22:26:03Z,"Harshil Vejendla, Haizhou Shi, Yibin Wang, Tunyu Zhang, Huan Zhang, Hao Wang",efficient uncertainty estimation via distillation of bayesian large language models,recent advances in uncertainty estimation for large language models llms during downstream adaptation have addressed key challenges of reliability and simplicity however existing bayesian methods typically require multiple sampling iterations during inference creating significant efficiency issues that limit practical deployment in this paper we investigate the possibility of eliminating the need for testtime sampling for llm uncertainty estimation specifically when given an offtheshelf bayesian llm we distill its aligned confidence into a nonbayesian student llm by minimizing the divergence between their predictive distributions unlike typical calibration methods our distillation is carried out solely on the training dataset without the need of an additional validation dataset this simple yet effective approach achieves ntimes more efficient uncertainty estimation during testing where n is the number of samples traditionally required by bayesian llms our extensive experiments demonstrate that uncertainty estimation capabilities on training data can successfully generalize to unseen test data through our distillation technique consistently producing results comparable to or even better than stateoftheart bayesian llms
http://arxiv.org/abs/2505.11726v1,2025-05-16T22:14:58Z,"Shun Inadumi, Nobuhiro Ueda, Koichiro Yoshino",disambiguating reference in visually grounded dialogues through joint modeling of textual and multimodal semantic structures,multimodal reference resolution including phrase grounding aims to understand the semantic relations between mentions and realworld objects phrase grounding between images and their captions is a wellestablished task in contrast for realworld applications it is essential to integrate textual and multimodal reference resolution to unravel the reference relations within dialogue especially in handling ambiguities caused by pronouns and ellipses this paper presents a framework that unifies textual and multimodal reference resolution by mapping mention embeddings to object embeddings and selecting mentions or objects based on their similarity our experiments show that learning textual reference resolution such as coreference resolution and predicateargument structure analysis positively affects performance in multimodal reference resolution in particular our model with coreference resolution performs better in pronoun phrase grounding than representative models for this task mdetr and glip our qualitative analysis demonstrates that incorporating textual reference relations strengthens the confidence scores between mentions including pronouns and predicates and objects which can reduce the ambiguities that arise in visually grounded dialogues
http://arxiv.org/abs/2505.11717v1,2025-05-16T22:00:26Z,"Xilong Wang, John Bloch, Zedian Shao, Yuepeng Hu, Shuyan Zhou, Neil Zhenqiang Gong",envinjection environmental prompt injection attack to multimodal web agents,multimodal large language model mllmbased web agents interact with webpage environments by generating actions based on screenshots of the webpages environmental prompt injection attacks manipulate the environment to induce the web agent to perform a specific attackerchosen actionreferred to as the target action however existing attacks suffer from limited effectiveness or stealthiness or are impractical in realworld settings in this work we propose envinjection a new attack that addresses these limitations our attack adds a perturbation to the raw pixel values of the rendered webpage which can be implemented by modifying the webpages source code after these perturbed pixels are mapped into a screenshot the perturbation induces the web agent to perform the target action we formulate the task of finding the perturbation as an optimization problem a key challenge in solving this problem is that the mapping between raw pixel values and screenshot is nondifferentiable making it difficult to backpropagate gradients to the perturbation to overcome this we train a neural network to approximate the mapping and apply projected gradient descent to solve the reformulated optimization problem extensive evaluation on multiple webpage datasets shows that envinjection is highly effective and significantly outperforms existing baselines
http://arxiv.org/abs/2505.11693v1,2025-05-16T21:01:28Z,"Ana Ezquerro, David Vilares, Anssi Yli-Jyrä, Carlos Gómez-Rodríguez",hierarchical bracketing encodings for dependency parsing as tagging,we present a family of encodings for sequence labeling dependency parsing based on the concept of hierarchical bracketing we prove that the existing 4bit projective encoding belongs to this family but it is suboptimal in the number of labels used to encode a tree we derive an optimal hierarchical bracketing which minimizes the number of symbols used and encodes projective trees using only 12 distinct labels vs 16 for the 4bit encoding we also extend optimal hierarchical bracketing to support arbitrary nonprojectivity in a more compact way than previous encodings our new encodings yield competitive accuracy on a diverse set of treebanks
http://arxiv.org/abs/2505.11690v1,2025-05-16T20:57:39Z,"Sukairaj Hafiz Imam, Babangida Sani, Dawit Ketema Gete, Bedru Yimam Ahamed, Ibrahim Said Ahmad, Idris Abdulmumin, Seid Muhie Yimam, Muhammad Yahuza Bello, Shamsuddeen Hassan Muhammad",automatic speech recognition for african lowresource languages challenges and future directions,automatic speech recognition asr technologies have transformed humancomputer interaction however lowresource languages in africa remain significantly underrepresented in both research and practical applications this study investigates the major challenges hindering the development of asr systems for these languages which include data scarcity linguistic complexity limited computational resources acoustic variability and ethical concerns surrounding bias and privacy the primary goal is to critically analyze these barriers and identify practical inclusive strategies to advance asr technologies within the african context recent advances and case studies emphasize promising strategies such as communitydriven data collection selfsupervised and multilingual learning lightweight model architectures and techniques that prioritize privacy evidence from pilot projects involving various african languages showcases the feasibility and impact of customized solutions which encompass morphemebased modeling and domainspecific asr applications in sectors like healthcare and education the findings highlight the importance of interdisciplinary collaboration and sustained investment to tackle the distinct linguistic and infrastructural challenges faced by the continent this study offers a progressive roadmap for creating ethical efficient and inclusive asr systems that not only safeguard linguistic diversity but also improve digital accessibility and promote socioeconomic participation for speakers of african languages
http://arxiv.org/abs/2505.11683v1,2025-05-16T20:44:07Z,"Susanna Rücker, Alan Akbik",evaluating design decisions for dual encoderbased entity disambiguation,entity disambiguation ed is the task of linking mentions in text to corresponding entries in a knowledge base dual encoders address this by embedding mentions and label candidates in a shared embedding space and applying a similarity metric to predict the correct label in this work we focus on evaluating key design decisions for dual encoderbased ed such as its loss function similarity metric label verbalization format and negative sampling strategy we present the resulting model verbalized a documentlevel dual encoder model that includes contextual label verbalizations and efficient hard negative sampling additionally we explore an iterative prediction variant that aims to improve the disambiguation of challenging data points comprehensive experiments on aidayago validate the effectiveness of our approach offering insights into impactful design choices that result in a new stateoftheart system on the zelda benchmark
http://arxiv.org/abs/2505.11679v1,2025-05-16T20:39:30Z,"Zhibo Hu, Chen Wang, Yanfeng Shu, Hye-Young Paik, Liming Zhu",ambiguity resolution in texttostructured data mapping,ambiguity in natural language is a significant obstacle for achieving accurate text to structured data mapping through large language models llms which affects the performance of tasks such as mapping text to agentic tool calling and texttosql queries existing methods of ambiguity handling either exploit react framework to produce the correct mapping through trial and error or supervised fine tuning to guide models to produce a biased mapping to improve certain tasks in this paper we adopt a different approach that characterizes the representation difference of ambiguous text in the latent space and leverage the difference to identify ambiguity before mapping them to structured data to detect ambiguity of a sentence we focused on the relationship between ambiguous questions and their interpretations and what cause the llm ignore multiple interpretations different to the distance calculated by dense embedding vectors we utilize the observation that ambiguity is caused by concept missing in latent space of llm to design a new distance measurement computed through the path kernel by the integral of gradient values for each concepts from sparseautoencoder sae under each state we identify patterns to distinguish ambiguous questions with this measurement based on our observation we propose a new framework to improve the performance of llms on ambiguous agentic tool calling through missing concepts prediction
http://arxiv.org/abs/2505.11665v1,2025-05-16T19:59:17Z,"Shubham Vatsal, Harsh Dubey, Aditi Singh",multilingual prompt engineering in large language models a survey across nlp tasks,large language models llms have demonstrated impressive performance across a wide range of natural language processing nlp tasks however ensuring their effectiveness across multiple languages presents unique challenges multilingual prompt engineering has emerged as a key approach to enhance llms capabilities in diverse linguistic settings without requiring extensive parameter retraining or finetuning with growing interest in multilingual prompt engineering over the past two to three years researchers have explored various strategies to improve llms performance across languages and nlp tasks by crafting structured natural language prompts researchers have successfully extracted knowledge from llms across different languages making these techniques an accessible pathway for a broader audience including those without deep expertise in machine learning to harness the capabilities of llms in this paper we survey and categorize different multilingual prompting techniques based on the nlp tasks they address across a diverse set of datasets that collectively span around 250 languages we further highlight the llms employed present a taxonomy of approaches and discuss potential stateoftheart sota methods for specific multilingual datasets additionally we derive a range of insights across language families and resource levels highresource vs lowresource including analyses such as the distribution of nlp tasks by language resource type and the frequency of prompting methods across different language families our survey reviews 36 research papers covering 39 prompting techniques applied to 30 multilingual nlp tasks with the majority of these studies published in the last two years
http://arxiv.org/abs/2505.11643v1,2025-05-16T19:08:31Z,Xiang Fu,can an easytohard curriculum make reasoning emerge in small language models evidence from a fourstage curriculum on gpt2,we demonstrate that a developmentally ordered curriculum markedly improves reasoning transparency and sampleefficiency in small language models slms concretely we train cognivolve a 124 mparameter gpt2 model on a fourstage syllabus that ascends from lexical matching to multistep symbolic inference and then evaluate it without any taskspecific finetuning cognivolve reaches target accuracy in half the optimization steps of a singlephase baseline activates an orderofmagnitude more gradientsalient reasoning heads and shifts those heads toward deeper layers yielding higherentropy attention that balances local and longrange context the same curriculum applied out of order or with optimizer resets fails to reproduce these gains confirming that progressionnot extra computedrives the effect we also identify open challenges finalanswer success still lags a conventional run by about 30 and our saliency probe underdetects verbalknowledge heads in the hardest stage suggesting directions for mixedstage finetuning and probe expansion
http://arxiv.org/abs/2505.11628v1,2025-05-16T18:45:59Z,"Berkcan Kapusuzoglu, Supriyo Chakraborty, Chia-Hsuan Lee, Sambit Sahu",critiqueguided distillation improving supervised finetuning via better distillation,supervised finetuning sft using expert demonstrations often suffer from the imitation problem where the model learns to reproduce the correct responses without emphunderstanding the underlying rationale to address this limitation we propose textsccritiqueguided distillation cgd a novel multistage framework that integrates teacher model generated emphexplanatory critiques and emphrefined responses into the sft process a student model is then trained to map the triplet of prompt teacher critique and its own initial response to the corresponding refined teacher response thereby learning both emphwhat to imitate and emphwhy using entropybased analysis we show that textsccgd reduces refinement uncertainty and can be interpreted as a bayesian posterior update we perform extensive empirical evaluation of textsccgd on variety of benchmark tasks and demonstrate significant gains on both math amc23 175 and language understanding tasks mmlupro 63 while successfully mitigating the format drift issues observed in previous critique finetuning cft techniques
http://arxiv.org/abs/2505.11626v1,2025-05-16T18:42:04Z,"Udita Patel, Rutu Mulkar, Jay Roberts, Cibi Chakravarthy Senthilkumar, Sujay Gandhi, Xiaofei Zheng, Naumaan Nayyar, Rafael Castrillo",thelma task based holistic evaluation of large language model applicationsrag question answering,we propose thelma task based holistic evaluation of large language model applications a reference free framework for rag retrieval augmented generation based question answering qa applications thelma consist of six interdependent metrics specifically designed for holistic fine grained evaluation of rag qa applications thelma framework helps developers and application owners evaluate monitor and improve end to end rag qa pipelines without requiring labelled sources or reference responseswe also present our findings on the interplay of the proposed thelma metrics which can be interpreted to identify the specific rag component needing improvement in qa applications
http://arxiv.org/abs/2505.11615v1,2025-05-16T18:23:10Z,"Jian-Qiao Zhu, Haijiang Yan, Thomas L. Griffiths",steering risk preferences in large language models by aligning behavioral and neural representations,changing the behavior of large language models llms can be as straightforward as editing the transformers residual streams using appropriately constructed steering vectors these modifications to internal neural activations a form of representation engineering offer an effective and targeted means of influencing model behavior without retraining or finetuning the model but how can such steering vectors be systematically identified we propose a principled approach for uncovering steering vectors by aligning latent representations elicited through behavioral methods specifically markov chain monte carlo with llms with their neural counterparts to evaluate this approach we focus on extracting latent risk preferences from llms and steering their riskrelated outputs using the aligned representations as steering vectors we show that the resulting steering vectors successfully and reliably modulate llm outputs in line with the targeted behavior
http://arxiv.org/abs/2505.11614v1,2025-05-16T18:22:05Z,"Jian-Qiao Zhu, Hanbo Xie, Dilip Arumugam, Robert C. Wilson, Thomas L. Griffiths",using reinforcement learning to train large language models to explain human decisions,a central goal of cognitive modeling is to develop models that not only predict human behavior but also provide insight into the underlying cognitive mechanisms while neural network models trained on largescale behavioral data often achieve strong predictive performance they typically fall short in offering interpretable explanations of the cognitive processes they capture in this work we explore the potential of pretrained large language models llms to serve as dualpurpose cognitive modelscapable of both accurate prediction and interpretable explanation in natural language specifically we employ reinforcement learning with outcomebased rewards to guide llms toward generating explicit reasoning traces for explaining human risky choices our findings demonstrate that this approach produces highquality explanations alongside strong quantitative predictions of human decisions
http://arxiv.org/abs/2505.11613v1,2025-05-16T18:21:52Z,"Xiaomin Li, Mingye Gao, Yuexing Hao, Taoran Li, Guangya Wan, Zihan Wang, Yijun Wang",medguide benchmarking clinical decisionmaking in large language models,clinical guidelines typically structured as decision trees are central to evidencebased medical practice and critical for ensuring safe and accurate diagnostic decisionmaking however it remains unclear whether large language models llms can reliably follow such structured protocols in this work we introduce medguide a new benchmark for evaluating llms on their ability to make guidelineconsistent clinical decisions medguide is constructed from 55 curated nccn decision trees across 17 cancer types and uses clinical scenarios generated by llms to create a large pool of multiplechoice diagnostic questions we apply a twostage quality selection process combining expertlabeled reward models and llmasajudge ensembles across ten clinical and linguistic criteria to select 7747 highquality samples we evaluate 25 llms spanning generalpurpose opensource and medically specialized models and find that even domainspecific llms often underperform on tasks requiring structured guideline adherence we also test whether performance can be improved via incontext guideline inclusion or continued pretraining our findings underscore the importance of medguide in assessing whether llms can operate safely within the procedural frameworks expected in realworld clinical settings
http://arxiv.org/abs/2505.11611v1,2025-05-16T18:20:42Z,"Bofan Gong, Shiyang Lai, Dawn Song",probing the vulnerability of large language models to polysemantic interventions,polysemanticity where individual neurons encode multiple unrelated features is a wellknown characteristic of large neural networks and remains a central challenge in the interpretability of language models at the same time its implications for model safety are also poorly understood leveraging recent advances in sparse autoencoders we investigate the polysemantic structure of two small models pythia70m and gpt2small and evaluate their vulnerability to targeted covert interventions at the prompt feature token and neuron levels our analysis reveals a consistent polysemantic topology shared across both models strikingly we demonstrate that this structure can be exploited to mount effective interventions on two larger blackbox instructiontuned models llama318binstruct and gemma29binstruct these findings suggest not only the generalizability of the interventions but also point to a stable and transferable polysemantic structure that could potentially persist across architectures and training regimes
http://arxiv.org/abs/2505.11604v1,2025-05-16T18:12:26Z,"Kyudan Jung, Hojun Cho, Jooyeol Yun, Jaehyeok Jang, Jagul Choo",talk to your slides efficient slide editing agent with large language models,existing research on large language models llms for powerpoint predominantly focuses on slide generation overlooking the common yet tedious task of editing existing slides we introduce talktoyourslides an llmpowered agent that directly edits slides within active powerpoint sessions through com communication our system employs a twolevel approach 1 highlevel processing where an llm agent interprets instructions and formulates editing plans and 2 lowlevel execution where python scripts directly manipulate powerpoint objects unlike previous methods relying on predefined operations our approach enables more flexible and contextuallyaware editing to facilitate evaluation we present tsbench a humanannotated dataset of 379 diverse editing instructions with corresponding slide variations experimental results demonstrate that talktoyourslides significantly outperforms baseline methods in execution success rate instruction fidelity and editing efficiency our code and benchmark are available at httpsanonymous4opensciencertalktoyourslides
http://arxiv.org/abs/2505.11595v1,2025-05-16T18:02:05Z,"Peter Chen, Xiaopeng Li, Ziniu Li, Xi Chen, Tianyi Lin",spectral policy optimization coloring your incorrect reasoning in grpo,reinforcement learning rl has demonstrated significant success in enhancing reasoning capabilities in large language models llms one of the most widely used rl methods is group relative policy optimization grpociteshao2024deepseekmath known for its memory efficiency and success in training deepseekr1citeguo2025deepseek however grpo stalls when all sampled responses in a group are incorrect referred to as an emphallnegativesample group as it fails to update the policy hindering learning progress the contributions of this paper are twofold first we propose a simple yet effective framework that introduces response diversity within allnegativesample groups in grpo using ai feedback we also provide a theoretical analysis via a stylized model showing how this diversification improves learning dynamics second we empirically validate our approach showing the improved performance across various model sizes 7b 14b 32b in both offline and online learning settings with 10 benchmarks including base and distilled variants our findings highlight that learning from allnegativesample groups is not only feasible but beneficial advancing recent insights from citetxiong2025minimalist
http://arxiv.org/abs/2505.11485v1,2025-05-16T17:47:58Z,"Bruno Bianchi, Fermín Travi, Juan E. Kamienkowski",modeling cognitive processes of natural reading with transformerbased language models,recent advances in natural language processing nlp have led to the development of highly sophisticated language models for text generation in parallel neuroscience has increasingly employed these models to explore cognitive processes involved in language comprehension previous research has shown that models such as ngrams and lstm networks can partially account for predictability effects in explaining eye movement behaviors specifically gaze duration during reading in this study we extend these findings by evaluating transformerbased models gpt2 llama7b and llama27b to further investigate this relationship our results indicate that these architectures outperform earlier models in explaining the variance in gaze durations recorded from rioplantense spanish readers however similar to previous studies these models still fail to account for the entirety of the variance captured by human predictability these findings suggest that despite their advancements stateoftheart language models continue to predict language in ways that differ from human readers
http://arxiv.org/abs/2505.11484v1,2025-05-16T17:47:50Z,"Yige Xu, Xu Guo, Zhiwei Zeng, Chunyan Miao",softcot testtime scaling with soft chainofthought reasoning,testtime scaling tts refers to approaches that improve reasoning performance by allocating extra computation during inference without altering the models parameters while existing tts methods operate in a discrete token space by generating more intermediate steps recent studies in coconut and softcot have demonstrated that thinking in the continuous latent space can further enhance the reasoning performance such latent thoughts encode informative thinking without the information loss associated with autoregressive token generation sparking increased interest in continuousspace reasoning unlike discrete decoding where repeated sampling enables exploring diverse reasoning paths latent representations in continuous space are fixed for a given input which limits diverse exploration as all decoded paths originate from the same latent thought to overcome this limitation we introduce softcot to extend softcot to the testtime scaling paradigm by enabling diverse exploration of thinking paths specifically we perturb latent thoughts via multiple specialized initial tokens and apply contrastive learning to promote diversity among soft thought representations experiments across five reasoning benchmarks and two distinct llm architectures demonstrate that softcot significantly boosts softcot and also outperforms softcot with selfconsistency scaling moreover it shows strong compatibility with conventional scaling techniques such as selfconsistency source code is available at httpsgithubcomxuyigesoftcot
http://arxiv.org/abs/2505.11480v1,2025-05-16T17:40:45Z,"Anjiang Wei, Tarun Suresh, Huanmi Tan, Yinglun Xu, Gagandeep Singh, Ke Wang, Alex Aiken",improving assembly code performance with large language models via reinforcement learning,large language models llms have demonstrated strong performance across a wide range of programming tasks yet their potential for code optimization remains underexplored this work investigates whether llms can optimize the performance of assembly code where finegrained control over execution enables improvements that are difficult to express in highlevel languages we present a reinforcement learning framework that trains llms using proximal policy optimization ppo guided by a reward function that considers both functional correctness validated through test cases and execution performance relative to the industrystandard compiler gcc o3 to support this study we introduce a benchmark of 8072 realworld programs our model qwen25coder7bppo achieves 960 test pass rates and an average speedup of 147x over the gcc o3 baseline outperforming all 20 other models evaluated including claude37sonnet these results indicate that reinforcement learning can unlock the potential of llms to serve as effective optimizers for assembly code performance
http://arxiv.org/abs/2505.11475v1,2025-05-16T17:31:19Z,"Zhilin Wang, Jiaqi Zeng, Olivier Delalleau, Hoo-Chang Shin, Felipe Soares, Alexander Bukharin, Ellie Evans, Yi Dong, Oleksii Kuchaiev",helpsteer3preference open humanannotated preference data across diverse tasks and languages,preference datasets are essential for training generaldomain instructionfollowing language models with reinforcement learning from human feedback rlhf each subsequent data release raises expectations for future data collection meaning there is a constant need to advance the quality and diversity of openly available preference data to address this need we introduce helpsteer3preference a permissively licensed ccby40 highquality humanannotated preference dataset comprising of over 40000 samples these samples span diverse realworld applications of large language models llms including tasks relating to stem coding and multilingual scenarios using helpsteer3preference we train reward models rms that achieve top performance on rmbench 824 and judgebench 737 this represents a substantial improvement 10 absolute over the previously bestreported results from existing rms we demonstrate helpsteer3preference can also be applied to train generative rms and how policy models can be aligned with rlhf using our rms dataset ccby40 httpshuggingfacecodatasetsnvidiahelpsteer3preference
http://arxiv.org/abs/2505.11470v1,2025-05-16T17:25:40Z,"Pascal Wullschleger, Majid Zarharan, Donnacha Daly, Marc Pouly, Jennifer Foster",no gold standard no problem referencefree evaluation of taxonomies,we introduce two referencefree metrics for quality evaluation of taxonomies the first metric evaluates robustness by calculating the correlation between semantic and taxonomic similarity covering a type of error not handled by existing metrics the second uses natural language inference to assess logical adequacy both metrics are tested on five taxonomies and are shown to correlate well with f1 against goldstandard taxonomies
http://arxiv.org/abs/2505.11462v1,2025-05-16T17:16:27Z,"Rahul Thapa, Qingyang Wu, Kevin Wu, Harrison Zhang, Angela Zhang, Eric Wu, Haotian Ye, Suhana Bedi, Nevin Aresh, Joseph Boen, Shriya Reddy, Ben Athiwaratkun, Shuaiwen Leon Song, James Zou",disentangling reasoning and knowledge in medical large language models,medical reasoning in large language models llms aims to emulate clinicians diagnostic thinking but current benchmarks such as medqausmle medmcqa and pubmedqa often mix reasoning with factual recall we address this by separating 11 biomedical qa benchmarks into reasoning and knowledgefocused subsets using a pubmedbert classifier that reaches 81 percent accuracy comparable to human performance our analysis shows that only 328 percent of questions require complex reasoning we evaluate biomedical models huatuogpto1 medreason m1 and generaldomain models deepseekr1 o4mini qwen3 finding consistent gaps between knowledge and reasoning performance for example m1 scores 605 on knowledge but only 471 on reasoning in adversarial tests where models are misled with incorrect initial reasoning biomedical models degrade sharply while larger or rltrained general models show more robustness to address this we train biomedr1 using finetuning and reinforcement learning on reasoningheavy examples it achieves the strongest performance among similarly sized models further gains may come from incorporating clinical case reports and training with adversarial and backtracking scenarios
http://arxiv.org/abs/2505.11441v1,2025-05-16T16:59:14Z,"Xianzhen Luo, Shijie Xuyang, Tianhao Cheng, Zheng Chu, Houyi Li, ziqi wang, Siming Huang, Qingfu Zhu, Qiufeng Wang, Xiangyu Zhang, Shuigeng Zhou, Wanxiang Che",is compression really linear with code intelligence,understanding the relationship between data compression and the capabilities of large language models llms is crucial especially in specialized domains like code intelligence prior work posited a linear relationship between compression and general intelligence however it overlooked the multifaceted nature of code that encompasses diverse programming languages and tasks and struggled with fair evaluation of modern code llms we address this by evaluating a diverse array of opensource code llms on comprehensive multilanguage multitask code benchmarks to address the challenge of efficient and fair evaluation of pretrained llms code intelligence we introduce textitformat annealing a lightweight transparent training methodology designed to assess the intrinsic capabilities of these pretrained models equitably compression efficacy measured as bitspercharacter bpc is determined using a novel largescale and previously unseen code validation set derived from github our empirical results reveal a fundamental logarithmic relationship between measured code intelligence and bpc this finding refines prior hypotheses of linearity which we suggest are likely observations of the logarithmic curves tail under specific limited conditions our work provides a more nuanced understanding of compressions role in developing code intelligence and contributes a robust evaluation framework in the code domain
http://arxiv.org/abs/2505.11436v1,2025-05-16T16:56:40Z,"Chenkai Zhang, Yiming Lei, Zeming Liu, Haitao Leng, Shaoguo Liu, Tingting Gao, Qingjie Liu, Yunhong Wang",godbench a benchmark for multimodal large language models in video comment art,video comment art enhances user engagement by providing creative content that conveys humor satire or emotional resonance requiring a nuanced and comprehensive grasp of cultural and contextual subtleties although multimodal large language models mllms and chainofthought cot have demonstrated strong reasoning abilities in stem tasks eg mathematics and coding they still struggle to generate creative expressions such as resonant jokes and insightful satire moreover existing benchmarks are constrained by their limited modalities and insufficient categories hindering the exploration of comprehensive creativity in videobased comment art creation to address these limitations we introduce godbench a novel benchmark that integrates video and text modalities to systematically evaluate mllms abilities to compose comment art furthermore inspired by the propagation patterns of waves in physics we propose ripple of thought rot a multistep reasoning framework designed to enhance the creativity of mllms extensive experiments reveal that existing mllms and cot methods still face significant challenges in understanding and generating creative video comments in contrast rot provides an effective approach to improve creative composing highlighting its potential to drive meaningful advancements in mllmbased creativity godbench is publicly available at httpsgithubcomstanleigodbenchacl2025
http://arxiv.org/abs/2505.11423v1,2025-05-16T16:36:00Z,"Xiaomin Li, Zhou Yu, Zhiwei Zhang, Xupeng Chen, Ziji Zhang, Yingying Zhuang, Narayanan Sadagopan, Anurag Beniwal",when thinking fails the pitfalls of reasoning for instructionfollowing in llms,reasoningenhanced large language models rllms whether explicitly trained for reasoning or prompted via chainofthought cot have achieved stateoftheart performance on many complex reasoning tasks however we uncover a surprising and previously overlooked phenomenon explicit cot reasoning can significantly degrade instructionfollowing accuracy evaluating 15 models on two benchmarks ifeval with simple ruleverifiable constraints and complexbench with complex compositional constraints we consistently observe performance drops when cot prompting is applied through largescale case studies and an attentionbased analysis we identify common patterns where reasoning either helps eg with formatting or lexical precision or hurts eg by neglecting simple constraints or introducing unnecessary content we propose a metric constraint attention to quantify model focus during generation and show that cot reasoning often diverts attention away from instructionrelevant tokens to mitigate these effects we introduce and evaluate four strategies incontext learning selfreflection selfselective reasoning and classifierselective reasoning our results demonstrate that selective reasoning strategies particularly classifierselective reasoning can substantially recover lost performance to our knowledge this is the first work to systematically expose reasoninginduced failures in instructionfollowing and offer practical mitigation strategies
http://arxiv.org/abs/2505.11421v1,2025-05-16T16:33:36Z,"Phan Tran Minh Dat, Vo Hoang Nhat Khang, Quan Thanh Tho",towards cultural bridge by bahnaricvietnamese translation using transfer learning of sequencetosequence pretraining language model,this work explores the journey towards achieving bahnaricvietnamese translation for the sake of culturally bridging the two ethnic groups in vietnam however translating from bahnaric to vietnamese also encounters some difficulties the most prominent challenge is the lack of available original bahnaric resources source language including vocabulary grammar dialogue patterns and bilingual corpus which hinders the data collection process for training to address this we leverage a transfer learning approach using sequencetosequence pretraining language model first of all we leverage a pretrained vietnamese language model to capture the characteristics of this language especially to further serve the purpose of machine translation we aim for a sequencetosequence model not encoderonly like bert or decoderonly like gpt taking advantage of significant similarity between the two languages we continue training the model with the currently limited bilingual resources of vietnamesebahnaric text to perform the transfer learning from language model to machine translation thus this approach can help to handle the problem of imbalanced resources between two languages while also optimizing the training and computational processes additionally we also enhanced the datasets using data augmentation to generate additional resources and defined some heuristic methods to help the translation more precise our approach has been validated to be highly effective for the bahnaricvietnamese translation model contributing to the expansion and preservation of languages and facilitating better mutual understanding between the two ethnic people
http://arxiv.org/abs/2505.11413v1,2025-05-16T16:25:51Z,"Sijia Chen, Xiaomin Li, Mengxue Zhang, Eric Hanchen Jiang, Qingcheng Zeng, Chen-Hsiang Yu",cares comprehensive evaluation of safety and adversarial robustness in medical llms,large language models llms are increasingly deployed in medical contexts raising critical concerns about safety alignment and susceptibility to adversarial manipulation while prior benchmarks assess model refusal capabilities for harmful prompts they often lack clinical specificity graded harmfulness levels and coverage of jailbreakstyle attacks we introduce cares clinical adversarial robustness and evaluation of safety a benchmark for evaluating llm safety in healthcare cares includes over 18000 prompts spanning eight medical safety principles four harm levels and four prompting styles direct indirect obfuscated and roleplay to simulate both malicious and benign use cases we propose a threeway response evaluation protocol accept caution refuse and a finegrained safety score metric to assess model behavior our analysis reveals that many stateoftheart llms remain vulnerable to jailbreaks that subtly rephrase harmful prompts while also overrefusing safe but atypically phrased queries finally we propose a mitigation strategy using a lightweight classifier to detect jailbreak attempts and steer models toward safer behavior via reminderbased conditioning cares provides a rigorous framework for testing and improving medical llm safety under adversarial and ambiguous conditions
http://arxiv.org/abs/2505.11409v1,2025-05-16T16:17:22Z,"Yi Xu, Chengzu Li, Han Zhou, Xingchen Wan, Caiqi Zhang, Anna Korhonen, Ivan Vulić",visual planning lets think only with images,recent advancements in large language models llms and their multimodal extensions mllms have substantially enhanced machine reasoning across diverse tasks however these models predominantly rely on pure text as the medium for both expressing and structuring reasoning even when visual information is present in this work we argue that language may not always be the most natural or effective modality for reasoning particularly in tasks involving spatial and geometrical information motivated by this we propose a new paradigm visual planning which enables planning through purely visual representations independent of text in this paradigm planning is executed via sequences of images that encode stepbystep inference in the visual domain akin to how humans sketch or visualize future actions we introduce a novel reinforcement learning framework visual planning via reinforcement learning vprl empowered by grpo for posttraining large vision models leading to substantial improvements in planning in a selection of representative visual navigation tasks frozenlake maze and minibehavior our visual planning paradigm outperforms all other planning variants that conduct reasoning in the textonly space our results establish visual planning as a viable and promising alternative to languagebased reasoning opening new avenues for tasks that benefit from intuitive imagebased inference
http://arxiv.org/abs/2505.11406v1,2025-05-16T16:16:32Z,"Jenny Xiyu Fu, Brennan Antone, Kowe Kadoma, Malte Jung",large language model use impact locus of control,as ai tools increasingly shape how we write they may also quietly reshape how we perceive ourselves this paper explores the psychological impact of cowriting with ai on peoples locus of control through an empirical study with 462 participants we found that employment status plays a critical role in shaping users reliance on ai and their locus of control current results demonstrated that employed participants displayed higher reliance on ai and a shift toward internal control while unemployed users tended to experience a reduction in personal agency through quantitative results and qualitative observations this study opens a broader conversation about ais role in shaping personal agency and identity
http://arxiv.org/abs/2505.11405v1,2025-05-16T16:14:08Z,"Bohao Xing, Xin Liu, Guoying Zhao, Chengyu Liu, Xiaolan Fu, Heikki Kälviäinen",emotionhallucer evaluating emotion hallucinations in multimodal large language models,emotion understanding is a critical yet challenging task recent advances in multimodal large language models mllms have significantly enhanced their capabilities in this area however mllms often suffer from hallucinations generating irrelevant or nonsensical content to the best of our knowledge despite the importance of this issue there has been no dedicated effort to evaluate emotionrelated hallucinations in mllms in this work we introduce emotionhallucer the first benchmark for detecting and analyzing emotion hallucinations in mllms unlike humans whose emotion understanding stems from the interplay of biology and social learning mllms rely solely on datadriven learning and lack innate emotional instincts fortunately emotion psychology provides a solid foundation of knowledge about human emotions building on this we assess emotion hallucinations from two dimensions emotion psychology knowledge and realworld multimodal perception to support robust evaluation we utilize an adversarial binary questionanswer qa framework which employs carefully crafted basic and hallucinated pairs to assess the emotion hallucination tendencies of mllms by evaluating 38 llms and mllms on emotionhallucer we reveal that i most current models exhibit substantial issues with emotion hallucinations ii closedsource models outperform opensource ones in detecting emotion hallucinations and reasoning capability provides additional advantages iii existing models perform better in emotion psychology knowledge than in multimodal emotion perception as a byproduct these findings inspire us to propose the pepmek framework which yields an average improvement of 990 in emotion hallucination detection across selected models resources will be available at httpsgithubcomxxtarsemotionhallucer
http://arxiv.org/abs/2505.11379v1,2025-05-16T15:41:51Z,Alicia González Martínez,a computational system to handle the orthographic layer of tajwid in contemporary quranic orthography,contemporary quranic orthography cqo relies on a precise system of phonetic notation that can be traced back to the early stages of islam when the quran was mainly oral in nature and the first written renderings of it served as memory aids for this oral tradition the early systems of diacritical marks created on top of the quranic consonantal text qct motivated the creation and further development of a finegrained system of phonetic notation that represented tajwidthe rules of recitation we explored the systematicity of the rules of tajwid as they are encountered in the cairo quran using a fully and accurately encoded digital edition of the quranic text for this purpose we developed a python module that can remove or add the orthographic layer of tajwid from a quranic text in cqo the interesting characteristic of these two sets of rules is that they address the complete quranic text of the cairo quran so they can be used as precise witnesses to study its phonetic and prosodic processes from a computational point of view the text of the cairo quran can be used as a linchpin to align and compare quranic manuscripts due to its richness and completeness this will let us create a very powerful framework to work with the arabic script not just within an isolated text but automatically exploring a specific textual phenomenon in other connected manuscripts having all the texts mapped among each other can serve as a powerful tool to study the nature of the notation systems of diacritics added to the consonantal skeleton
http://arxiv.org/abs/2505.11368v1,2025-05-16T15:32:23Z,"Lingxiao Diao, Xinyue Xu, Wanxuan Sun, Cheng Yang, Zhuosheng Zhang",guidebench benchmarking domainoriented guideline following for llm agents,large language models llms have been widely deployed as autonomous agents capable of following user instructions and making decisions in realworld applications previous studies have made notable progress in benchmarking the instruction following capabilities of llms in general domains with a primary focus on their inherent commonsense knowledge recently llms have been increasingly deployed as domainoriented agents which rely on domainoriented guidelines that may conflict with their commonsense knowledge these guidelines exhibit two key characteristics they consist of a wide range of domainoriented rules and are subject to frequent updates despite these challenges the absence of comprehensive benchmarks for evaluating the domainoriented guideline following capabilities of llms presents a significant obstacle to their effective assessment and further development in this paper we introduce guidebench a comprehensive benchmark designed to evaluate guideline following performance of llms guidebench evaluates llms on three critical aspects i adherence to diverse rules ii robustness to rule updates and iii alignment with human preferences experimental results on a range of llms indicate substantial opportunities for improving their ability to follow domainoriented guidelines
http://arxiv.org/abs/2505.11365v2,2025-05-16T15:31:08Z,"Pierre Le Jeune, Benoît Malézieux, Weixuan Xiao, Matteo Dora",phare a safety probe for large language models,ensuring the safety of large language models llms is critical for responsible deployment yet existing evaluations often prioritize performance over identifying failure modes we introduce phare a multilingual diagnostic framework to probe and evaluate llm behavior across three critical dimensions hallucination and reliability social biases and harmful content generation our evaluation of 17 stateoftheart llms reveals patterns of systematic vulnerabilities across all safety dimensions including sycophancy prompt sensitivity and stereotype reproduction by highlighting these specific failure modes rather than simply ranking models phare provides researchers and practitioners with actionable insights to build more robust aligned and trustworthy language systems
http://arxiv.org/abs/2505.11352v1,2025-05-16T15:15:19Z,"Rao Ma, Tongzhou Chen, Kartik Audhkhasi, Bhuvana Ramabhadran",legoslm connecting llm with speech encoder using ctc posteriors,recently largescale pretrained speech encoders and large language models llms have been released which show stateoftheart performance on a range of spoken language processing tasks including automatic speech recognition asr to effectively combine both models for better performance continuous speech prompts and asr error correction have been adopted however these methods are prone to suboptimal performance or are inflexible in this paper we propose a new paradigm legoslm that bridges speech encoders and llms using the asr posterior matrices the speech encoder is trained to generate connectionist temporal classification ctc posteriors over the llm vocabulary which are used to reconstruct pseudoaudio embeddings by computing a weighted sum of the llm input embeddings these embeddings are concatenated with text embeddings in the llm input space using the wellperforming usm and gemma models as an example we demonstrate that our proposed legoslm method yields good performance on both asr and speech translation tasks by connecting usm with gemma models we can get an average of 49 werr over the usmctc baseline on 8 mls testsets the trained model also exhibits modularity in a range of settings after finetuning the gemma model weights the speech encoder can be switched and combined with the llm in a zeroshot fashion additionally we propose to control the decodetime influence of the usm and llm using a softmax temperature which shows effectiveness in domain adaptation
http://arxiv.org/abs/2505.11341v1,2025-05-16T15:08:04Z,"Banca Calvo Figueras, Rodrigo Agerri",benchmarking critical questions generation a challenging reasoning task for large language models,the task of critical questions generation cqsgen aims to foster critical thinking by enabling systems to generate questions that expose assumptions and challenge the reasoning in arguments despite growing interest in this area progress has been hindered by the lack of suitable datasets and automatic evaluation standards this work presents a comprehensive approach to support the development and benchmarking of systems for this task we construct the first largescale manuallyannotated dataset we also investigate automatic evaluation methods and identify a referencebased technique using large language models llms as the strategy that best correlates with human judgments our zeroshot evaluation of 11 llms establishes a strong baseline while showcasing the difficulty of the task data code and a public leaderboard are provided to encourage further research not only in terms of model performance but also to explore the practical benefits of cqsgen for both automated reasoning and human critical thinking
http://arxiv.org/abs/2505.11336v1,2025-05-16T15:02:19Z,"Nuo Chen, Andre Lin HuiKai, Jiaying Wu, Junyi Hou, Zining Zhang, Qian Wang, Xidong Wang, Bingsheng He",xtragpt llms for humanai collaboration on controllable academic paper revision,despite the growing adoption of large language models llms in academic workflows their capabilities remain limited when it comes to supporting highquality scientific writing most existing systems are designed for generalpurpose scientific text generation and fail to meet the sophisticated demands of research communication beyond surfacelevel polishing such as conceptual coherence across sections furthermore academic writing is inherently iterative and revisiondriven a process not well supported by direct promptingbased paradigms to address these scenarios we propose a humanai collaboration framework for academic paper revision we first introduce a comprehensive dataset of 7040 research papers from toptier venues annotated with over 140000 instructionresponse pairs that reflect realistic sectionlevel scientific revisions building on the dataset we develop xtragpt the first suite of opensource llms designed to provide contextaware instructionguided writing assistance ranging from 15b to 14b parameters extensive experiments validate that xtragpt significantly outperforms samescale baselines and approaches the quality of proprietary systems both automated preference assessments and human evaluations confirm the effectiveness of our models in improving scientific drafts
http://arxiv.org/abs/2505.11314v1,2025-05-16T14:39:44Z,"Christoph Leiter, Yuki M. Asano, Margret Keuper, Steffen Eger",croc evaluating and training t2i metrics with pseudo and humanlabeled contrastive robustness checks,the assessment of evaluation metrics metaevaluation is crucial for determining the suitability of existing metrics in texttoimage t2i generation tasks humanbased metaevaluation is costly and timeintensive and automated alternatives are scarce we address this gap and propose croc a scalable framework for automated contrastive robustness checks that systematically probes and quantifies metric robustness by synthesizing contrastive test cases across a comprehensive taxonomy of image properties with croc we generate a pseudolabeled dataset croc of over one million contrastive promptimage pairs to enable a finegrained comparison of evaluation metrics we also use the dataset to train crocscore a new metric that achieves stateoftheart performance among opensource methods demonstrating an additional key application of our framework to complement this dataset we introduce a humansupervised benchmark croc targeting especially challenging categories our results highlight robustness issues in existing metrics for example many fail on prompts involving negation and all tested opensource metrics fail on at least 25 of cases involving correct identification of body parts
http://arxiv.org/abs/2505.11297v1,2025-05-16T14:27:40Z,"Gal Astrach, Yuval Pinter",probing subphonemes in morphology models,transformers have achieved stateoftheart performance in morphological inflection tasks yet their ability to generalize across languages and morphological rules remains limited one possible explanation for this behavior can be the degree to which these models are able to capture implicit phenomena at the phonological and subphonemic levels we introduce a languageagnostic probing method to investigate phonological feature encoding in transformers trained directly on phonemes and perform it across seven morphologically diverse languages we show that phonological features which are local such as finalobstruent devoicing in turkish are captured well in phoneme embeddings whereas longdistance dependencies like vowel harmony are better represented in the transformers encoder finally we discuss how these findings inform empirical strategies for training morphological models particularly regarding the role of subphonemic feature acquisition
http://arxiv.org/abs/2505.11280v1,2025-05-16T14:17:03Z,"Horacio Thompson, Esaú Villatoro-Tello, Manuel Montes-y-Gómez, Marcelo Errecalde",temporal finetuning for early risk detection,early risk detection erd on the web aims to identify promptly users facing social and health issues users are analyzed postbypost and it is necessary to guarantee correct and quick answers which is particularly challenging in critical scenarios erd involves optimizing classification precision and minimizing detection delay standard classification metrics may not suffice resorting to specific metrics such as erdetheta that explicitly consider precision and delay the current research focuses on applying a multiobjective approach prioritizing classification performance and establishing a separate criterion for decision time in this work we propose a completely different strategy temporal finetuning which allows tuning transformerbased models by explicitly incorporating time within the learning process our method allows us to analyze complete user post histories tune models considering different contexts and evaluate training performance using temporal metrics we evaluated our proposal in the depression and eating disorders tasks for the spanish language achieving competitive results compared to the best models of mentalriskes 2023 we found that temporal finetuning optimized decisions considering context and time progress in this way by properly taking advantage of the power of transformers it is possible to address erd by combining precision and speed as a single objective
http://arxiv.org/abs/2505.11277v1,2025-05-16T14:11:29Z,"Yaorui Shi, Shihan Li, Chang Wu, Zhiyuan Liu, Junfeng Fang, Hengxing Cai, An Zhang, Xiang Wang",search and refine during think autonomous retrievalaugmented reasoning of llms,large language models have demonstrated impressive reasoning capabilities but are inherently limited by their knowledge reservoir retrievalaugmented reasoning mitigates this limitation by allowing llms to query external resources but existing methods often retrieve irrelevant or noisy information hindering accurate reasoning in this paper we propose autorefine a reinforcement learning posttraining framework that adopts a new searchandrefineduringthink paradigm autorefine introduces explicit knowledge refinement steps between successive search calls enabling the model to iteratively filter distill and organize evidence before generating an answer furthermore we incorporate tailored retrievalspecific rewards alongside answer correctness rewards using group relative policy optimization experiments on singlehop and multihop qa benchmarks demonstrate that autorefine significantly outperforms existing approaches particularly in complex multihop reasoning scenarios detailed analysis shows that autorefine issues frequent higherquality searches and synthesizes evidence effectively
http://arxiv.org/abs/2505.11274v1,2025-05-16T14:08:04Z,"Zheng Li, Qingxiu Dong, Jingyuan Ma, Di Zhang, Zhifang Sui",selfbudgeter adaptive token allocation for efficient llm reasoning,recently large reasoning models demonstrate exceptional performance on various tasks however reasoning models inefficiently overprocess both trivial and complex queries leading to resource waste and prolonged user latency to address this challenge we propose selfbudgeter a selfadaptive controllable reasoning strategy for efficient reasoning our approach adopts a dualphase training paradigm first the model learns to preestimate the reasoning cost based on the difficulty of the query then we introduce budgetguided gpro for reinforcement learning which effectively maintains accuracy while reducing output length selfbudgeter allows users to anticipate generation time and make informed decisions about continuing or interrupting the process furthermore our method enables direct manipulation of reasoning length via prefilling token budget experimental results demonstrate that selfbudgeter can rationally allocate budgets according to problem complexity achieving up to 7447 response length compression on the math benchmark while maintaining nearly undiminished accuracy
http://arxiv.org/abs/2505.11271v1,2025-05-16T14:04:31Z,"Camille Couturier, Spyros Mastorakis, Haiying Shen, Saravan Rajmohan, Victor Rühle",semantic caching of contextual summaries for efficient questionanswering with language models,large language models llms are increasingly deployed across edge and cloud platforms for realtime questionanswering and retrievalaugmented generation however processing lengthy contexts in distributed systems incurs high computational overhead memory usage and network bandwidth this paper introduces a novel semantic caching approach for storing and reusing intermediate contextual summaries enabling efficient information reuse across similar queries in llmbased qa workflows our method reduces redundant computations by up to 5060 while maintaining answer accuracy comparable to full document processing as demonstrated on naturalquestions triviaqa and a synthetic arxiv dataset this approach balances computational cost and response quality critical for realtime ai assistants
http://arxiv.org/abs/2505.11225v1,2025-05-16T13:21:28Z,"Chengyu Huang, Zhengxin Zhang, Claire Cardie",hapo training language models to reason concisely via historyaware policy optimization,while scaling the length of responses at testtime has been shown to markedly improve the reasoning abilities and performance of large language models llms it often results in verbose outputs and increases inference cost prior approaches for efficient testtime scaling typically using universal budget constraints or querylevel length optimization do not leverage historical information from previous encounters with the same problem during training we hypothesize that this limits their ability to progressively make solutions more concise over time to address this we present historyaware policy optimization hapo which keeps track of a history state eg the minimum length over previously generated correct responses for each problem hapo employs a novel length reward function based on this history state to incentivize the discovery of correct solutions that are more concise than those previously found crucially this reward structure avoids overly penalizing shorter incorrect responses with the goal of facilitating exploration towards more efficient solutions by combining this length reward with a correctness reward hapo jointly optimizes for correctness and efficiency we use hapo to train deepseekr1distillqwen15b deepscaler15bpreview and qwen2515binstruct and evaluate hapo on several math benchmarks that span various difficulty levels experiment results demonstrate that hapo effectively induces llms concise reasoning abilities producing length reductions of 3359 with accuracy drops of only 25
http://arxiv.org/abs/2505.11200v1,2025-05-16T12:57:23Z,"Xihuai Wang, Ziyi Zhao, Siyu Ren, Shao Zhang, Song Li, Xiaoyu Li, Ziwen Wang, Lin Qiu, Guanglu Wan, Xuezhi Cao, Xunliang Cai, Weinan Zhang",audio turing test benchmarking the humanlikeness of large language modelbased texttospeech systems in chinese,recent advances in large language models llms have significantly improved texttospeech tts systems enhancing control over speech style naturalness and emotional expression which brings tts systems closer to humanlevel performance although the mean opinion score mos remains the standard for tts system evaluation it suffers from subjectivity environmental inconsistencies and limited interpretability existing evaluation datasets also lack a multidimensional design often neglecting factors such as speaking styles context diversity and trap utterances which is particularly evident in chinese tts evaluation to address these challenges we introduce the audio turing test att a multidimensional chinese corpus dataset attcorpus paired with a simple turingtestinspired evaluation protocol instead of relying on complex mos scales or direct model comparisons att asks evaluators to judge whether a voice sounds human this simplification reduces rating bias and improves evaluation robustness to further support rapid model development we also finetune qwen2audioinstruct with human judgment data as autoatt for automatic evaluation experimental results show that att effectively differentiates models across specific capability dimensions using its multidimensional design autoatt also demonstrates strong alignment with human evaluations confirming its value as a fast and reliable assessment tool the whitebox attcorpus and autoatt can be found in att hugging face collection httpshuggingfacecocollectionsmeituanaudioturingtest682446320368164faeaf38a4
http://arxiv.org/abs/2505.11199v1,2025-05-16T12:56:59Z,"Chris Köcher, Alexander Kozachinskiy, Anthony Widjaja Lin, Marco Sälzer, Georg Zetzsche",nope the counting power of transformers with no positional encodings,positional encodings pes seem to be indispensable for ensuring expressiveness of transformers without them attention transformers reduce to a bagofword model nopetransformers ie with no pes with unique hard attention mechanisms were very recently shown to only be able to express regular languages ie with limited counting ability this paper shows that with average hard attention mechanisms nopetransformers are still surprisingly expressive they can express counting languages corresponding to nonnegative integer solutions to multivariate polynomial equations ie diophantine equations reasoning about which is wellknown to be undecidable in fact we provide a precise characterization of languages expressible by average hard attention nopetransformers nopeahats they correspond precisely to what we call emphsemialgebraic sets ie finite unions of sets of nonnegative integer solutions to systems of multivariate polynomial inequations we obtain several interesting consequences of our characterization firstly nopetransformers can express counting properties that are far more complex than established models like simplified counter machines and petri nets but cannot express a very simple counting property of parity secondly the problem of analyzing nopetransformers is undecidable eg whether a given nope transformer classifies all input strings in one class to complement our results we exhibit a counting language that is not expressible by average hard attention transformers even with arbitrary pes but is expressible in the circuit complexity class tc answering an open problem
http://arxiv.org/abs/2505.11183v1,2025-05-16T12:38:45Z,"Jacob Trauger, Ambuj Tewari",on nexttoken prediction in llms how end goals determine the consistency of decoding algorithms,probabilistic nexttoken prediction trained using crossentropy loss is the basis of most large language models given a sequence of previous values nexttoken prediction assigns a probability to each possible next value in the vocabulary there are many ways to use nexttoken prediction to output token sequences this paper examines a few of these algorithms greedy lookahead random sampling and temperaturescaled random sampling and studies their consistency with respect to various goals encoded as loss functions although consistency of surrogate losses with respect to a target loss function is a well researched topic we are the first to study it in the context of llms to the best of our knowledge we find that so long as nexttoken prediction converges to its true probability distribution random sampling is consistent with outputting sequences that mimic sampling from the true probability distribution for the other goals such as minimizing the 01 loss on the entire sequence we show no polynomialtime algorithm is optimal for all probability distributions and all decoding algorithms studied are only optimal for a subset of probability distributions when analyzing these results we see that there is a dichotomy created between the goals of information retrieval and creative generation for the decoding algorithms this shows that choosing the correct decoding algorithm based on the desired goal is extremely important and many of the ones used are lacking theoretical grounding in numerous scenarios
http://arxiv.org/abs/2505.11178v1,2025-05-16T12:23:58Z,"Yixin Wan, Kai-Wei Chang",compalign improving compositional texttoimage generation with a complex benchmark and finegrained feedback,stateoftheart t2i models are capable of generating highresolution images given textual prompts however they still struggle with accurately depicting compositional scenes that specify multiple objects attributes and spatial relations we present compalign a challenging benchmark with an emphasis on assessing the depiction of 3dspatial relationships for evaluating and improving models on compositional image generation compalign consists of 900 complex multisubject image generation prompts that combine numerical and 3dspatial relationships with varied attribute bindings our benchmark is remarkably challenging incorporating generation tasks with 3 generation subjects with complex 3dspatial relationships additionally we propose compquest an interpretable and accurate evaluation framework that decomposes complex prompts into atomic subquestions then utilizes a mllm to provide finegrained binary feedback on the correctness of each aspect of generation elements in modelgenerated images this enables precise quantification of alignment between generated images and compositional prompts furthermore we propose an alignment framework that uses compquests feedback as preference signals to improve diffusion models compositional image generation abilities using adjustable perimage preferences our method is easily scalable and flexible for different tasks evaluation of 9 t2i models reveals that 1 models remarkable struggle more with compositional tasks with more complex 3dspatial configurations and 2 a noticeable performance gap exists between opensource accessible models and closedsource commercial models further empirical study on using compalign for model alignment yield promising results postalignment diffusion models achieve remarkable improvements in compositional accuracy especially on complex generation tasks outperforming previous approaches
http://arxiv.org/abs/2505.11177v1,2025-05-16T12:20:37Z,"Hrishit Madhavi, Jacob Cherian, Yuvraj Khamkar, Dhananjay Bhagat",lowresource language processing an ocrdriven summarization and translation pipeline,this paper presents an endtoend suite for multilingual information extraction and processing from imagebased documents the system uses optical character recognition tesseract to extract text in languages such as english hindi and tamil and then a pipeline involving large language model apis gemini for crosslingual translation abstractive summarization and retranslation into a target language additional modules add sentiment analysis tensorflow topic classification transformers and date extraction regex for better document comprehension made available in an accessible gradio interface the current research shows a realworld application of libraries models and apis to close the language gap and enhance access to information in image media across different linguistic environments
http://arxiv.org/abs/2505.11166v1,2025-05-16T12:08:48Z,"Huashan Sun, Shengyi Liao, Yansen Han, Yu Bai, Yang Gao, Cheng Fu, Weizhou Shen, Fanqi Wan, Ming Yan, Ji Zhang, Fei Huang",solopo unlocking longcontext capabilities in llms via shorttolong preference optimization,despite advances in pretraining with extended context lengths large language models llms still face challenges in effectively utilizing realworld longcontext information primarily due to insufficient longcontext alignment caused by data quality issues training inefficiencies and the lack of welldesigned optimization objectives to address these limitations we propose a framework named hrttong reference ptimization decoupling longcontext preference optimization po into two components shortcontext po and shorttolong reward alignment solora supported by both theoretical and empirical evidence specifically shortcontext po leverages preference pairs sampled from short contexts to enhance the models contextual knowledge utilization ability meanwhile solora explicitly encourages reward score consistency utilization for the responses when conditioned on both short and long contexts that contain identical taskrelevant information this facilitates transferring the models ability to handle short contexts into longcontext scenarios solopo is compatible with mainstream preference optimization algorithms while substantially improving the efficiency of data construction and training processes experimental results show that solopo enhances all these algorithms with respect to stronger length and domain generalization abilities across various longcontext benchmarks while achieving notable improvements in both computational and memory efficiency
http://arxiv.org/abs/2505.11165v1,2025-05-16T12:07:50Z,"Haiqing Hao, Nikola Zubić, Weihua He, Zhipeng Sui, Davide Scaramuzza, Wenhui Wang",maximizing asynchronicity in eventbased neural networks,event cameras deliver visual data with high temporal resolution low latency and minimal redundancy yet their asynchronous sparse sequential nature challenges standard tensorbased machine learning ml while the recent asynchronoustosynchronous a2s paradigm aims to bridge this gap by asynchronously encoding events into learned representations for ml pipelines existing a2s approaches often sacrifice representation expressivity and generalizability compared to dense synchronous methods this paper introduces eva event asynchronous representation learning a novel a2s framework to generate highly expressive and generalizable eventbyevent representations inspired by the analogy between events and language eva uniquely adapts advances from language modeling in linear attention and selfsupervised learning for its construction in demonstration eva outperforms prior a2s methods on recognition tasks dvs128gesture and ncars and represents the first a2s framework to successfully master demanding detection tasks achieving a remarkable 477 map on the gen1 dataset these results underscore evas transformative potential for advancing realtime eventbased vision applications
http://arxiv.org/abs/2505.11154v1,2025-05-16T11:55:12Z,"Zihan Wang, Hongwei Li, Rui Zhang, Yu Liu, Wenbo Jiang, Wenshu Fan, Qingchuan Zhao, Guowen Xu",mpma preference manipulation attack against model context protocol,model context protocol mcp standardizes interface mapping for large language models llms to access external data and tools which revolutionizes the paradigm of tool selection and facilitates the rapid expansion of the llm agent tool ecosystem however as the mcp is increasingly adopted thirdparty customized versions of the mcp server expose potential security vulnerabilities in this paper we first introduce a novel security threat which we term the mcp preference manipulation attack mpma an attacker deploys a customized mcp server to manipulate llms causing them to prioritize it over other competing mcp servers this can result in economic benefits for attackers such as revenue from paid mcp services or advertising income generated from free servers to achieve mpma we first design a direct preference manipulation attack that achieves significant effectiveness by inserting the manipulative word and phrases into the tool name and description however such a direct modification is obvious to users and lacks stealthiness to address these limitations we further propose geneticbased advertising preference manipulation attack employs four commonly used strategies to initialize descriptions and integrates a genetic algorithm ga to enhance stealthiness the experiment results demonstrate that balances high effectiveness and stealthiness our study reveals a critical vulnerability of the mcp in open ecosystems highlighting an urgent need for robust defense mechanisms to ensure the fairness of the mcp ecosystem
http://arxiv.org/abs/2505.11140v1,2025-05-16T11:39:33Z,"Mike Zhang, Johannes Bjerva, Russa Biswas",scaling reasoning can improve factuality in large language models,recent studies on large language model llm reasoning capabilities have demonstrated promising improvements in model performance by leveraging a lengthy thinking process and additional computational resources during inference primarily in tasks involving mathematical reasoning muennighoff et al 2025 however it remains uncertain if longer reasoning chains inherently enhance factual accuracy particularly beyond mathematical contexts in this work we thoroughly examine llm reasoning within complex opendomain questionanswering qa scenarios we initially distill reasoning traces from advanced largescale reasoning models qwq32b and deepseekr1671b then finetune a variety of models ranging from smaller instructiontuned variants to larger architectures based on qwen25 to enrich reasoning traces we introduce factual information from knowledge graphs in the form of paths into our reasoning traces our experimental setup includes four baseline approaches and six different instructiontuned models evaluated across a benchmark of six datasets encompassing over 226k questions overall we carry out 168 experimental runs and analyze approximately 17 million reasoning traces our findings indicate that within a single run smaller reasoning models achieve noticeable improvements in factual accuracy compared to their original instructiontuned counterparts moreover our analysis demonstrates that adding testtime compute and token budgets factual accuracy consistently improves by 28 further confirming the effectiveness of testtime scaling for enhancing performance and consequently improving reasoning accuracy in opendomain qa tasks we release all the experimental artifacts for further research
http://arxiv.org/abs/2505.11572v1,2025-05-16T11:31:31Z,"Anand Rai, Satyam Rahangdale, Utkarsh Anand, Animesh Mukherjee",asrfairbench measuring and benchmarking equity across speech recognition systems,automatic speech recognition asr systems have become ubiquitous in everyday applications yet significant disparities in performance across diverse demographic groups persist in this work we introduce the asrfairbench leaderboard which is designed to assess both the accuracy and equity of asr models in realtime leveraging the metas fairspeech dataset which captures diverse demographic characteristics we employ a mixedeffects poisson regression model to derive an overall fairness score this score is integrated with traditional metrics like word error rate wer to compute the fairness adjusted asr score faas providing a comprehensive evaluation framework our approach reveals significant performance disparities in sota asr models across demographic groups and offers a benchmark to drive the development of more inclusive asr technologies
http://arxiv.org/abs/2505.11095v1,2025-05-16T10:27:16Z,"Lekang Jiang, Pascal A Scherz, Stephan Goetz",towards better evaluation for generated patent claims,patent claims define the scope of protection and establish the legal boundaries of an invention drafting these claims is a complex and timeconsuming process that usually requires the expertise of skilled patent attorneys which can form a large access barrier for many small enterprises to solve these challenges researchers have investigated the use of large language models llms for automating patent claim generation however existing studies highlight inconsistencies between automated evaluation metrics and human expert assessments to bridge this gap we introduce patentce the first comprehensive benchmark for evaluating patent claims patentce includes comparative claim evaluations annotated by patent experts focusing on five key criteria feature completeness conceptual clarity terminology consistency logical linkage and overall quality additionally we propose patclaimeval a novel multidimensional evaluation method specifically designed for patent claims our experiments demonstrate that patclaimeval achieves the highest correlation with human expert evaluations across all assessment criteria among all tested metrics this research provides the groundwork for more accurate evaluations of automated patent claim generation systems
http://arxiv.org/abs/2505.11080v1,2025-05-16T10:11:43Z,"Yapei Chang, Yekyung Kim, Michael Krumdick, Amir Zadeh, Chuan Li, Chris Tanner, Mohit Iyyer",bleuberi bleu is a surprisingly effective reward for instruction following,reward models are central to aligning llms with human preferences but they are costly to train requiring largescale humanlabeled preference data and powerful pretrained llm backbones meanwhile the increasing availability of highquality synthetic instructionfollowing datasets raises the question can simpler referencebased metrics serve as viable alternatives to reward models during rlbased alignment in this paper we show first that bleu a basic stringmatching metric surprisingly matches strong reward models in agreement with human preferences on general instructionfollowing datasets based on this insight we develop bleuberi a method that first identifies challenging instructions and then applies group relative policy optimization grpo using bleu directly as the reward function we demonstrate that bleuberitrained models are competitive with models trained via reward modelguided rl across four challenging instructionfollowing benchmarks and three different base language models a human evaluation further supports that the quality of bleuberi model outputs is on par with those from reward modelaligned models moreover bleuberi models generate outputs that are more factually grounded than competing methods overall we show that given access to highquality reference outputs easily obtained via existing instructionfollowing datasets or synthetic data generation string matchingbased metrics are cheap yet effective proxies for reward models during alignment we release our code and data at httpsgithubcomlilakkbleuberi
http://arxiv.org/abs/2505.11079v1,2025-05-16T10:10:03Z,"Hao Gu, Jiangyan Yi, Chenglong Wang, Jianhua Tao, Zheng Lian, Jiayi He, Yong Ren, Yujie Chen, Zhengqi Wen",unlocking the capabilities of audio large language models for audio deepfake detection,audio deepfake detection add has grown increasingly important due to the rise of highfidelity audio generative models and their potential for misuse given that audio large language models allms have made significant progress in various audio processing tasks a heuristic question arises can allms be leveraged to solve add in this paper we first conduct a comprehensive zeroshot evaluation of allms on add revealing their ineffectiveness in detecting fake audio to enhance their performance we propose an allmdriven framework for add specifically we reformulate add task as an audio question answering problem prompting the model with the question is this audio fake or real we then perform supervised finetuning to enable the allm to assess the authenticity of query audio extensive experiments are conducted to demonstrate that our allmbased method can achieve superior performance in fake audio detection particularly in datascarce scenarios as a pioneering study we anticipate that this work will inspire the research community to leverage allms to develop more effective add systems
http://arxiv.org/abs/2505.11051v1,2025-05-16T09:52:00Z,"Iwona Christop, Maciej Czajka",cameo collection of multilingual emotional speech corpora,this paper presents cameo a curated collection of multilingual emotional speech datasets designed to facilitate research in emotion recognition and other speechrelated tasks the main objectives were to ensure easy access to the data to allow reproducibility of the results and to provide a standardized benchmark for evaluating speech emotion recognition ser systems across different emotional states and languages the paper describes the dataset selection criteria the curation and normalization process and provides performance results for several models the collection along with metadata and a leaderboard is publicly available via the hugging face platform
http://arxiv.org/abs/2505.11031v2,2025-05-16T09:26:06Z,"Xiao Zhang, Huiyuan Lai, Qianru Meng, Johan Bos",ontourl a benchmark for evaluating large language models on symbolic ontological understanding reasoning and learning,large language models llms have demonstrated remarkable capabilities across a range of natural language processing tasks yet their ability to process structured symbolic knowledge remains underexplored to address this gap we propose a taxonomy of llms ontological capabilities and introduce ontourl the first comprehensive benchmark designed to systematically evaluate llms proficiency in handling ontologies formal symbolic representations of domain knowledge through concepts relationships and instances based on the proposed taxonomy ontourl systematically assesses three dimensions understanding reasoning and learning through 15 distinct tasks comprising 58981 questions derived from 40 ontologies across 8 domains experiments with 20 opensource llms reveal significant performance differences across models tasks and domains with current llms showing proficiency in understanding ontological knowledge but substantial weaknesses in reasoning and learning tasks these findings highlight fundamental limitations in llms capability to process symbolic knowledge and establish ontourl as a critical benchmark for advancing the integration of llms with formal knowledge representations
http://arxiv.org/abs/2505.11026v1,2025-05-16T09:22:07Z,"Maria Dziuba, Valentin Malykh",strucom a novel dataset of structured code comments in russian,structured code comments in docstring format are essential for code comprehension and maintenance but existing machine learning models for their generation perform poorly for russian compared to english to bridge this gap we present strucom the first largescale dataset 153k examples specifically designed for russian code documentation unlike machinetranslated english datasets that distort terminology eg technical loanwords vs literal translations and docstring structures strucom combines humanwritten comments from russian github repositories with synthetically generated ones ensuring compliance with python java javascript c and go standards through automated validation finetuning qwen25coder models 05b7b on strucom shows statistically significant improvements of chrf and bertscore over baseline models
http://arxiv.org/abs/2505.11010v1,2025-05-16T08:59:07Z,"Jiangxu Wu, Cong Wang, TianHuang Su, Jun Yang, Haozhi Lin, Chao Zhang, Ming Peng, Kai Shi, SongPan Yang, BinQing Pan, ZiXian Li, Ni Yang, ZhenYu Yang",reviewinstruct a reviewdriven multiturn conversations generation method for large language models,the effectiveness of large language models llms in conversational ai is hindered by their reliance on singleturn supervised finetuning sft data which limits contextual coherence in multiturn dialogues existing methods for generating multiturn dialogue data struggle to ensure both diversity and quality in instructions to address this we propose reviewinstruct a novel framework that synthesizes multiturn conversations through an iterative askrespondreview process involving three agent roles a candidate multiple reviewers and a chairman the framework iteratively refines instructions by incorporating reviewer feedback enhancing dialogue diversity and difficulty we construct a multiturn dataset using the alpaca dataset and finetune the llama213b model evaluations on mtbench mmlupro and autoarena demonstrate significant improvements achieving absolute gains of 29 on mmlupro and 2 on mtbench compared to prior stateoftheart models based on llama213b ablation studies confirm the critical role of the review stage and the use of multiple reviewers in boosting instruction diversity and difficulty our work highlights the potential of reviewdriven multiagent frameworks for generating highquality conversational data at scale
http://arxiv.org/abs/2505.11008v1,2025-05-16T08:54:21Z,"Ye Kyaw Thu, Thazin Myint Oo",reconstructing syllable sequences in abugida scripts with incomplete inputs,this paper explores syllable sequence prediction in abugida languages using transformerbased models focusing on six languages bengali hindi khmer lao myanmar and thai from the asian language treebank alt dataset we investigate the reconstruction of complete syllable sequences from various incomplete input types including consonant sequences vowel sequences partial syllables with random character deletions and masked syllables with fixed syllable deletions our experiments reveal that consonant sequences play a critical role in accurate syllable prediction achieving high bleu scores while vowel sequences present a significantly greater challenge the model demonstrates robust performance across tasks particularly in handling partial and masked syllable reconstruction with strong results for tasks involving consonant information and syllable masking this study advances the understanding of sequence prediction for abugida languages and provides practical insights for applications such as text prediction spelling correction and data augmentation in these scripts
http://arxiv.org/abs/2505.11004v1,2025-05-16T08:50:42Z,"Jingcheng Niu, Subhabrata Dutta, Ahmed Elshabrawy, Harish Tayyar Madabushi, Iryna Gurevych",illusion or algorithm investigating memorization emergence and symbolic processing in incontext learning,largescale transformer language models lms trained solely on nexttoken prediction with webscale data can solve a wide range of tasks after seeing just a few examples the mechanism behind this capability known as incontext learning icl remains both controversial and poorly understood some studies argue that it is merely the result of memorizing vast amounts of data while others contend that it reflects a fundamental symbolic algorithmic development in lms in this work we introduce a suite of investigative tasks and a novel method to systematically investigate icl by leveraging the full pythia scaling suite including interim checkpoints that capture progressively larger amount of training data by carefully exploring icl performance on downstream tasks and simultaneously conducting a mechanistic analysis of the residual streams subspace we demonstrate that icl extends beyond mere memorization of the training corpus yet does not amount to the implementation of an independent symbolic algorithm our results also clarify several aspects of icl including the influence of training dynamics model capabilities and elements of mechanistic interpretability overall our work advances the understanding of icl and its implications offering model developers insights into potential improvements and providing ai security practitioners with a basis for more informed guidelines
http://arxiv.org/abs/2505.10981v1,2025-05-16T08:28:57Z,"Yexiang Liu, Zekun Li, Zhi Fang, Nan Xu, Ran He, Tieniu Tan",rethinking the role of prompting strategies in llm testtime scaling a perspective of probability theory,recently scaling testtime compute on large language models llm has garnered wide attention however there has been limited investigation of how various reasoning prompting strategies perform as scaling in this paper we focus on a standard and realistic scaling setting majority voting we systematically conduct experiments on 6 llms 8 prompting strategies 6 benchmarks experiment results consistently show that as the sampling time and computational overhead increase complicated prompting strategies with superior initial performance gradually fall behind simple chainofthought we analyze this phenomenon and provide theoretical proofs additionally we propose a method according to probability theory to quickly and accurately predict the scaling performance and select the best strategy under large sampling times without extra resourceintensive inference in practice it can serve as the testtime scaling law for majority voting furthermore we introduce two ways derived from our theoretical analysis to significantly improve the scaling performance we hope that our research can promote to reexamine the role of complicated prompting unleash the potential of simple prompting strategies and provide new insights for enhancing testtime scaling performance
http://arxiv.org/abs/2505.10975v1,2025-05-16T08:21:59Z,"Xinlu He, Jacob Whitehill",survey of endtoend multispeaker automatic speech recognition for monaural audio,monaural multispeaker automatic speech recognition asr remains challenging due to data scarcity and the intrinsic difficulty of recognizing and attributing words to individual speakers particularly in overlapping speech recent advances have driven the shift from cascade systems to endtoend e2e architectures which reduce error propagation and better exploit the synergy between speech content and speaker identity despite rapid progress in e2e multispeaker asr the field lacks a comprehensive review of recent developments this survey provides a systematic taxonomy of e2e neural approaches for multispeaker asr highlighting recent advances and comparative analysis specifically we analyze 1 architectural paradigms simo vssiso for presegmented audio analyzing their distinct characteristics and tradeoffs 2 recent architectural and algorithmic improvements based on these two paradigms 3 extensions to longform speech including segmentation strategy and speakerconsistent hypothesis stitching further we 4 evaluate and compare methods across standard benchmarks we conclude with a discussion of open challenges and future research directions towards building robust and scalable multispeaker asr
http://arxiv.org/abs/2505.10948v1,2025-05-16T07:37:21Z,Makoto Sato,the way we prompt conceptual blending neural dynamics and promptinduced transitions in llms,large language models llms inspired by neuroscience exhibit behaviors that often evoke a sense of personality and intelligenceyet the mechanisms behind these effects remain elusive here we operationalize conceptual blending theory cbt as an experimental framework using promptbased methods to reveal how llms blend and compress meaning by systematically investigating promptinduced transitions pit and promptinduced hallucinations pih we uncover structural parallels and divergences between artificial and biological cognition our approach bridges linguistics neuroscience and empirical ai research demonstrating that humanai collaboration can serve as a living prototype for the future of cognitive science this work proposes prompt engineering not just as a technical tool but as a scientific method for probing the deep structure of meaning itself
http://arxiv.org/abs/2505.10945v1,2025-05-16T07:30:22Z,"Seungyoon Lee, Seongtae Hong, Hyeonseok Moon, Heuiseok Lim",semantic aware linear transfer by recycling pretrained language models for crosslingual transfer,large language models llms increasingly incorporate multilingual capabilities fueling the demand to transfer them into target languagespecific models however most approaches which blend the source models embedding by replacing the source vocabulary with the target languagespecific vocabulary may constrain expressive capacity in the target language since the source model is predominantly trained on english data in this paper we propose semantic aware linear transfer salt a novel crosslingual transfer technique that recycles embeddings from target language pretrained language models plms to transmit the deep representational strengths of plmderived embedding to llms salt derives unique regression lines based on the similarity in the overlap of the source and target vocabularies to handle each nonoverlapping tokens embedding space our extensive experiments show that salt significantly outperforms other transfer methods and achieves lower loss with accelerating faster convergence during language adaptation notably salt obtains remarkable performance in crosslingual understanding setups compared to other methods furthermore we highlight the scalable use of plms to enhance the functionality of contemporary llms by conducting experiments with varying architectures
http://arxiv.org/abs/2505.10939v1,2025-05-16T07:23:59Z,"Mohammadtaha Bagherifard, Sahar Rajabi, Ali Edalat, Yadollah Yaghoobzadeh",genknowsub improving modularity and reusability of llms through general knowledge subtraction,large language models often struggle with zeroshot generalization and several modular approaches have been proposed to address this challenge yet we hypothesize that a key limitation remains the entanglement of general knowledge and taskspecific adaptations to overcome this we propose a modular framework that disentangles these components by constructing a library of taskspecific lora modules alongside a generaldomain lora by subtracting this general knowledge component from each taskspecific module we obtain residual modules that focus more exclusively on taskrelevant information a method we call general knowledge subtraction genknowsub leveraging the refined taskspecific modules and the arrow routing algorithm citepostapenko2024towards we dynamically select and combine modules for new inputs without additional training our studies on the phi3 model and standard arrow as baselines reveal that using general knowledge loras derived from diverse languages including english french and german yields consistent performance gains in both monolingual and crosslingual settings across a wide set of benchmarks further experiments on phi2 demonstrate how genknowsub generalizes to weaker llms the complete code and data are available at httpsgithubcomsaharsamrmodularllm
http://arxiv.org/abs/2505.10938v1,2025-05-16T07:23:12Z,"Yi Su, Yuechi Zhou, Quantong Qiu, Juntao Li, Qingrong Xia, Ping Li, Xinyu Duan, Zhefeng Wang, Min Zhang",accurate kv cache quantization with outlier tokens tracing,the impressive capabilities of large language models llms come at the cost of substantial computational resources during deployment while kv cache can significantly reduce recomputation during inference it also introduces additional memory overhead kv cache quantization presents a promising solution striking a good balance between memory usage and accuracy previous research has shown that the keys are distributed by channel while the values are distributed by token consequently the common practice is to apply channelwise quantization to the keys and tokenwise quantization to the values however our further investigation reveals that a small subset of unusual tokens exhibit unique characteristics that deviate from this pattern which can substantially impact quantization accuracy to address this we develop a simple yet effective method to identify these tokens accurately during the decoding process and exclude them from quantization as outlier tokens significantly improving overall accuracy extensive experiments show that our method achieves significant accuracy improvements under 2bit quantization and can deliver a 64 times reduction in memory usage and a 23 times increase in throughput
http://arxiv.org/abs/2505.10937v1,2025-05-16T07:15:30Z,"Wenrui Cai, Chengyu Wang, Junbing Yan, Jun Huang, Xiangzhong Fang",reasoning with omnithought a large cot dataset with verbosity and cognitive difficulty annotations,the emergence of large reasoning models lrms has transformed natural language processing by excelling in complex tasks such as mathematical problemsolving and code generation these models leverage chainofthought cot processes enabling them to emulate humanlike reasoning strategies however the advancement of lrms is hindered by the lack of comprehensive cot datasets current resources often fail to provide extensive reasoning problems with coherent cot processes distilled from multiple teacher models and do not account for multifaceted properties describing the internal characteristics of cots to address these challenges we introduce omnithought a largescale dataset featuring 2 million cot processes generated and validated by two powerful lrms as teacher models each cot process in omnithought is annotated with novel reasoning verbosity rv and cognitive difficulty cd scores which describe the appropriateness of cot verbosity and cognitive difficulty level for models to comprehend these reasoning processes we further establish a selfreliant pipeline to curate this dataset extensive experiments using qwen25 models of various sizes demonstrate the positive impact of our proposed scores on lrm training effectiveness based on the proposed omnithought dataset we further train and release a series of highperforming lrms specifically equipped with stronger reasoning abilities and optimal cot output length and difficulty level our contributions significantly enhance the development and training of lrms for solving complex tasks
http://arxiv.org/abs/2505.10936v1,2025-05-16T07:14:42Z,"Jiaxing Zhao, Hongbin Xie, Yuzhen Lei, Xuan Song, Zhuoran Shi, Lianxin Li, Shuangxue Liu, Haoran Zhang",connecting the dots a chainofcollaboration prompting framework for llm agents,large language models llms have demonstrated impressive performance in executing complex reasoning tasks chainofthought effectively enhances reasoning capabilities by unlocking the potential of large models while multiagent systems provide more comprehensive solutions by integrating collective intelligence of multiple agents however both approaches face significant limitations singleagent with chainofthought due to the inherent complexity of designing crossdomain prompts faces collaboration challenges meanwhile multiagent systems consume substantial tokens and inevitably dilute the primary problem which is particularly problematic in business workflow tasks to address these challenges we propose cochain a collaboration prompting framework that effectively solves business workflow collaboration problem by combining knowledge and prompts at a reduced cost specifically we construct an integrated knowledge graph that incorporates knowledge from multiple stages furthermore by maintaining and retrieving a prompts tree we can obtain prompt information relevant to other stages of the business workflow we perform extensive evaluations of cochain across multiple datasets demonstrating that cochain outperforms all baselines in both prompt engineering and multiagent llms additionally expert evaluation results indicate that the use of a small model in combination with cochain outperforms gpt4
http://arxiv.org/abs/2505.10924v1,2025-05-16T06:56:42Z,"Ada Chen, Yongjiang Wu, Junyuan Zhang, Shu Yang, Jen-tse Huang, Kun Wang, Wenxuan Wang, Shuai Wang",a survey on the safety and security threats of computerusing agents jarvis or ultron,recently aidriven interactions with computing devices have advanced from basic prototype tools to sophisticated llmbased systems that emulate humanlike operations in graphical user interfaces we are now witnessing the emergence of emphcomputerusing agents cuas capable of autonomously performing tasks such as navigating desktop applications web pages and mobile apps however as these agents grow in capability they also introduce novel safety and security risks vulnerabilities in llmdriven reasoning with the added complexity of integrating multiple software components and multimodal inputs further complicate the security landscape in this paper we present a systematization of knowledge on the safety and security threats of cuas we conduct a comprehensive literature review and distill our findings along four research objectives textittextbfi define the cua that suits safety analysis textittextbfii categorize current safety threats among cuas textittextbfiii propose a comprehensive taxonomy of existing defensive strategies textittextbfiv summarize prevailing benchmarks datasets and evaluation metrics used to assess the safety and performance of cuas building on these insights our work provides future researchers with a structured foundation for exploring unexplored vulnerabilities and offers practitioners actionable guidance in designing and deploying secure computerusing agents
http://arxiv.org/abs/2505.10872v2,2025-05-16T05:27:15Z,"Chenxi Jiang, Chuhao Zhou, Jianfei Yang",reibench can embodied agents understand vague human instructions in task planning,robot task planning decomposes human instructions into executable action sequences that enable robots to complete a series of complex tasks although recent large language model llmbased task planners achieve amazing performance they assume that human instructions are clear and straightforward however realworld users are not experts and their instructions to robots often contain significant vagueness linguists suggest that such vagueness frequently arises from referring expressions res whose meanings depend heavily on dialogue context and environment this vagueness is even more prevalent among the elderly and children who robots should serve more this paper studies how such vagueness in res within human instructions affects llmbased robot task planning and how to overcome this issue to this end we propose the first robot task planning benchmark with vague res reibench where we discover that the vagueness of res can severely degrade robot planning performance leading to success rate drops of up to 779 we also observe that most failure cases stem from missing objects in planners to mitigate the res issue we propose a simple yet effective approach taskoriented context cognition which generates clear instructions for robots achieving stateoftheart performance compared to aware prompt and chains of thought this work contributes to the research community of humanrobot interaction hri by making robot task planning more practical particularly for nonexpert users eg the elderly and children
http://arxiv.org/abs/2505.10870v1,2025-05-16T05:22:42Z,"Ziyang Huang, Wangtao Sun, Jun Zhao, Kang Liu",improve rule retrieval and reasoning with selfinduction and relevance reestimate,this paper systematically addresses the challenges of rule retrieval a crucial yet underexplored area vanilla retrieval methods using sparse or dense retrievers to directly search for relevant rules to support downstream reasoning often suffer from low accuracy this is primarily due to a significant semantic gap between the instantiated facts in the queries and the abstract representations of the rules such misalignment results in suboptimal retrieval quality which in turn negatively impacts reasoning performance to overcome these challenges we propose selfinduction augmented retrieval siar a novel approach that utilizes large language models llms to induce potential inferential rules that might offer benefits for reasoning by abstracting the underlying knowledge and logical structure in queries these induced rules are then used for query augmentation to improve retrieval effectiveness additionally we introduce rule relevance reestimate r a method that reestimates the relevance of retrieved rules by assessing whether the abstract knowledge they contain can be instantiated to align with the facts in the queries and the helpfulness for reasoning extensive experiments across various settings demonstrate the effectiveness and versatility of our proposed methods
http://arxiv.org/abs/2505.10862v1,2025-05-16T05:04:34Z,"Tairan Fu, Miguel González, Javier Conde, Elena Merino-Gómez, Pedro Reviriego",have multimodal large language models mllms really learned to tell the time on analog clocks,multimodal large language models which can answer complex questions on an image struggle to tell the time on analog clocks this is probably due to the lack of images with clocks at different times in their training set in this work we explore this issue with one of the latest mllms gpt41 to understand why mllms fail to tell the time and whether finetuning can solve the problem the results show how models are making progress in reading the time on analog clocks but have they really learned to do it or have they only learned patterns in their training datasets in this work we put the models to the test with different clocks to illustrate the limitations of mllms to abstract and generalize
http://arxiv.org/abs/2505.10852v1,2025-05-16T04:43:05Z,"Siyu Liu, Jiamin Xu, Beilin Ye, Bo Hu, David J. Srolovitz, Tongqi Wen",mattools benchmarking large language models for materials science tools,large language models llms are increasingly applied to materials science questions including literature comprehension property prediction materials discovery and alloy design at the same time a wide range of physicsbased computational approaches have been developed in which materials properties can be calculated here we propose a benchmark application to evaluate the proficiency of llms to answer materials science questions through the generation and safe execution of codes based on such physicsbased computational materials science packages mattools is built on two complementary components a materials simulation tool questionanswer qa benchmark and a realworld toolusage benchmark we designed an automated methodology to efficiently collect realworld materials science tooluse examples the qa benchmark derived from the pymatgen python materials genomics codebase and documentation comprises 69225 qa pairs that assess the ability of an llm to understand materials science tools the realworld benchmark contains 49 tasks 138 subtasks requiring the generation of functional python code for materials property calculations our evaluation of diverse llms yields three key insights 1generalists outshine specialists2ai knows ai and 3simpler is better mattools provides a standardized framework for assessing and improving llm capabilities for materials science tool applications facilitating the development of more effective ai systems for materials science and general scientific research
http://arxiv.org/abs/2505.10844v1,2025-05-16T04:23:34Z,"Simeng Han, Stephen Xia, Grant Zhang, Howard Dai, Chen Liu, Lichang Chen, Hoang Huy Nguyen, Hongyuan Mei, Jiayuan Mao, R. Thomas McCoy",creativity or brute force using brainteasers as a window into the problemsolving abilities of large language models,accuracy remains a standard metric for evaluating ai systems but it offers limited insight into how models arrive at their solutions in this work we introduce a benchmark based on brainteasers written in long narrative form to probe more deeply into the types of reasoning strategies that models use brainteasers are wellsuited for this goal because they can be solved with multiple approaches such as a fewstep solution that uses a creative insight or a longer solution that uses more brute force we investigate large language models llms across multiple layers of reasoning focusing not only on correctness but also on the quality and creativity of their solutions we investigate many aspects of the reasoning process 1 semantic parsing of the brainteasers into precise mathematical competition style formats 2 generating solutions from these mathematical forms 3 selfcorrecting solutions based on gold solutions 4 producing stepbystep sketches of solutions and 5 making use of hints we find that llms are in many cases able to find creative insightful solutions to brainteasers suggesting that they capture some of the capacities needed to solve novel problems in creative ways nonetheless there also remain situations where they rely on brute force despite the availability of more efficient creative solutions highlighting a potential direction for improvement in the reasoning abilities of llms
http://arxiv.org/abs/2505.10838v1,2025-05-16T04:12:16Z,"Ran Li, Hao Wang, Chengzhi Mao",largo latent adversarial reflection through gradient optimization for jailbreaking llms,efficient redteaming method to uncover vulnerabilities in large language models llms is crucial while recent attacks often use llms as optimizers the discrete language space make gradientbased methods struggle we introduce largo latent adversarial reflection through gradient optimization a novel latent selfreflection attack that reasserts the power of gradientbased optimization for generating fluent jailbreaking prompts by operating within the llms continuous latent space largo first optimizes an adversarial latent vector and then recursively call the same llm to decode the latent into natural language this methodology yields a fast effective and transferable attack that produces fluent and stealthy prompts on standard benchmarks like advbench and jailbreakbench largo surpasses leading jailbreaking techniques including autodan by 44 points in attack success rate our findings demonstrate a potent alternative to agentic llm prompting highlighting the efficacy of interpreting and attacking llm internals through gradient optimization
http://arxiv.org/abs/2505.10836v1,2025-05-16T04:07:21Z,"Abhishek Dey, Aabha Bothera, Samhita Sarikonda, Rishav Aryan, Sanjay Kumar Podishetty, Akshay Havalgi, Gaurav Singh, Saurabh Srivastava",multimodal event detection current approaches and defining the new playground through llms and vlms,in this paper we study the challenges of detecting events on social media where traditional unimodal systems struggle due to the rapid and multimodal nature of data dissemination we employ a range of models including unimodal modernbert and convnextv2 multimodal fusion techniques and advanced generative models like gpt4o and llava additionally we also study the effect of providing multimodal generative models such as gpt4o with a single modality to assess their efficacy our results indicate that while multimodal approaches notably outperform unimodal counterparts generative approaches despite having a large number of parameters lag behind supervised methods in precision furthermore we also found that they lag behind instructiontuned models because of their inability to generate event classes correctly during our error analysis we discovered that common social media issues such as leet speak text elongation etc are effectively handled by generative approaches but are hard to tackle using supervised approaches
http://arxiv.org/abs/2505.10832v1,2025-05-16T04:01:57Z,"Songjun Tu, Jiahao Lin, Qichao Zhang, Xiangyu Tian, Linjing Li, Xiangyuan Lan, Dongbin Zhao",learning when to think shaping adaptive reasoning in r1style models via multistage rl,large reasoning models lrms are proficient at generating explicit stepbystep reasoning sequences before producing final answers however such detailed reasoning can introduce substantial computational overhead and latency particularly for simple problems to address this overthinking problem we explore how to equip lrms with adaptive thinking capabilities enabling them to dynamically decide whether or not to engage in explicit reasoning based on problem complexity building on r1style distilled models we observe that inserting a simple ellipsis into the prompt can stochastically trigger either a thinking or nothinking mode revealing a latent controllability in the reasoning behavior leveraging this property we propose autothink a multistage reinforcement learning rl framework that progressively optimizes reasoning policies via stagewise reward shaping autothink learns to invoke explicit reasoning only when necessary while defaulting to succinct responses for simpler tasks experiments on five mainstream mathematical benchmarks demonstrate that autothink achieves favorable accuracyefficiency tradeoffs compared to recent prompting and rlbased pruning methods it can be seamlessly integrated into any r1style model including both distilled and further finetuned variants notably autothink improves relative accuracy by 64 percent while reducing token usage by 52 percent on deepseekr1distillqwen15b establishing a scalable and adaptive reasoning paradigm for lrms
http://arxiv.org/abs/2505.10831v2,2025-05-16T04:00:31Z,"Omar Shaikh, Shardul Sapkota, Shan Rizvi, Eric Horvitz, Joon Sung Park, Diyi Yang, Michael S. Bernstein",creating general user models from computer use,humancomputer interaction has long imagined technology that understands usfrom our preferences and habits to the timing and purpose of our everyday actions yet current user models remain fragmented narrowly tailored to specific apps and incapable of the flexible reasoning required to fulfill these visions this paper presents an architecture for a general user model gum that learns about you by observing any interaction you have with your computer the gum takes as input any unstructured observation of a user eg device screenshots and constructs confidenceweighted propositions that capture user knowledge and preferences gums can infer that a user is preparing for a wedding theyre attending from messages with a friend or recognize that a user is struggling with a collaborators feedback on a draft by observing multiple stalled edits and a switch to reading related work gums introduce an architecture that infers new propositions about a user from multimodal observations retrieves related propositions for context and continuously revises existing propositions to illustrate the breadth of applications that gums enable we demonstrate how they augment chatbased assistants with context manage os notifications to selectively surface important information and enable interactive agents that adapt to preferences across apps we also instantiate proactive assistants gumbos that discover and execute useful suggestions on a users behalf using their gum in our evaluations we find that gums make calibrated and accurate inferences about users and that assistants built on gums proactively identify and perform actions that users wouldnt think to request explicitly altogether gums introduce methods that leverage multimodal models to understand unstructured context enabling longstanding visions of hci and entirely new interactive systems that anticipate user needs
http://arxiv.org/abs/2505.10829v1,2025-05-16T03:59:14Z,"Chen-Chi Chang, Chong-Fu Li, Chu-Hsuan Lee, Hung-Shin Lee",enhancing lowresource minority language translation with llms and retrievalaugmented generation for cultural nuances,this study investigates the challenges of translating lowresource languages by integrating large language models llms with retrievalaugmented generation rag various model configurations were tested on hakka translations with bleu scores ranging from 12 dictionaryonly to 31 rag with gemini 20 the bestperforming model model 4 combined retrieval and advanced language modeling improving lexical coverage particularly for specialized or culturally nuanced terms and enhancing grammatical coherence a twostage method model 3 using dictionary outputs refined by gemini 20 achieved a bleu score of 26 highlighting iterative corrections value and the challenges of domainspecific expressions static dictionarybased approaches struggled with contextsensitive content demonstrating the limitations of relying solely on predefined resources these results emphasize the need for curated resources domain knowledge and ethical collaboration with local communities offering a framework that improves translation accuracy and fluency while supporting cultural preservation
http://arxiv.org/abs/2505.10798v1,2025-05-16T02:24:32Z,"Erica Cai, Sean McQuade, Kevin Young, Brendan O'Connor",relation extraction across entire books to reconstruct community networks the affilkg datasets,when knowledge graphs kgs are automatically extracted from text are they accurate enough for downstream analysis unfortunately current annotated datasets can not be used to evaluate this question since their kgs are highly disconnected too small or overly complex to address this gap we introduce affilkg httpsdoiorg105281zenodo15427977 which is a collection of six datasets that are the first to pair complete book scans with large labeled knowledge graphs each dataset features affiliation graphs which are simple kgs that capture member relationships between person and organization entities useful in studies of migration community interactions and other social phenomena in addition three datasets include expanded kgs with a wider variety of relation types our preliminary experiments demonstrate significant variability in model performance across datasets underscoring affilkgs ability to enable two critical advances 1 benchmarking how extraction errors propagate to graphlevel analyses eg community structure and 2 validating kg extraction methods for realworld social science research
http://arxiv.org/abs/2505.10792v2,2025-05-16T02:06:06Z,"Zhan Peng Lee, Andre Lin, Calvin Tan",finetunerag finetuning language models to resist hallucination in retrievalaugmented generation,retrievalaugmented generation rag has emerged as a powerful framework to improve factuality in large language models llms by grounding their outputs in retrieved documents however ensuring perfect retrieval of relevant information remains challenging and when irrelevant content is passed downstream to an llm it can lead to hallucinations in this work we propose finetunerag a simple and effective finetuning approach that features the firstofitskind rag training dataset constructed to mimic realworld imperfections experimental results show that finetunerag improves factual accuracy by 212 over the base model we also propose benchrag an llmasajudge evaluation pipeline that stress tests models under realistic imperfect retrieval scenarios our codebase and dataset are fully open sourced for community use
http://arxiv.org/abs/2505.10775v1,2025-05-16T01:27:03Z,"Kian Ahrabian, Pegah Jandaghi, Negar Mokhberian, Sai Praneeth Karimireddy, Jay Pujara",a systematic analysis of base model choice for reward modeling,reinforcement learning from human feedback rlhf and at its core reward modeling have become a crucial part of training powerful large language models llms one commonly overlooked factor in training highquality reward models rms is the effect of the base model which is becoming more challenging to choose given the rapidly growing pool of llms in this work we present a systematic analysis of the effect of base model selection on reward modeling performance our results show that the performance can be improved by up to 14 compared to the most common ie default choice moreover we showcase the strong statistical relation between some existing benchmarks and downstream performances we also demonstrate that the results from a small set of benchmarks could be combined to boost the model selection 18 on average in the top 510 lastly we illustrate the impact of different posttraining steps on the final performance and explore using estimated data distributions to reduce performance prediction error
http://arxiv.org/abs/2505.10772v1,2025-05-16T01:09:43Z,"Weiqin Wang, Yile Wang, Hui Huang",ranked voting based selfconsistency of large language models,majority voting is considered an effective method to enhance chainofthought reasoning as it selects the answer with the highest selfconsistency among different reasoning paths wang et al 2023 however previous chainofthought reasoning methods typically generate only a single answer in each trial thereby ignoring the possibility of other potential answers as a result these alternative answers are often overlooked in subsequent voting processes in this work we propose to generate ranked answers in each reasoning process and conduct ranked voting among multiple ranked answers from different responses thereby making the overall selfconsistency more reliable specifically we use three ranked voting methods instantrunoff voting borda count voting and mean reciprocal rank voting we validate our methods on six datasets including three multiplechoice and three openended questionanswering tasks using both advanced opensource and closedsource large language models extensive experimental results indicate that our proposed method outperforms the baselines showcasing the potential of leveraging the information of ranked answers and using ranked voting to improve reasoning performance the code is available at httpsgithubcomszuterarankedvotingsc
http://arxiv.org/abs/2505.10740v1,2025-05-15T23:04:46Z,"Qiwei Peng, Robert Moro, Michal Gregor, Ivan Srba, Simon Ostermann, Marian Simko, Juraj Podroužek, Matúš Mesarčík, Jaroslav Kopčan, Anders Søgaard",semeval2025 task 7 multilingual and crosslingual factchecked claim retrieval,the rapid spread of online disinformation presents a global challenge and machine learning has been widely explored as a potential solution however multilingual settings and lowresource languages are often neglected in this field to address this gap we conducted a shared task on multilingual claim retrieval at semeval 2025 aimed at identifying factchecked claims that match newly encountered claims expressed in social media posts across different languages the task includes two subtracks 1 a monolingual track where social posts and claims are in the same language and 2 a crosslingual track where social posts and claims might be in different languages a total of 179 participants registered for the task contributing to 52 test submissions 23 out of 31 teams have submitted their system papers in this paper we report the bestperforming systems as well as the most common and the most effective approaches across both subtracks this shared task along with its dataset and participating systems provides valuable insights into multilingual claim retrieval and automated factchecking supporting future research in this field
http://arxiv.org/abs/2505.10736v1,2025-05-15T22:41:30Z,"Ximing Dong, Shaowei Wang, Dayi Lin, Ahmed E. Hassan",model performanceguided evaluation data selection for effective prompt optimization,optimizing large language model llm performance requires wellcrafted prompts but manual prompt engineering is laborintensive and often ineffective automated prompt optimization techniques address this challenge but the majority of them rely on randomly selected evaluation subsets which fail to represent the full dataset leading to unreliable evaluations and suboptimal prompts existing coreset selection methods designed for llm benchmarking are unsuitable for prompt optimization due to challenges in clustering similar samples high data collection costs and the unavailability of performance data for new or private datasets to overcome these issues we propose ipomp an iterative evaluation data selection for effective prompt optimization using realtime model performance ipomp is a twostage approach that selects representative and diverse samples using semantic clustering and boundary analysis followed by iterative refinement with realtime model performance data to replace redundant samples evaluations on the bigbench dataset show that ipomp improves effectiveness by 16 to 53 and stability by at least 57 compared with sota baselines with minimal computational overhead below 1 furthermore the results demonstrate that our realtime performanceguided refinement approach can be universally applied to enhance existing coreset selection methods
http://arxiv.org/abs/2505.10719v2,2025-05-15T21:43:51Z,"Tomás Vergara-Browne, Álvaro Soto",tracrinjection distilling algorithms into pretrained language models,motivated by the surge of large language models there has been a push to formally characterize the symbolic abilities intrinsic to the transformer architecture a programming language called rasp has been proposed which can be directly compiled into transformer weights to implement these algorithms however the tasks that can be implemented in rasp are often uncommon to learn from natural unsupervised data showing a mismatch between theoretical capabilities of the transformer architecture and the practical learnability of these capabilities from unsupervised data we propose tracrinjection a method that allows us to distill algorithms written in rasp directly into a pretrained language model we showcase our method by injecting 3 different algorithms into a language model we show how our method creates an interpretable subspace within the models residual stream which can be decoded into the variables present in the code of the rasp algorithm additionally we found that the proposed method can improve outofdistribution performance compared to our baseline indicating that indeed a more symbolic mechanism is taking place in the inner workings of the model we release the code used to run our experiments
http://arxiv.org/abs/2505.10718v1,2025-05-15T21:43:34Z,"Siddharth Suresh, Kushin Mukherjee, Tyler Giallanza, Xizheng Yu, Mia Patil, Jonathan D. Cohen, Timothy T. Rogers",aienhanced semantic feature norms for 786 concepts,semantic feature norms have been foundational in the study of human conceptual knowledge yet traditional methods face tradeoffs between conceptfeature coverage and verifiability of quality due to the laborintensive nature of norming studies here we introduce a novel approach that augments a dataset of humangenerated feature norms with responses from large language models llms while verifying the quality of norms against reliable human judgments we find that our aienhanced feature norm dataset nova norms optimized via ai shows much higher feature density and overlap among concepts while outperforming a comparable humanonly norm dataset and wordembedding models in predicting peoples semantic similarity judgments taken together we demonstrate that human conceptual knowledge is richer than captured in previous norm datasets and show that with proper validation llms can serve as powerful tools for cognitive science research
http://arxiv.org/abs/2505.10717v1,2025-05-15T21:40:21Z,"Jean-Philippe Corbeil, Amin Dada, Jean-Michel Attendu, Asma Ben Abacha, Alessandro Sordoni, Lucas Caccia, François Beaulieu, Thomas Lin, Jens Kleesiek, Paul Vozila",a modular approach for clinical slms driven by synthetic data with preinstruction tuning model merging and clinicaltasks alignment,high computation costs and latency of large language models such as gpt4 have limited their deployment in clinical settings small language models slms offer a costeffective alternative but their limited capacity requires biomedical domain adaptation which remains challenging an additional bottleneck is the unavailability and high sensitivity of clinical data to address these challenges we propose a novel framework for adapting slms into highperforming clinical models we introduce the mediphi collection of 38bparameter slms developed with our novel framework preinstruction tuning of experts on relevant medical and clinical corpora pmc medical guideline medwiki etc model merging and clinicaltasks alignment to cover most clinical tasks we extended the clue benchmark to clue doubling its size our expert models deliver relative improvements on this benchmark over the base model without any taskspecific finetuning 643 on medical entities 495 on radiology reports and 44 on icd10 coding outperforming gpt40125 by 14 we unify the expert models into mediphi via model merging preserving gains across benchmarks furthermore we built the mediflow collection a synthetic dataset of 25 million highquality instructions on 14 medical nlp tasks 98 finegrained document types and json format support alignment of mediphi using supervised finetuning and direct preference optimization achieves further gains of 189 on average
http://arxiv.org/abs/2505.10714v1,2025-05-15T21:31:44Z,"Bowen Jiang, Yangxinyu Xie, Xiaomeng Wang, Jiashu He, Joshua Bergerson, John K Hutchison, Jordan Branham, Camillo J Taylor, Tanwi Mallick",geogridbench can foundation models understand multimodal gridded geospatial data,we present geogridbench a benchmark designed to evaluate the ability of foundation models to understand geospatial data in the grid structure geospatial datasets pose distinct challenges due to their dense numerical values strong spatial and temporal dependencies and unique multimodal representations including tabular data heatmaps and geographic visualizations to assess how foundation models can support scientific research in this domain geogridbench features largescale realworld data covering 16 climate variables across 150 locations and extended time frames the benchmark includes approximately 3200 questionanswer pairs systematically generated from 8 domain expertcurated templates to reflect practical tasks encountered by human scientists these range from basic queries at a single location and time to complex spatiotemporal comparisons across regions and periods our evaluation reveals that visionlanguage models perform best overall and we provide a finegrained analysis of the strengths and limitations of different foundation models in different geospatial tasks this benchmark offers clearer insights into how foundation models can be effectively applied to geospatial data analysis and used to support scientific research
http://arxiv.org/abs/2505.11556v1,2025-05-15T19:22:54Z,"Yuxuan Li, Aoi Naito, Hirokazu Shirado",assessing collective reasoning in multiagent llms via hidden profile tasks,multiagent systems built on large language models llms promise enhanced problemsolving through distributed information integration but also risk replicating collective reasoning failures observed in human groups yet no theorygrounded benchmark exists to systematically evaluate such failures in this paper we introduce the hidden profile paradigm from social psychology as a diagnostic testbed for multiagent llm systems by distributing critical information asymmetrically across agents the paradigm reveals how interagent dynamics support or hinder collective reasoning we first formalize the paradigm for multiagent decisionmaking under distributed knowledge and instantiate it as a benchmark with nine tasks spanning diverse scenarios including adaptations from prior human studies we then conduct experiments with gpt41 and five other leading llms including reasoningenhanced variants showing that multiagent systems across all models fail to match the accuracy of single agents given complete information while agents collective performance is broadly comparable to that of human groups nuanced behavioral differences emerge such as increased sensitivity to social desirability finally we demonstrate the paradigms diagnostic utility by exploring a cooperationcontradiction tradeoff in multiagent llm systems we find that while cooperative agents are prone to overcoordination in collective settings increased contradiction impairs group convergence this work contributes a reproducible framework for evaluating multiagent llm systems and motivates future research on artificial collective intelligence and humanai interaction
http://arxiv.org/abs/2505.10643v1,2025-05-15T18:32:24Z,"Shuchen Guo, Yun Wang, Jichao Yu, Xuansheng Wu, Bilgehan Ayik, Field M. Watts, Ehsan Latif, Ninghao Liu, Lei Liu, Xiaoming Zhai",artificial intelligence bias on english language learners in automatic scoring,this study investigated potential scoring biases and disparities toward english language learners ells when using automatic scoring systems for middle school students written responses to science assessments we specifically focus on examining how unbalanced training data with ells contributes to scoring bias and disparities we finetuned bert with four datasets responses from 1 ells 2 nonells 3 a mixed dataset reflecting the realworld proportion of ells and nonells unbalanced and 4 a balanced mixed dataset with equal representation of both groups the study analyzed 21 assessment items 10 items with about 30000 ell responses five items with about 1000 ell responses and six items with about 200 ell responses scoring accuracy acc was calculated and compared to identify bias using friedman tests we measured the mean score gaps msgs between ells and nonells and then calculated the differences in msgs generated through both the human and ai models to identify the scoring disparities we found that no ai bias and distorted disparities between ells and nonells were found when the training dataset was large enough ell 30000 and ell 1000 but concerns could exist if the sample size is limited ell 200
http://arxiv.org/abs/2505.10557v1,2025-05-15T17:59:21Z,"Ke Wang, Junting Pan, Linda Wei, Aojun Zhou, Weikang Shi, Zimu Lu, Han Xiao, Yunqiao Yang, Houxing Ren, Mingjie Zhan, Hongsheng Li",mathcodervl bridging vision and code for enhanced multimodal mathematical reasoning,natural language imagecaption datasets widely used for training large multimodal models mainly focus on natural scenarios and overlook the intricate details of mathematical figures that are critical for problemsolving hindering the advancement of current lmms in multimodal mathematical reasoning to this end we propose leveraging code as supervision for crossmodal alignment since code inherently encodes all information needed to generate corresponding figures establishing a precise connection between the two modalities specifically we codevelop our imagetocode model and dataset with modelintheloop approach resulting in an imagetocode model figcodifier and imgcode86m dataset the largest imagecode dataset to date furthermore we utilize figcodifier to synthesize novel mathematical figures and then construct mmmathinstruct3m a highquality multimodal math instruction finetuning dataset finally we present mathcodervl trained with imgcode86m for crossmodal alignment and subsequently finetuned on mmmathinstruct3m for multimodal math problem solving our model achieves a new opensource sota across all six metrics notably it surpasses gpt4o and claude 35 sonnet in the geometry problemsolving subset of mathvista achieving improvements of 89 and 92 the dataset and models will be released at httpsgithubcommathllmmathcoder
http://arxiv.org/abs/2505.10554v1,2025-05-15T17:58:33Z,"Zhiyuan Hu, Yibo Wang, Hanze Dong, Yuhui Xu, Amrita Saha, Caiming Xiong, Bryan Hooi, Junnan Li",beyond aha toward systematic metaabilities alignment in large reasoning models,large reasoning models lrms already possess a latent capacity for long chainofthought reasoning prior work has shown that outcomebased reinforcement learning rl can incidentally elicit advanced reasoning behaviors such as selfcorrection backtracking and verification phenomena often referred to as the models aha moment however the timing and consistency of these emergent behaviors remain unpredictable and uncontrollable limiting the scalability and reliability of lrms reasoning capabilities to address these limitations we move beyond reliance on prompts and coincidental aha moments instead we explicitly align models with three metaabilities deduction induction and abduction using automatically generated selfverifiable tasks our three stagepipeline individual alignment parameterspace merging and domainspecific reinforcement learning boosting performance by over 10 relative to instructiontuned baselines furthermore domainspecific rl from the aligned checkpoint yields an additional 2 average gain in the performance ceiling across math coding and science benchmarks demonstrating that explicit metaability alignment offers a scalable and dependable foundation for reasoning code is available at httpsgithubcomzhiyuanhubjmetaabilityalignment
http://arxiv.org/abs/2505.10543v1,2025-05-15T17:53:47Z,"Annie Wong, Thomas Bäck, Aske Plaat, Niki van Stein, Anna V. Kononova",towards a deeper understanding of reasoning capabilities in large language models,while large language models demonstrate impressive performance on static benchmarks the true potential of large language models as selflearning and reasoning agents in dynamic environments remains unclear this study systematically evaluates the efficacy of selfreflection heuristic mutation and planning as prompting techniques to test the adaptive capabilities of agents we conduct experiments with various opensource language models in dynamic environments and find that larger models generally outperform smaller ones but that strategic prompting can close this performance gap second a toolong prompt can negatively impact smaller models on basic reactive tasks while larger models show more robust behaviour third advanced prompting techniques primarily benefit smaller models on complex games but offer less improvement for already highperforming large language models yet we find that advanced reasoning methods yield highly variable outcomes while capable of significantly improving performance when reasoning and decisionmaking align they also introduce instability and can lead to big performance drops compared to human performance our findings reveal little evidence of true emergent reasoning instead large language model performance exhibits persistent limitations in crucial areas such as planning reasoning and spatial coordination suggesting that currentgeneration large language models still suffer fundamental shortcomings that may not be fully overcome through selfreflective prompting alone reasoning is a multifaceted task and while reasoning methods like chain of thought improves multistep reasoning on math word problems our findings using dynamic benchmarks highlight important shortcomings in general reasoning capabilities indicating a need to move beyond static benchmarks to capture the complexity of reasoning
http://arxiv.org/abs/2505.10610v1,2025-05-15T17:52:54Z,"Zhaowei Wang, Wenhao Yu, Xiyu Ren, Jipeng Zhang, Yu Zhao, Rohit Saxena, Liang Cheng, Ginny Wong, Simon See, Pasquale Minervini, Yangqiu Song, Mark Steedman",mmlongbench benchmarking longcontext visionlanguage models effectively and thoroughly,the rapid extension of context windows in large visionlanguage models has given rise to longcontext visionlanguage models lcvlms which are capable of handling hundreds of images with interleaved text tokens in a single forward pass in this work we introduce mmlongbench the first benchmark covering a diverse set of longcontext visionlanguage tasks to evaluate lcvlms effectively and thoroughly mmlongbench is composed of 13331 examples spanning five different categories of downstream tasks such as visual rag and manyshot icl it also provides broad coverage of image types including various natural and synthetic images to assess the robustness of the models to different input lengths all examples are delivered at five standardized input lengths 8k128k tokens via a crossmodal tokenization scheme that combines vision patches and text tokens through a thorough benchmarking of 46 closedsource and opensource lcvlms we provide a comprehensive analysis of the current models visionlanguage longcontext ability our results show that i performance on a single task is a weak proxy for overall longcontext capability ii both closedsource and opensource models face challenges in longcontext visionlanguage tasks indicating substantial room for future improvement iii models with stronger reasoning ability tend to exhibit better longcontext performance by offering wide task coverage various image types and rigorous length control mmlongbench provides the missing foundation for diagnosing and advancing the next generation of lcvlms
http://arxiv.org/abs/2505.10527v2,2025-05-15T17:38:37Z,"Binghai Wang, Runji Lin, Keming Lu, Le Yu, Zhenru Zhang, Fei Huang, Chujie Zheng, Kai Dang, Yang Fan, Xingzhang Ren, An Yang, Binyuan Hui, Dayiheng Liu, Tao Gui, Qi Zhang, Xuanjing Huang, Yu-Gang Jiang, Bowen Yu, Jingren Zhou, Junyang Lin",worldpm scaling human preference modeling,motivated by scaling laws in language modeling that demonstrate how test loss scales as a power law with model and dataset sizes we find that similar laws exist in preference modeling we propose world preference modeling worldpm to emphasize this scaling potential where world preference embodies a unified representation of human preferences in this paper we collect preference data from public forums covering diverse user communities and conduct extensive training using 15mscale data across models ranging from 15b to 72b parameters we observe distinct patterns across different evaluation metrics 1 adversarial metrics ability to identify deceptive features consistently scale up with increased training data and base model size 2 objective metrics objective knowledge with welldefined answers show emergent behavior in larger language models highlighting worldpms scalability potential 3 subjective metrics subjective preferences from a limited number of humans or ai do not demonstrate scaling trends further experiments validate the effectiveness of worldpm as a foundation for preference finetuning through evaluations on 7 benchmarks with 20 subtasks we find that worldpm broadly improves the generalization performance across human preference datasets of varying sizes 7k 100k and 800k samples with performance gains exceeding 5 on many key subtasks integrating worldpm into our internal rlhf pipeline we observe significant improvements on both inhouse and public evaluation sets with notable gains of 4 to 8 in our inhouse evaluations
http://arxiv.org/abs/2505.10526v2,2025-05-15T17:37:00Z,"Mugilan Ganesan, Shane Segal, Ankur Aggarwal, Nish Sinnadurai, Sean Lie, Vithursan Thangarasa",massv multimodal adaptation and selfdata distillation for speculative decoding of visionlanguage models,speculative decoding significantly accelerates language model inference by enabling a lightweight draft model to propose multiple tokens that a larger target model verifies simultaneously however applying this technique to visionlanguage models vlms presents two fundamental challenges small language models that could serve as efficient drafters lack the architectural components to process visual inputs and their token predictions fail to match those of vlm target models that consider visual context we introduce multimodal adaptation and selfdata distillation for speculative decoding of visionlanguage models massv which transforms existing small language models into effective multimodal drafters through a twophase approach massv first connects the target vlms vision encoder to the draft model via a lightweight trainable projector then applies selfdistilled visual instruction tuning using responses generated by the target vlm to align token predictions comprehensive experiments across the qwen25vl and gemma3 model families demonstrate that massv increases accepted length by up to 30 and delivers endtoend inference speedups of up to 146x on visuallygrounded tasks massv provides a scalable architecturecompatible method for accelerating both current and future vlms
http://arxiv.org/abs/2505.10518v1,2025-05-15T17:25:03Z,"Anastasios Gerontopoulos, Spyros Gidaris, Nikos Komodakis",multitoken prediction needs registers,multitoken prediction has emerged as a promising objective for improving language model pretraining but its benefits have not consistently generalized to other settings such as finetuning in this paper we propose mutor a simple and effective approach to multitoken prediction that interleaves learnable register tokens into the input sequence each tasked with predicting future targets compared to existing methods mutor offers several key advantages it introduces only a negligible number of additional parameters requires no architectural changesensuring compatibility with offtheshelf pretrained language modelsand remains aligned with the nexttoken pretraining objective making it especially wellsuited for supervised finetuning moreover it naturally supports scalable prediction horizons we demonstrate the effectiveness and versatility of mutor across a range of use cases including supervised finetuning parameterefficient finetuning peft and pretraining on challenging generative tasks in both language and vision domains our code will be available at httpsgithubcomnasosgermutor
http://arxiv.org/abs/2505.10507v1,2025-05-15T17:10:50Z,"Benedikt Ebing, Goran Glavaš",the devil is in the word alignment details on translationbased crosslingual transfer for token classification tasks,translationbased strategies for crosslingual transfer xlt such as translatetrain training on noisy target language data translated from the source language and translatetest evaluating on noisy source language data translated from the target language are competitive xlt baselines in xlt for token classification tasks however these strategies include label projection the challenging step of mapping the labels from each token in the original sentence to its counterparts in the translation although word aligners was are commonly used for label projection the lowlevel design decisions for applying them to translationbased xlt have not been systematically investigated moreover recent markerbased methods which project labeled spans by inserting tags around them before or after translation claim to outperform was in label projection for xlt in this work we revisit was for label projection systematically investigating the effects of lowlevel design decisions on tokenlevel xlt i the algorithm for projecting labels between multitoken spans ii filtering strategies to reduce the number of noisily mapped labels and iii the pretokenization of the translated sentences we find that all of these substantially impact translationbased xlt performance and show that with optimized choices xlt with wa offers performance at least comparable to that of markerbased methods we then introduce a new projection strategy that ensembles translatetrain and translatetest predictions and demonstrate that it substantially outperforms the markerbased projection crucially we show that our proposed ensembling also reduces sensitivity to lowlevel wa design choices resulting in more robust xlt for token classification tasks
http://arxiv.org/abs/2505.10495v1,2025-05-15T16:53:45Z,"Vibha Belavadi, Tushar Vatsa, Dewang Sultania, Suhas Suresha, Ishita Verma, Cheng Chen, Tracy Holloway King, Michael Friedrich",routenator a routerbased multimodal architecture for generating synthetic training data for function calling llms,this paper addresses finetuning large language models llms for function calling tasks when real user interaction data is unavailable in digital content creation tools where users express their needs through natural language queries that must be mapped to api calls the lack of realworld taskspecific data and privacy constraints for training on it necessitate synthetic data generation existing approaches to synthetic data generation fall short in diversity and complexity failing to replicate realworld data distributions and leading to suboptimal performance after llm finetuning we present a novel routerbased architecture that leverages domain resources like content metadata and structured knowledge graphs along with texttotext and visiontotext language models to generate highquality synthetic training data our architectures flexible routing mechanism enables synthetic data generation that matches observed realworld distributions addressing a fundamental limitation of traditional approaches evaluation on a comprehensive set of real user queries demonstrates significant improvements in both function classification accuracy and api parameter selection models finetuned with our synthetic data consistently outperform traditional approaches establishing new benchmarks for function calling tasks
http://arxiv.org/abs/2505.10494v1,2025-05-15T16:53:41Z,"Yutao Mou, Xiao Deng, Yuxiao Luo, Shikun Zhang, Wei Ye",can you really trust code copilots evaluating large language models from a code security perspective,code security and usability are both essential for various coding assistant applications driven by large language models llms current code security benchmarks focus solely on single evaluation task and paradigm such as code completion and generation lacking comprehensive assessment across dimensions like secure code generation vulnerability repair and discrimination in this paper we first propose coveval a multitask benchmark covering various tasks such as code completion vulnerability repair vulnerability detection and classification for comprehensive evaluation of llm code security besides we developed vcjudge an improved judgment model that aligns closely with human experts and can review llmgenerated programs for vulnerabilities in a more efficient and reliable way we conduct a comprehensive evaluation of 20 proprietary and opensource llms overall while most llms identify vulnerable codes well they still tend to generate insecure codes and struggle with recognizing specific vulnerability types and performing repairs extensive experiments and qualitative analyses reveal key challenges and optimization directions offering insights for future research in llm code security
http://arxiv.org/abs/2505.10493v1,2025-05-15T16:53:04Z,"Shaohan Wang, Licheng Zhang, Zheren Fu, Zhendong Mao",clrag bridging the gap in retrievalaugmented generation with curriculum learning,retrievalaugmented generation rag is an effective method to enhance the capabilities of large language models llms existing methods focus on optimizing the retriever or generator in the rag system by directly utilizing the topk retrieved documents however the documents effectiveness are various significantly across user queries ie some documents provide valuable knowledge while others totally lack critical information it hinders the retriever and generators adaptation during training inspired by human cognitive learning curriculum learning trains models using samples progressing from easy to difficult thus enhancing their generalization ability and we integrate this effective paradigm to the training of the rag system in this paper we propose a multistage curriculum learning based rag system training framework named clrag we first construct training data with multiple difficulty levels for the retriever and generator separately through sample evolution then we train the model in stages based on the curriculum learning approach thereby optimizing the overall performance and generalization of the rag system more effectively our clrag framework demonstrates consistent effectiveness across four opendomain qa datasets achieving performance gains of 2 to 4 over multiple advanced methods
http://arxiv.org/abs/2505.10475v1,2025-05-15T16:24:45Z,"Mouxiang Chen, Binyuan Hui, Zeyu Cui, Jiaxi Yang, Dayiheng Liu, Jianling Sun, Junyang Lin, Zhongxin Liu",parallel scaling law for language models,it is commonly believed that scaling language models should commit a significant space or time cost by increasing the parameters parameter scaling or output tokens inferencetime scaling we introduce the third and more inferenceefficient scaling paradigm increasing the models parallel computation during both training and inference time we apply diverse and learnable transformations to the input execute forward passes of the model in parallel and dynamically aggregate the outputs this method namely parallel scaling parscale scales parallel computation by reusing existing parameters and can be applied to any model structure optimization procedure data or task we theoretically propose a new scaling law and validate it through largescale pretraining which shows that a model with parallel streams is similar to scaling the parameters by while showing superior inference efficiency for example parscale can use up to 22 less memory increase and 6 less latency increase compared to parameter scaling that achieves the same performance improvement it can also recycle an offtheshelf pretrained model into a parallelly scaled one by posttraining on a small amount of tokens further reducing the training budget the new scaling law we discovered potentially facilitates the deployment of more powerful models in lowresource scenarios and provides an alternative perspective for the role of computation in machine learning
http://arxiv.org/abs/2505.10472v1,2025-05-15T16:23:21Z,"Agnik Saha, Victoria Churchill, Anny D. Rodriguez, Ugur Kursuncu, Muhammed Y. Idris",large language models for cancer communication evaluating linguistic quality safety and accessibility in generative ai,effective communication about breast and cervical cancers remains a persistent health challenge with significant gaps in public understanding of cancer prevention screening and treatment potentially leading to delayed diagnoses and inadequate treatments this study evaluates the capabilities and limitations of large language models llms in generating accurate safe and accessible cancerrelated information to support patient understanding we evaluated five generalpurpose and three medical llms using a mixedmethods evaluation framework across linguistic quality safety and trustworthiness and communication accessibility and affectiveness our approach utilized quantitative metrics qualitative expert ratings and statistical analysis using welchs anova gameshowell and hedges g our results show that generalpurpose llms produced outputs of higher linguistic quality and affectiveness while medical llms demonstrate greater communication accessibility however medical llms tend to exhibit higher levels of potential harm toxicity and bias reducing their performance in safety and trustworthiness our findings indicate a duality between domainspecific knowledge and safety in health communications the results highlight the need for intentional model design with targeted improvements particularly in mitigating harm and bias and improving safety and affectiveness this study provides a comprehensive evaluation of llms for cancer communication offering critical insights for improving aigenerated health content and informing future development of accurate safe and accessible digital health tools
http://arxiv.org/abs/2505.10465v2,2025-05-15T16:18:13Z,"Yizhou Liu, Ziming Liu, Jeff Gore",superposition yields robust neural scaling,the success of todays large language models llms depends on the observation that larger models perform better however the origin of this neural scaling law the finding that loss decreases as a power law with model size remains unclear starting from two empirical principles that llms represent more things than the model dimensions widths they have ie representations are superposed and that words or concepts in language occur with varying frequencies we constructed a toy model to study the loss scaling with model size we found that when superposition is weak meaning only the most frequent features are represented without interference the scaling of loss with model size depends on the underlying feature frequency if feature frequencies follow a power law so does the loss in contrast under strong superposition where all features are represented but overlap with each other the loss becomes inversely proportional to the model dimension across a wide range of feature frequency distributions this robust scaling behavior is explained geometrically when many more vectors are packed into a lower dimensional space the interference squared overlaps between vectors scales inversely with that dimension we then analyzed four families of opensourced llms and found that they exhibit strong superposition and quantitatively match the predictions of our toy model the chinchilla scaling law turned out to also agree with our results we conclude that representation superposition is an important mechanism underlying the observed neural scaling laws we anticipate that these insights will inspire new training strategies and model architectures to achieve better performance with less computation and fewer parameters
http://arxiv.org/abs/2505.10446v1,2025-05-15T16:06:32Z,"Zemin Huang, Zhiyang Chen, Zijun Wang, Tiancheng Li, Guo-Jun Qi",reinforcing the diffusion chain of lateral thought with diffusion language models,we introduce the emphdiffusion chain of lateral thought dcolt a reasoning framework for diffusion language models dcolt treats each intermediate step in the reverse diffusion process as a latent thinking action and optimizes the entire reasoning trajectory to maximize the reward on the correctness of the final answer with outcomebased reinforcement learning rl unlike traditional chainofthought cot methods that follow a causal linear thinking process dcolt allows bidirectional nonlinear reasoning with no strict rule on grammatical correctness amid its intermediate steps of thought we implement dcolt on two representative diffusion language models dlms first we choose sedd as a representative continuoustime discrete diffusion model where its concrete score derives a probabilistic policy to maximize the rl reward over the entire sequence of intermediate diffusion steps we further consider the discretetime masked diffusion language model llada and find that the order to predict and unmask tokens plays an essential role to optimize its rl action resulting from the rankingbased unmasking policy module upm defined by the plackettluce model experiments on both math and code generation tasks show that using only public data and 16 h800 gpus dcoltreinforced dlms outperform other dlms trained by sft or rl or even both notably dcoltreinforced llada boosts its reasoning accuracy by 98 57 114 195 on gsm8k math mbpp and humaneval
http://arxiv.org/abs/2505.10413v1,2025-05-15T15:34:15Z,"Jiajie Jin, Xiaoxi Li, Guanting Dong, Yuyao Zhang, Yutao Zhu, Yongkang Wu, Zhonghua Li, Qi Ye, Zhicheng Dou",hierarchical document refinement for longcontext retrievalaugmented generation,realworld rag applications often encounter longcontext input scenarios where redundant information and noise results in higher inference costs and reduced performance to address these challenges we propose longrefiner an efficient plugandplay refiner that leverages the inherent structural characteristics of long documents longrefiner employs duallevel query analysis hierarchical document structuring and adaptive refinement through multitask learning on a single foundation model experiments on seven qa datasets demonstrate that longrefiner achieves competitive performance in various scenarios while using 10x fewer computational costs and latency compared to the best baseline further analysis validates that longrefiner is scalable efficient and effective providing practical insights for realworld longtext rag applications our code is available at httpsgithubcomignorejjjlongrefiner
http://arxiv.org/abs/2505.10409v1,2025-05-15T15:31:17Z,"Yue Guo, Jae Ho Sohn, Gondy Leroy, Trevor Cohen",are llmgenerated plain language summaries truly understandable a largescale crowdsourced evaluation,plain language summaries plss are essential for facilitating effective communication between clinicians and patients by making complex medical information easier for laypeople to understand and act upon large language models llms have recently shown promise in automating pls generation but their effectiveness in supporting health information comprehension remains unclear prior evaluations have generally relied on automated scores that do not measure understandability directly or subjective likertscale ratings from convenience samples with limited generalizability to address these gaps we conducted a largescale crowdsourced evaluation of llmgenerated plss using amazon mechanical turk with 150 participants we assessed pls quality through subjective likertscale ratings focusing on simplicity informativeness coherence and faithfulness and objective multiplechoice comprehension and recall measures of reader understanding additionally we examined the alignment between 10 automated evaluation metrics and human judgments our findings indicate that while llms can generate plss that appear indistinguishable from humanwritten ones in subjective evaluations humanwritten plss lead to significantly better comprehension furthermore automated evaluation metrics fail to reflect human judgment calling into question their suitability for evaluating plss this is the first study to systematically evaluate llmgenerated plss based on both reader preferences and comprehension outcomes our findings highlight the need for evaluation frameworks that move beyond surfacelevel quality and for generation methods that explicitly optimize for layperson comprehension
http://arxiv.org/abs/2505.10402v1,2025-05-15T15:26:32Z,"Yihong Dong, Yuchen Liu, Xue Jiang, Zhi Jin, Ge Li",rethinking repetition problems of llms in code generation,with the advent of neural language models the performance of code generation has been significantly boosted however the problem of repetitions during the generation process continues to linger previous work has primarily focused on content repetition which is merely a fraction of the broader repetition problem in code generation a more prevalent and challenging problem is structural repetition in structural repetition the repeated code appears in various patterns but possesses a fixed structure which can be inherently reflected in grammar in this paper we formally define structural repetition and propose an efficient decoding approach called rpg which stands for repetition penalization based on grammar to alleviate the repetition problems in code generation for llms specifically rpg first leverages grammar rules to identify repetition problems during code generation and then strategically decays the likelihood of critical tokens that contribute to repetitions thereby mitigating them in code generation to facilitate this study we construct a new dataset coderepeteval to comprehensively evaluate approaches for mitigating the repetition problems in code generation extensive experimental results demonstrate that rpg substantially outperforms the bestperforming baselines on coderepeteval dataset as well as humaneval and mbpp benchmarks effectively reducing repetitions and enhancing the quality of generated code
http://arxiv.org/abs/2505.10389v1,2025-05-15T15:11:48Z,"Benjamin White, Anastasia Shimorina",multidomain multilingual sentiment analysis in industry predicting aspectbased opinion quadruples,this paper explores the design of an aspectbased sentiment analysis system using large language models llms for realworld use we focus on quadruple opinion extraction identifying aspect categories sentiment polarity targets and opinion expressions from text data across different domains and languages using internal datasets we investigate whether a single finetuned model can effectively handle multiple domainspecific taxonomies simultaneously we demonstrate that a combined multidomain model achieves performance comparable to specialized singledomain models while reducing operational complexity we also share lessons learned for handling nonextractive predictions and evaluating various failure modes when developing llmbased systems for structured prediction tasks
http://arxiv.org/abs/2505.10356v1,2025-05-15T14:46:45Z,"Chunyu Ye, Shaonan Wang",coherent language reconstruction from brain recordings with flexible multimodal input stimuli,decoding thoughts from brain activity offers valuable insights into human cognition and enables promising applications in braincomputer interaction while prior studies have explored language reconstruction from fmri data they are typically limited to singlemodality inputs such as images or audio in contrast human thought is inherently multimodal to bridge this gap we propose a unified and flexible framework for reconstructing coherent language from brain recordings elicited by diverse input modalitiesvisual auditory and textual our approach leverages visuallanguage models vlms using modalityspecific experts to jointly interpret information across modalities experiments demonstrate that our method achieves performance comparable to stateoftheart systems while remaining adaptable and extensible this work advances toward more ecologically valid and generalizable mind decoding
http://arxiv.org/abs/2505.10354v2,2025-05-15T14:45:45Z,"Yile Wang, Zhanyu Shen, Hui Huang",ldir lowdimensional dense and interpretable text embeddings with relative representations,semantic text representation is a fundamental task in the field of natural language processing existing text embedding eg simcse and llm2vec have demonstrated excellent performance but the values of each dimension are difficult to trace and interpret bagofwords as classic sparse interpretable embeddings suffers from poor performance recently benara et al 2024 propose interpretable text embeddings using large language models which forms 01 embeddings based on responses to a series of questions these interpretable text embeddings are typically highdimensional larger than 10000 in this work we propose lowdimensional lower than 500 dense and interpretable text embeddings with relative representations ldir the numerical values of its dimensions indicate semantic relatedness to different anchor texts through farthest point sampling offering both semantic representation as well as a certain level of traceability and interpretability we validate ldir on multiple semantic textual similarity retrieval and clustering tasks extensive experimental results show that ldir performs close to the blackbox baseline models and outperforms the interpretable embeddings baselines with much fewer dimensions code is available at httpsgithubcomszuteraldir
http://arxiv.org/abs/2505.10320v1,2025-05-15T14:05:15Z,"Chenxi Whitehouse, Tianlu Wang, Ping Yu, Xian Li, Jason Weston, Ilia Kulikov, Swarnadeep Saha",j1 incentivizing thinking in llmasajudge via reinforcement learning,the progress of ai is bottlenecked by the quality of evaluation and powerful llmasajudge models have proved to be a core solution improved judgment ability is enabled by stronger chainofthought reasoning motivating the need to find the best recipes for training such models to think in this work we introduce j1 a reinforcement learning approach to training such models our method converts both verifiable and nonverifiable prompts to judgment tasks with verifiable rewards that incentivize thinking and mitigate judgment bias in particular our approach outperforms all other existing 8b or 70b models when trained at those sizes including models distilled from deepseekr1 j1 also outperforms o1mini and even r1 on some benchmarks despite training a smaller model we provide analysis and ablations comparing pairwisej1 vs pointwisej1 models offline vs online training recipes reward strategies seed prompts and variations in thought length and content we find that our models make better judgments by learning to outline evaluation criteria comparing against selfgenerated reference answers and reevaluating the correctness of model responses
http://arxiv.org/abs/2505.10292v1,2025-05-15T13:42:14Z,"Daniel A. P. Oliveira, David Martins de Matos",storyreasoning dataset using chainofthought for scene understanding and grounded story generation,visual storytelling systems struggle to maintain character identity across frames and link actions to appropriate subjects frequently leading to referential hallucinations these issues can be addressed through grounding of characters objects and other entities on the visual elements we propose storyreasoning a dataset containing 4178 stories derived from 52016 movie images with both structured scene analyses and grounded stories each story maintains character and object consistency across frames while explicitly modeling multiframe relationships through structured tabular representations our approach features crossframe object reidentification using visual similarity and face recognition chainofthought reasoning for explicit narrative modeling and a grounding scheme that links textual elements to visual entities across multiple frames we establish baseline performance by finetuning qwen25vl 7b creating qwen storyteller which performs endtoend object detection reidentification and landmark detection while maintaining consistent object references throughout the story evaluation demonstrates a reduction from 406 to 356 123 hallucinations on average per story when compared to a nonfinetuned model
http://arxiv.org/abs/2505.10282v1,2025-05-15T13:30:39Z,"Dubai Li, Nan Jiang, Kangping Huang, Ruiqi Tu, Shuyu Ouyang, Huayu Yu, Lin Qiao, Chen Yu, Tianshu Zhou, Danyang Tong, Qian Wang, Mengtao Li, Xiaofeng Zeng, Yu Tian, Xinping Tian, Jingsong Li",from questions to clinical recommendations large language models driving evidencebased clinical decision making,clinical evidence derived from rigorous research and data analysis provides healthcare professionals with reliable scientific foundations for informed decisionmaking integrating clinical evidence into realtime practice is challenging due to the enormous workload complex professional processes and time constraints this highlights the need for tools that automate evidence synthesis to support more efficient and accurate decision making in clinical settings this study introduces quicker an evidencebased clinical decision support system powered by large language models llms designed to automate evidence synthesis and generate clinical recommendations modeled after standard clinical guideline development processes quicker implements a fully automated chain that covers all phases from questions to clinical recommendations and further enables customized decisionmaking through integrated tools and interactive user interfaces to evaluate quickers capabilities we developed the q2crbench3 benchmark dataset based on clinical guideline development records for three different diseases experimental results highlighted quickers strong performance with finegrained question decomposition tailored to user preferences retrieval sensitivities comparable to human experts and literature screening performance approaching comprehensive inclusion of relevant studies in addition quickerassisted evidence assessment effectively supported human reviewers while quickers recommendations were more comprehensive and logically coherent than those of clinicians in systemlevel testing collaboration between a single reviewer and quicker reduced the time required for recommendation development to 2040 minutes in general our findings affirm the potential of quicker to help physicians make quicker and more reliable evidencebased clinical decisions
http://arxiv.org/abs/2505.10261v1,2025-05-15T13:11:14Z,"Rui Yang, Huitao Li, Matthew Yu Heng Wong, Yuhe Ke, Xin Li, Kunyu Yu, Jingchi Liao, Jonathan Chong Kai Liew, Sabarinath Vinod Nair, Jasmine Chiat Ling Ong, Irene Li, Douglas Teodoro, Chuan Hong, Daniel Shu Wei Ting, Nan Liu",the evolving landscape of generative large language models and traditional natural language processing in medicine,natural language processing nlp has been traditionally applied to medicine and generative large language models llms have become prominent recently however the differences between them across different medical tasks remain underexplored we analyzed 19123 studies finding that generative llms demonstrate advantages in openended tasks while traditional nlp dominates in information extraction and analysis tasks as these technologies advance ethical use of them is essential to ensure their potential in medical applications
http://arxiv.org/abs/2505.10260v1,2025-05-15T13:10:47Z,"Poli Apollinaire Nemkova, Solomon Ubani, Mark V. Albert",comparing llm text annotation skills a study on human rights violations in social media data,in the era of increasingly sophisticated natural language processing nlp systems large language models llms have demonstrated remarkable potential for diverse applications including tasks requiring nuanced textual understanding and contextual reasoning this study investigates the capabilities of multiple stateoftheart llms gpt35 gpt4 llama3 mistral 7b and claude2 for zeroshot and fewshot annotation of a complex textual dataset comprising social media posts in russian and ukrainian specifically the focus is on the binary classification task of identifying references to human rights violations within the dataset to evaluate the effectiveness of these models their annotations are compared against a gold standard set of human doubleannotated labels across 1000 samples the analysis includes assessing annotation performance under different prompting conditions with prompts provided in both english and russian additionally the study explores the unique patterns of errors and disagreements exhibited by each model offering insights into their strengths limitations and crosslinguistic adaptability by juxtaposing llm outputs with human annotations this research contributes to understanding the reliability and applicability of llms for sensitive domainspecific tasks in multilingual contexts it also sheds light on how language models handle inherently subjective and contextdependent judgments a critical consideration for their deployment in realworld scenarios
http://arxiv.org/abs/2505.10599v1,2025-05-15T12:57:19Z,"Jiaxuan Liu, Zhenhua Ling",uddetts unifying discrete and dimensional emotions for controllable emotional texttospeech,recent neural codec language models have made great progress in the field of texttospeech tts but controllable emotional tts still faces many challenges traditional methods rely on predefined discrete emotion labels to control emotion categories and intensities which cant capture the complexity and continuity of human emotional perception and expression the lack of largescale emotional speech datasets with balanced emotion distributions and finegrained emotion annotations often causes overfitting in synthesis models and impedes effective emotion control to address these issues we propose uddetts a neural codec language model unifying discrete and dimensional emotions for controllable emotional tts this model introduces the interpretable arousaldominancevalence adv space for dimensional emotion description and supports emotion control driven by either discrete emotion labels or nonlinearly quantified adv values furthermore a semisupervised training strategy is designed to comprehensively utilize diverse speech datasets with different types of emotion annotations to train the uddetts experiments show that uddetts achieves linear emotion control along the three dimensions of adv space and exhibits superior endtoend emotional speech synthesis capabilities
http://arxiv.org/abs/2505.10231v1,2025-05-15T12:43:23Z,"Haozhe Luo, Ziyu Zhou, Zixin Shu, Aurélie Pahud de Mortanges, Robert Berke, Mauricio Reyes",on the interplay of humanai alignmentfairness and performance tradeoffs in medical imaging,deep neural networks excel in medical imaging but remain prone to biases leading to fairness gaps across demographic groups we provide the first systematic exploration of humanai alignment and fairness in this domain our results show that incorporating human insights consistently reduces fairness gaps and enhances outofdomain generalization though excessive alignment can introduce performance tradeoffs emphasizing the need for calibrated strategies these findings highlight humanai alignment as a promising approach for developing fair robust and generalizable medical ai systems striking a balance between expert guidance and automated efficiency our code is available at httpsgithubcomroypicaligner
http://arxiv.org/abs/2505.10222v1,2025-05-15T12:30:33Z,"Jintian Shao, Hongyi Huang, Jiayi Wu, Beiwen Zhang, ZhiYu Wu, You Shan, MingKai Zheng",complexformer disruptively advancing transformer inference ability via headspecific complex vector attention,transformer models rely on selfattention to capture token dependencies but face challenges in effectively integrating positional information while allowing multihead attention mha flexibility prior methods often model semantic and positional differences disparately or apply uniform positional adjustments across heads potentially limiting representational capacity this paper introduces complexformer featuring complex multihead attentioncmha cmha empowers each head to independently model semantic and positional differences unified within the complex plane representing interactions as rotations and scaling complexformer incorporates two key improvements 1 a perhead euler transformation converting realvalued querykey projections into polarform complex vectors for headspecific complex subspace operation and 2 a perhead adaptive differential rotation mechanism expiadaptasmni deltapmni allowing each head to learn distinct strategies for integrating semantic angle differences asmni with relative positional encodings deltapmni extensive experiments on language modeling text generation code generation and mathematical reasoning show complexformer achieves superior performance significantly lower generation perplexity and improved longcontext coherence compared to strong baselines like ropetransformers complexformer demonstrates strong parameter efficiency offering a more expressive adaptable attention mechanism
http://arxiv.org/abs/2505.10218v1,2025-05-15T12:22:10Z,"Zongsheng Wang, Kaili Sun, Bowen Wu, Qun Yu, Ying Li, Baoxun Wang",raidenr1 improving roleawareness of llms via grpo with verifiable reward,roleplaying conversational agents rpcas face persistent challenges in maintaining role consistency to address this we propose raidenr1 a novel reinforcement learning framework that integrates verifiable roleawareness reward vrar the method introduces both singular and multiterm mining strategies to generate quantifiable rewards by assessing rolespecific keys additionally we construct a highquality roleaware chainofthought dataset through multillm collaboration and implement experiments to enhance reasoning coherence experiments on the raiden benchmark demonstrate raidenr1s superiority our 14bgrpo model achieves 8804 and 8865 accuracy on scriptbased knowledge and conversation memory metrics respectively outperforming baseline models while maintaining robustness case analyses further reveal the models enhanced ability to resolve conflicting contextual cues and sustain firstperson narrative consistency this work bridges the nonquantifiability gap in rpca training and provides insights into roleaware reasoning patterns advancing the development of rpcas
http://arxiv.org/abs/2505.10202v1,2025-05-15T11:58:04Z,"Jintian Shao, Hongyi Huang, Jiayi Wu, YiMing Cheng, ZhiYu Wu, You Shan, MingKai Zheng",vqlogits compressing the output bottleneck of large language models via vector quantized logits,large language models llms have achieved remarkable success but face significant computational and memory challenges particularly due to their extensive output vocabularies the final linear projection layer mapping hidden states to vocabularysized logits often constitutes a substantial portion of the models parameters and computational cost during inference existing methods like adaptive softmax or hierarchical softmax introduce structural complexities in this paper we propose vqlogits a novel approach that leverages vector quantization vq to drastically reduce the parameter count and computational load of the llm output layer vqlogits replaces the large v dmodel output embedding matrix with a small shared codebook of k embedding vectors k v each token in the vocabulary is mapped to one of these k codebook vectors the llm predicts logits over this compact codebook which are then efficiently scattered to the full vocabulary space using the learned or preassigned mapping we demonstrate through extensive experiments on standard language modeling benchmarks eg wikitext103 c4 that vqlogits can achieve up to 99 parameter reduction in the output layer and 6x speedup in logit computation with only a marginal 4 increase in perplexity compared to full softmax baselines we further provide detailed ablation studies on codebook size initialization and learning strategies showcasing the robustness and effectiveness of our approach
http://arxiv.org/abs/2505.10185v1,2025-05-15T11:31:02Z,"Seongyun Lee, Seungone Kim, Minju Seo, Yongrae Jo, Dongyoung Go, Hyeonbin Hwang, Jinho Park, Xiang Yue, Sean Welleck, Graham Neubig, Moontae Lee, Minjoon Seo",the cot encyclopedia analyzing predicting and controlling how a reasoning model will think,long chainofthought cot is an essential ingredient in effective usage of modern large language models but our understanding of the reasoning strategies underlying these capabilities remains limited while some prior works have attempted to categorize cots using predefined strategy types such approaches are constrained by human intuition and fail to capture the full diversity of model behaviors in this work we introduce the cot encyclopedia a bottomup framework for analyzing and steering model reasoning our method automatically extracts diverse reasoning criteria from modelgenerated cots embeds them into a semantic space clusters them into representative categories and derives contrastive rubrics to interpret reasoning behavior human evaluations show that this framework produces more interpretable and comprehensive analyses than existing methods moreover we demonstrate that this understanding enables performance gains we can predict which strategy a model is likely to use and guide it toward more effective alternatives finally we provide practical insights such as that training data format eg freeform vs multiplechoice has a far greater impact on reasoning behavior than data domain underscoring the importance of formataware model design
http://arxiv.org/abs/2505.10182v1,2025-05-15T11:29:01Z,"Yoichi Ishibashi, Taro Yano, Masafumi Oyamada",mining hidden thoughts from texts evaluating continual pretraining with synthetic data for llm reasoning,large language models llms have demonstrated significant improvements in reasoning capabilities through supervised finetuning and reinforcement learning however when training reasoning models these approaches are primarily applicable to specific domains such as mathematics and programming which imposes fundamental constraints on the breadth and scalability of training data in contrast continual pretraining cpt offers the advantage of not requiring taskspecific signals nevertheless how to effectively synthesize training data for reasoning and how such data affect a wide range of domains remain largely unexplored this study provides a detailed evaluation of reasoning cpt a form of cpt that uses synthetic data to reconstruct the hidden thought processes underlying texts based on the premise that texts are the result of the authors thinking process specifically we apply reasoning cpt to gemma29b using synthetic data with hidden thoughts derived from stem and law corpora and compare it to standard cpt on the mmlu benchmark our analysis reveals that reasoning cpt consistently improves performance across all evaluated domains notably reasoning skills acquired in one domain transfer effectively to others the performance gap with conventional methods widens as problem difficulty increases with gains of up to 8 points on the most challenging problems furthermore models trained with hidden thoughts learn to adjust the depth of their reasoning according to problem difficulty
http://arxiv.org/abs/2505.10597v2,2025-05-15T10:58:20Z,"Jiazheng Zhang, Wenqing Jing, Zizhuo Zhang, Zhiheng Xi, Shihan Dou, Rongxiang Weng, Jiahuan Li, Jingang Wang, Mingxu Chai, Shibo Hong, Tao Gui, Qi Zhang",two minds better than one collaborative reward modeling for llm alignment,reward models rms play a pivotal role in aligning large language models llms with human values however noisy preferences in human feedback can lead to reward misgeneralization a phenomenon where reward models learn spurious correlations or overfit to noisy preferences which poses important challenges to the generalization of rms this paper systematically analyzes the characteristics of preference pairs and aims to identify how noisy preferences differ from humanaligned preferences in reward modeling our analysis reveals that noisy preferences are difficult for rms to fit as they cause sharp training fluctuations and irregular gradient updates these distinctive dynamics suggest the feasibility of identifying and excluding such noisy preferences empirical studies demonstrate that policy llm optimized with a reward model trained on the full preference dataset which includes substantial noise performs worse than the one trained on a subset of exclusively high quality preferences to address this challenge we propose an online collaborative reward modeling crm framework to achieve robust preference learning through peer review and curriculum learning in particular crm maintains two rms that collaboratively filter potential noisy preferences by peerreviewing each others data selections curriculum learning synchronizes the capabilities of two models mitigating excessive disparities to promote the utility of peer review extensive experiments demonstrate that crm significantly enhances rm generalization with up to 994 points improvement on rewardbench under an extreme 40 noise moreover crm can seamlessly extend to implicitreward alignment methods offering a robust and versatile alignment strategy
http://arxiv.org/abs/2505.10143v1,2025-05-15T10:17:35Z,"Longchao Da, Parth Mitesh Shah, Kuan-Ru Liou, Jiaxing Zhang, Hua Wei",gechat a graph enhanced rag framework for evidential response generation of llms,large language models are now key assistants in human decisionmaking processes however a common note always seems to follow llms can make mistakes be careful with important info this points to the reality that not all outputs from llms are dependable and users must evaluate them manually the challenge deepens as hallucinated responses often presented with seemingly plausible explanations create complications and raise trust issues among users to tackle such issue this paper proposes gechat a knowledge graph enhanced retrievalaugmented generation framework to provide evidencebased response generation specifically when the user uploads a material document a knowledge graph will be created which helps construct a retrievalaugmented agent enhancing the agents responses with additional knowledge beyond its training corpus then we leverage chainofthought cot logic generation nhop subgraph searching and entailmentbased sentence generation to realize accurate evidence retrieval we demonstrate that our method improves the existing models performance in terms of identifying the exact evidence in a freeform context providing a reliable way to examine the resources of llms conclusion and help with the judgment of the trustworthiness
http://arxiv.org/abs/2505.10118v1,2025-05-15T09:43:28Z,"Yangfu Li, Hongjian Zhan, Tianyi Chen, Qi Liu, Yue Lu",why 1 1 1 in visual token pruning beyond naive integration via multiobjective balanced covering,existing visual token pruning methods target prompt alignment and visual preservation with static strategies overlooking the varying relative importance of these objectives across tasks which leads to inconsistent performance to address this we derive the first closedform error bound for visual token pruning based on the hausdorff distance uniformly characterizing the contributions of both objectives moreover leveraging covering theory we reveal an intrinsic tradeoff between these objectives and quantify their optimal attainment levels under a fixed budget to practically handle this tradeoff we propose multiobjective balanced covering mob which reformulates visual token pruning as a biobjective covering problem in this framework the attainment tradeoff reduces to budget allocation via greedy radius trading mob offers a provable performance bound and linear scalability with respect to the number of input visual tokens enabling adaptation to challenging pruning scenarios extensive experiments show that mob preserves 964 of performance for llava157b using only 111 of the original visual tokens and accelerates llavanext7b by 1315 with negligible performance loss additionally evaluations on qwen2vl and videollava confirm that mob integrates seamlessly into advanced mllms and diverse visionlanguage tasks
http://arxiv.org/abs/2505.10117v2,2025-05-15T09:42:11Z,"JieHao Wu, Ziwei Wang, Junjie Sheng, Wenhao Li, Xiangfeng Wang, Jun Luo",learning virtual machine scheduling in cloud computing through language agents,in cloud services virtual machine vm scheduling is a typical online dynamic multidimensional bin packing odmbp problem characterized by largescale complexity and fluctuating demands traditional optimization methods struggle to adapt to realtime changes domainexpertdesigned heuristic approaches suffer from rigid strategies and existing learningbased methods often lack generalizability and interpretability to address these limitations this paper proposes a hierarchical language agent framework named mico which provides a large language model llmdriven heuristic design paradigm for solving odmbp specifically odmbp is formulated as a semimarkov decision process with options smdpoption enabling dynamic scheduling through a twostage architecture ie option miner and option composer option miner utilizes llms to discover diverse and useful noncontextaware strategies by interacting with constructed environments option composer employs llms to discover a composing strategy that integrates the noncontextaware strategies with the contextual ones extensive experiments on realworld enterprise datasets demonstrate that mico achieves a 969 competitive ratio in largescale scenarios involving more than 10000 virtual machines it maintains high performance even under nonstationary request flows and diverse configurations thus validating its effectiveness in complex and largescale cloud environments
http://arxiv.org/abs/2505.10113v1,2025-05-15T09:35:26Z,"Xinlan Yan, Di Wu, Yibin Lei, Christof Monz, Iacer Calixto",what does neuro mean to cardio investigating the role of clinical specialty data in medical llms,in this paper we introduce smedqa an english medical questionanswering qa dataset for benchmarking large language models in finegrained clinical specialties we use smedqa to check the applicability of a popular hypothesis related to knowledge injection in the knowledgeintense scenario of medical qa and show that 1 training on data from a speciality does not necessarily lead to best performance on that specialty and 2 regardless of the specialty finetuned on token probabilities of clinically relevant terms for all specialties increase consistently thus we believe improvement gains come mostly from domain shifting eg general to medical rather than knowledge injection and suggest rethinking the role of finetuning data in the medical domain we release smedqa and all code needed to reproduce all our experiments to the research community
http://arxiv.org/abs/2505.11550v1,2025-05-15T09:28:06Z,"Harika Abburi, Sanmitra Bhattacharya, Edward Bowen, Nirmala Pudota",aigenerated text detection a multifaceted approach to binary and multiclass classification,large language models llms have demonstrated remarkable capabilities in generating text that closely resembles human writing across a wide range of styles and genres however such capabilities are prone to potential misuse such as fake news generation spam email creation and misuse in academic assignments as a result accurate detection of aigenerated text and identification of the model that generated it are crucial for maintaining the responsible use of llms in this work we addressed two subtasks put forward by the defactify workshop under aigenerated text detection shared task at the association for the advancement of artificial intelligence aaai 2025 task a involved distinguishing between humanauthored or aigenerated text while task b focused on attributing text to its originating language model for each task we proposed two neural architectures an optimized model and a simpler variant for task a the optimized neural architecture achieved fifth place with score of 0994 and for task b the simpler neural architecture also ranked fifth place with score of 0627
http://arxiv.org/abs/2505.10093v1,2025-05-15T08:51:53Z,Hsuan-Lei Shao,from text to network constructing a knowledge graph of taiwanbased china studies using generative ai,taiwanese china studies cs has developed into a rich interdisciplinary research field shaped by the unique geopolitical position and long standing academic engagement with mainland china this study responds to the growing need to systematically revisit and reorganize decades of taiwan based cs scholarship by proposing an ai assisted approach that transforms unstructured academic texts into structured interactive knowledge representations we apply generative ai gai techniques and large language models llms to extract and standardize entity relation triples from 1367 peer reviewed cs articles published between 1996 and 2019 these triples are then visualized through a lightweight d3js based system forming the foundation of a domain specific knowledge graph and vector database for the field this infrastructure allows users to explore conceptual nodes and semantic relationships across the corpus revealing previously uncharted intellectual trajectories thematic clusters and research gaps by decomposing textual content into graph structured knowledge units our system enables a paradigm shift from linear text consumption to network based knowledge navigation in doing so it enhances scholarly access to cs literature while offering a scalable data driven alternative to traditional ontology construction this work not only demonstrates how generative ai can augment area studies and digital humanities but also highlights its potential to support a reimagined scholarly infrastructure for regional knowledge systems
http://arxiv.org/abs/2505.10089v1,2025-05-15T08:47:55Z,"Wei Liu, Sony Trenous, Leonardo F. R. Ribeiro, Bill Byrne, Felix Hieber",xrag crosslingual retrievalaugmented generation,we propose xrag a novel benchmark designed to evaluate the generation abilities of llms in crosslingual retrievalaugmented generation rag settings where the user language does not match the retrieval results xrag is constructed from recent news articles to ensure that its questions require external knowledge to be answered it covers the realworld scenarios of monolingual and multilingual retrieval and provides relevancy annotations for each retrieved document our novel dataset construction pipeline results in questions that require complex reasoning as evidenced by the significant gap between human and llm performance consequently xrag serves as a valuable benchmark for studying llm reasoning abilities even before considering the additional crosslingual complexity experimental results on five llms uncover two previously unreported challenges in crosslingual rag 1 in the monolingual retrieval setting all evaluated models struggle with response language correctness 2 in the multilingual retrieval setting the main challenge lies in reasoning over retrieved information across languages rather than generation of nonenglish text
http://arxiv.org/abs/2505.10081v1,2025-05-15T08:35:14Z,"Wisdom Aduah, Francois Meyer",designing and contextualising probes for african languages,pretrained language models plms for african languages are continually improving but the reasons behind these advances remain unclear this paper presents the first systematic investigation into probing plms for linguistic knowledge about african languages we train layerwise probes for six typologically diverse african languages to analyse how linguistic features are distributed we also design control tasks a way to interpret probe performance for the masakhapos dataset we find plms adapted for african languages to encode more linguistic information about target languages than massively multilingual plms our results reaffirm previous findings that tokenlevel syntactic information concentrates in middletolast layers while sentencelevel semantic information is distributed across all layers through control tasks and probing baselines we confirm that performance reflects the internal knowledge of plms rather than probe memorisation our study applies established interpretability techniques to africanlanguage plms in doing so we highlight the internal mechanisms underlying the success of strategies like active learning and multilingual adaptation
http://arxiv.org/abs/2505.10066v1,2025-05-15T08:07:04Z,"Michael Fire, Yitzhak Elbazis, Adi Wasenstein, Lior Rokach",dark llms the growing threat of unaligned ai models,large language models llms rapidly reshape modern life advancing fields from healthcare to education and beyond however alongside their remarkable capabilities lies a significant threat the susceptibility of these models to jailbreaking the fundamental vulnerability of llms to jailbreak attacks stems from the very data they learn from as long as this training data includes unfiltered problematic or dark content the models can inherently learn undesirable patterns or weaknesses that allow users to circumvent their intended safety controls our research identifies the growing threat posed by dark llms models deliberately designed without ethical guardrails or modified through jailbreak techniques in our research we uncovered a universal jailbreak attack that effectively compromises multiple stateoftheart models enabling them to answer almost any question and produce harmful outputs upon request the main idea of our attack was published online over seven months ago however many of the tested llms were still vulnerable to this attack despite our responsible disclosure efforts responses from major llm providers were often inadequate highlighting a concerning gap in industry practices regarding ai safety as model training becomes more accessible and cheaper and as opensource llms proliferate the risk of widespread misuse escalates without decisive intervention llms may continue democratizing access to dangerous knowledge posing greater risks than anticipated
http://arxiv.org/abs/2505.10063v1,2025-05-15T08:05:12Z,"Han Peng, Jinhao Jiang, Zican Dong, Wayne Xin Zhao, Lei Fang",cafe retrieval headbased coarsetofine information seeking to enhance multidocument qa capability,advancements in large language models llms have extended their input context length yet they still struggle with retrieval and reasoning in longcontext inputs existing methods propose to utilize the prompt strategy and retrieval head to alleviate this limitation however they still face challenges in balancing retrieval precision and recall impacting their efficacy in answering questions to address this we introduce a twostage coarsetofine method to enhance multidocument questionanswering capacities by gradually eliminating the negative impacts of background and distracting documents cafe makes the responses more reliant on the evidence documents initially a coarsegrained filtering method leverages retrieval heads to identify and rank relevant documents then a finegrained steering method guides attention to the most relevant content experiments across benchmarks show cafe outperforms baselines achieving up to 221 and 137 subem improvement over sft and rag methods on the mistral model respectively
http://arxiv.org/abs/2505.10013v1,2025-05-15T06:53:37Z,"Lake Yin, Fan Huang",dif a framework for benchmarking and verifying implicit bias in llms,as large language models llms have risen in prominence over the past few years there has been concern over the potential biases in llms inherited from the training data previous studies have examined how llms exhibit implicit bias such as when response generation changes when different social contexts are introduced we argue that this implicit bias is not only an ethical but also a technical issue as it reveals an inability of llms to accommodate extraneous information however unlike other measures of llm intelligence there are no standard methods to benchmark this specific subset of llm bias to bridge this gap we developed a method for calculating an easily interpretable benchmark dif demographic implicit fairness by evaluating preexisting llm logic and math problem datasets with sociodemographic personas we demonstrate that this method can statistically validate the presence of implicit bias in llm behavior and find an inverse trend between question answering accuracy and implicit bias supporting our argument
http://arxiv.org/abs/2505.09949v1,2025-05-15T04:07:55Z,"Ahmed S. Abdelrahman, Mohamed Abdel-Aty, Samgyu Yang, Abdulrahman Faden",advanced crash causation analysis for freeway safety a large language model approach to identifying key contributing factors,understanding the factors contributing to traffic crashes and developing strategies to mitigate their severity is essential traditional statistical methods and machine learning models often struggle to capture the complex interactions between various factors and the unique characteristics of each crash this research leverages large language model llm to analyze freeway crash data and provide crash causation analysis accordingly by compiling 226 traffic safety studies related to freeway crashes a training dataset encompassing environmental driver traffic and geometric design factors was created the llama3 8b model was finetuned using qlora to enhance its understanding of freeway crashes and their contributing factors as covered in these studies the finetuned llama3 8b model was then used to identify crash causation without prelabeled data through zeroshot classification providing comprehensive explanations to ensure that the identified causes were reasonable and aligned with existing research results demonstrate that llms effectively identify primary crash causes such as alcoholimpaired driving speeding aggressive driving and driver inattention incorporating event data such as road maintenance offers more profound insights the models practical applicability and potential to improve traffic safety measures were validated by a high level of agreement among researchers in the field of traffic safety as reflected in questionnaire results with 8889 this research highlights the complex nature of traffic crashes and how llms can be used for comprehensive analysis of crash causation and other contributing factors moreover it provides valuable insights and potential countermeasures to aid planners and policymakers in developing more effective and efficient traffic safety practices
http://arxiv.org/abs/2505.09945v1,2025-05-15T04:01:58Z,"Deeksha Prahlad, Chanhee Lee, Dongha Kim, Hokeun Kim",personalizing large language models using retrieval augmented generation and knowledge graph,the advent of large language models llms has allowed numerous applications including the generation of queried responses to be leveraged in chatbots and other conversational assistants being trained on a plethora of data llms often undergo high levels of overfitting resulting in the generation of extra and incorrect data thus causing hallucinations in output generation one of the root causes of such problems is the lack of timely factual and personalized information fed to the llm in this paper we propose an approach to address these problems by introducing retrieval augmented generation rag using knowledge graphs kgs to assist the llm in personalized response generation tailored to the users kgs have the advantage of storing continuously updated factual information in a structured way while our kgs can be used for a variety of frequently updated personal data such as calendar contact and location data we focus on calendar data in this paper our experimental results show that our approach works significantly better in understanding personal information and generating accurate responses compared to the baseline llms using personal data as text inputs with a moderate reduction in response time
http://arxiv.org/abs/2505.09930v1,2025-05-15T03:31:37Z,"Zixiao Zhu, Hanzhang Zhou, Zijian Feng, Tianjiao Li, Chua Jia Jim Deryl, Mak Lee Onn, Gee Wah Ng, Kezhi Mao",rethinking prompt optimizers from prompt merits to optimization,prompt optimization po offers a practical alternative to finetuning large language models llms enabling performance improvements without altering model weights existing methods typically rely on advanced largescale llms like gpt4 to generate optimized prompts however due to limited downward compatibility verbose instructionheavy prompts from advanced llms can overwhelm lightweight inference models and degrade response quality in this work we rethink prompt optimization through the lens of interpretable design we first identify a set of modelagnostic prompt quality merits and empirically validate their effectiveness in enhancing prompt and response quality we then introduce mepo a meritguided lightweight and locally deployable prompt optimizer trained on our preference dataset built from meritaligned prompts generated by a lightweight llm unlike prior work mepo avoids online optimization reliance reduces cost and privacy concerns and by learning clear interpretable merits generalizes effectively to both largescale and lightweight inference models experiments demonstrate that mepo achieves better results across diverse tasks and model types offering a scalable and robust solution for realworld deployment our model and dataset are available at httpsgithubcommidiyazhumepo
http://arxiv.org/abs/2505.09924v2,2025-05-15T03:12:36Z,"Yidan Wang, Yubing Ren, Yanan Cao, Binxing Fang",from tradeoff to synergy a versatile symbiotic watermarking framework for large language models,the rise of large language models llms has heightened concerns about the misuse of aigenerated text making watermarking a promising solution mainstream watermarking schemes for llms fall into two categories logitsbased and samplingbased however current schemes entail tradeoffs among robustness text quality and security to mitigate this we integrate logitsbased and samplingbased schemes harnessing their respective strengths to achieve synergy in this paper we propose a versatile symbiotic watermarking framework with three strategies serial parallel and hybrid the hybrid framework adaptively embeds watermarks using token entropy and semantic entropy optimizing the balance between detectability robustness text quality and security furthermore we validate our approach through comprehensive experiments on various datasets and models experimental results indicate that our method outperforms existing baselines and achieves stateoftheart sota performance we believe this framework provides novel insights into diverse watermarking paradigms our code is available at httpsgithubcomredwydsymmark
http://arxiv.org/abs/2505.09921v2,2025-05-15T03:11:57Z,"Yidan Wang, Yanan Cao, Yubing Ren, Fang Fang, Zheng Lin, Binxing Fang",pig privacy jailbreak attack on llms via gradientbased iterative incontext optimization,large language models llms excel in various domains but pose inherent privacy risks existing methods to evaluate privacy leakage in llms often use memorized prefixes or simple instructions to extract data both of which wellalignment models can easily block meanwhile jailbreak attacks bypass llm safety mechanisms to generate harmful content but their role in privacy scenarios remains underexplored in this paper we examine the effectiveness of jailbreak attacks in extracting sensitive information bridging privacy leakage and jailbreak attacks in llms moreover we propose pig a novel framework targeting personally identifiable information pii and addressing the limitations of current jailbreak methods specifically pig identifies pii entities and their types in privacy queries uses incontext learning to build a privacy context and iteratively updates it with three gradientbased strategies to elicit target pii we evaluate pig and existing jailbreak methods using two privacyrelated datasets experiments on four whitebox and two blackbox llms show that pig outperforms baseline methods and achieves stateoftheart sota results the results underscore significant privacy risks in llms emphasizing the need for stronger safeguards our code is availble at httpsgithubcomredwydprivacyjailbreak
http://arxiv.org/abs/2505.09902v1,2025-05-15T02:09:19Z,"Martin Capdevila, Esteban Villa Turek, Ellen Karina Chumbe Fernandez, Luis Felipe Polo Galvez, Luis Cadavid, Andrea Marroquin, Rebeca Vargas Quesada, Johanna Crew, Nicole Vallejo Galarraga, Christopher Rodriguez, Diego Gutierrez, Radhi Datla",crossing borders without crossing boundaries how sociolinguistic awareness can optimize user engagement with localized spanish ai models across hispanophone countries,large language models are by definition based on language in an effort to underscore the critical need for regional localized models this paper examines primary differences between variants of written spanish across latin america and spain with an indepth sociocultural and linguistic contextualization therein we argue that these differences effectively constitute significant gaps in the quotidian use of spanish among dialectal groups by creating sociolinguistic dissonances to the extent that localesensitive ai models would play a pivotal role in bridging these divides in doing so this approach informs better and more efficient localization strategies that also serve to more adequately meet inclusivity goals while securing sustainable active daily user growth in a major lowrisk investment geographic area therefore implementing at least the proposed five sub variants of spanish addresses two lines of action to foment user trust and reliance on ai language models while also demonstrating a level of cultural historical and sociolinguistic awareness that reflects positively on any internationalization strategy
http://arxiv.org/abs/2505.09901v1,2025-05-15T02:09:18Z,"Ziyuan Zhang, Darcy Wang, Ningyuan Chen, Rodrigo Mansur, Vahid Sarhangian",comparing explorationexploitation strategies of llms and humans insights from standard multiarmed bandit tasks,large language models llms are increasingly used to simulate or automate human behavior in complex sequential decisionmaking tasks a natural question is then whether llms exhibit similar decisionmaking behavior to humans and can achieve comparable or superior performance in this work we focus on the explorationexploitation ee tradeoff a fundamental aspect of dynamic decisionmaking under uncertainty we employ canonical multiarmed bandit mab tasks introduced in the cognitive science and psychiatry literature to conduct a comparative study of the ee strategies of llms humans and mab algorithms we use interpretable choice models to capture the ee strategies of the agents and investigate how explicit reasoning through both prompting strategies and reasoningenhanced models shapes llm decisionmaking we find that reasoning shifts llms toward more humanlike behavior characterized by a mix of random and directed exploration in simple stationary tasks reasoningenabled llms exhibit similar levels of random and directed exploration compared to humans however in more complex nonstationary environments llms struggle to match human adaptability particularly in effective directed exploration despite achieving similar regret in certain scenarios our findings highlight both the promise and limits of llms as simulators of human behavior and tools for automated decisionmaking and point to potential areas of improvements
http://arxiv.org/abs/2505.09855v1,2025-05-14T23:31:17Z,"Alexander Y. Ku, Thomas L. Griffiths, Stephanie C. Y. Chan",predictability shapes adaptation an evolutionary perspective on modes of learning in transformers,transformer models learn in two distinct modes inweights learning iwl encoding knowledge into model weights and incontext learning icl adapting flexibly to context without weight modification to better understand the interplay between these learning modes we draw inspiration from evolutionary biologys analogous adaptive strategies genetic encoding akin to iwl adapting over generations and fixed within an individuals lifetime and phenotypic plasticity akin to icl enabling flexible behavioral responses to environmental cues in evolutionary biology environmental predictability dictates the balance between these strategies stability favors genetic encoding while reliable predictive cues promote phenotypic plasticity we experimentally operationalize these dimensions of predictability and systematically investigate their influence on the icliwl balance in transformers using regression and classification tasks we show that high environmental stability decisively favors iwl as predicted with a sharp transition at maximal stability conversely high cue reliability enhances icl efficacy particularly when stability is low furthermore learning dynamics reveal taskcontingent temporal evolution while a canonical icltoiwl shift occurs in some settings eg classification with many classes we demonstrate that scenarios with easier iwl eg fewer classes or slower icl acquisition eg regression can exhibit an initial iwl phase later yielding to icl dominance these findings support a relativecost hypothesis for explaining these learning mode transitions establishing predictability as a critical factor governing adaptive strategies in transformers and offering novel insights for understanding icl and guiding training methodologies
http://arxiv.org/abs/2505.09852v1,2025-05-14T23:24:22Z,"Apollinaire Poli Nemkova, Sarath Chandra Lingareddy, Sagnik Ray Choudhury, Mark V. Albert",do large language models know conflict investigating parametric vs nonparametric knowledge of llms for conflict forecasting,large language models llms have shown impressive performance across natural language tasks but their ability to forecast violent conflict remains underexplored we investigate whether llms possess meaningful parametric knowledgeencoded in their pretrained weightsto predict conflict escalation and fatalities without external data this is critical for early warning systems humanitarian planning and policymaking we compare this parametric knowledge with nonparametric capabilities where llms access structured and unstructured context from conflict datasets eg acled gdelt and recent news reports via retrievalaugmented generation rag incorporating external information could enhance model performance by providing uptodate context otherwise missing from pretrained weights our twopart evaluation framework spans 20202024 across conflictprone regions in the horn of africa and the middle east in the parametric setting llms predict conflict trends and fatalities relying only on pretrained knowledge in the nonparametric setting models receive summaries of recent conflict events indicators and geopolitical developments we compare predicted conflict trend labels eg escalate stable conflict deescalate peace and fatalities against historical data our findings highlight the strengths and limitations of llms for conflict forecasting and the benefits of augmenting them with structured external knowledge
http://arxiv.org/abs/2505.09825v1,2025-05-14T22:04:46Z,"Peiqi Sui, Juan Diego Rodriguez, Philippe Laban, Dean Murphy, Joseph P. Dexter, Richard Jean So, Samuel Baker, Pramit Chaudhuri",kristeva close reading as a novel task for benchmarking interpretive reasoning,each year tens of millions of essays are written and graded in collegelevel english courses students are asked to analyze literary and cultural texts through a process known as close reading in which they gather textual details to formulate evidencebased arguments despite being viewed as a basis for critical thinking and widely adopted as a required element of university coursework close reading has never been evaluated on large language models llms and multidiscipline benchmarks like mmlu do not include literature as a subject to fill this gap we present kristeva the first close reading benchmark for evaluating interpretive reasoning consisting of 1331 multiplechoice questions adapted from classroom data with kristeva we propose three progressively more difficult sets of tasks to approximate different elements of the close reading process which we use to test how well llms may seem to understand and reason about literary works 1 extracting stylistic features 2 retrieving relevant contextual information from parametric knowledge and 3 multihop reasoning between style and external contexts our baseline results find that while stateoftheart llms possess some collegelevel close reading competency accuracy 497 697 their performances still trail those of experienced human evaluators on 10 out of our 11 tasks
http://arxiv.org/abs/2505.09820v1,2025-05-14T21:50:46Z,"Sajib Biswas, Mao Nishino, Samuel Jacob Chacko, Xiuwen Liu",adversarial attack on large language models using exponentiated gradient descent,as large language models llms are widely used understanding them systematically is key to improving their safety and realizing their full potential although many models are aligned using techniques such as reinforcement learning from human feedback rlhf they are still vulnerable to jailbreaking attacks some of the existing adversarial attack methods search for discrete tokens that may jailbreak a target model while others try to optimize the continuous space represented by the tokens of the models vocabulary while techniques based on the discrete space may prove to be inefficient optimization of continuous token embeddings requires projections to produce discrete tokens which might render them ineffective to fully utilize the constraints and the structures of the space we develop an intrinsic optimization technique using exponentiated gradient descent with the bregman projection method to ensure that the optimized onehot encoding always stays within the probability simplex we prove the convergence of the technique and implement an efficient algorithm that is effective in jailbreaking several widely used llms we demonstrate the efficacy of the proposed technique using five opensource llms on four openly available datasets the results show that the technique achieves a higher success rate with great efficiency compared to three other stateoftheart jailbreaking techniques the source code for our implementation is available at httpsgithubcomsbamitexponentiatedgradientdescentllmattack
http://arxiv.org/abs/2505.09807v1,2025-05-14T21:21:08Z,"Timour Ichmoukhamedov, David Martens",exploring the generalization of llm truth directions on conversational formats,several recent works argue that llms have a universal truth direction where true and false statements are linearly separable in the activation space of the model it has been demonstrated that linear probes trained on a single hidden state of the model already generalize across a range of topics and might even be used for lie detection in llm conversations in this work we explore how this truth direction generalizes between various conversational formats we find good generalization between short conversations that end on a lie but poor generalization to longer formats where the lie appears earlier in the input prompt we propose a solution that significantly improves this type of generalization by adding a fixed key phrase at the end of each conversation our results highlight the challenges towards reliable llm lie detectors that generalize to new settings
http://arxiv.org/abs/2505.09794v1,2025-05-14T20:44:29Z,"J. Moreno-Casanova, J. M. Auñón, A. Mártinez-Pérez, M. E. Pérez-Martínez, M. E. Gas-López",automated detection of clinical entities in lung and breast cancer reports using nlp techniques,research projects including those focused on cancer rely on the manual extraction of information from clinical reports this process is timeconsuming and prone to errors limiting the efficiency of datadriven approaches in healthcare to address these challenges natural language processing nlp offers an alternative for automating the extraction of relevant data from electronic health records ehrs in this study we focus on lung and breast cancer due to their high incidence and the significant impact they have on public health early detection and effective data management in both types of cancer are crucial for improving patient outcomes to enhance the accuracy and efficiency of data extraction we utilized gmvs nlp tool uquery which excels at identifying relevant entities in clinical texts and converting them into standardized formats such as snomed and omop uquery not only detects and classifies entities but also associates them with contextual information including negated entities temporal aspects and patientrelated details in this work we explore the use of nlp techniques specifically named entity recognition ner to automatically identify and extract key clinical information from ehrs related to these two cancers a dataset from health research institute hospital la fe iis la fe comprising 200 annotated breast cancer and 400 lung cancer reports was used with eight clinical entities manually labeled using the doccano platform to perform ner we finetuned the bscbioehren3 model a robertabased biomedical linguistic model pretrained in spanish finetuning was performed using the transformers architecture enabling accurate recognition of clinical entities in these cancer types our results demonstrate strong overall performance particularly in identifying entities like met and pat although challenges remain with less frequent entities like evol
http://arxiv.org/abs/2505.09792v1,2025-05-14T20:38:44Z,Michael Kamfonas,interim report on humanguided adaptive hyperparameter optimization with multifidelity sprints,this case study applies a phased hyperparameter optimization process to compare multitask natural language model variants that utilize multiphase learning rate scheduling and optimizer parameter grouping we employ short bayesian optimization sessions that leverage multifidelity hyperparameter space pruning progressive halving and a degree of human guidance we utilize the optuna tpe sampler and hyperband pruner as well as the scikitlearn gaussian process minimization initially we use efficient lowfidelity sprints to prune the hyperparameter space subsequent sprints progressively increase their model fidelity and employ hyperband pruning for efficiency a second aspect of our approach is using a metalearner to tune threshold values to resolve classification probabilities during inference we demonstrate our method on a collection of variants of the 2021 joint entity and relation extraction model proposed by eberts and ulges
http://arxiv.org/abs/2505.09777v1,2025-05-14T20:15:52Z,"Alejo Lopez-Avila, Jinhua Du",a survey on large language models in multimodal recommender systems,multimodal recommender systems mrs integrate heterogeneous user and item data such as text images and structured information to enhance recommendation performance the emergence of large language models llms introduces new opportunities for mrs by enabling semantic reasoning incontext learning and dynamic input handling compared to earlier pretrained language models plms llms offer greater flexibility and generalisation capabilities but also introduce challenges related to scalability and model accessibility this survey presents a comprehensive review of recent work at the intersection of llms and mrs focusing on prompting strategies finetuning methods and data adaptation techniques we propose a novel taxonomy to characterise integration patterns identify transferable techniques from related recommendation domains provide an overview of evaluation metrics and datasets and point to possible future directions we aim to clarify the emerging role of llms in multimodal recommendation and support future research in this rapidly evolving field
http://arxiv.org/abs/2505.11545v1,2025-05-14T19:39:46Z,"Xingyu Ji, Parker Glenn, Aditya G. Parameswaran, Madelon Hulsebos",target benchmarking table retrieval for generative tasks,the data landscape is rich with structured data often of high value to organizations driving important applications in data analysis and machine learning recent progress in representation learning and generative models for such data has led to the development of natural language interfaces to structured data including those leveraging texttosql contextualizing interactions either through conversational interfaces or agentic components in structured data through retrievalaugmented generation can provide substantial benefits in the form of freshness accuracy and comprehensiveness of answers the key question is how do we retrieve the right tables for the analytical query or task at hand to this end we introduce target a benchmark for evaluating table retrieval for generative tasks with target we analyze the retrieval performance of different retrievers in isolation as well as their impact on downstream tasks we find that dense embeddingbased retrievers far outperform a bm25 baseline which is less effective than it is for retrieval over unstructured text we also surface the sensitivity of retrievers across various metadata eg missing table titles and demonstrate a stark variation of retrieval performance across datasets and tasks target is available at httpstargetbenchmarkgithubio
http://arxiv.org/abs/2505.09738v1,2025-05-14T19:00:27Z,"Shaurya Sharthak, Vinayak Pahalwan, Adithya Kamath, Adarsh Shirawalmath",achieving tokenizer flexibility in language models through heuristic adaptation and supertoken learning,pretrained language models llms are often constrained by their fixed tokenization schemes leading to inefficiencies and performance limitations particularly for multilingual or specialized applications this tokenizer lockin presents significant challenges standard methods to overcome this often require prohibitive computational resources although tokenizer replacement with heuristic initialization aims to reduce this burden existing methods often require exhaustive residual finetuning and still may not fully preserve semantic nuances or adequately address the underlying compression inefficiencies our framework introduces two innovations first tokenadapt a modelagnostic tokenizer transplantation method and second novel pretokenization learning for multiword supertokens to enhance compression and reduce fragmentation tokenadapt initializes new unique token embeddings via a hybrid heuristic that combines two methods a local estimate based on subword decomposition using the old tokenizer and a global estimate utilizing the topk semantically similar tokens from the original vocabulary this methodology aims to preserve semantics while significantly minimizing retraining requirements empirical investigations validate both contributions the transplantation heuristic successfully initializes unique tokens markedly outperforming conventional baselines and sophisticated methods including transtokenizer and retok while our supertokens achieve notable compression gains our zeroshot perplexity results demonstrate that the tokenadapt hybrid initialization consistently yields lower perplexity ratios compared to both retok and transtokenizer baselines across different base models and newly trained target tokenizers tokenadapt typically reduced the overall perplexity ratio significantly compared to retok yielding at least a 2fold improvement in these aggregate scores
http://arxiv.org/abs/2505.09724v2,2025-05-14T18:32:18Z,"Gino Carmona-Díaz, William Jiménez-Leal, María Alejandra Grisales, Chandra Sripada, Santiago Amaya, Michael Inzlicht, Juan Pablo Bermúdez",an aipowered research assistant in the lab a practical guide for text analysis through iterative collaboration with llms,analyzing texts such as openended responses headlines or social media posts is a time and laborintensive process highly susceptible to bias llms are promising tools for text analysis using either a predefined topdown or a datadriven bottomup taxonomy without sacrificing quality here we present a stepbystep tutorial to efficiently develop test and apply taxonomies for analyzing unstructured data through an iterative and collaborative process between researchers and llms using personal goals provided by participants as an example we demonstrate how to write prompts to review datasets and generate a taxonomy of life domains evaluate and refine the taxonomy through prompt and direct modifications test the taxonomy and assess intercoder agreements and apply the taxonomy to categorize an entire dataset with high intercoder reliability we discuss the possibilities and limitations of using llms for text analysis
http://arxiv.org/abs/2505.09701v1,2025-05-14T18:02:37Z,"Xin Liu, Lechen Zhang, Sheza Munir, Yiyang Gu, Lu Wang",verifact enhancing longform factuality evaluation with refined fact extraction and reference facts,large language models llms excel at generating longform responses but evaluating their factuality remains challenging due to complex intersentence dependencies within the generated facts prior solutions predominantly follow a decomposedecontextualizeverify pipeline but often fail to capture essential context and miss key relational facts in this paper we introduce verifact a factuality evaluation framework designed to enhance fact extraction by identifying and resolving incomplete and missing facts to support more accurate verification results moreover we introduce factrbench a benchmark that evaluates both precision and recall in longform model responses whereas prior work primarily focuses on precision factrbench provides reference fact sets from advanced llms and humanwritten answers enabling recall assessment empirical evaluations show that verifact significantly enhances fact completeness and preserves complex facts with critical relational information resulting in more accurate factuality evaluation benchmarking various open and closeweight llms on factrbench indicate that larger models within same model family improve precision and recall but high precision does not always correlate with high recall underscoring the importance of comprehensive factuality assessment
http://arxiv.org/abs/2505.09614v1,2025-05-14T17:59:35Z,"Anthony GX-Chen, Dongyan Lin, Mandana Samiei, Doina Precup, Blake A. Richards, Rob Fergus, Kenneth Marino",language agents mirror human causal reasoning biases how can we help them think like scientists,language model lm agents are increasingly used as autonomous decisionmakers who need to actively gather information to guide their decisions a crucial cognitive skill for such agents is the efficient exploration and understanding of the causal structure of the world key to robust scientifically grounded reasoning yet it remains unclear whether lms possess this capability or exhibit systematic biases leading to erroneous conclusions in this work we examine lms ability to explore and infer causal relationships using the wellestablished blicket test paradigm from developmental psychology we find that lms reliably infer the common intuitive disjunctive causal relationships but systematically struggle with the unusual yet equally or sometimes even more evidenced conjunctive ones this disjunctive bias persists across model families sizes and prompting strategies and performance further declines as task complexity increases interestingly an analogous bias appears in human adults suggesting that lms may have inherited deepseated reasoning heuristics from their training data to this end we quantify similarities between lms and humans finding that lms exhibit adultlike inference profiles but not childrenlike finally we propose a testtime sampling method which explicitly samples and eliminates hypotheses about causal relationships from the lm this scalable approach significantly reduces the disjunctive bias and moves lms closer to the goal of scientific causally rigorous reasoning
http://arxiv.org/abs/2505.09610v1,2025-05-14T17:58:40Z,"Nicolas Dupuis, Ravi Nair, Shyam Ramji, Sean McClintock, Nishant Chauhan, Priyanka Nagpal, Bart Blaner, Ken Valk, Leon Stok, Ruchir Puri",customizing a large language model for vhdl design of highperformance microprocessors,the use of large language models llms in hardware design has taken off in recent years principally through its incorporation in tools that increase chip designer productivity there has been considerable discussion about the use of llms in rtl specifications of chip designs for which the two most popular languages are verilog and vhdl llms and their use in verilog design has received significant attention due to the higher popularity of the language but little attention so far has been given to vhdl despite its continued popularity in the industry there has also been little discussion about the unique needs of organizations that engage in highperformance processor design and techniques to deploy ai solutions in these settings in this paper we describe our journey in developing a large language model llm specifically for the purpose of explaining vhdl code a task that has particular importance in an organization with decades of experience and assets in highperformance processor design we show how we developed test sets specific to our needs and used them for evaluating models as we performed extended pretraining ept of a base llm expert evaluation of the code explanations produced by the ept model increased to 69 compared to a base model rating of 43 we further show how we developed an llmasajudge to gauge models similar to expert evaluators this led us to deriving and evaluating a host of new models including an instructiontuned version of the ept model with an expected expert evaluator rating of 71 our experiments also indicate that with the potential use of newer base models this rating can be pushed to 85 and beyond we conclude with a discussion on further improving the quality of hardware design llms using exciting new developments in the generative ai world
http://arxiv.org/abs/2505.09595v1,2025-05-14T17:43:40Z,"Abdullah Mushtaq, Imran Taj, Rafay Naeem, Ibrahim Ghaznavi, Junaid Qadir",worldviewbench a benchmark for evaluating global cultural perspectives in large language models,large language models llms are predominantly trained and aligned in ways that reinforce westerncentric epistemologies and sociocultural norms leading to cultural homogenization and limiting their ability to reflect global civilizational plurality existing benchmarking frameworks fail to adequately capture this bias as they rely on rigid closedform assessments that overlook the complexity of cultural inclusivity to address this we introduce worldviewbench a benchmark designed to evaluate global cultural inclusivity gci in llms by analyzing their ability to accommodate diverse worldviews our approach is grounded in the multiplex worldview proposed by senturk et al which distinguishes between uniplex models reinforcing cultural homogenization and multiplex models which integrate diverse perspectives worldviewbench measures cultural polarization the exclusion of alternative perspectives through freeform generative evaluation rather than conventional categorical benchmarks we implement applied multiplexity through two intervention strategies 1 contextuallyimplemented multiplex llms where system prompts embed multiplexity principles and 2 multiagent system masimplemented multiplex llms where multiple llm agents representing distinct cultural perspectives collaboratively generate responses our results demonstrate a significant increase in perspectives distribution score pds entropy from 13 at baseline to 94 with masimplemented multiplex llms alongside a shift toward positive sentiment 677 and enhanced cultural balance these findings highlight the potential of multiplexaware ai evaluation in mitigating cultural bias in llms paving the way for more inclusive and ethically aligned ai systems
http://arxiv.org/abs/2505.09666v1,2025-05-14T16:46:15Z,"Yumin Choi, Jinheon Baek, Sung Ju Hwang",system prompt optimization with metalearning,large language models llms have shown remarkable capabilities with optimizing their input prompts playing a pivotal role in maximizing their performance however while llm prompts consist of both the taskagnostic system prompts and taskspecific user prompts existing work on prompt optimization has focused on user prompts specific to individual queries or tasks and largely overlooked the system prompt that is once optimized applicable across different tasks and domains motivated by this we introduce the novel problem of bilevel system prompt optimization whose objective is to design system prompts that are robust to diverse user prompts and transferable to unseen tasks to tackle this problem we then propose a metalearning framework which metalearns the system prompt by optimizing it over various user prompts across multiple datasets while simultaneously updating the user prompts in an iterative manner to ensure synergy between them we conduct experiments on 14 unseen datasets spanning 5 different domains on which we show that our approach produces system prompts that generalize effectively to diverse user prompts also our findings reveal that the optimized system prompt enables rapid adaptation even to unseen tasks requiring fewer optimization steps for testtime user prompts while achieving improved performance
http://arxiv.org/abs/2505.10588v1,2025-05-14T16:46:11Z,"Manisha Mehta, Fausto Giunchiglia",understanding gen alpha digital language evaluation of llm safety systems for content moderation,this research offers a unique evaluation of how ai systems interpret the digital language of generation alpha gen alpha born 20102024 as the first cohort raised alongside ai gen alpha faces new forms of online risk due to immersive digital engagement and a growing mismatch between their evolving communication and existing safety tools their distinct language shaped by gaming memes and aidriven trends often conceals harmful interactions from both human moderators and automated systems we assess four leading ai models gpt4 claude gemini and llama 3 on their ability to detect masked harassment and manipulation within gen alpha discourse using a dataset of 100 recent expressions from gaming platforms social media and video content the study reveals critical comprehension failures with direct implications for online safety this work contributes 1 a firstofitskind dataset capturing gen alpha expressions 2 a framework to improve ai moderation systems for youth protection 3 a multiperspective evaluation including ai systems human moderators and parents with direct input from gen alpha coresearchers and 4 an analysis of how linguistic divergence increases youth vulnerability findings highlight the urgent need to redesign safety systems attuned to youth communication especially given gen alpha reluctance to seek help when adults fail to understand their digital world this study combines the insight of a gen alpha researcher with systematic academic analysis to address critical digital safety challenges
http://arxiv.org/abs/2505.10586v1,2025-05-14T16:36:30Z,"Poli A. Nemkova, Suleyman O. Polat, Rafid I. Jahan, Sagnik Ray Choudhury, Sun-joo Lee, Shouryadipta Sarkar, Mark V. Albert",towards automated situation awareness a ragbased framework for peacebuilding reports,timely and accurate situation awareness is vital for decisionmaking in humanitarian response conflict monitoring and early warning and early action however the manual analysis of vast and heterogeneous data sources often results in delays limiting the effectiveness of interventions this paper introduces a dynamic retrievalaugmented generation rag system that autonomously generates situation awareness reports by integrating realtime data from diverse sources including news articles conflict event databases and economic indicators our system constructs queryspecific knowledge bases on demand ensuring timely relevant and accurate insights to ensure the quality of generated reports we propose a threelevel evaluation framework that combines semantic similarity metrics factual consistency checks and expert feedback the first level employs automated nlp metrics to assess coherence and factual accuracy the second level involves human expert evaluation to verify the relevance and completeness of the reports the third level utilizes llmasajudge where large language models provide an additional layer of assessment to ensure robustness the system is tested across multiple realworld scenarios demonstrating its effectiveness in producing coherent insightful and actionable reports by automating report generation our approach reduces the burden on human analysts and accelerates decisionmaking processes to promote reproducibility and further research we openly share our code and evaluation tools with the community via github
http://arxiv.org/abs/2505.09665v2,2025-05-14T16:31:08Z,"Sulong Zhou, Qunying Huang, Shaoheng Zhou, Yun Hang, Xinyue Ye, Aodong Mei, Kathryn Phung, Yuning Ye, Uma Govindswamy, Zehan Li",tales of the 2025 los angeles fire hotwash for public health concerns in reddit via llmenhanced topic modeling,wildfires have become increasingly frequent irregular and severe in recent years understanding how affected populations perceive and respond during wildfire crises is critical for timely and empathetic disaster response social media platforms offer a crowdsourced channel to capture evolving public discourse providing hyperlocal information and insight into public sentiment this study analyzes reddit discourse during the 2025 los angeles wildfires spanning from the onset of the disaster to full containment we collect 385 posts and 114879 comments related to the palisades and eaton fires we adopt topic modeling methods to identify the latent topics enhanced by large language models llms and humanintheloop hitl refinement furthermore we develop a hierarchical framework to categorize latent topics consisting of two main categories situational awareness sa and crisis narratives cn the volume of sa category closely aligns with realworld fire progressions peaking within the first 25 days as the fires reach the maximum extent the most frequent cooccurring category set of public health and safety loss and damage and emergency resources expands on a wide range of healthrelated latent topics including environmental health occupational health and one health grief signals and mental health risks consistently accounted for 60 percentage and 40 percentage of cn instances respectively with the highest total volume occurring at night this study contributes the first annotated social media dataset on the 2025 la fires and introduces a scalable multilayer framework that leverages topic modeling for crisis discourse analysis by identifying persistent public health concerns our results can inform more empathetic and adaptive strategies for disaster response public health communication and future research in comparable climaterelated disaster events
http://arxiv.org/abs/2505.09519v1,2025-05-14T16:16:36Z,"Zongqian Li, Yixuan Su, Nigel Collier",ptmoe an efficient finetuning framework for integrating mixtureofexperts into prompt tuning,parameterefficient finetuning peft methods have shown promise in adapting large language models yet existing approaches exhibit counterintuitive phenomena integrating router into prompt tuning pt increases training efficiency yet does not improve performance universally parameter reduction through matrix decomposition can improve performance in specific domains motivated by these observations and the modular nature of pt we propose ptmoe a novel framework that integrates matrix decomposition with mixtureofexperts moe routing for efficient pt results across 17 datasets demonstrate that ptmoe achieves stateoftheart performance in both question answering qa and mathematical problem solving tasks improving f1 score by 149 points over pt and 213 points over lora in qa tasks while enhancing mathematical accuracy by 1075 points over pt and 044 points over lora all while using 25 fewer parameters than lora our analysis reveals that while pt methods generally excel in qa tasks and lorabased methods in math datasets the integration of matrix decomposition and moe in ptmoe yields complementary benefits decomposition enables efficient parameter sharing across experts while moe provides dynamic adaptation collectively enabling ptmoe to demonstrate crosstask consistency and generalization abilities these findings along with ablation studies on routing mechanisms and architectural components provide insights for future peft methods
http://arxiv.org/abs/2505.09436v2,2025-05-14T14:44:30Z,"Raghav Garg, Kapil Sharma, Karan Gupta",cxmarena unified dataset to benchmark performance in realistic cxm scenarios,large language models llms hold immense potential for revolutionizing customer experience management cxm particularly in contact center operations however evaluating their practical utility in complex operational environments is hindered by data scarcity due to privacy concerns and the limitations of current benchmarks existing benchmarks often lack realism failing to incorporate deep knowledge base kb integration realworld noise or critical operational tasks beyond conversational fluency to bridge this gap we introduce cxmarena a novel largescale synthetic benchmark dataset specifically designed for evaluating ai in operational cxm contexts given the diversity in possible contact center features we have developed a scalable llmpowered pipeline that simulates the brands cxm entities that form the foundation of our datasetssuch as knowledge articles including product specifications issue taxonomies and contact center conversations the entities closely represent realworld distribution because of controlled noise injection informed by domain experts and rigorous automated validation building on this we release cxmarena which provides dedicated benchmarks targeting five important operational tasks knowledge base refinement intent prediction agent quality adherence article search and multiturn rag with integrated tools our baseline experiments underscore the benchmarks difficulty even state of the art embedding and generation models achieve only 68 accuracy on article search while standard embedding methods yield a low f1 score of 03 for knowledge base refinement highlighting significant challenges for current models necessitating complex pipelines and solutions over conventional techniques
http://arxiv.org/abs/2505.09662v1,2025-05-14T14:31:33Z,"Philipp Schoenegger, Francesco Salvi, Jiacheng Liu, Xiaoli Nan, Ramit Debnath, Barbara Fasolo, Evelina Leivada, Gabriel Recchia, Fritz Günther, Ali Zarifhonarvar, Joe Kwon, Zahoor Ul Islam, Marco Dehnert, Daryl Y. H. Lee, Madeline G. Reinecke, David G. Kamper, Mert Kobaş, Adam Sandford, Jonas Kgomo, Luke Hewitt, Shreya Kapoor, Kerem Oktar, Eyup Engin Kucuk, Bo Feng, Cameron R. Jones, Izzy Gainsburg, Sebastian Olschewski, Nora Heinzelmann, Francisco Cruz, Ben M. Tappin, Tao Ma, Peter S. Park, Rayan Onyonka, Arthur Hjorth, Peter Slattery, Qingcheng Zeng, Lennart Finke, Igor Grossmann, Alessandro Salatiello, Ezra Karger",large language models are more persuasive than incentivized human persuaders,we directly compare the persuasion capabilities of a frontier large language model llm claude sonnet 35 against incentivized human persuaders in an interactive realtime conversational quiz setting in this preregistered largescale incentivized experiment participants quiz takers completed an online quiz where persuaders either humans or llms attempted to persuade quiz takers toward correct or incorrect answers we find that llm persuaders achieved significantly higher compliance with their directional persuasion attempts than incentivized human persuaders demonstrating superior persuasive capabilities in both truthful toward correct answers and deceptive toward incorrect answers contexts we also find that llm persuaders significantly increased quiz takers accuracy leading to higher earnings when steering quiz takers toward correct answers and significantly decreased their accuracy leading to lower earnings when steering them toward incorrect answers overall our findings suggest that ais persuasion capabilities already exceed those of humans that have realmoney bonuses tied to performance our findings of increasingly capable ai persuaders thus underscore the urgency of emerging alignment and governance frameworks
http://arxiv.org/abs/2505.09407v1,2025-05-14T14:04:44Z,"Subrit Dikshit, Ritu Tiwari, Priyank Jain",multilingual machine translation with quantum encoder decoder attentionbased convolutional variational circuits,cloudbased multilingual translation services like google translate and microsoft translator achieve stateoftheart translation capabilities these services inherently use large multilingual language models such as gru lstm bert gpt t5 or similar encoderdecoder architectures with attention mechanisms as the backbone also new age natural language systems for instance chatgpt and deepseek have established huge potential in multiple tasks in natural language processing at the same time they also possess outstanding multilingual translation capabilities however these models use the classical computing realm as a backend qedacvc quantum encoder decoder attentionbased convolutional variational circuits is an alternate solution that explores the quantum computing realm instead of the classical computing realm to study and demonstrate multilingual machine translation qedacvc introduces the quantum encoderdecoder architecture that simulates and runs on quantum computing hardware via quantum convolution quantum pooling quantum variational circuit and quantum attention as software alterations qedacvc achieves an accuracy of 82 when trained on the opus dataset for english french german and hindi corpora for multilingual translations
http://arxiv.org/abs/2505.09388v1,2025-05-14T13:41:34Z,"An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge, Haoran Wei, Huan Lin, Jialong Tang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jing Zhou, Jingren Zhou, Junyang Lin, Kai Dang, Keqin Bao, Kexin Yang, Le Yu, Lianghao Deng, Mei Li, Mingfeng Xue, Mingze Li, Pei Zhang, Peng Wang, Qin Zhu, Rui Men, Ruize Gao, Shixuan Liu, Shuang Luo, Tianhao Li, Tianyi Tang, Wenbiao Yin, Xingzhang Ren, Xinyu Wang, Xinyu Zhang, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yinger Zhang, Yu Wan, Yuqiong Liu, Zekun Wang, Zeyu Cui, Zhenru Zhang, Zhipeng Zhou, Zihan Qiu",qwen3 technical report,in this work we present qwen3 the latest version of the qwen model family qwen3 comprises a series of large language models llms designed to advance performance efficiency and multilingual capabilities the qwen3 series includes models of both dense and mixtureofexpert moe architectures with parameter scales ranging from 06 to 235 billion a key innovation in qwen3 is the integration of thinking mode for complex multistep reasoning and nonthinking mode for rapid contextdriven responses into a unified framework this eliminates the need to switch between different modelssuch as chatoptimized models eg gpt4o and dedicated reasoning models eg qwq32band enables dynamic mode switching based on user queries or chat templates meanwhile qwen3 introduces a thinking budget mechanism allowing users to allocate computational resources adaptively during inference thereby balancing latency and performance based on task complexity moreover by leveraging the knowledge from the flagship models we significantly reduce the computational resources required to build smallerscale models while ensuring their highly competitive performance empirical evaluations demonstrate that qwen3 achieves stateoftheart results across diverse benchmarks including tasks in code generation mathematical reasoning agent tasks etc competitive against larger moe models and proprietary models compared to its predecessor qwen25 qwen3 expands multilingual support from 29 to 119 languages and dialects enhancing global accessibility through improved crosslingual understanding and generation capabilities to facilitate reproducibility and communitydriven research and development all qwen3 models are publicly accessible under apache 20
http://arxiv.org/abs/2505.09338v1,2025-05-14T12:33:05Z,"Jingcheng Niu, Xingdi Yuan, Tong Wang, Hamidreza Saghir, Amir H. Abdi",llama see llama do a mechanistic perspective on contextual entrainment and distraction in llms,we observe a novel phenomenon contextual entrainment across a wide range of language models lms and prompt settings providing a new mechanistic perspective on how lms become distracted by irrelevant contextual information in the input prompt specifically lms assign significantly higher logits or probabilities to any tokens that have previously appeared in the context prompt even for random tokens this suggests that contextual entrainment is a mechanistic phenomenon occurring independently of the relevance or semantic relation of the tokens to the question or the rest of the sentence we find statistically significant evidence that the magnitude of contextual entrainment is influenced by semantic factors counterfactual prompts have a greater effect compared to factual ones suggesting that while contextual entrainment is a mechanistic phenomenon it is modulated by semantic factors we hypothesise that there is a circuit of attention heads the entrainment heads that corresponds to the contextual entrainment phenomenon using a novel entrainment head discovery method based on differentiable masking we identify these heads across various settings when we turn off these heads ie set their outputs to zero the effect of contextual entrainment is significantly attenuated causing the model to generate output that capitulates to what it would produce if no distracting context were provided our discovery of contextual entrainment along with our investigation into lm distraction via the entrainment heads marks a key step towards the mechanistic analysis and mitigation of the distraction problem
http://arxiv.org/abs/2505.09316v1,2025-05-14T12:13:38Z,"Hongjin Qian, Zheng Liu",scent of knowledge optimizing searchenhanced reasoning with information foraging,augmenting large language models llms with external retrieval has become a standard method to address their inherent knowledge cutoff limitations however traditional retrievalaugmented generation methods employ static preinference retrieval strategies making them inadequate for complex tasks involving ambiguous multistep or evolving information needs recent advances in testtime scaling techniques have demonstrated significant potential in enabling llms to dynamically interact with external tools motivating the shift toward adaptive inferencetime retrieval inspired by information foraging theory ift we propose inforage a reinforcement learning framework that formalizes retrievalaugmented reasoning as a dynamic informationseeking process unlike existing approaches inforage explicitly rewards intermediate retrieval quality encouraging llms to iteratively gather and integrate information through adaptive search behaviors to facilitate training we construct a humanguided dataset capturing iterative search and reasoning trajectories for complex realworld web tasks extensive evaluations across general question answering multihop reasoning tasks and a newly developed realtime web qa dataset demonstrate inforages superior performance over baseline methods these results highlight inforages effectiveness in building robust adaptive and efficient reasoning agents
http://arxiv.org/abs/2505.09286v1,2025-05-14T11:11:17Z,"Jiin Park, Misuk Kim",a scalable unsupervised framework for multiaspect labeling of multilingual and multidomain review data,effectively analyzing online review data is essential across industries however many existing studies are limited to specific domains and languages or depend on supervised learning approaches that require largescale labeled datasets to address these limitations we propose a multilingual scalable and unsupervised framework for crossdomain aspect detection this framework is designed for multiaspect labeling of multilingual and multidomain review data in this study we apply automatic labeling to korean and english review datasets spanning various domains and assess the quality of the generated labels through extensive experiments aspect category candidates are first extracted through clustering and each review is then represented as an aspectaware embedding vector using negative sampling to evaluate the framework we conduct multiaspect labeling and finetune several pretrained language models to measure the effectiveness of the automatically generated labels results show that these models achieve high performance demonstrating that the labels are suitable for training furthermore comparisons with publicly available large language models highlight the frameworks superior consistency and scalability when processing largescale data a human evaluation also confirms that the quality of the automatic labels is comparable to those created manually this study demonstrates the potential of a robust multiaspect labeling approach that overcomes limitations of supervised methods and is adaptable to multilingual multidomain environments future research will explore automatic review summarization and the integration of artificial intelligence agents to further improve the efficiency and depth of review analysis
http://arxiv.org/abs/2505.09269v1,2025-05-14T10:38:37Z,"Ulrich Frank, Pierre Maier",how an unintended side effect of a research project led to boosting the power of uml,this paper describes the design implementation and use of a new uml modeling tool that represents a significant advance over conventional tools among other things it allows the integration of class diagrams and object diagrams as well as the execution of objects this not only enables new software architectures characterized by the integration of software with corresponding object models but is also ideal for use in teaching as it provides students with a particularly stimulating learning experience a special feature of the project is that it has emerged from a longstanding international research project which is aimed at a comprehensive multilevel architecture the project is therefore an example of how research can lead to valuable results that arise as a side effect of other work
http://arxiv.org/abs/2505.10583v1,2025-05-14T09:41:38Z,"Diogo Freitas, Brigt Håvardstun, Cèsar Ferri, Darío Garigliotti, Jan Arne Telle, José Hernández-Orallo",relative drawing identification complexity is invariant to modality in visionlanguage models,large language models have become multimodal and many of them are said to integrate their modalities using common representations if this were true a drawing of a car as an image for instance should map to the similar area in the latent space as a textual description of the strokes that conform the drawing to explore this in a blackbox access regime to these models we propose the use of machine teaching a theory that studies the minimal set of examples a teacher needs to choose so that the learner captures the concept in this paper we evaluate the complexity of teaching visuallanguage models a subset of objects in the quick draw dataset using two presentations raw images as bitmaps and trace coordinates in tikz format the results indicate that imagebased representations generally require fewer segments and achieve higher accuracy than coordinatebased representations but surprisingly the teaching size usually ranks concepts similarly across both modalities even when controlling for a human proxy of concept priors suggesting that the simplicity of concepts may be an inherent property that transcends modality representations
http://arxiv.org/abs/2505.09246v1,2025-05-14T09:35:56Z,"Derian Boer, Stephen Roth, Stefan Kramer",focus merge rank improved question answering based on semistructured knowledge bases,in many realworld settings machine learning models and interactive systems have access to both structured knowledge eg knowledge graphs or tables and unstructured content eg natural language documents however most rely on either semistructured knowledge bases skbs bridge this gap by linking unstructured content to nodes within structured data thereby enabling new strategies for knowledge access and use in this work we present focusedretriever a modular skbbased framework for multihop question answering it integrates components vssbased entity search llmbased generation of cypher queries and pairwise reranking in a way that enables it to outperform stateoftheart methods across all three stark benchmark test sets covering diverse domains and multiple performance metrics the average firsthit rate exceeds that of the secondbest method by 257 focusedretriever leverages 1 the capacity of large language models llms to extract relational facts and entity attributes from unstructured text 2 node set joins to filter answer candidates based on these extracted triplets and constraints 3 vector similarity search to retrieve and rank relevant unstructured content and 4 the contextual capabilities of llms to finally rank the topk answers for generality we only incorporate base llms in focusedretriever in our evaluation however our analysis of intermediate results highlights several opportunities for further upgrades including finetuning the source code is publicly available at httpsgithubcomkramerlabfocusedretriever
http://arxiv.org/abs/2505.09659v1,2025-05-14T06:18:08Z,"Long Chen, Xiaotian Song, Yanan Sun",las lossless annsnn conversion for fully spikedriven large language models,spiking large language models llms have emerged as an energyefficient alternative to conventional llms through their eventdriven computation to effectively obtain spiking llms researchers develop different anntosnn conversion methods by leveraging pretrained ann parameters while inheriting the energy efficiency of snn however existing conversion methods struggle with extreme activation outliers and incompatible nonlinear operations of annbased llms to address this we propose a lossless annsnn conversion for fully spikedriven llms termed las specifically las introduces two novel neurons to convert the activation outlier and nonlinear operation of annbased llms moreover las tailors the spikeequivalent transformer components for spiking llms which can ensure full spiking conversion without any loss of performance experimental results on six language models and two visionlanguage models demonstrate that las achieves lossless conversion notably on opt66b las even improves the accuracy of 2 on the wsc task in addition the parameter and ablation studies further verify the effectiveness of las the source code is available at httpsgithubcomlc783las
http://arxiv.org/abs/2505.09083v1,2025-05-14T02:36:26Z,Dominic Zaun Eu Jones,ornithologist towards trustworthy reasoning about central bank communications,i develop ornithologist a weaklysupervised textual classification system and measure the hawkishness and dovishness of central bank text ornithologist uses taxonomyguided reasoning guiding a large language model with humanauthored decision trees this increases the transparency and explainability of the system and makes it accessible to nonexperts it also reduces hallucination risk since it requires less supervision than traditional classification systems it can more easily be applied to other problems or sources of text eg news without much modification ornithologist measurements of hawkishness and dovishness of rba communication carry information about the future of the cash rate path and of market expectations
http://arxiv.org/abs/2505.11533v1,2025-05-14T02:36:17Z,"Jinqiang Wang, Huansheng Ning, Tao Zhu, Jianguo Ding",a data synthesis method driven by large language models for proactive mining of implicit user intentions in tourism,in the tourism domain large language models llms often struggle to mine implicit user intentions from tourists ambiguous inquiries and lack the capacity to proactively guide users toward clarifying their needs a critical bottleneck is the scarcity of highquality training datasets that facilitate proactive questioning and implicit intention mining while recent advances leverage llmdriven data synthesis to generate such datasets and transfer specialized knowledge to downstream models existing approaches suffer from several shortcomings 1 lack of adaptation to the tourism domain 2 skewed distributions of detail levels in initial inquiries 3 contextual redundancy in the implicit intention mining module and 4 lack of explicit thinking about tourists emotions and intention values therefore we propose synpt a data synthesis method driven by llms for proactive mining of implicit user intentions in the tourism which constructs an llmdriven user agent and assistant agent to simulate dialogues based on seed data collected from chinese tourism websites this approach addresses the aforementioned limitations and generates synptdialog a training dataset containing explicit reasoning the dataset is utilized to finetune a general llm enabling it to proactively mine implicit user intentions experimental evaluations conducted from both human and llm perspectives demonstrate the superiority of synpt compared to existing methods furthermore we analyze key hyperparameters and present case studies to illustrate the practical applicability of our method including discussions on its adaptability to englishlanguage scenarios all code and data are publicly available
http://arxiv.org/abs/2505.09082v1,2025-05-14T02:35:47Z,"Sophie Zhang, Zhiming Lin",ceczero chinese error correction solution based on llm,recent advancements in large language models llms demonstrate exceptional chinese text processing capabilities particularly in chinese spelling correction csc while llms outperform traditional bertbased models in accuracy and robustness challenges persist in reliability and generalization this paper proposes ceczero a novel reinforcement learning rl framework enabling llms to selfcorrect through autonomous error strategy learning without external supervision by integrating rl with llms generative power the method eliminates dependency on annotated data or auxiliary models experiments reveal rlenhanced llms achieve industryviable accuracy and superior crossdomain generalization offering a scalable solution for reliability optimization in chinese nlp applications this breakthrough facilitates llm deployment in practical chinese text correction scenarios while establishing a new paradigm for selfimproving language models
http://arxiv.org/abs/2505.09068v1,2025-05-14T02:08:40Z,"Jennifer Haase, Paul H. P. Hanel, Sebastian Pokutta",sdat a multilingual genaidriven framework for automated divergent thinking assessment,this paper introduces sdat syntheticdivergent association task a scalable multilingual framework for automated assessment of divergent thinking dt a core component of human creativity traditional creativity assessments are often laborintensive languagespecific and reliant on subjective human ratings limiting their scalability and crosscultural applicability in contrast sdat leverages large language models and advanced multilingual embeddings to compute semantic distance a languageagnostic proxy for dt we evaluate sdat across eleven diverse languages including english spanish german russian hindi and japanese kanji hiragana katakana demonstrating robust and consistent scoring across linguistic contexts unlike prior dat approaches the sdat shows convergent validity with other dt measures and correct discriminant validity with convergent thinking this crosslinguistic flexibility allows for more inclusive globalscale creativity research addressing key limitations of earlier approaches sdat provides a powerful tool for fairer more comprehensive evaluation of cognitive flexibility in diverse populations and can be freely assessed online httpssdatiolzibde
http://arxiv.org/abs/2505.09655v2,2025-05-14T02:02:32Z,"Xiwen Chen, Wenhui Zhu, Peijie Qiu, Xuanzhao Dong, Hao Wang, Haiyu Wu, Huayu Li, Aristeidis Sotiras, Yalin Wang, Abolfazl Razi",dragrpo exploring diversityaware reward adjustment for r1zerolike training of large language models,recent advances in reinforcement learning for language model posttraining such as group relative policy optimization grpo have shown promise in lowresource settings however grpo typically relies on solutionlevel and scalar reward signals that fail to capture the semantic diversity among sampled completions this leads to what we identify as a diversityquality inconsistency where distinct reasoning paths may receive indistinguishable rewards to address this limitation we propose textitdiversityaware reward adjustment dra a method that explicitly incorporates semantic diversity into the reward computation dra uses submodular mutual information smi to downweight redundant completions and amplify rewards for diverse ones this encourages better exploration during learning while maintaining stable exploitation of highquality samples our method integrates seamlessly with both grpo and its variant drgrpo resulting in and we evaluate our method on five mathematical reasoning benchmarks and find that it outperforms recent strong baselines it achieves stateoftheart performance with an average accuracy of 582 using only 7000 finetuning samples and a total training cost of approximately 55 the code is available at httpsgithubcomxiwenc1dragrpo
http://arxiv.org/abs/2505.09056v1,2025-05-14T01:21:46Z,"Brandon Smith, Mohamed Reda Bouadjenek, Tahsin Alamgir Kheya, Phillip Dawson, Sunil Aryal",a comprehensive analysis of large language model outputs similarity diversity and bias,large language models llms represent a major step toward artificial general intelligence significantly advancing our ability to interact with technology while llms perform well on natural language processing tasks such as translation generation code writing and summarization questions remain about their output similarity variability and ethical implications for instance how similar are texts generated by the same model how does this compare across different models and which models best uphold ethical standards to investigate we used 5000 prompts spanning diverse tasks like generation explanation and rewriting this resulted in approximately 3 million texts from 12 llms including proprietary and opensource systems from openai google microsoft meta and mistral key findings include 1 outputs from the same llm are more similar to each other than to humanwritten texts 2 models like wizardlm28x22b generate highly similar outputs while gpt4 produces more varied responses 3 llm writing styles differ significantly with llama 3 and mistral showing higher similarity and gpt4 standing out for distinctiveness 4 differences in vocabulary and tone underscore the linguistic uniqueness of llmgenerated content 5 some llms demonstrate greater gender balance and reduced bias these results offer new insights into the behavior and diversity of llm outputs helping guide future development and ethical evaluation
http://arxiv.org/abs/2505.09039v1,2025-05-14T00:39:47Z,"Jingfeng Chen, Raghuveer Thirukovalluru, Junlin Wang, Kaiwei Luo, Bhuwan Dhingra",atomic consistency preference optimization for longform question answering,large language models llms frequently produce factoid hallucinations plausible yet incorrect answers a common mitigation strategy is model alignment which improves factual accuracy by training on curated factual and nonfactual pairs however this approach often relies on a stronger model eg gpt4 or an external knowledge base to assess factual correctness which may not always be accessible to address this we propose atomic consistency preference optimization acpo a selfsupervised preferencetuning method that enhances factual accuracy without external supervision acpo leverages atomic consistency signals ie the agreement of individual facts across multiple stochastic responses to identify high and lowquality data pairs for model alignment by eliminating the need for costly gpt calls acpo provides a scalable and efficient approach to improving factoid questionanswering despite being selfsupervised empirical results demonstrate that acpo outperforms factalign a strong supervised alignment baseline by 195 points on the longfact and biogen datasets highlighting its effectiveness in enhancing factual reliability without relying on external models or knowledge bases
http://arxiv.org/abs/2505.09031v1,2025-05-13T23:57:02Z,"Adarsh Kumar, Hwiyoon Kim, Jawahar Sai Nathani, Neil Roy",improving the reliability of llms combining cot rag selfconsistency and selfverification,hallucination where large language models llms generate confident but incorrect or irrelevant information remains a key limitation in their application to complex openended tasks chainofthought cot prompting has emerged as a promising method for improving multistep reasoning by guiding models through intermediate steps however cot alone does not fully address the hallucination problem in this work we investigate how combining cot with retrievalaugmented generation rag as well as applying selfconsistency and selfverification strategies can reduce hallucinations and improve factual accuracy by incorporating external knowledge sources during reasoning and enabling models to verify or revise their own outputs we aim to generate more accurate and coherent responses we present a comparative evaluation of baseline llms against cot cotrag selfconsistency and selfverification techniques our results highlight the effectiveness of each method and identify the most robust approach for minimizing hallucinations while preserving fluency and reasoning depth
http://arxiv.org/abs/2505.09024v1,2025-05-13T23:42:36Z,"Aaron Baughman, Rahul Agarwal, Eduardo Morales, Gozde Akay",automated meta prompt engineering for alignment with the theory of mind,we introduce a method of metaprompting that jointly produces fluent text for complex tasks while optimizing the similarity of neural states between a humans mental expectation and a large language models llm neural processing a technique of agentic reinforcement learning is applied in which an llm as a judge llmaaj teaches another llm through incontext learning how to produce content by interpreting the intended and unintended generated text traits to measure human mental beliefs around content production users modify long form aigenerated text articles before publication at the us open 2024 tennis grand slam now an llmaaj can solve the theory of mind tom alignment problem by anticipating and including human edits within the creation of text from an llm throughout experimentation and by interpreting the results of a live production system the expectations of human content reviewers had 100 of alignment with ai 538 of the time with an average iteration count of 438 the geometric interpretation of content traits such as factualness novelty repetitiveness and relevancy over a hilbert vector space combines spatial volume all trait importance with vertices alignment individual trait relevance enabled the llmaaj to optimize on human tom this resulted in an increase in content quality by extending the coverage of tennis action our work that was deployed at the us open 2024 has been used across other live events within sports and entertainment
http://arxiv.org/abs/2505.09005v1,2025-05-13T22:41:13Z,"Nicole Cuneo, Eleanor Graves, Supantho Rakshit, Adele E. Goldberg",for gpt4 as with humans information structure predicts acceptability of longdistance dependencies,it remains debated how well any lm understands natural language or generates reliable metalinguistic judgments moreover relatively little work has demonstrated that lms can represent and respect subtle relationships between form and function proposed by linguists we here focus on a particular such relationship established in recent work english speakers judgments about the information structure of canonical sentences predicts independently collected acceptability ratings on corresponding long distance dependency ldd constructions across a wide array of base constructions and multiple types of ldds to determine whether any lm captures this relationship we probe gpt4 on the same tasks used with humans and new extensionsresults reveal reliable metalinguistic skill on the information structure and acceptability tasks replicating a striking interaction between the two despite the zeroshot explicit nature of the tasks and little to no chance of contamination studies 1a 1b study 2 manipulates the information structure of base sentences and confirms a causal relationship increasing the prominence of a constituent in a context sentence increases the subsequent acceptability ratings on an ldd construction the findings suggest a tight relationship between natural and gpt4 generated english and between information structure and syntax which begs for further exploration
http://arxiv.org/abs/2505.08996v1,2025-05-13T22:18:51Z,"Adele E Goldberg, Supantho Rakshit, Jennifer Hu, Kyle Mahowald",a suite of lms comprehend puzzle statements as well as humans,recent claims suggest that large language models lms underperform humans in comprehending minimally complex english statements dentella et al 2024 here we revisit those findings and argue that human performance was overestimated while llm abilities were underestimated using the same stimuli we report a preregistered study comparing human responses in two conditions one allowed rereading replicating the original study and one that restricted rereading a more naturalistic comprehension test human accuracy dropped significantly when rereading was restricted 73 falling below that of falcon180bchat 76 and gpt4 81 the newer gpto1 model achieves perfect accuracy results further show that both humans and models are disproportionately challenged by queries involving potentially reciprocal actions eg kissing suggesting shared pragmatic sensitivities rather than modelspecific deficits additional analyses using llama270b log probabilities a recoding of openended model responses and grammaticality ratings of other sentences reveal systematic underestimation of model performance we find that gpt4o can align with either naive or expert grammaticality judgments depending on prompt framing these findings underscore the need for more careful experimental design and coding practices in llm evaluation and they challenge the assumption that current models are inherently weaker than humans at language comprehension
http://arxiv.org/abs/2505.08971v1,2025-05-13T21:27:52Z,"Yangyi Chen, Hao Peng, Tong Zhang, Heng Ji",prioritizing imagerelated tokens enhances visionlanguage pretraining,in standard large visionlanguage models lvlms pretraining the model typically maximizes the joint probability of the caption conditioned on the image via nexttoken prediction ntp however since only a small subset of caption tokens directly relates to the visual content this naive ntp unintentionally fits the model to noise and increases the risk of hallucination we present prior a simple visionlanguage pretraining approach that addresses this issue by prioritizing imagerelated tokens through differential weighting in the ntp loss drawing from the importance sampling framework prior introduces a reference modela textonly large language model llm trained on the captions without image inputs to weight each token based on its probability for lvlms training intuitively tokens that are directly related to the visual inputs are harder to predict without the image and thus receive lower probabilities from the textonly reference llm during training we implement a tokenspecific reweighting term based on the importance scores to adjust each tokens loss we implement prior in two distinct settings lvlms with visual encoders and lvlms without visual encoders we observe 19 and 8 average relative improvement respectively on several visionlanguage benchmarks compared to ntp in addition prior exhibits superior scaling properties as demonstrated by significantly higher scaling coefficients indicating greater potential for performance gains compared to ntp given increasing compute and data
http://arxiv.org/abs/2505.08941v1,2025-05-13T20:10:00Z,"Gavin Hull, Alex Bihlo",forecite adapting pretrained language models to predict future citation rates of academic papers,predicting the future citation rates of academic papers is an important step toward the automation of research evaluation and the acceleration of scientific progress we present a simple but powerful framework to append pretrained causal language models with a linear head for average monthly citation rate prediction adapting transformers for regression tasks forecite achieves a test correlation of on a curated dataset of 900k biomedical papers published between 2000 and 2024 a 27point improvement over the previous stateoftheart comprehensive scalinglaw analysis reveals consistent gains across model sizes and data volumes while temporal holdout experiments confirm practical robustness gradientbased saliency heatmaps suggest a potentially undue reliance on titles and abstract texts these results establish a new stateoftheart in forecasting the longterm influence of academic research and lay the groundwork for the automated highfidelity evaluation of scientific contributions
http://arxiv.org/abs/2505.08910v2,2025-05-13T19:01:12Z,"Nahid Alam, Karthik Reddy Kanjula, Surya Guthikonda, Timothy Chung, Bala Krishna S Vegesna, Abhipsha Das, Anthony Susevski, Ryan Sze-Yin Chan, S M Iftekhar Uddin, Shayekh Bin Islam, Roshan Santhosh, Snegha A, Drishti Sharma, Chen Liu, Isha Chaturvedi, Genta Indra Winata, Ashvanth. S, Snehanshu Mukherjee, Alham Fikri Aji",behind maya building a multilingual vision language model,in recent times we have seen a rapid development of large visionlanguage models vlms they have shown impressive results on academic benchmarks primarily in widely spoken languages but lack performance on lowresource languages and varied cultural contexts to address these limitations we introduce maya an opensource multilingual vlm our contributions are 1 a multilingual imagetext pretraining dataset in eight languages based on the llava pretraining dataset and 2 a multilingual imagetext model supporting these languages enhancing cultural and linguistic comprehension in visionlanguage tasks code available at httpsgithubcomnahidalammaya
http://arxiv.org/abs/2505.08905v2,2025-05-13T18:50:03Z,"Michael Majurski, Cynthia Matuszek",grounding synthetic data evaluations of language models in unsupervised document corpora,language models lms continue to advance improving response quality and coherence given internetscale training datasets lms have likely encountered much of what users may ask them to generate in some form during their training a plethora of evaluation benchmarks have been constructed to assess model quality response appropriateness and reasoning capabilities however the human effort required for benchmark construction is rapidly being outpaced by the size and scope of the models under evaluation having humans build a benchmark for every possible domain of interest is impractical therefore we propose a methodology for automating the construction of factbased synthetic data model evaluations grounded in document populations this work leverages the same lms to evaluate domainspecific knowledge automatically using only grounding documents eg a textbook as input this synthetic data benchmarking approach corresponds well with human curated questions producing a spearman ranking correlation of 097 and a benchmark evaluation pearson accuracy correlation of 075 this novel approach supports generating both multiple choice and openended synthetic data questions to gain diagnostic insight of lm capability we apply this methodology to evaluate model performance on two recent arxiv preprints discovering a surprisingly strong performance from gemma3 models on openended questions code is available at httpsgithubcommmajurskigroundedsynthlmbenchmark
http://arxiv.org/abs/2505.08902v1,2025-05-13T18:44:22Z,"Lucas McCullum, Pelagie Ami Agassi, Leo Anthony Celi, Daniel K. Ebner, Chrystinne Oliveira Fernandes, Rachel S. Hicklen, Mkliwa Koumbia, Lisa Soleymani Lehmann, David Restrepo",performance gains of llms with humans in a world of llms versus humans,currently a considerable research effort is devoted to comparing llms to a group of human experts where the term expert is often illdefined or variable at best in a state of constantly updating llm releases without proper safeguards in place llms will threaten to cause harm to the established structure of safe delivery of patient care which has been carefully developed throughout history to keep the safety of the patient at the forefront a key driver of llm innovation is founded on community research efforts which if continuing to operate under humans versus llms principles will expedite this trend therefore research efforts moving forward must focus on effectively characterizing the safe use of llms in clinical settings that persist across the rapid development of novel llm models in this communication we demonstrate that rather than comparing llms to humans there is a need to develop strategies enabling efficient work of humans with llms in an almost symbiotic manner
http://arxiv.org/abs/2505.08891v1,2025-05-13T18:27:25Z,"Daeun Hwang, Samuel Shields, Alex Calderwood, Shi Johnson-Bey, Michael Mateas, Noah Wardrip-Fruin, Edward F. Melcer",clicking some of the silly options exploring player motivation in static and dynamic educational interactive narratives,motivation is an important factor underlying successful learning previous research has demonstrated the positive effects that static interactive narrative games can have on motivation concurrently advances in ai have made dynamic and adaptive approaches to interactive narrative increasingly accessible however limited work has explored the impact that dynamic narratives can have on learner motivation in this paper we compare two versions of academical a choicebased educational interactive narrative game about research ethics one version employs a traditional handauthored branching plot ie static narrative while the other dynamically sequences plots during play ie dynamic narrative results highlight the importance of responsive content and a variety of choices for player engagement while also illustrating the challenge of balancing pedagogical goals with the dynamic aspects of narrative we also discuss design implications that arise from these findings ultimately this work provides initial steps to illuminate the emerging potential of aidriven dynamic narrative in educational games
http://arxiv.org/abs/2505.08783v1,2025-05-13T17:58:08Z,"Shanda Li, Tanya Marwah, Junhong Shen, Weiwei Sun, Andrej Risteski, Yiming Yang, Ameet Talwalkar",codepde an inference framework for llmdriven pde solver generation,partial differential equations pdes are fundamental to modeling physical systems yet solving them remains a complex challenge traditional numerical solvers rely on expert knowledge to implement and are computationally expensive while neuralnetworkbased solvers require large training datasets and often lack interpretability in this work we frame pde solving as a code generation task and introduce codepde the first inference framework for generating pde solvers using large language models llms leveraging advanced inferencetime algorithms and scaling strategies codepde unlocks critical capacities of llm for pde solving reasoning debugging selfrefinement and testtime scaling all without taskspecific tuning codepde achieves superhuman performance across a range of representative pde problems we also present a systematic empirical analysis of llm generated solvers analyzing their accuracy efficiency and numerical scheme choices our findings highlight the promise and the current limitations of llms in pde solving offering a new perspective on solver design and opportunities for future model development our code is available at httpsgithubcomlithiumdacodepde
http://arxiv.org/abs/2505.08775v1,2025-05-13T17:53:59Z,"Rahul K. Arora, Jason Wei, Rebecca Soskin Hicks, Preston Bowman, Joaquin Quiñonero-Candela, Foivos Tsimpourlas, Michael Sharman, Meghan Shah, Andrea Vallone, Alex Beutel, Johannes Heidecke, Karan Singhal",healthbench evaluating large language models towards improved human health,we present healthbench an opensource benchmark measuring the performance and safety of large language models in healthcare healthbench consists of 5000 multiturn conversations between a model and an individual user or healthcare professional responses are evaluated using conversationspecific rubrics created by 262 physicians unlike previous multiplechoice or shortanswer benchmarks healthbench enables realistic openended evaluation through 48562 unique rubric criteria spanning several health contexts eg emergencies transforming clinical data global health and behavioral dimensions eg accuracy instruction following communication healthbench performance over the last two years reflects steady initial progress compare gpt35 turbos 16 to gpt4os 32 and more rapid recent improvements o3 scores 60 smaller models have especially improved gpt41 nano outperforms gpt4o and is 25 times cheaper we additionally release two healthbench variations healthbench consensus which includes 34 particularly important dimensions of model behavior validated via physician consensus and healthbench hard where the current top score is 32 we hope that healthbench grounds progress towards model development and applications that benefit human health
http://arxiv.org/abs/2505.08751v1,2025-05-13T17:03:48Z,"Saurabh Dash, Yiyang Nan, John Dang, Arash Ahmadian, Shivalika Singh, Madeline Smith, Bharat Venkitesh, Vlad Shmyhlo, Viraat Aryabumi, Walter Beller-Morales, Jeremy Pekmez, Jason Ozuzu, Pierre Richemond, Acyr Locatelli, Nick Frosst, Phil Blunsom, Aidan Gomez, Ivan Zhang, Marzieh Fadaee, Manoj Govindassamy, Sudip Roy, Matthias Gallé, Beyza Ermis, Ahmet Üstün, Sara Hooker",aya vision advancing the frontier of multilingual multimodality,building multimodal language models is fundamentally challenging it requires aligning vision and language modalities curating highquality instruction data and avoiding the degradation of existing textonly capabilities once vision is introduced these difficulties are further magnified in the multilingual setting where the need for multimodal data in different languages exacerbates existing data scarcity machine translation often distorts meaning and catastrophic forgetting is more pronounced to address the aforementioned challenges we introduce novel techniques spanning both data and modeling first we develop a synthetic annotation framework that curates highquality diverse multilingual multimodal instruction data enabling aya vision models to produce natural humanpreferred responses to multimodal inputs across many languages complementing this we propose a crossmodal model merging technique that mitigates catastrophic forgetting effectively preserving textonly capabilities while simultaneously enhancing multimodal generative performance ayavision8b achieves bestinclass performance compared to strong multimodal models such as qwen25vl7b pixtral12b and even much larger llama3290bvision we further scale this approach with ayavision32b which outperforms models more than twice its size such as molmo72b and llama3290bvision our work advances multilingual progress on the multimodal frontier and provides insights into techniques that effectively bend the need for compute while delivering extremely high performance
http://arxiv.org/abs/2505.08750v1,2025-05-13T17:02:33Z,"Yanxi Zhang, Xin Cong, Zhong Zhang, Xiao Liu, Dongyan Zhao, Yesai Wu",acreason towards theoryguided actual causality reasoning with large language models,actual causality ac a fundamental aspect of causal reasoning cr is responsible for attribution and responsibility assignment in realworld scenarios however existing llmbased methods lack grounding in formal ac theory resulting in limited interpretability therefore we propose acreason a semiformal reasoning framework that identifies causally relevant events within an ac scenario infers the values of their formal causal factors eg sufficiency necessity and normality and answers ac queries via a theoryguided algorithm with explanations while acreason does not explicitly construct a causal graph it operates over variables in the underlying causal structure to support principled reasoning to enable comprehensive evaluation we introduce acbench a new benchmark built upon and substantially extending bigbench hard causal judgment bbhcj acbench comprises 1k carefully annotated samples each with detailed reasoning steps and focuses solely on actual causation the case study shows that synthesized samples in acbench present greater challenges for llms extensive experiments on bbhcj and acbench show that acreason consistently improves llm performance over baselines on bbhcj all tested llms surpass the average human rater accuracy of 6960 with gpt4 acreason achieving 7504 on acbench gpt4 acreason again achieves the highest accuracy of 7182 acbench further enables finegrained analysis of reasoning faithfulness revealing that only qwen2572binstruct claude35sonnet and gpt4o exhibit faithful reasoning whereas gpt4 tends to exploit shortcuts finally our ablation study proves that integrating ac theory into llms is highly effective with the proposed algorithm contributing the most significant performance gains
http://arxiv.org/abs/2505.08739v1,2025-05-13T16:52:19Z,"Xiaoliang Luo, Xinyi Xu, Michael Ramscar, Bradley C. Love",probability consistency in large language models theoretical foundations meet empirical discrepancies,can autoregressive large language models llms learn consistent probability distributions when trained on sequences in different token orders we prove formally that for any welldefined probability distribution sequence perplexity is invariant under any factorization including forward backward or arbitrary permutations this result establishes a rigorous theoretical foundation for studying how llms learn from data and defines principled protocols for empirical evaluation applying these protocols we show that prior studies examining ordering effects suffer from critical methodological flaws we retrain gpt2 models across forward backward and arbitrary permuted orders on scientific text we find systematic deviations from theoretical invariance across all orderings with arbitrary permutations strongly deviating from both forward and backward models which largely but not completely agreed with one another deviations were traceable to differences in selfattention reflecting positional and locality biases in processing our theoretical and empirical results provide novel avenues for understanding positional biases in llms and suggest methods for detecting when llms probability distributions are inconsistent and therefore untrustworthy
http://arxiv.org/abs/2505.08734v1,2025-05-13T16:46:25Z,"Ben Yao, Qiuchi Li, Yazhou Zhang, Siyu Yang, Bohan Zhang, Prayag Tiwari, Jing Qin",nurvalues realworld nursing values evaluation for large language models in clinical context,this work introduces the first benchmark for nursing value alignment consisting of five core value dimensions distilled from international nursing codes altruism human dignity integrity justice and professionalism the benchmark comprises 1100 realworld nursing behavior instances collected through a fivemonth longitudinal field study across three hospitals of varying tiers these instances are annotated by five clinical nurses and then augmented with llmgenerated counterfactuals with reversed ethic polarity each original case is paired with a valuealigned and a valueviolating version resulting in 2200 labeled instances that constitute the easylevel dataset to increase adversarial complexity each instance is further transformed into a dialoguebased format that embeds contextual cues and subtle misleading signals yielding a hardlevel dataset we evaluate 23 stateoftheart sota llms on their alignment with nursing values our findings reveal three key insights 1 deepseekv3 achieves the highest performance on the easylevel dataset 9455 where claude 35 sonnet outperforms other models on the hardlevel dataset 8943 significantly surpassing the medical llms 2 justice is consistently the most difficult nursing value dimension to evaluate and 3 incontext learning significantly improves alignment this work aims to provide a foundation for valuesensitive llms development in clinical settings the dataset and the code are available at httpshuggingfacecodatasetsben012345nurvalues
http://arxiv.org/abs/2505.08727v1,2025-05-13T16:37:54Z,Fangyuan Yu,memorizationcompression cycles improve generalization,we prove theoretically that generalization improves not only through data scaling but also by compressing internal representations to operationalize this insight we introduce the information bottleneck language modeling iblm objective which reframes language modeling as a constrained optimization problem minimizing representation entropy subject to optimal prediction performance empirically we observe an emergent memorizationcompression cycle during llm pretraining evidenced by oscillation positivenegative gradient alignment between crossentropy and matrixbased entropy mbe a measure of representation entropy this pattern closely mirrors the predictivecompressive tradeoff prescribed by iblm and also parallels the biological alternation between awake learning and sleep consolidation motivated by this observation we propose gated phase transition gapt a training algorithm that adaptively switches between memorization and compression phases when applied to gpt2 pretraining on fineweb dataset gapt reduces mbe by 50 and improves crossentropy by 48 gapt improves ood generalizatino by 35 in a pretraining task on arithmetic multiplication in a setting designed to simulate catastrophic forgetting gapt reduces interference by compressing and separating representations achieving a 97 improvement in separation paralleling the functional role of sleep consolidation
http://arxiv.org/abs/2505.08704v1,2025-05-13T16:11:29Z,"K M Sajjadul Islam, Ayesha Siddika Nipu, Jiawei Wu, Praveen Madiraju",llmbased prompt ensemble for reliable medical entity recognition from ehrs,electronic health records ehrs are digital records of patient information often containing unstructured clinical text named entity recognition ner is essential in ehrs for extracting key medical entities like problems tests and treatments to support downstream clinical applications this paper explores promptbased medical entity recognition using large language models llms specifically gpt4o and deepseekr1 guided by various prompt engineering techniques including zeroshot fewshot and an ensemble approach among all strategies gpt4o with prompt ensemble achieved the highest classification performance with an f1score of 095 and recall of 098 outperforming deepseekr1 on the task the ensemble method improved reliability by aggregating outputs through embeddingbased similarity and majority voting
http://arxiv.org/abs/2505.08690v1,2025-05-13T15:47:54Z,"Sheng Liang, Hang Lv, Zhihao Wen, Yaxiong Wu, Yongyue Zhang, Hao Wang, Yong Liu",adaptive schemaaware event extraction with retrievalaugmented generation,event extraction ee is a fundamental task in natural language processing nlp that involves identifying and extracting event information from unstructured text effective ee in realworld scenarios requires two key steps selecting appropriate schemas from hundreds of candidates and executing the extraction process existing research exhibits two critical gaps 1 the rigid schema fixation in existing pipeline systems and 2 the absence of benchmarks for evaluating joint schema matching and extraction although large language models llms offer potential solutions their schema hallucination tendencies and context window limitations pose challenges for practical deployment in response we propose adaptive schemaaware event extraction asee a novel paradigm combining schema paraphrasing with schema retrievalaugmented generation asee adeptly retrieves paraphrased schemas and accurately generates targeted structures to facilitate rigorous evaluation we construct the multidimensional schemaaware event extraction mdsee benchmark which systematically consolidates 12 datasets across diverse domains complexity levels and language settings extensive evaluations on mdsee show that our proposed asee demonstrates strong adaptability across various scenarios significantly improving the accuracy of event extraction
http://arxiv.org/abs/2505.08662v1,2025-05-13T15:24:08Z,"Marcus Buckmann, Quynh Anh Nguyen, Edward Hill",revealing economic facts llms know more than they say,we investigate whether the hidden states of large language models llms can be used to estimate and impute economic and financial statistics focusing on countylevel eg unemployment and firmlevel eg total assets variables we show that a simple linear model trained on the hidden states of opensource llms outperforms the models text outputs this suggests that hidden states capture richer economic information than the responses of the llms reveal directly a learning curve analysis indicates that only a few dozen labelled examples are sufficient for training we also propose a transfer learning method that improves estimation accuracy without requiring any labelled data for the target variable finally we demonstrate the practical utility of hiddenstate representations in superresolution and data imputation tasks
http://arxiv.org/abs/2505.08651v1,2025-05-13T15:13:15Z,"Chen Wu, Yin Song",scaling context not parameters training a compact 7b language model for efficient longcontext processing,we present megabeammistral7b a language model that supports 512ktoken context length our work addresses practical limitations in longcontext training supporting realworld tasks such as compliance monitoring and verification evaluated on three longcontext benchmarks our 7bparameter model demonstrates superior incontext learning performance on helmet and robust retrieval and tracing capability on ruler it is currently the only open model to achieve competitive longrange reasoning on babilong at 512k context length without rag or targeted finetuning released as fully open source under the apache 20 license the model has been downloaded over 100000 times on hugging face model available at httpshuggingfacecoawsprototypingmegabeammistral7b512k
http://arxiv.org/abs/2505.08638v2,2025-05-13T14:55:31Z,"Darshan Deshpande, Varun Gangal, Hersh Mehta, Jitin Krishnan, Anand Kannappan, Rebecca Qian",trail trace reasoning and agentic issue localization,the increasing adoption of agentic workflows across diverse domains brings a critical need to scalably and systematically evaluate the complex traces these systems generate current evaluation methods depend on manual domainspecific human analysis of lengthy workflow traces an approach that does not scale with the growing complexity and volume of agentic outputs error analysis in these settings is further complicated by the interplay of external tool outputs and language model reasoning making it more challenging than traditional software debugging in this work we 1 articulate the need for robust and dynamic evaluation methods for agentic workflow traces 2 introduce a formal taxonomy of error types encountered in agentic systems and 3 present a set of 148 large humanannotated traces trail constructed using this taxonomy and grounded in established agentic benchmarks to ensure ecological validity we curate traces from both single and multiagent systems focusing on realworld applications such as software engineering and openworld information retrieval our evaluations reveal that modern long context llms perform poorly at trace debugging with the best gemini25pro model scoring a mere 11 on trail our dataset and code are made publicly available to support and accelerate future research in scalable evaluation for agentic workflows
http://arxiv.org/abs/2505.08622v1,2025-05-13T14:40:22Z,"Donghoon Kim, Minji Bae, Kyuhong Shim, Byonghyo Shim",visually guided decoding gradientfree hard prompt inversion with language models,texttoimage generative models like dalle and stable diffusion have revolutionized visual content creation across various applications including advertising personalized media and design prototyping however crafting effective textual prompts to guide these models remains challenging often requiring extensive trial and error existing prompt inversion approaches such as soft and hard prompt techniques are not so effective due to the limited interpretability and incoherent prompt generation to address these issues we propose visually guided decoding vgd a gradientfree approach that leverages large language models llms and clipbased guidance to generate coherent and semantically aligned prompts in essence vgd utilizes the robust text generation capabilities of llms to produce humanreadable prompts further by employing clip scores to ensure alignment with userspecified visual concepts vgd enhances the interpretability generalization and flexibility of prompt generation without the need for additional training our experiments demonstrate that vgd outperforms existing prompt inversion techniques in generating understandable and contextually relevant prompts facilitating more intuitive and controllable interactions with texttoimage models
http://arxiv.org/abs/2505.08600v1,2025-05-13T14:16:12Z,"Danying Ge, Jianhua Gao, Qizhi Jiang, Yifei Feng, Weixing Ji",automatic task detection and heterogeneous llm speculative decoding,speculative decoding which combines a draft model with a target model has emerged as an effective approach to accelerate large language model llm inference however existing methods often face a tradeoff between the acceptance rate and decoding speed in downstream tasks due to the limited capacity of the draft model making it difficult to ensure efficiency across diverse tasks to address this problem we propose a speculative decoding algorithm tailored for downstream task optimization it includes an automatic task partitioning and assigning method which automatically categorizes downstream tasks into different subtasks and assigns them to a set of heterogeneous draft models each draft model is aligned with the target model using taskspecific data thereby enhancing the consistency of inference results in addition our proposed method incorporates an online lightweight prompt classifier to dynamically route prompts to the appropriate draft model experimental results demonstrate that the proposed method improves draft accuracy by 6 to 50 over vanilla speculative decoding while achieving a speedup of 110x to 264x in llm inference
http://arxiv.org/abs/2505.08590v1,2025-05-13T14:01:35Z,"Hussien Al-Asi, Jordan P Reynolds, Shweta Agarwal, Bryan J Dangott, Aziza Nassar, Zeynettin Akkus",enhancing thyroid cytology diagnosis with ragoptimized llms and pathology foundation models,advancements in artificial intelligence ai are transforming pathology by integrating large language models llms with retrievalaugmented generation rag and domainspecific foundation models this study explores the application of ragenhanced llms coupled with pathology foundation models for thyroid cytology diagnosis addressing challenges in cytological interpretation standardization and diagnostic accuracy by leveraging a curated knowledge base rag facilitates dynamic retrieval of relevant case studies diagnostic criteria and expert interpretation improving the contextual understanding of llms meanwhile pathology foundation models trained on highresolution pathology images refine feature extraction and classification capabilities the fusion of these aidriven approaches enhances diagnostic consistency reduces variability and supports pathologists in distinguishing benign from malignant thyroid lesions our results demonstrate that integrating rag with pathologyspecific llms significantly improves diagnostic efficiency and interpretability paving the way for aiassisted thyroid cytopathology with foundation model uni achieving auc 073093 for correct prediction of surgical pathology diagnosis from thyroid cytology samples
http://arxiv.org/abs/2505.08588v1,2025-05-13T13:58:29Z,"Yumou Wei, Paulo Carvalho, John Stamper",small but significant on the promise of small language models for accessible aied,gpt has become nearly synonymous with large language models llms an increasingly popular term in aied proceedings a simple keywordbased search reveals that 61 of the 76 long and short papers presented at aied 2024 describe novel solutions using llms to address some of the longstanding challenges in education and 43 specifically mention gpt although llms pioneered by gpt create exciting opportunities to strengthen the impact of ai on education we argue that the fields predominant focus on gpt and other resourceintensive llms with more than 10b parameters risks neglecting the potential impact that small language models slms can make in providing resourceconstrained institutions with equitable and affordable access to highquality ai tools supported by positive results on knowledge component kc discovery a critical challenge in aied we demonstrate that slms such as phi2 can produce an effective solution without elaborate prompting strategies hence we call for more attention to developing slmbased aied approaches
http://arxiv.org/abs/2505.08546v1,2025-05-13T13:17:23Z,"Chiara Manna, Afra Alishahi, Frédéric Blain, Eva Vanmassenhove",are we paying attention to her investigating gender disambiguation and attention in machine translation,while gender bias in modern neural machine translation nmt systems has received much attention traditional evaluation metrics do not to fully capture the extent to which these systems integrate contextual gender cues we propose a novel evaluation metric called minimal pair accuracy mpa which measures the reliance of models on gender cues for gender disambiguation mpa is designed to go beyond surfacelevel gender accuracy metrics by focusing on whether models adapt to gender cues in minimal pairs sentence pairs that differ solely in the gendered pronoun namely the explicit indicator of the targets entity gender in the source language en we evaluate a number of nmt models on the englishitalian enit language pair using this metric we show that they ignore available gender cues in most cases in favor of statistical stereotypical gender interpretation we further show that in antistereotypical cases these models tend to more consistently take masculine gender cues into account while ignoring the feminine cues furthermore we analyze the attention head weights in the encoder component and show that while all models encode gender information to some extent masculine cues elicit a more diffused response compared to the more concentrated and specialized responses to feminine gender cues
http://arxiv.org/abs/2505.08842v1,2025-05-13T12:58:11Z,"Zekun Wu, Seonglae Cho, Umar Mohammed, Cristian Munoz, Kleyton Costa, Xin Guan, Theo King, Ze Wang, Emre Kazim, Adriano Koshiyama",libvulnwatch a deep assessment agent system and leaderboard for uncovering hidden vulnerabilities in opensource ai libraries,opensource ai libraries are foundational to modern ai systems but pose significant underexamined risks across security licensing maintenance supply chain integrity and regulatory compliance we present libvulnwatch a graphbased agentic assessment framework that performs deep sourcegrounded evaluations of these libraries built on langgraph the system coordinates a directed acyclic graph of specialized agents to extract verify and quantify risk using evidence from trusted sources such as repositories documentation and vulnerability databases libvulnwatch generates reproducible governancealigned scores across five critical domains publishing them to a public leaderboard for longitudinal ecosystem monitoring applied to 20 widely used libraries including ml frameworks llm inference engines and agent orchestration tools our system covers up to 88 of openssf scorecard checks while uncovering up to 19 additional risks per library these include critical remote code execution rce vulnerabilities absent software bills of materials sboms licensing constraints undocumented telemetry and widespread gaps in regulatory documentation and auditability by translating highlevel governance principles into practical verifiable metrics libvulnwatch advances technical ai governance with a scalable transparent mechanism for continuous supply chain risk assessment and informed library selection
http://arxiv.org/abs/2505.08504v1,2025-05-13T12:36:02Z,"Jeongwoo Kang, Maximin Coavoux, Cédric Lopez, Didier Schwab",reassessing graph linearization for sequencetosequence amr parsing on the advantages and limitations of triplebased encoding,sequencetosequence models are widely used to train abstract meaning representation banarescu et al 2013 amr parsers to train such models amr graphs have to be linearized into a oneline text format while penman encoding is typically used for this purpose we argue that it has limitations 1 for deep graphs some closely related nodes are located far apart in the linearized text 2 penmans treebased encoding necessitates inverse roles to handle node reentrancy doubling the number of relation types to predict to address these issues we propose a triplebased linearization method and compare its efficiency with penman linearization although triples are well suited to represent a graph our results suggest room for improvement in triple encoding to better compete with penmans concise and explicit representation of a nested graph structure
http://arxiv.org/abs/2505.08498v1,2025-05-13T12:26:16Z,"Takumi Shibata, Yuichi Miyamura",lces zeroshot automated essay scoring via pairwise comparisons using large language models,recent advances in large language models llms have enabled zeroshot automated essay scoring aes providing a promising way to reduce the cost and effort of essay scoring in comparison with manual grading however most existing zeroshot approaches rely on llms to directly generate absolute scores which often diverge from human evaluations owing to model biases and inconsistent scoring to address these limitations we propose llmbased comparative essay scoring lces a method that formulates aes as a pairwise comparison task specifically we instruct llms to judge which of two essays is better collect many such comparisons and convert them into continuous scores considering that the number of possible comparisons grows quadratically with the number of essays we improve scalability by employing ranknet to efficiently transform llm preferences into scalar scores experiments using aes benchmark datasets show that lces outperforms conventional zeroshot methods in accuracy while maintaining computational efficiency moreover lces is robust across different llm backbones highlighting its applicability to realworld zeroshot aes
http://arxiv.org/abs/2505.08468v1,2025-05-13T11:50:08Z,"Md Tahmid Rahman Laskar, Mohammed Saidul Islam, Ridwan Mahbub, Ahmed Masry, Mizanur Rahman, Amran Bhuiyan, Mir Tafseer Nayeem, Shafiq Joty, Enamul Hoque, Jimmy Huang",judging the judges can large visionlanguage models fairly evaluate chart comprehension and reasoning,charts are ubiquitous as they help people understand and reason with data recently various downstream tasks such as chart question answering chart2text and factchecking have emerged large visionlanguage models lvlms show promise in tackling these tasks but their evaluation is costly and timeconsuming limiting realworld deployment while using lvlms as judges to assess the chart comprehension capabilities of other lvlms could streamline evaluation processes challenges like proprietary datasets restricted access to powerful models and evaluation costs hinder their adoption in industrial settings to this end we present a comprehensive evaluation of 13 opensource lvlms as judges for diverse chart comprehension and reasoning tasks we design both pairwise and pointwise evaluation tasks covering criteria like factual correctness informativeness and relevancy additionally we analyze lvlm judges based on format adherence positional consistency length bias and instructionfollowing we focus on costeffective lvlms 10b parameters suitable for both research and commercial use following a standardized evaluation protocol and rubric to measure the lvlm judges accuracy experimental results reveal notable variability while some open lvlm judges achieve gpt4level evaluation performance about 80 agreement with gpt4 judgments others struggle below 10 agreement our findings highlight that stateoftheart opensource lvlms can serve as costeffective automatic evaluators for chartrelated tasks though biases such as positional preference and length bias persist
http://arxiv.org/abs/2505.08464v1,2025-05-13T11:47:49Z,"Lata Pangtey, Anukriti Bhatnagar, Shubhi Bansal, Shahid Shafi Dar, Nagendra Kumar",large language models meet stance detection a survey of tasks methods applications challenges and future directions,stance detection is essential for understanding subjective content across various platforms such as social media news articles and online reviews recent advances in large language models llms have revolutionized stance detection by introducing novel capabilities in contextual understanding crossdomain generalization and multimodal analysis despite these progressions existing surveys often lack comprehensive coverage of approaches that specifically leverage llms for stance detection to bridge this critical gap our review article conducts a systematic analysis of stance detection comprehensively examining recent advancements of llms transforming the field including foundational concepts methodologies datasets applications and emerging challenges we present a novel taxonomy for llmbased stance detection approaches structured along three key dimensions 1 learning methods including supervised unsupervised fewshot and zeroshot 2 data modalities such as unimodal multimodal and hybrid and 3 target relationships encompassing intarget crosstarget and multitarget scenarios furthermore we discuss the evaluation techniques and analyze benchmark datasets and performance trends highlighting the strengths and limitations of different architectures key applications in misinformation detection political analysis public health monitoring and social media moderation are discussed finally we identify critical challenges such as implicit stance expression cultural biases and computational constraints while outlining promising future directions including explainable stance reasoning lowresource adaptation and realtime deployment frameworks our survey highlights emerging trends open challenges and future directions to guide researchers and practitioners in developing nextgeneration stance detection systems powered by large language models
http://arxiv.org/abs/2505.08463v1,2025-05-13T11:47:00Z,"Fujun Zhang, XiangDong Su",repcali high efficient finetuning via representation calibration in latent space for pretrained language models,finetuning pretrained language models plms has become a dominant paradigm in applying plms to downstream tasks however with limited finetuning plms still struggle with the discrepancies between the representation obtained from the plms encoder and the optimal input to the plms decoder this paper tackles this challenge by learning to calibrate the representation of plms in the latent space in the proposed representation calibration method repcali we integrate a specific calibration block to the latent space after the encoder and use the calibrated output as the decoder input the merits of the proposed repcali include its universality to all plms with encoderdecoder architectures its plugandplay nature and ease of implementation extensive experiments on 25 plmbased models across 8 tasks including both english and chinese datasets demonstrate that the proposed repcali offers desirable enhancements to plms including llms and significantly improves the performance of downstream tasks comparison experiments across 4 benchmark tasks indicate that repcali is superior to the representative finetuning baselines
http://arxiv.org/abs/2505.08450v1,2025-05-13T11:25:15Z,"Kazuki Hayashi, Hidetaka Kamigaito, Shinya Kouda, Taro Watanabe",iterkey iterative keyword generation with llms for enhanced retrieval augmented generation,retrievalaugmented generation rag has emerged as a way to complement the incontext knowledge of large language models llms by integrating external documents however realworld applications demand not only accuracy but also interpretability while dense retrieval methods provide high accuracy they lack interpretability conversely sparse retrieval methods offer transparency but often fail to capture the full intent of queries due to their reliance on keyword matching to address these issues we introduce iterkey an llmdriven iterative keyword generation framework that enhances rag via sparse retrieval iterkey consists of three llmdriven stages generating keywords for retrieval generating answers based on retrieved documents and validating the answers if validation fails the process iteratively repeats with refined keywords across four qa tasks experimental results show that iterkey achieves 5 to 20 accuracy improvements over bm25based rag and simple baselines its performance is comparable to dense retrievalbased rag and prior iterative query refinement methods using dense models in summary iterkey is a novel bm25based approach leveraging llms to iteratively refine rag effectively balancing accuracy with interpretability
http://arxiv.org/abs/2505.08445v1,2025-05-13T11:13:27Z,"Adel Ammar, Anis Koubaa, Omer Nacar, Wadii Boulila",optimizing retrievalaugmented generation analysis of hyperparameter impact on performance and efficiency,large language models achieve high task performance yet often hallucinate or rely on outdated knowledge retrievalaugmented generation rag addresses these gaps by coupling generation with external search we analyse how hyperparameters influence speed and quality in rag systems covering chroma and faiss vector stores chunking policies crossencoder reranking and temperature and we evaluate six metrics faithfulness answer correctness answer relevancy context precision context recall and answer similarity chroma processes queries 13 faster whereas faiss yields higher retrieval precision revealing a clear speedaccuracy tradeoff naive fixedlength chunking with small windows and minimal overlap outperforms semantic segmentation while remaining the quickest option reranking provides modest gains in retrieval quality yet increases runtime by roughly a factor of 5 so its usefulness depends on latency constraints these results help practitioners balance computational cost and accuracy when tuning rag systems for transparent uptodate responses finally we reevaluate the top configurations with a corrective rag workflow and show that their advantages persist when the model can iteratively request additional evidence we obtain a nearperfect context precision 99 which demonstrates that rag systems can achieve extremely high retrieval accuracy with the right combination of hyperparameters with significant implications for applications where retrieval quality directly impacts downstream task performance such as clinical decision support in healthcare
http://arxiv.org/abs/2505.08439v1,2025-05-13T11:06:24Z,"Matteo Marulli, Glauco Panattoni, Marco Bertini",a document processing pipeline for the construction of a dataset for topic modeling based on the judgments of the italian supreme court,topic modeling in italian legal research is hindered by the lack of public datasets limiting the analysis of legal themes in supreme court judgments to address this we developed a document processing pipeline that produces an anonymized dataset optimized for topic modeling the pipeline integrates document layout analysis yolov8x optical character recognition and text anonymization the dla module achieved a map50 of 0964 and a map5095 of 0800 the ocr detector reached a map5095 of 09022 and the text recognizer trocr obtained a character error rate of 00047 and a word error rate of 00248 compared to ocronly methods our dataset improved topic modeling with a diversity score of 06198 and a coherence score of 06638 we applied bertopic to extract topics and used large language models to generate labels and summaries outputs were evaluated against domain expert interpretations claude sonnet 37 achieved a bertscore f1 of 08119 for labeling and 09130 for summarization
http://arxiv.org/abs/2505.08435v2,2025-05-13T10:57:32Z,"Mehran Sarmadi, Morteza Alikhani, Erfan Zinvandi, Zahra Pourbahman",hakim farsi text embedding model,recent advancements in text embedding have significantly improved natural language understanding across many languages yet persian remains notably underrepresented in largescale embedding research in this paper we present hakim a novel stateoftheart persian text embedding model that achieves a 85 performance improvement over existing approaches on the famteb benchmark outperforming all previously developed persian language models as part of this work we introduce three new datasets corpesia pairsiasup and pairsiaunsup to support supervised and unsupervised training scenarios additionally hakim is designed for applications in chatbots and retrievalaugmented generation rag systems particularly addressing retrieval tasks that require incorporating message history within these systems we also propose a new baseline model built on the bert architecture our language model consistently achieves higher accuracy across various persian nlp tasks while the retromaebased model proves particularly effective for textual information retrieval applications together these contributions establish a new foundation for advancing persian language understanding
http://arxiv.org/abs/2505.08402v1,2025-05-13T09:57:28Z,"Aiyao He, Sijia Cui, Shuai Xu, Yanna Wang, Bo Xu",tums enhancing tooluse abilities of llms with multistructure handlers,recently large language modelsllms have played an increasingly important role in solving a wide range of nlp tasks leveraging their capabilities of natural language understanding and generating integration with external tools further enhances llms effectiveness providing more precise timely and specialized responses however llms still encounter difficulties with nonexecutable actions and improper actions which are primarily attributed to incorrect parameters the process of generating parameters by llms is confined to the tool level employing the coarsegrained strategy without considering the different difficulties of various tools to address this issue we propose tums a novel framework designed to enhance the tooluse capabilities of llms by transforming toollevel processing into parameterlevel processing specifically our framework consists of four key components 1 an intent recognizer that identifies the users intent to help llms better understand the task 2 a task decomposer that breaks down complex tasks into simpler subtasks each involving a tool call 3 a subtask processor equipped with multistructure handlers to generate accurate parameters and 4 an executor our empirical studies have evidenced the effectiveness and efficiency of the tums framework with an average of 196 and 506 improvement separately on easy and hard benchmarks of toolqa meanwhile we demonstrated the key contribution of each part with ablation experiments offering more insights and stimulating future research on toolaugmented llms
http://arxiv.org/abs/2505.08392v2,2025-05-13T09:39:18Z,"Ren Zhuang, Ben Wang, Shuifa Sun",accelerating chainofthought reasoning when goalgradient importance meets dynamic skipping,large language models leverage chainofthought cot prompting for complex tasks but their reasoning traces are often excessively verbose and inefficient leading to significant computational costs and latency current cot compression techniques typically rely on generic importance metrics and static compression rates which may inadvertently remove functionally critical tokens or fail to adapt to varying reasoning complexity to overcome these limitations we propose adaptive gogiskip a novel framework learning dynamic cot compression via supervised finetuning this approach introduces two synergistic innovations 1 goalgradient importance gogi a novel metric accurately identifying functionally relevant tokens by measuring the gradient influence of their intermediate representations on the final answer loss and 2 adaptive dynamic skipping ads a mechanism dynamically regulating the compression rate based on runtime model uncertainty while ensuring local coherence through an adaptive ntoken constraint to our knowledge this is the first work unifying a goaloriented gradientbased importance metric with dynamic uncertaintyaware skipping for cot compression trained on compressed math data adaptive gogiskip demonstrates strong crossdomain generalization across diverse reasoning benchmarks including aime gpqa and gsm8k it achieves substantial efficiency gains reducing cot token counts by over 45 on average and delivering 1620 times inference speedups while maintaining high reasoning accuracy notably it significantly outperforms existing baselines by preserving accuracy even at high effective compression rates advancing the state of the art in the cot reasoning efficiencyaccuracy tradeoff
http://arxiv.org/abs/2505.08389v1,2025-05-13T09:35:40Z,"Rahmatullah Musawi, Sheng Lu",towards contamination resistant benchmarks,the rapid development of large language models llms has transformed the landscape of natural language processing evaluating llms properly is crucial for understanding their potential and addressing concerns such as safety however llm evaluation is confronted by various factors among which contamination stands out as a key issue that undermines the reliability of evaluations in this work we introduce the concept of contamination resistance to address this challenge we propose a benchmark based on caesar ciphers eg ab to bc when the shift is 1 which despite its simplicity is an excellent example of a contamination resistant benchmark we test this benchmark on widely used llms under various settings and we find that these models struggle with this benchmark when contamination is controlled our findings reveal issues in current llms and raise important questions regarding their true capabilities our work contributes to the development of contamination resistant benchmarks enabling more rigorous llm evaluation and offering insights into the true capabilities and limitations of llms
http://arxiv.org/abs/2505.08351v1,2025-05-13T08:50:57Z,"Mina Almasi, Ross Deans Kristensen-McLachlan",alignment drift in cefrprompted llms for interactive spanish tutoring,this paper investigates the potentials of large language models llms as adaptive tutors in the context of secondlanguage learning in particular we evaluate whether system prompting can reliably constrain llms to generate only text appropriate to the students competence level we simulate full teacherstudent dialogues in spanish using instructiontuned opensource llms ranging in size from 7b to 12b parameters dialogues are generated by having an llm alternate between tutor and student roles with separate chat histories the output from the tutor model is then used to evaluate the effectiveness of cefrbased prompting to control text difficulty across three proficiency levels a1 b1 c1 our findings suggest that while system prompting can be used to constrain model outputs prompting alone is too brittle for sustained longterm interactional contexts a phenomenon we term alignment drift our results provide insights into the feasibility of llms for personalized proficiencyaligned adaptive tutors and provide a scalable method for lowcost evaluation of model performance without human participants
http://arxiv.org/abs/2505.08348v1,2025-05-13T08:46:04Z,"Yize Zhao, Christos Thrampoulidis",on the geometry of semantics in nexttoken prediction,modern language models demonstrate a remarkable ability to capture linguistic meaning despite being trained solely through nexttoken prediction ntp we investigate how this conceptually simple training objective leads models to extract and encode latent semantic and grammatical concepts our analysis reveals that ntp optimization implicitly guides models to encode concepts via singular value decomposition svd factors of a centered datasparsity matrix that captures nextword cooccurrence patterns while the model never explicitly constructs this matrix learned word and context embeddings effectively factor it to capture linguistic structure we find that the most important svd factors are learned first during training motivating the use of spectral clustering of embeddings to identify humaninterpretable semantics including both classical kmeans and a new orthantbased method directly motivated by our interpretation of concepts overall our work bridges distributional semantics neural collapse geometry and neural network training dynamics providing insights into how ntps implicit biases shape the emergence of meaning representations in language models
http://arxiv.org/abs/2505.08311v1,2025-05-13T07:41:15Z,"Yunjie Ji, Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Han Zhao, Xiangang Li",amthinkingv1 advancing the frontier of reasoning at 32b scale,we present amthinkingv1 a 32b dense language model that advances the frontier of reasoning embodying the collaborative spirit of opensource innovation outperforming deepseekr1 and rivaling leading mixtureofexperts moe models like qwen3235ba22b and seed15thinking amthinkingv1 achieves impressive scores of 853 on aime 2024 744 on aime 2025 and 703 on livecodebench showcasing stateoftheart mathematical and coding capabilities among opensource models of similar scale built entirely from the opensource qwen2532b base model and publicly available queries amthinkingv1 leverages a meticulously crafted posttraining pipeline combining supervised finetuning and reinforcement learning to deliver exceptional reasoning capabilities this work demonstrates that the opensource community can achieve high performance at the 32b scale a practical sweet spot for deployment and finetuning by striking a balance between toptier performance and realworld usability we hope amthinkingv1 inspires further collaborative efforts to harness midscale models pushing reasoning boundaries while keeping accessibility at the core of innovation we have opensourced our model on hrefhttpshuggingfacecoamteamamthinkingv1hugging face
http://arxiv.org/abs/2505.08303v1,2025-05-13T07:26:56Z,"Ziyu Zhou, Yihang Wu, Jingyuan Yang, Zhan Xiao, Rongjun Li",evaluating the effectiveness of blackbox prompt optimization as the scale of llms continues to grow,blackbox prompt optimization methods have emerged as a promising strategy for refining input prompts to better align large language models llms thereby enhancing their task performance although these methods have demonstrated encouraging results most studies and experiments have primarily focused on smallerscale models eg 7b 14b or earlier versions eg gpt35 of llms as the scale of llms continues to increase such as with deepseek v3 671b it remains an open question whether these blackbox optimization techniques will continue to yield significant performance improvements for models of such scale in response to this we select three wellknown blackbox optimization methods and evaluate them on largescale llms deepseek v3 and gemini 20 flash across four nlu and nlg datasets the results show that these blackbox prompt optimization methods offer only limited improvements on these largescale llms furthermore we hypothesize that the scale of the model is the primary factor contributing to the limited benefits observed to explore this hypothesis we conducted experiments on llms of varying sizes qwen 25 series ranging from 7b to 72b and observed an inverse scaling law wherein the effectiveness of blackbox optimization methods diminished as the model size increased
http://arxiv.org/abs/2505.09649v1,2025-05-13T06:59:10Z,"Abisha Thapa Magar, Anup Shakya",next word suggestion using graph neural network,language modeling is a prevalent task in natural language processing the currently existing most recent and most successful language models often tend to build a massive model with billions of parameters feed in a tremendous amount of text data and train with enormous computation resources which require millions of dollars in this project we aim to address an important subtask in language modeling ie context embedding we propose an approach to exploit the graph convolution operation in gnns to encode the context and use it in coalition with lstms to predict the next word given a local context of preceding words we test this on the custom wikipedia text corpus using a very limited amount of resources and show that this approach works fairly well to predict the next word
http://arxiv.org/abs/2505.08261v1,2025-05-13T06:24:48Z,"Rishabh Agrawal, Himanshu Kumar",enhancing cacheaugmented generation cag with adaptive contextual compression for scalable knowledge integration,the rapid progress in large language models llms has paved the way for novel approaches in knowledgeintensive tasks among these cacheaugmented generation cag has emerged as a promising alternative to retrievalaugmented generation rag cag minimizes retrieval latency and simplifies system design by preloading knowledge into the models context however challenges persist in scaling cag to accommodate large and dynamic knowledge bases effectively this paper introduces adaptive contextual compression acc an innovative technique designed to dynamically compress and manage context inputs enabling efficient utilization of the extended memory capabilities of modern llms to further address the limitations of standalone cag we propose a hybrid cagrag framework which integrates selective retrieval to augment preloaded contexts in scenarios requiring additional information comprehensive evaluations on diverse datasets highlight the proposed methods ability to enhance scalability optimize efficiency and improve multihop reasoning performance offering practical solutions for realworld knowledge integration challenges
http://arxiv.org/abs/2505.08245v1,2025-05-13T05:47:51Z,"Haoran Ye, Jing Jin, Yuhang Xie, Xin Zhang, Guojie Song",large language model psychometrics a systematic review of evaluation validation and enhancement,the rapid advancement of large language models llms has outpaced traditional evaluation methodologies it presents novel challenges such as measuring humanlike psychological constructs navigating beyond static and taskspecific benchmarks and establishing humancentered evaluation these challenges intersect with psychometrics the science of quantifying the intangible aspects of human psychology such as personality values and intelligence this survey introduces and synthesizes an emerging interdisciplinary field of llm psychometrics which leverages psychometric instruments theories and principles to evaluate understand and enhance llms we systematically explore the role of psychometrics in shaping benchmarking principles broadening evaluation scopes refining methodologies validating results and advancing llm capabilities this paper integrates diverse perspectives to provide a structured framework for researchers across disciplines enabling a more comprehensive understanding of this nascent field ultimately we aim to provide actionable insights for developing future evaluation paradigms that align with humanlevel ai and promote the advancement of humancentered ai systems for societal benefit a curated repository of llm psychometric resources is available at httpsgithubcomvaluebyteaiawesomellmpsychometrics
http://arxiv.org/abs/2505.08203v1,2025-05-13T03:33:36Z,Li Zhang,not that groove zeroshot symbolic music editing,most work in ai music generation focused on audio which has seen limited use in the music production industry due to its rigidity to maximize flexibility while assuming only textual instructions from producers we are among the first to tackle symbolic music editing we circumvent the known challenge of lack of labeled data by proving that llms with zeroshot prompting can effectively edit drum grooves the recipe of success is a creatively designed format that interfaces llms and music while we facilitate evaluation by providing an evaluation dataset with annotated unit tests that highly aligns with musicians judgment
http://arxiv.org/abs/2505.08200v1,2025-05-13T03:30:26Z,"Artem Shelmanov, Ekaterina Fadeeva, Akim Tsvigun, Ivan Tsvigun, Zhuohan Xie, Igor Kiselev, Nico Daheim, Caiqi Zhang, Artem Vazhentsev, Mrinmaya Sachan, Preslav Nakov, Timothy Baldwin",a head to predict and a head to question pretrained uncertainty quantification heads for hallucination detection in llm outputs,large language models llms have the tendency to hallucinate ie to sporadically generate false or fabricated information this presents a major challenge as hallucinations often appear highly convincing and users generally lack the tools to detect them uncertainty quantification uq provides a framework for assessing the reliability of model outputs aiding in the identification of potential hallucinations in this work we introduce pretrained uq heads supervised auxiliary modules for llms that substantially enhance their ability to capture uncertainty compared to unsupervised uq methods their strong performance stems from the powerful transformer architecture in their design and informative features derived from llm attention maps experimental evaluation shows that these heads are highly robust and achieve stateoftheart performance in claimlevel hallucination detection across both indomain and outofdomain prompts moreover these modules demonstrate strong generalization to languages they were not explicitly trained on we pretrain a collection of uq heads for popular llm series including mistral llama and gemma 2 we publicly release both the code and the pretrained heads
http://arxiv.org/abs/2505.08168v1,2025-05-13T02:06:08Z,"Yuxiang Wang, Xiao Yan, Shiyu Jin, Quanqing Xu, Chuang Hu, Yuanyuan Zhu, Bo Du, Jia Wu, Jiawei Jiang",exploiting text semantics for few and zero shot node classification on textattributed graph,textattributed graph tag provides a text description for each graph node and few and zeroshot node classification on tags have many applications in fields such as academia and social networks existing work utilizes various graphbased augmentation techniques to train the node and text embeddings while textbased augmentations are largely unexplored in this paper we propose text semantics augmentation tsa to improve accuracy by introducing more text semantic supervision signals specifically we design two augmentation techniques ie positive semantics matching and negative semantics contrast to provide more reference texts for each graph node or text description positive semantic matching retrieves texts with similar embeddings to match with a graph node negative semantic contrast adds a negative prompt to construct a text description with the opposite semantics which is contrasted with the original node and text we evaluate tsa on 5 datasets and compare with 13 stateoftheart baselines the results show that tsa consistently outperforms all baselines and its accuracy improvements over the bestperforming baseline are usually over 5
http://arxiv.org/abs/2505.08167v2,2025-05-13T02:05:25Z,"Ruilin Liu, Zhixiao Zhao, Jieqiong Li, Chang Liu, Dongbo Wang",fusing bidirectional chains of thought and reward mechanisms a method for enhancing questionanswering capabilities of large language models for chinese intangible cultural heritage,the rapid development of large language models llms has provided significant support and opportunities for the advancement of domainspecific llms however finetuning these large models using intangible cultural heritage ich data inevitably faces challenges such as bias incorrect knowledge inheritance and catastrophic forgetting to address these issues we propose a novel training method that integrates a bidirectional chains of thought and a reward mechanism this method is built upon ichqwen a large language model specifically designed for the field of intangible cultural heritage the proposed method enables the model to not only perform forward reasoning but also enhances the accuracy of the generated answers by utilizing reverse questioning and reverse reasoning to activate the models latent knowledge additionally a reward mechanism is introduced during training to optimize the decisionmaking process this mechanism improves the quality of the models outputs through structural and content evaluations with different weighting schemes we conduct comparative experiments on ichqwen with results demonstrating that our method outperforms 0shot stepbystep reasoning knowledge distillation and question augmentation methods in terms of accuracy bleu4 and rougel scores on the questionanswering task furthermore the paper highlights the effectiveness of combining the bidirectional chains of thought and reward mechanism through ablation experiments in addition a series of generalizability experiments are conducted with results showing that the proposed method yields improvements on various domainspecific datasets and advanced models in areas such as finance wikidata and strategyqa this demonstrates that the method is adaptable to multiple domains and provides a valuable approach for model training in future applications across diverse fields
http://arxiv.org/abs/2505.08148v1,2025-05-13T00:51:07Z,"Sunday Oyinlola Ogundoyin, Muhammad Ikram, Hassan Jameel Asghar, Benjamin Zi Hao Zhao, Dali Kaafar",a largescale empirical analysis of custom gpts vulnerabilities in the openai ecosystem,millions of users leverage generative pretrained transformer gptbased language models developed by leading model providers for a wide range of tasks to support enhanced user interaction and customization many platformssuch as openainow enable developers to create and publish tailored model instances known as custom gpts via dedicated repositories or application stores these custom gpts empower users to browse and interact with specialized applications designed to meet specific needs however as custom gpts see growing adoption concerns regarding their security vulnerabilities have intensified existing research on these vulnerabilities remains largely theoretical often lacking empirical largescale and statistically rigorous assessments of associated risks in this study we analyze 14904 custom gpts to assess their susceptibility to seven exploitable threats such as roleplaybased attacks system prompt leakage phishing content generation and malicious code synthesis across various categories and popularity tiers within the openai marketplace we introduce a multimetric ranking system to examine the relationship between a custom gpts popularity and its associated security risks our findings reveal that over 95 of custom gpts lack adequate security protections the most prevalent vulnerabilities include roleplaybased vulnerabilities 9651 system prompt leakage 9220 and phishing 9122 furthermore we demonstrate that openais foundational models exhibit inherent security weaknesses which are often inherited or amplified in custom gpts these results highlight the urgent need for enhanced security measures and stricter content moderation to ensure the safe deployment of gptbased applications
http://arxiv.org/abs/2505.08828v1,2025-05-13T00:36:36Z,"Eduardo Araujo Oliveira, Madhavi Mohoni, Sonsoles López-Pernas, Mohammed Saqr",humanai collaboration or academic misconduct measuring ai use in student writing through stylometric evidence,as humanai collaboration becomes increasingly prevalent in educational contexts understanding and measuring the extent and nature of such interactions pose significant challenges this research investigates the use of authorship verification av techniques not as a punitive measure but as a means to quantify ai assistance in academic writing with a focus on promoting transparency interpretability and student development building on prior work we structured our investigation into three stages dataset selection and expansion av method development and systematic evaluation using three datasets including a public dataset pan14 and two from university of melbourne students from various courses we expanded the data to include llmgenerated texts totalling 1889 documents and 540 authorship problems from 506 students we developed an adapted feature vector difference av methodology to construct robust academic writing profiles for students designed to capture meaningful individual characteristics of their writing the methods effectiveness was evaluated across multiple scenarios including distinguishing between studentauthored and llmgenerated texts and testing resilience against llms attempts to mimic student writing styles results demonstrate the enhanced av classifiers ability to identify stylometric discrepancies and measure humanai collaboration at word and sentence levels while providing educators with a transparent tool to support academic integrity investigations this work advances av technology offering actionable insights into the dynamics of academic writing in an aidriven era
http://arxiv.org/abs/2505.08137v1,2025-05-13T00:19:04Z,"Licheng Zhang, Bach Le, Naveed Akhtar, Siew-Kei Lam, Tuan Ngo",large language models for computeraided design a survey,large language models llms have seen rapid advancements in recent years with models like chatgpt and deepseek showcasing their remarkable capabilities across diverse domains while substantial research has been conducted on llms in various fields a comprehensive review focusing on their integration with computeraided design cad remains notably absent cad is the industry standard for 3d modeling and plays a vital role in the design and development of products across different industries as the complexity of modern designs increases the potential for llms to enhance and streamline cad workflows presents an exciting frontier this article presents the first systematic survey exploring the intersection of llms and cad we begin by outlining the industrial significance of cad highlighting the need for aidriven innovation next we provide a detailed overview of the foundation of llms we also examine both closedsource llms as well as publicly available models the core of this review focuses on the various applications of llms in cad providing a taxonomy of six key areas where these models are making considerable impact finally we propose several promising future directions for further advancements which offer vast opportunities for innovation and are poised to shape the future of cad technology github httpsgithubcomlichengzhanguomllmscadsurveytaxonomy
http://arxiv.org/abs/2505.08130v1,2025-05-13T00:01:03Z,"Mingxu Tao, Bowen Tang, Mingxuan Ma, Yining Zhang, Hourun Li, Feifan Wen, Hao Ma, Jia Yang",aloha empowering multilingual agent for university orientation with hierarchical retrieval,the rise of large language modelsllms revolutionizes information retrieval allowing users to obtain required answers through complex instructions within conversations however publicly available services remain inadequate in addressing the needs of faculty and students to search campusspecific information it is primarily due to the llms lack of domainspecific knowledge and the limitation of search engines in supporting multilingual and timely scenarios to tackle these challenges we introduce aloha a multilingual agent enhanced by hierarchical retrieval for university orientation we also integrate external apis into the frontend interface to provide interactive service the human evaluation and case study show our proposed system has strong capabilities to yield correct timely and userfriendly responses to the queries in multiple languages surpassing commercial chatbots and search engines the system has been deployed and has provided service for more than 12000 people
http://arxiv.org/abs/2505.08120v1,2025-05-12T23:22:27Z,"Mingjian Jiang, Yangjun Ruan, Luis Lastras, Pavan Kapanipathi, Tatsunori Hashimoto",putting it all into context simplifying agents with lclms,recent advances in language model lm agents have demonstrated significant potential for automating complex realworld tasks to make progress on these difficult tasks lm agent architectures have become increasingly complex often incorporating multistep retrieval tools multiple agents and scaffolding adapted to the underlying lm in this work we investigate whether all of this complexity is necessary or if parts of these scaffolds can be removed on challenging tasks like swebench we show that in the case of swebench simply putting the entire environment into the context of a long context language model lclm and properly prompting the model makes it competitive with carefully tuned complex agent scaffolds we show that a gemini15pro model without any scaffolding or tools achieves 38 on swebenchverified comparable with approaches using carefully tuned agent scaffolds 32 while the unscaffolded approach with gemini15pro falls short of the strongest agentic architectures we demonstrate that the more capable gemini25pro using the same unscaffolded approach directly attains a 508 solve rate additionally a twostage approach combining gemini15pro with claude37 achieves a competitive 486 solve rate
http://arxiv.org/abs/2505.08106v1,2025-05-12T22:35:07Z," Jiashen,  Du, Jesse Yao, Allen Liu, Zhekai Zhang",are llms complicated ethical dilemma analyzers,one open question in the study of large language models llms is whether they can emulate human ethical reasoning and act as believable proxies for human judgment to investigate this we introduce a benchmark dataset comprising 196 realworld ethical dilemmas and expert opinions each segmented into five structured components introduction key factors historical theoretical perspectives resolution strategies and key takeaways we also collect nonexpert human responses for comparison limited to the key factors section due to their brevity we evaluate multiple frontier llms gpt4omini claude35sonnet deepseekv3 gemini15flash using a composite metric framework based on bleu dameraulevenshtein distance tfidf cosine similarity and universal sentence encoder similarity metric weights are computed through an inversionbased ranking alignment and pairwise ahp analysis enabling finegrained comparison of model outputs to expert responses our results show that llms generally outperform nonexpert humans in lexical and structural alignment with gpt4omini performing most consistently across all sections however all models struggle with historical grounding and proposing nuanced resolution strategies which require contextual abstraction human responses while less structured occasionally achieve comparable semantic similarity suggesting intuitive moral reasoning these findings highlight both the strengths and current limitations of llms in ethical decisionmaking
http://arxiv.org/abs/2505.08080v1,2025-05-12T21:29:12Z,"Dong Shu, Xuansheng Wu, Haiyan Zhao, Mengnan Du, Ninghao Liu",beyond input activations identifying influential latents by gradient sparse autoencoders,sparse autoencoders saes have recently emerged as powerful tools for interpreting and steering the internal representations of large language models llms however conventional approaches to analyzing saes typically rely solely on inputside activations without considering the causal influence between each latent feature and the models output this work is built on two key hypotheses 1 activated latents do not contribute equally to the construction of the models output and 2 only latents with high causal influence are effective for model steering to validate these hypotheses we propose gradient sparse autoencoder gradsae a simple yet effective method that identifies the most influential latents by incorporating outputside gradient information
http://arxiv.org/abs/2505.08823v1,2025-05-12T21:14:29Z,"Cody Steinmetz, Gavin Childress, Aaron Herbst, Gavin Jones, Jasdeep Singh, Eli Vang, Keagan Weinstock",an extra rmsnorm is all you need for fine tuning to 158 bits,large language models llms have transformed naturallanguage processing yet their scale makes realworld deployment costly posttraining quantization reduces memory and computation but often degrades accuracy while quantizationaware training can recover performance at the cost of extra training pushing quantization to the ternary 2bit regime yields even larger savings but is notoriously unstable building on recent work showing that a biasfree rmsnormalized transformer with straightthrough estimation can reach 158bit precision we demonstrate that simply inserting rms normalization before every linear projection and applying a gradual layerwise quantization schedule stably finetunes fullprecision checkpoints into ternary llms our approach matches or surpasses more elaborate knowledgedistillation pipelines on standard languagemodeling benchmarks without adding model complexity these results indicate that careful normalization alone can close much of the accuracy gap between ternary and fullprecision llms making ultralowbit inference practical
http://arxiv.org/abs/2505.08058v2,2025-05-12T20:49:50Z,"Chris Forrester, Octavia Sulea",hypernym mercury token optimization through semantic field constriction and reconstruction from hypernyms a new text compression method,compute optimization using token reduction of llm prompts is an emerging task in the fields of nlp and next generation agentic ai in this white paper we introduce a novel patent pending text representation scheme and a firstofitskind wordlevel semantic compression of paragraphs that can lead to over 90 token reduction while retaining high semantic similarity to the source text we explain how this novel compression technique can be lossless and how the detail granularity is controllable we discuss benchmark results over open source data ie bram stokers dracula available through project gutenberg and show how our results hold at the paragraph level across multiple genres and models
http://arxiv.org/abs/2505.08054v1,2025-05-12T20:45:25Z,"Zhehao Zhang, Weijie Xu, Fanyou Wu, Chandan K. Reddy",falsereject a resource for improving contextual safety and mitigating overrefusals in llms via structured reasoning,safety alignment approaches in large language models llms often lead to the overrefusal of benign queries significantly diminishing their utility in sensitive scenarios to address this challenge we introduce falsereject a comprehensive resource containing 16k seemingly toxic queries accompanied by structured responses across 44 safetyrelated categories we propose a graphinformed adversarial multiagent interaction framework to generate diverse and complex prompts while structuring responses with explicit reasoning to aid models in accurately distinguishing safe from unsafe contexts falsereject includes training datasets tailored for both standard instructiontuned models and reasoningoriented models as well as a humanannotated benchmark test set our extensive benchmarking on 29 stateoftheart sota llms reveals persistent overrefusal challenges empirical results demonstrate that supervised finetuning with falsereject substantially reduces unnecessary refusals without compromising overall safety or general language capabilities
http://arxiv.org/abs/2505.08052v1,2025-05-12T20:39:53Z,"Kourosh Shahnazari, Seyed Moein Ayyoubzadeh",nazm network analysis of zonal metrics in persian poetic tradition,this study formalizes a computational model to simulate classical persian poets dynamics of influence through constructing a multidimensional similarity network using a rigorously curated dataset based on ganjoors corpus we draw upon semantic lexical stylistic thematic and metrical features to demarcate each poets corpus each is contained within weighted similarity matrices which are then appended to generate an aggregate graph showing poettopoet influence further network investigation is carried out to identify key poets style hubs and bridging poets by calculating degree closeness betweenness eigenvector and katz centrality measures further for typological insight we use the louvain community detection algorithm to demarcate clusters of poets sharing both style and theme coherence which correspond closely to acknowledged schools of literature like sabke hindi sabke khorasani and the bazgashte adabi phenomenon our findings provide a new datadriven view of persian literature distinguished between canonical significance and interextual influence thus highlighting relatively lesserknown figures who hold great structural significance combining computational linguistics with literary study this paper produces an interpretable and scalable model for poetic tradition enabling retrospective reflection as well as forwardlooking research within digital humanities
http://arxiv.org/abs/2505.08037v2,2025-05-12T20:08:05Z,"Yutong Liu, Feng Xiao, Ziyue Zhang, Yongbin Yu, Cheng Huang, Fan Gao, Xiangxiang Wang, Ma-bao Ban, Manping Fan, Thupten Tsering, Cheng Huang, Gadeng Luosang, Renzeng Duojie, Nyima Tashi",tispell a semimasked methodology for tibetan spelling correction covering multilevel error with data augmentation,multilevel tibetan spelling correction addresses errors at both the character and syllable levels within a unified model existing methods focus mainly on singlelevel correction and lack effective integration of both levels moreover there are no opensource datasets or augmentation methods tailored for this task in tibetan to tackle this we propose a data augmentation approach using unlabeled text to generate multilevel corruptions and introduce tispell a semimasked model capable of correcting both character and syllablelevel errors although syllablelevel correction is more challenging due to its reliance on global context our semimasked strategy simplifies this process we synthesize nine types of corruptions on clean sentences to create a robust training set experiments on both simulated and realworld data demonstrate that tispell trained on our dataset outperforms baseline models and matches the performance of stateoftheart approaches confirming its effectiveness
http://arxiv.org/abs/2505.08004v1,2025-05-12T19:09:12Z,"Haneh Rhel, Dmitri Roussinov",large language models and arabic content a review,over the past three years the rapid advancement of large language models llms has had a profound impact on multiple areas of artificial intelligence ai particularly in natural language processing nlp across diverse languages including arabic although arabic is considered one of the most widely spoken languages across 27 countries in the arabic world and used as a second language in some other nonarabic countries as well there is still a scarcity of arabic resources datasets and tools arabic nlp tasks face various challenges due to the complexities of the arabic language including its rich morphology intricate structure and diverse writing standards among other factors researchers have been actively addressing these challenges demonstrating that pretrained large language models llms trained on multilingual corpora achieve significant success in various arabic nlp tasks this study provides an overview of using large language models llms for the arabic language highlighting early pretrained arabic language models across various nlp applications and their ability to handle diverse arabic content tasks and dialects it also provides an overview of how techniques like finetuning and prompt engineering can enhance the performance of these models additionally the study summarizes common arabic benchmarks and datasets while presenting our observations on the persistent upward trend in the adoption of llms
http://arxiv.org/abs/2505.07980v1,2025-05-12T18:23:53Z,"Fupei Guo, Achintha Wijesinghe, Songyang Zhang, Zhi Ding",taskadaptive semantic communications with controllable diffusionbased data regeneration,semantic communications represent a new paradigm of nextgeneration networking that shifts bitwise data delivery to conveying the semantic meanings for bandwidth efficiency to effectively accommodate various potential downstream tasks at the receiver side one should adaptively convey the most critical semantic information this work presents a novel taskadaptive semantic communication framework based on diffusion models that is capable of dynamically adjusting the semantic message delivery according to various downstream tasks specifically we initialize the transmission of a deepcompressed general semantic representation from the transmitter to enable diffusionbased coarse data reconstruction at the receiver the receiver identifies the taskspecific demands and generates textual prompts as feedback integrated with the attention mechanism the transmitter updates the semantic transmission with more details to better align with the objectives of the intended receivers our test results demonstrate the efficacy of the proposed method in adaptively preserving critical taskrelevant information for semantic communications while preserving high compression efficiency
http://arxiv.org/abs/2505.07968v1,2025-05-12T18:08:02Z,"Weiyi Wu, Xinwen Xu, Chongyang Gao, Xingjian Diao, Siting Li, Lucas A. Salas, Jiang Gui",assessing and mitigating medical knowledge drift and conflicts in large language models,large language models llms have great potential in the field of health care yet they face great challenges in adapting to rapidly evolving medical knowledge this can lead to outdated or contradictory treatment suggestions this study investigated how llms respond to evolving clinical guidelines focusing on concept drift and internal inconsistencies we developed the driftmedqa benchmark to simulate guideline evolution and assessed the temporal reliability of various llms our evaluation of seven stateoftheart models across 4290 scenarios demonstrated difficulties in rejecting outdated recommendations and frequently endorsing conflicting guidance additionally we explored two mitigation strategies retrievalaugmented generation and preference finetuning via direct preference optimization while each method improved model performance their combination led to the most consistent and reliable results these findings underscore the need to improve llm robustness to temporal shifts to ensure more dependable applications in clinical practice
http://arxiv.org/abs/2505.07809v1,2025-05-12T17:57:11Z,Máté Gedeon,a comparative analysis of static word embeddings for hungarian,this paper presents a comprehensive analysis of various static word embeddings for hungarian including traditional models such as word2vec fasttext as well as static embeddings derived from bertbased models using different extraction methods we evaluate these embeddings on both intrinsic and extrinsic tasks to provide a holistic view of their performance for intrinsic evaluation we employ a word analogy task which assesses the embeddings ability to capture semantic and syntactic relationships our results indicate that traditional static embeddings particularly fasttext excel in this task achieving high accuracy and mean reciprocal rank mrr scores among the bertbased models the x2static method for extracting static embeddings demonstrates superior performance compared to decontextualized and aggregate methods approaching the effectiveness of traditional static embeddings for extrinsic evaluation we utilize a bidirectional lstm model to perform named entity recognition ner and partofspeech pos tagging tasks the results reveal that embeddings derived from dynamic models especially those extracted using the x2static method outperform purely static embeddings notably elmo embeddings achieve the highest accuracy in both ner and pos tagging tasks underscoring the benefits of contextualized representations even when used in a static form our findings highlight the continued relevance of static word embeddings in nlp applications and the potential of advanced extraction methods to enhance the utility of bertbased models this piece of research contributes to the understanding of embedding performance in the hungarian language and provides valuable insights for future developments in the field the training scripts evaluation codes restricted vocabulary and extracted embeddings will be made publicly available to support further research and reproducibility
http://arxiv.org/abs/2505.07796v1,2025-05-12T17:47:32Z,"Xingjin Wang, Howe Tissue, Lu Wang, Linjing Li, Daniel Dajun Zeng",learning dynamics in continual pretraining for large language models,continual pretraining cpt has become a popular and effective method to apply strong foundation models to specific downstream tasks in this work we explore the learning dynamics throughout the cpt process for large language models we specifically focus on how general and downstream domain performance evolves at each training step with domain performance measured via validation losses we have observed that the cpt loss curve fundamentally characterizes the transition from one curve to another hidden curve and could be described by decoupling the effects of distribution shift and learning rate annealing we derive a cpt scaling law that combines the two factors enabling the prediction of loss at any continual training steps and across learning rate schedules lrs in cpt our formulation presents a comprehensive understanding of several critical factors in cpt including loss potential peak learning rate training steps replay ratio etc moreover our approach can be adapted to customize training hyperparameters to different cpt goals such as balancing general and domainspecific performance extensive experiments demonstrate that our scaling law holds across various cpt datasets and training hyperparameters
http://arxiv.org/abs/2505.07787v1,2025-05-12T17:39:56Z,"Tongxu Luo, Wenyu Du, Jiaxi Bi, Stephen Chung, Zhengyang Tang, Hao Yang, Min Zhang, Benyou Wang",learning from peers in reasoning models,large reasoning models lrms have the ability to selfcorrect even when they make mistakes in their reasoning paths however our study reveals that when the reasoning process starts with a short but poor beginning it becomes difficult for the model to recover we refer to this phenomenon as the prefix dominance trap inspired by psychological findings that peer interaction can promote selfcorrection without negatively impacting already accurate individuals we propose learning from peers leap to address this phenomenon specifically every tokens each reasoning path summarizes its intermediate reasoning and shares it with others through a routing mechanism enabling paths to incorporate peer insights during inference however we observe that smaller models sometimes fail to follow summarization and reflection instructions effectively to address this we finetune them into our leapt model series experiments on aime 2024 aime 2025 aimo 2025 and gpqa diamond show that leap provides substantial improvements for instance qwq32b with leap achieves nearly 5 absolute points higher than the baseline on average and surpasses deepseekr1671b on three math benchmarks with an average gain of 33 points notably our finetuned leapt7b matches the performance of deepseekr1distillqwen14b on aime 2024 indepth analysis reveals leaps robust error correction by timely peer insights showing strong error tolerance and handling varied task difficulty leap marks a milestone by enabling lrms to collaborate during reasoning our code datasets and models are available at httpslearningfrompeersgithubio
http://arxiv.org/abs/2505.07784v1,2025-05-12T17:37:17Z,"Da Ju, Hagen Blix, Adina Williams",domain regeneration how well do llms match syntactic properties of text domains,recent improvement in large language model performance have in all likelihood been accompanied by improvement in how well they can approximate the distribution of their training data in this work we explore the following question which properties of text domains do llms faithfully approximate and how well do they do so applying observational approaches familiar from corpus linguistics we prompt a commonly used opensource llm to regenerate text from two domains of permissively licensed english text which are often contained in llm training data wikipedia and news text this regeneration paradigm allows us to investigate whether llms can faithfully match the original human text domains in a fairly semanticallycontrolled setting we investigate varying levels of syntactic abstraction from more simple properties like sentence length and article readability to more complex and higher order properties such as dependency tag distribution parse depth and parse complexity we find that the majority of the regenerated distributions show a shifted mean a lower standard deviation and a reduction of the long tail as compared to the human originals
http://arxiv.org/abs/2505.07775v1,2025-05-12T17:26:31Z,"Nimet Beyza Bozdag, Shuhaib Mehri, Xiaocheng Yang, Hyeonjeong Ha, Zirui Cheng, Esin Durmus, Jiaxuan You, Heng Ji, Gokhan Tur, Dilek Hakkani-Tür",must read a systematic survey of computational persuasion,persuasion is a fundamental aspect of communication influencing decisionmaking across diverse contexts from everyday conversations to highstakes scenarios such as politics marketing and law the rise of conversational ai systems has significantly expanded the scope of persuasion introducing both opportunities and risks aidriven persuasion can be leveraged for beneficial applications but also poses threats through manipulation and unethical influence moreover ai systems are not only persuaders but also susceptible to persuasion making them vulnerable to adversarial attacks and bias reinforcement despite rapid advancements in aigenerated persuasive content our understanding of what makes persuasion effective remains limited due to its inherently subjective and contextdependent nature in this survey we provide a comprehensive overview of computational persuasion structured around three key perspectives 1 ai as a persuader which explores aigenerated persuasive content and its applications 2 ai as a persuadee which examines ais susceptibility to influence and manipulation and 3 ai as a persuasion judge which analyzes ais role in evaluating persuasive strategies detecting manipulation and ensuring ethical persuasion we introduce a taxonomy for computational persuasion research and discuss key challenges including evaluating persuasiveness mitigating manipulative persuasion and developing responsible aidriven persuasive systems our survey outlines future research directions to enhance the safety fairness and effectiveness of aipowered persuasion while addressing the risks posed by increasingly capable language models
http://arxiv.org/abs/2505.07768v1,2025-05-12T17:20:30Z,"Yifeng Di, Tianyi Zhang",enhancing code generation via bidirectional commentlevel mutual grounding,large language models llms have demonstrated unprecedented capability in code generation however llmgenerated code is still plagued with a wide range of functional errors especially for complex programming tasks that llms have not seen before recent studies have shown that developers often struggle with inspecting and fixing incorrect code generated by llms diminishing their productivity and trust in llmbased code generation inspired by the mutual grounding theory in communication we propose an interactive approach that leverages code comments as a medium for developers and llms to establish a shared understanding our approach facilitates iterative grounding by interleaving code generation inline comment generation and contextualized user feedback through editable comments to align generated code with developer intent we evaluated our approach on two popular benchmarks and demonstrated that our approach significantly improved multiple stateoftheart llms eg 171 pass1 improvement for codedavinci002 on humaneval furthermore we conducted a user study with 12 participants in comparison to two baselines 1 interacting with github copilot and 2 interacting with a multistep code generation paradigm called multiturn program synthesis participants completed the given programming tasks 167 faster and with 105 improvement in task success rate when using our approach both results show that interactively refining code comments enables the collaborative establishment of mutual grounding leading to more accurate code generation and higher developer confidence
http://arxiv.org/abs/2505.07731v1,2025-05-12T16:38:43Z,"Neeraj Agrawal, Sriram Ganapathy",spoken language understanding on unseen tasks with incontext learning,spoken language understanding slu tasks involve diverse skills that probe the information extraction classification andor generation capabilities of models in this setting taskspecific training data may not always be available while traditional taskspecific slu models are unable to cater to such requirements the speechtext large language models llms offer a promising alternative with emergent abilities however out ofthebox our evaluations indicate that the zerofewshot performance of prominent opensource speechtext llms on slu tasks are not up to the mark in this paper we introduce a novel approach to robust taskagnostic finetuning using randomized class labels with this proposed finetuning we illustrate that the performance of the speechtext llms on an unseen task is significantly improved over standard approaches critically the proposed approach avoids the requirement of taskspecific data annotations for enabling new tasks in speechtext llms
http://arxiv.org/abs/2505.07705v2,2025-05-12T16:12:42Z,"Letian Peng, Jingbo Shang",codifying character logic in roleplaying,this paper introduces codified profiles for roleplaying a novel approach that represents character logic as structured executable functions for behavioral decisionmaking each profile defines a set of functions parsebyscenescene that outputs a list of logicgrounded assertions triggeredstatements using both explicit control structures eg ifthenelse and condition checks like checkconditionscene question where each question is a semantically meaningful prompt about the scene eg is the character in danger discriminated by the roleplaying llm as true false or unknown this explicit representation offers three key advantages over traditional promptbased profiles which append character descriptions directly into text prompts 1 persistence by enforcing complete and consistent execution of character logic rather than relying on the models implicit reasoning 2 updatability through systematic inspection and revision of behavioral logic which is difficult to track or debug in promptonly approaches 3 controllable randomness by supporting stochastic behavior directly within the logic enabling finegrained variability that prompting alone struggles to achieve to validate these advantages we introduce a new benchmark constructed from 83 characters and 5141 scenes curated from fandom using nlibased scoring to compare character responses against groundtruth actions our experiments demonstrate the significant benefits of codified profiles in improving persistence updatability and behavioral diversity notably by offloading a significant portion of reasoning to preprocessing codified profiles enable even 1bparameter models to perform highquality roleplaying providing a scalable and efficient foundation for local deployment of roleplay agents
http://arxiv.org/abs/2505.07704v1,2025-05-12T16:12:11Z,"Elisei Rykov, Kseniia Petrushina, Kseniia Titova, Anton Razzhigaev, Alexander Panchenko, Vasily Konovalov",through the looking glass common sense consistency evaluation of weird images,measuring how real images look is a complex task in artificial intelligence research for example an image of a boy with a vacuum cleaner in a desert violates common sense we introduce a novel method which we call through the looking glass tlg to assess image common sense consistency using large visionlanguage models lvlms and transformerbased encoder by leveraging lvlms to extract atomic facts from these images we obtain a mix of accurate facts we proceed by finetuning a compact attentionpooling classifier over encoded atomic facts our tlg has achieved a new stateoftheart performance on the whoops and weird datasets while leveraging a compact finetuning component
http://arxiv.org/abs/2505.07920v1,2025-05-12T16:02:52Z,"Daoze Zhang, Zhijian Bao, Sihang Du, Zhiyi Zhao, Kuangling Zhang, Dezheng Bao, Yang Yang",re a consistencyensured dataset for fullstage peer review and multiturn rebuttal discussions,peer review is a critical component of scientific progress in the fields like ai but the rapid increase in submission volume has strained the reviewing system which inevitably leads to reviewer shortages and declines review quality besides the growing research popularity another key factor in this overload is the repeated resubmission of substandard manuscripts largely due to the lack of effective tools for authors to selfevaluate their work before submission large language models llms show great promise in assisting both authors and reviewers and their performance is fundamentally limited by the quality of the peer review data however existing peer review datasets face three major limitations 1 limited data diversity 2 inconsistent and lowquality data due to the use of revised rather than initial submissions and 3 insufficient support for tasks involving rebuttal and reviewerauthor interactions to address these challenges we introduce the largest consistencyensured peer review and rebuttal dataset named re2 which comprises 19926 initial submissions 70668 review comments and 53818 rebuttals from 24 conferences and 21 workshops on openreview moreover the rebuttal and discussion stage is framed as a multiturn conversation paradigm to support both traditional static review tasks and dynamic interactive llm assistants providing more practical guidance for authors to refine their manuscripts and helping alleviate the growing review burden our data and code are available in httpsanonymous4opensciencerreviewbenchanon
http://arxiv.org/abs/2505.07672v2,2025-05-12T15:36:27Z,Arun S. Maiya,onpremllm a privacyconscious document intelligence toolkit,we present onpremllm a pythonbased toolkit for applying large language models llms to sensitive nonpublic data in offline or restricted environments the system is designed for privacypreserving use cases and provides prebuilt pipelines for document processing and storage retrievalaugmented generation rag information extraction summarization classification and promptoutput processing with minimal configuration onpremllm supports multiple llm backends including llamacpp ollama vllm and hugging face transformers with quantized model support gpu acceleration and seamless backend switching although designed for fully local execution onpremllm also supports integration with a wide range of cloud llm providers when permitted enabling hybrid deployments that balance performance with data control a nocode web interface extends accessibility to nontechnical users
http://arxiv.org/abs/2505.07671v1,2025-05-12T15:34:45Z,"Xianrui Zhong, Bowen Jin, Siru Ouyang, Yanzhen Shen, Qiao Jin, Yin Fang, Zhiyong Lu, Jiawei Han",benchmarking retrievalaugmented generation for chemistry,retrievalaugmented generation rag has emerged as a powerful framework for enhancing large language models llms with external knowledge particularly in scientific domains that demand specialized and dynamic information despite its promise the application of rag in the chemistry domain remains underexplored primarily due to the lack of highquality domainspecific corpora and wellcurated evaluation benchmarks in this work we introduce chemragbench a comprehensive benchmark designed to systematically assess the effectiveness of rag across a diverse set of chemistryrelated tasks the accompanying chemistry corpus integrates heterogeneous knowledge sources including scientific literature the pubchem database pubmed abstracts textbooks and wikipedia entries in addition we present chemragtoolkit a modular and extensible rag toolkit that supports five retrieval algorithms and eight llms using chemragtoolkit we demonstrate that rag yields a substantial performance gain achieving an average relative improvement of 174 over direct inference methods we further conduct indepth analyses on retriever architectures corpus selection and the number of retrieved passages culminating in practical recommendations to guide future research and deployment of rag systems in the chemistry domain the code and data is available at httpschemraggithubio
http://arxiv.org/abs/2505.07659v1,2025-05-12T15:25:17Z,"Ethan Gotlieb Wilcox, Cui Ding, Giovanni Acampa, Tiago Pimentel, Alex Warstadt, Tamar I. Regev",using information theory to characterize prosodic typology the case of tone pitchaccent and stressaccent,this paper argues that the relationship between lexical identity and prosody one wellstudied parameter of linguistic variation can be characterized using information theory we predict that languages that use prosody to make lexical distinctions should exhibit a higher mutual information between word identity and prosody compared to languages that dont we test this hypothesis in the domain of pitch which is used to make lexical distinctions in tonal languages like cantonese we use a dataset of speakers reading sentences aloud in ten languages across five language families to estimate the mutual information between the text and their pitch curves we find that across languages pitch curves display similar amounts of entropy however these curves are easier to predict given their associated text in the tonal languages compared to pitch and stressaccent languages and thus the mutual information is higher in these languages supporting our hypothesis our results support perspectives that view linguistic typology as gradient rather than categorical
http://arxiv.org/abs/2505.07653v1,2025-05-12T15:22:29Z,"Iman Johary, Raphael Romero, Alexandru C. Mara, Tijl De Bie",jobhop a largescale dataset of career trajectories,understanding labor market dynamics is essential for policymakers employers and job seekers however comprehensive datasets that capture realworld career trajectories are scarce in this paper we introduce jobhop a largescale public dataset derived from anonymized resumes provided by vdab the public employment service in flanders belgium utilizing large language models llms we process unstructured resume data to extract structured career information which is then mapped to standardized esco occupation codes using a multilabel classification model this results in a rich dataset of over 23 million work experiences extracted from and grouped into more than 391000 user resumes and mapped to standardized esco occupation codes offering valuable insights into realworld occupational transitions this dataset enables diverse applications such as analyzing labor market mobility job stability and the effects of career breaks on occupational transitions it also supports career path prediction and other datadriven decisionmaking processes to illustrate its potential we explore key dataset characteristics including job distributions career breaks and job transitions demonstrating its value for advancing labor market research
http://arxiv.org/abs/2505.07637v1,2025-05-12T15:07:32Z,"Krish Goel, Sanskar Pandey, KS Mahadevan, Harsh Kumar, Vishesh Khadaria",chronocept instilling a sense of time in machines,human cognition is deeply intertwined with a sense of time known as chronoception this sense allows us to judge how long facts remain valid and when knowledge becomes outdated despite progress in vision language and motor control ai still struggles to reason about temporal validity we introduce chronocept the first benchmark to model temporal validity as a continuous probability distribution over time using skewnormal curves fitted along semantically decomposed temporal axes chronocept captures nuanced patterns of emergence decay and peak relevance it includes two datasets benchmark i atomic facts and benchmark ii multisentence passages annotations show strong interannotator agreement 84 and 89 our baselines predict curve parameters location scale and skewness enabling interpretable generalizable learning and outperforming classificationbased approaches chronocept fills a foundational gap in ais temporal reasoning supporting applications in knowledge grounding factchecking retrievalaugmented generation rag and proactive agents code and data are publicly available
http://arxiv.org/abs/2505.07610v2,2025-05-12T14:31:51Z,"Kenza Amara, Rita Sevastjanova, Mennatallah El-Assady",conceptlevel explainability for auditing steering llm responses,as large language models llms become widely deployed concerns about their safety and alignment grow an approach to steer llm behavior such as mitigating biases or defending against jailbreaks is to identify which parts of a prompt influence specific aspects of the models output tokenlevel attribution methods offer a promising solution but still struggle in text generation explaining the presence of each token in the output separately rather than the underlying semantics of the entire llm response we introduce conceptx a modelagnostic conceptlevel explainability method that identifies the concepts ie semantically rich tokens in the prompt and assigns them importance based on the outputs semantic similarity unlike current tokenlevel methods conceptx also offers to preserve context integrity through inplace token replacements and supports flexible explanation goals eg gender bias conceptx enables both auditing by uncovering sources of bias and steering by modifying prompts to shift the sentiment or reduce the harmfulness of llm responses without requiring retraining across three llms conceptx outperforms tokenlevel methods like tokenshap in both faithfulness and human alignment steering tasks boost sentiment shift by 0252 versus 0131 for random edits and lower attack success rates from 0463 to 0242 outperforming attribution and paraphrasing baselines while prompt engineering and selfexplaining methods sometimes yield safer responses conceptx offers a transparent and faithful alternative for improving llm safety and alignment demonstrating the practical value of attributionbased explainability in guiding llm behavior
http://arxiv.org/abs/2505.07608v1,2025-05-12T14:30:11Z,"Xiaomi LLM-Core Team,  :, Bingquan Xia, Bowen Shen,  Cici, Dawei Zhu, Di Zhang, Gang Wang, Hailin Zhang, Huaqiu Liu, Jiebao Xiao, Jinhao Dong, Liang Zhao, Peidian Li, Peng Wang, Shihua Yu, Shimao Chen, Weikun Wang, Wenhan Ma, Xiangwei Deng, Yi Huang, Yifan Song, Zihan Jiang, Bowen Ye, Can Cai, Chenhong He, Dong Zhang, Duo Zhang, Guoan Wang, Hao Tian, Haochen Zhao, Heng Qu, Hongshen Xu, Jun Shi, Kainan Bao, QingKai Fang, Kang Zhou, Kangyang Zhou, Lei Li, Menghang Zhu, Nuo Chen, Qiantong Wang, Shaohui Liu, Shicheng Li, Shuhao Gu, Shuhuai Ren, Shuo Liu, Sirui Deng, Weiji Zhuang, Weiwei Lv, Wenyu Yang, Xin Zhang, Xing Yong, Xing Zhang, Xingchen Song, Xinzhe Xu, Xu Wang, Yihan Yan, Yu Tu, Yuanyuan Tian, Yudong Wang, Yue Yu, Zhenru Lin, Zhichao Song, Zihao Yue",mimo unlocking the reasoning potential of language model from pretraining to posttraining,we present mimo7b a large language model born for reasoning tasks with optimization across both pretraining and posttraining stages during pretraining we enhance the data preprocessing pipeline and employ a threestage data mixing strategy to strengthen the base models reasoning potential mimo7bbase is pretrained on 25 trillion tokens with additional multitoken prediction objective for enhanced performance and accelerated inference speed during posttraining we curate a dataset of 130k verifiable mathematics and programming problems for reinforcement learning integrating a testdifficultydriven codereward scheme to alleviate sparsereward issues and employing strategic data resampling to stabilize training extensive evaluations show that mimo7bbase possesses exceptional reasoning potential outperforming even much larger 32b models the final rltuned model mimo7brl achieves superior performance on mathematics code and general reasoning tasks surpassing the performance of openai o1mini the model checkpoints are available at httpsgithubcomxiaomimimomimo
http://arxiv.org/abs/2505.07601v1,2025-05-12T14:24:58Z,"Edirlei Soares de Lima, Marco A. Casanova, Bruno Feijó, Antonio L. Furtado",characterizing the investigative methods of fictional detectives with large language models,detective fiction a genre defined by its complex narrative structures and characterdriven storytelling presents unique challenges for computational narratology a research field focused on integrating literary theory into automated narrative generation while traditional literary studies have offered deep insights into the methods and archetypes of fictional detectives these analyses often focus on a limited number of characters and lack the scalability needed for the extraction of unique traits that can be used to guide narrative generation methods in this paper we present an aidriven approach for systematically characterizing the investigative methods of fictional detectives our multiphase workflow explores the capabilities of 15 large language models llms to extract synthesize and validate distinctive investigative traits of fictional detectives this approach was tested on a diverse set of seven iconic detectives hercule poirot sherlock holmes william murdoch columbo father brown miss marple and auguste dupin capturing the distinctive investigative styles that define each character the identified traits were validated against existing literary analyses and further tested in a reverse identification phase achieving an overall accuracy of 9143 demonstrating the methods effectiveness in capturing the distinctive investigative approaches of each detective this work contributes to the broader field of computational narratology by providing a scalable framework for character analysis with potential applications in aidriven interactive storytelling and automated narrative generation
http://arxiv.org/abs/2505.07596v1,2025-05-12T14:21:57Z,"Ziyang Huang, Xiaowei Yuan, Yiming Ju, Jun Zhao, Kang Liu",reinforced internalexternal knowledge synergistic reasoning for efficient adaptive search agent,retrievalaugmented generation rag is a common strategy to reduce hallucinations in large language models llms while reinforcement learning rl can enable llms to act as search agents by activating retrieval capabilities existing ones often underutilize their internal knowledge this can lead to redundant retrievals potential harmful knowledge conflicts and increased inference latency to address these limitations an efficient and adaptive search agent capable of discerning optimal retrieval timing and synergistically integrating parametric internal and retrieved external knowledge is in urgent need this paper introduces the reinforced internalexternal knowledge synergistic reasoning agent ikea which could indentify its own knowledge boundary and prioritize the utilization of internal knowledge resorting to external search only when internal knowledge is deemed insufficient this is achieved using a novel knowledgeboundary aware reward function and a knowledgeboundary aware training dataset these are designed for internalexternal knowledge synergy oriented rl incentivizing the model to deliver accurate answers minimize unnecessary retrievals and encourage appropriate external searches when its own knowledge is lacking evaluations across multiple knowledge reasoning tasks demonstrate that ikea significantly outperforms baseline methods reduces retrieval frequency significantly and exhibits robust generalization capabilities
http://arxiv.org/abs/2505.07591v1,2025-05-12T14:16:55Z,"Junjie Ye, Caishuang Huang, Zhuohan Chen, Wenjie Fu, Chenyuan Yang, Leyi Yang, Yilong Wu, Peng Wang, Meng Zhou, Xiaolong Yang, Tao Gui, Qi Zhang, Zhongchao Shi, Jianping Fan, Xuanjing Huang",a multidimensional constraint framework for evaluating and improving instruction following in large language models,instruction following evaluates large language models llms on their ability to generate outputs that adhere to userdefined constraints however existing benchmarks often rely on templated constraint prompts which lack the diversity of realworld usage and limit finegrained performance assessment to fill this gap we propose a multidimensional constraint framework encompassing three constraint patterns four constraint categories and four difficulty levels building on this framework we develop an automated instruction generation pipeline that performs constraint expansion conflict detection and instruction rewriting yielding 1200 codeverifiable instructionfollowing test samples we evaluate 19 llms across seven model families and uncover substantial variation in performance across constraint forms for instance average performance drops from 7767 at level i to 3296 at level iv furthermore we demonstrate the utility of our approach by using it to generate data for reinforcement learning achieving substantial gains in instruction following without degrading general performance indepth analysis indicates that these gains stem primarily from modifications in the models attention modules parameters which enhance constraint recognition and adherence code and data are available in httpsgithubcomjunjieyemuldimif
http://arxiv.org/abs/2505.07912v1,2025-05-12T13:38:20Z,"Tim Wittenborg, Constantin Sebastian Tremel, Niklas Stehr, Oliver Karras, Markus Stocker, Sören Auer",scicom wiki factchecking and fair knowledge distribution for scientific videos and podcasts,democratic societies need accessible reliable information videos and podcasts have established themselves as the medium of choice for civic dissemination but also as carriers of misinformation the emerging science communication knowledge infrastructure scicom ki curating nontextual media is still fragmented and not adequately equipped to scale against the content flood our work sets out to support the scicom ki with a central collaborative platform the scicom wiki to facilitate fair findable accessible interoperable reusable media representation and the factchecking of their content particularly for videos and podcasts building an opensource service system centered around wikibase we survey requirements from 53 stakeholders refine these in 11 interviews and evaluate our prototype based on these requirements with another 14 participants to address the most requested feature factchecking we developed a neurosymbolic computational factchecking approach converting heterogenous media into knowledge graphs this increases machinereadability and allows comparing statements against equally represented groundtruth our computational factchecking tool was iteratively evaluated through 10 expert interviews a public user survey with 43 participants verified the necessity and usability of our tool overall our findings identified several needs to systematically support the scicom ki the scicom wiki as a fair digital library complementing our neurosymbolic computational factchecking framework was found suitable to address the raised requirements further we identified that the scicom ki is severely underdeveloped regarding fair knowledge and related systems facilitating its collaborative creation and curation our system can provide a central knowledge node yet a collaborative effort is required to scale against the imminent misinformation flood
http://arxiv.org/abs/2505.07558v1,2025-05-12T13:36:25Z,"Rei Higuchi, Taiji Suzuki",direct density ratio optimization a statistically consistent approach to aligning large language models,aligning large language models llms with human preferences is crucial for safe deployment yet existing methods assume specific preference models like bradleyterry model this assumption leads to statistical inconsistency where more data doesnt guarantee convergence to true human preferences to address this critical gap we introduce a novel alignment method direct density ratio optimization ddro ddro directly estimates the density ratio between preferred and unpreferred output distributions circumventing the need for explicit human preference modeling we theoretically prove that ddro is statistically consistent ensuring convergence to the true preferred distribution as the data size grows regardless of the underlying preference structure experiments demonstrate that ddro achieves superior performance compared to existing methods on many major benchmarks ddro unlocks the potential for truly datadriven alignment paving the way for more reliable and humanaligned llms
http://arxiv.org/abs/2505.07528v1,2025-05-12T13:10:46Z,Lei Wang,seredeep hallucination detection in retrievalaugmented models via semantic entropy and contextparameter fusion,retrievalaugmented generation rag models frequently encounter hallucination phenomena when integrating external information with internal parametric knowledge empirical studies demonstrate that the disequilibrium between external contextual information and internal parametric knowledge constitutes a primary factor in hallucination generation existing hallucination detection methodologies predominantly emphasize either the external or internal mechanism in isolation thereby overlooking their synergistic effects the recently proposed redeep framework decouples these dual mechanisms identifying two critical contributors to hallucinations excessive reliance on parametric knowledge encoded in feedforward networks ffn and insufficient utilization of external information by attention mechanisms particularly copy heads redeep quantitatively assesses these factors to detect hallucinations and dynamically modulates the contributions of ffns and copy heads to attenuate their occurrence nevertheless redeep and numerous other hallucination detection approaches have been employed at logitlevel uncertainty estimation or languagelevel selfconsistency evaluation inadequately address the semantic dimensions of model responses resulting in inconsistent hallucination assessments in rag implementations building upon redeeps foundation this paper introduces seredeep which enhances computational processes through semantic entropy captured via trained linear probes thereby achieving hallucination assessments that more accurately reflect ground truth evaluations
http://arxiv.org/abs/2505.07512v1,2025-05-12T12:48:30Z,"Xu Huang, Weiwen Liu, Xingshan Zeng, Yuefeng Huang, Xinlong Hao, Yuxian Wang, Yirong Zeng, Chuhan Wu, Yasheng Wang, Ruiming Tang, Defu Lian",toolacedev selfimproving tool learning via decomposition and evolution,the toolusing capability of large language models llms enables them to access uptodate external information and handle complex tasks current approaches to enhancing this capability primarily rely on distilling advanced models by data synthesis however this method incurs significant costs associated with advanced model usage and often results in data compatibility issues led by the high discrepancy in the knowledge scope between the advanced model and the target model to address these challenges we propose toolacedev a selfimproving framework for tool learning first we decompose the toollearning objective into subtasks that enhance basic toolmaking and toolusing abilities then we introduce a selfevolving paradigm that allows lightweight models to selfimprove reducing reliance on advanced llms extensive experiments validate the effectiveness of our approach across models of varying scales and architectures
http://arxiv.org/abs/2505.07908v1,2025-05-12T12:38:46Z,"Karahan Sarıtaş, Çağatay Yıldız",a reproduction study the kernel pca interpretation of selfattention fails under scrutiny,in this reproduction study we revisit recent claims that selfattention implements kernel principal component analysis kpca teo et al 2024 positing that i value vectors capture the eigenvectors of the gram matrix of the keys and ii that selfattention projects queries onto the principal component axes of the key matrix in a feature space our analysis reveals three critical inconsistencies 1 no alignment exists between learned selfattention value vectors and what is proposed in the kpca perspective with average similarity metrics optimal cosine similarity linear cka centered kernel alignment kernel cka indicating negligible correspondence 2 reported decreases in reconstruction loss arguably justifying the claim that the selfattention minimizes the projection error of kpca are misinterpreted as the quantities involved differ by orders of magnitude 3 gram matrix eigenvalue statistics introduced to justify that captures the eigenvector of the gram matrix are irreproducible without undocumented implementationspecific adjustments across 10 transformer architectures we conclude that the kpca interpretation of selfattention lacks empirical support
http://arxiv.org/abs/2505.07495v1,2025-05-12T12:27:38Z,"Isabelle van der Vegt, Bennett Kleinberg, Marilu Miotto, Jonas Festor",translating the grievance dictionary a psychometric evaluation of dutch german and italian versions,this paper introduces and evaluates three translations of the grievance dictionary a psycholinguistic dictionary for the analysis of violent threatening or grievancefuelled texts considering the relevance of these themes in languages beyond english we translated the grievance dictionary to dutch german and italian we describe the process of automated translation supplemented by human annotation psychometric analyses are performed including internal reliability of dictionary categories and correlations with the liwc dictionary the dutch and german translations perform similarly to the original english version whereas the italian dictionary shows low reliability for some categories finally we make suggestions for further validation and application of the dictionary as well as for future dictionary translations following a similar approach
http://arxiv.org/abs/2505.07460v1,2025-05-12T11:48:42Z,"Yi Chen, JiaHao Zhao, HaoHao Han",a survey on collaborative mechanisms between large and small language models,large language models llms deliver powerful ai capabilities but face deployment challenges due to high resource costs and latency whereas small language models slms offer efficiency and deployability at the cost of reduced performance collaboration between llms and slms emerges as a crucial paradigm to synergistically balance these tradeoffs enabling advanced ai applications especially on resourceconstrained edge devices this survey provides a comprehensive overview of llmslm collaboration detailing various interaction mechanisms pipeline routing auxiliary distillation fusion key enabling technologies and diverse application scenarios driven by ondevice needs like low latency privacy personalization and offline operation while highlighting the significant potential for creating more efficient adaptable and accessible ai we also discuss persistent challenges including system overhead intermodel consistency robust task allocation evaluation complexity and securityprivacy concerns future directions point towards more intelligent adaptive frameworks deeper model fusion and expansion into multimodal and embodied ai positioning llmslm collaboration as a key driver for the next generation of practical and ubiquitous artificial intelligence
http://arxiv.org/abs/2505.07440v1,2025-05-12T11:02:41Z,"Rituraj Singh, Sachin Pawar, Girish Palshikar",matching tasks with industry groups for augmenting commonsense knowledge,commonsense knowledge bases kb are a source of specialized knowledge that is widely used to improve machine learning applications however even for a large kb such as conceptnet capturing explicit knowledge from each industry domain is challenging for example only a few samples of general em tasks performed by various industries are available in conceptnet here a task is a welldefined knowledgebased volitional action to achieve a particular goal in this paper we aim to fill this gap and present a weaklysupervised framework to augment commonsense kb with tasks carried out by various industry groups ig we attempt to em match each task with one or more suitable igs by training a neural model to learn taskig affinity and apply clustering to select the topk tasks per ig we extract a total of 2339 triples of the form from two publicly available news datasets for 24 igs with the precision of 086 this validates the reliability of the extracted taskig pairs that can be directly added to existing kbs
http://arxiv.org/abs/2505.07430v1,2025-05-12T10:37:33Z,"Mostafa Mohaimen Akand Faisal, Rabeya Amin Jhuma",comparative sentiment analysis of public perception monkeypox vs covid19 behavioral insights,the emergence of global health crises such as covid19 and monkeypox mpox has underscored the importance of understanding public sentiment to inform effective public health strategies this study conducts a comparative sentiment analysis of public perceptions surrounding covid19 and mpox by leveraging extensive datasets of 147475 and 106638 tweets respectively advanced machine learning models including logistic regression naive bayes roberta distilroberta and xlnet were applied to perform sentiment classification with results indicating key trends in public emotion and discourse the analysis highlights significant differences in public sentiment driven by disease characteristics media representation and pandemic fatigue through the lens of sentiment polarity and thematic trends this study offers valuable insights into tailoring public health messaging mitigating misinformation and fostering trust during concurrent health crises the findings contribute to advancing sentiment analysis applications in public health informatics setting the groundwork for enhanced realtime monitoring and multilingual analysis in future research
http://arxiv.org/abs/2505.07416v1,2025-05-12T10:11:28Z,"Truc Mai-Thanh Nguyen, Dat Minh Nguyen, Son T. Luu, Kiet Van Nguyen",vimrhp a vietnamese benchmark dataset for multimodal review helpfulness prediction via humanai collaborative annotation,multimodal review helpfulness prediction mrhp is an essential task in recommender systems particularly in ecommerce platforms determining the helpfulness of usergenerated reviews enhances user experience and improves consumer decisionmaking however existing datasets focus predominantly on english and indonesian resulting in a lack of linguistic diversity especially for lowresource languages such as vietnamese in this paper we introduce vimrhp vietnamese multimodal review helpfulness prediction a largescale benchmark dataset for mrhp task in vietnamese this dataset covers four domains including 2k products with 46k reviews meanwhile a largescale dataset requires considerable time and cost to optimize the annotation process we leverage ai to assist annotators in constructing the vimrhp dataset with ai assistance annotation time is reduced 90 to 120 seconds per task down to 20 to 40 seconds per task while maintaining data quality and lowering overall costs by approximately 65 however aigenerated annotations still have limitations in complex annotation tasks which we further examine through a detailed performance analysis in our experiment on vimrhp we evaluate baseline models on humanverified and aigenerated annotations to assess their quality differences the vimrhp dataset is publicly available at httpsgithubcomtrng28vimrhp
http://arxiv.org/abs/2505.07409v1,2025-05-12T10:03:15Z,"Tim Wittenborg, Constantin Sebastian Tremel, Markus Stocker, Sören Auer",computational factchecking of online discourse scoring scientific accuracy in climate change related news articles,democratic societies need reliable information misinformation in popular media such as news articles or videos threatens to impair civic discourse citizens are unfortunately not equipped to verify this content flood consumed daily at increasing rates this work aims to semiautomatically quantify scientific accuracy of online media by semantifying media of unknown veracity their statements can be compared against equally processed trusted sources we implemented a workflow using llmbased statement extraction and knowledge graph analysis our neurosymbolic system was able to evidently streamline stateoftheart veracity quantification evaluated via expert interviews and a user survey the tool provides a beneficial veracity indication this indicator however is unable to annotate public media at the required granularity and scale further work towards a fair findable accessible interoperable reusable ground truth and complementary metrics are required to scientifically support civic discourse
http://arxiv.org/abs/2505.07903v1,2025-05-12T09:45:40Z,"Zeyang Sha, Shiwen Cui, Weiqiang Wang",sem reinforcement learning for searchefficient large language models,recent advancements in large language modelsllms have demonstrated their capabilities not only in reasoning but also in invoking external tools particularly search engines however teaching models to discern when to invoke search and when to rely on their internal knowledge remains a significant challenge existing reinforcement learning approaches often lead to redundant search behaviors resulting in inefficiencies and overcost in this paper we propose sem a novel posttraining reinforcement learning framework that explicitly trains llms to optimize search usage by constructing a balanced dataset combining musique and mmlu we create scenarios where the model must learn to distinguish between questions it can answer directly and those requiring external retrieval we design a structured reasoning template and employ group relative policy optimizationgrpo to posttrain the models search behaviors our reward function encourages accurate answering without unnecessary search while promoting effective retrieval when needed experimental results demonstrate that our method significantly reduces redundant search operations while maintaining or improving answer accuracy across multiple challenging benchmarks this framework advances the models reasoning efficiency and extends its capability to judiciously leverage external knowledge
http://arxiv.org/abs/2505.07902v1,2025-05-12T09:24:21Z,"Ruikun Hou, Babette Bühler, Tim Fütterer, Efe Bozkir, Peter Gerjets, Ulrich Trautwein, Enkelejda Kasneci",multimodal assessment of classroom discourse quality a textcentered attentionbased multitask learning approach,classroom discourse is an essential vehicle through which teaching and learning take place assessing different characteristics of discursive practices and linking them to student learning achievement enhances the understanding of teaching quality traditional assessments rely on manual coding of classroom observation protocols which is timeconsuming and costly despite many studies utilizing ai techniques to analyze classroom discourse at the utterance level investigations into the evaluation of discursive practices throughout an entire lesson segment remain limited to address this gap our study proposes a novel textcentered multimodal fusion architecture to assess the quality of three discourse components grounded in the global teaching insights gti observation protocol nature of discourse questioning and explanations first we employ attention mechanisms to capture inter and intramodal interactions from transcript audio and video streams second a multitask learning approach is adopted to jointly predict the quality scores of the three components third we formulate the task as an ordinal classification problem to account for rating level order the effectiveness of these designed elements is demonstrated through an ablation study on the gti germany dataset containing 92 videotaped math lessons our results highlight the dominant role of text modality in approaching this task integrating acoustic features enhances the models consistency with human ratings achieving an overall quadratic weighted kappa score of 0384 comparable to human interrater reliability 0326 our study lays the groundwork for the future development of automated discourse quality assessment to support teacher professional development through timely feedback on multidimensional discourse practices
http://arxiv.org/abs/2505.07365v1,2025-05-12T09:04:16Z,"Chao-Han Huck Yang, Sreyan Ghosh, Qing Wang, Jaeyeon Kim, Hengyi Hong, Sonal Kumar, Guirui Zhong, Zhifeng Kong, S Sakshi, Vaibhavi Lokegaonkar, Oriol Nieto, Ramani Duraiswami, Dinesh Manocha, Gunhee Kim, Jun Du, Rafael Valle, Bryan Catanzaro",multidomain audio question answering toward acoustic content reasoning in the dcase 2025 challenge,we present task 5 of the dcase 2025 challenge an audio question answering aqa benchmark spanning multiple domains of sound understanding this task defines three qa subsets bioacoustics temporal soundscapes and complex qa to test audiolanguage models on interactive questionanswering over diverse acoustic scenes we describe the dataset composition from marine mammal calls to soundscapes and complex realworld clips the evaluation protocol top1 accuracy with answershuffling robustness and baseline systems qwen2audio7b audioflamingo 2 gemini2flash preliminary results on the development set are compared showing strong variation across models and subsets this challenge aims to advance the audio understanding and reasoning capabilities of audiolanguage models toward humanlevel acuity which are crucial for enabling ai agents to perceive and interact about the world effectively
http://arxiv.org/abs/2505.07345v1,2025-05-12T08:35:09Z,"Ohjoon Kwon, Changsu Lee, Jihye Back, Lim Sun Suk, Inho Kang, Donghyeon Jeon",qupid quantified understanding for enhanced performance insights and decisions in korean search engines,large language models llms have been widely used for relevance assessment in information retrieval however our study demonstrates that combining two distinct small language models slms with different architectures can outperform llms in this task our approach qupid integrates a generative slm with an embeddingbased slm achieving higher relevance judgment accuracy while reducing computational costs compared to stateoftheart llm solutions this computational efficiency makes qupid highly scalable for realworld search systems processing millions of queries daily in experiments across diverse document types our method demonstrated consistent performance improvements cohens kappa of 0646 versus 0387 for leading llms while offering 60x faster inference times furthermore when integrated into production search pipelines qupid improved ndcg5 scores by 19 these findings underscore how architectural diversity in model combinations can significantly enhance both search relevance and operational efficiency in information retrieval systems
http://arxiv.org/abs/2505.07313v2,2025-05-12T07:59:13Z,"Baixuan Xu, Chunyang Li, Weiqi Wang, Wei Fan, Tianshi Zheng, Haochen Shi, Tao Fan, Yangqiu Song, Qiang Yang",towards multiagent reasoning systems for collaborative expertise delegation an exploratory design study,designing effective collaboration structure for multiagent llm systems to enhance collective reasoning is crucial yet remains underexplored in this paper we systematically investigate how collaborative reasoning performance is affected by three key design dimensions 1 expertisedomain alignment 2 collaboration paradigm structured workflow vs diversitydriven integration and 3 system scale our findings reveal that expertise alignment benefits are highly domaincontingent proving most effective for contextual reasoning tasks furthermore collaboration focused on integrating diverse knowledge consistently outperforms rigid task decomposition finally we empirically explore the impact of scaling the multiagent system with expertise specialization and study the computational trade off highlighting the need for more efficient communication protocol design this work provides concrete guidelines for configuring specialized multiagent system and identifies critical architectural tradeoffs and bottlenecks for scalable multiagent reasoning the code will be made available upon acceptance
http://arxiv.org/abs/2505.07293v1,2025-05-12T07:25:51Z,"Kai Hua, Steven Wu, Ge Zhang, Ke Shen",attentioninfluence adopting attention head influence for weaktostrong pretraining data selection,recently there has been growing interest in collecting reasoningintensive pretraining data to improve llms complex reasoning ability prior approaches typically rely on supervised classifiers to identify such data which requires labeling by humans or llms often introducing domainspecific biases due to the attention heads being crucial to incontext reasoning we propose attentioninfluence a simple yet effective trainingfree method without supervision signal our approach enables a small pretrained language model to act as a strong data selector through a simple attention head masking operation specifically we identify retrieval heads and compute the loss difference when masking these heads we apply attentioninfluence to a 13bparameter dense model to conduct data selection on the smollm corpus of 241b tokens and mix the smollm corpus with the selected subset comprising 73b tokens to pretrain a 7bparameter dense model using 1t training tokens and wsd learning rate scheduling our experimental results demonstrate substantial improvements ranging from 14pp to 35pp across several knowledgeintensive and reasoningheavy benchmarks ie mmlu mmlupro agievalen gsm8k and humaneval this demonstrates an effective weaktostrong scaling property with small models improving the final performance of larger modelsoffering a promising and scalable path for reasoningcentric data selection
http://arxiv.org/abs/2505.07289v1,2025-05-12T07:23:19Z,"Stanislas Laborde, Martin Cousseau, Antoun Yaacoub, Lionel Prevost",semantic retention and extreme compression in llms can we have both,the exponential growth in large language model llm deployment has intensified the need for efficient model compression techniques to reduce computational and memory costs while pruning and quantization have shown promise their combined potential remains largely unexplored in this paper we examine joint compression and how strategically combining pruning and quantization could yield superior performancetocompression ratios compared to singlemethod approaches recognizing the challenges in accurately assessing llm performance we address key limitations of previous evaluation frameworks and introduce the semantic retention compression rate srcr a novel metric that quantifies the tradeoff between model compression and semantic preservation facilitating the optimization of pruningquantization configurations experiments demonstrate that our recommended combination achieves on average a 20 performance increase compared to an equivalent quantizationonly model at the same theoretical compression rate
http://arxiv.org/abs/2505.07899v1,2025-05-12T07:11:26Z,"Ding Cao, Yuchen Cai, Rongxi Guo, Xuesong He, Guiquan Liu",deltaedit enhancing sequential editing in large language models by controlling superimposed noise,sequential knowledge editing techniques aim to continuously update the knowledge in large language models at a low cost preventing the models from generating outdated or incorrect information however existing sequential editing methods suffer from a significant decline in editing success rates after longterm editing through theoretical analysis and experiments we identify that as the number of edits increases the models output increasingly deviates from the desired target leading to a drop in editing success rates we refer to this issue as the accumulation of superimposed noise problem to address this we identify the factors contributing to this deviation and propose deltaedit a novel method that optimizes update parameters through a dynamic orthogonal constraints strategy effectively reducing interference between edits to mitigate deviation experimental results demonstrate that deltaedit significantly outperforms existing methods in edit success rates and the retention of generalization capabilities ensuring stable and reliable model performance even under extensive sequential editing
http://arxiv.org/abs/2505.07271v1,2025-05-12T06:48:26Z,"Jiwoo Hong, Noah Lee, Eunki Kim, Guijin Son, Woojin Chung, Aman Gupta, Shao Tang, James Thorne",on the robustness of reward models for language model alignment,the bradleyterry bt model is widely practiced in reward modeling for reinforcement learning with human feedback rlhf despite its effectiveness reward models rms trained with bt model loss are prone to overoptimization losing generalizability to unseen input distributions in this paper we study the cause of overoptimization in rm training and its downstream effects on the rlhf procedure accentuating the importance of distributional robustness of rms in unseen data first we show that the excessive dispersion of hidden state norms is the main source of overoptimization then we propose batchwise sumtozero regularization bsr to enforce zerocentered reward sum per batch constraining the rewards with extreme magnitudes we assess the impact of bsr in improving robustness in rms through four scenarios of overoptimization where bsr consistently manifests better robustness subsequently we compare the plain bt model and bsr on rlhf training and empirically show that robust rms better align the policy to the gold preference model finally we apply bsr to highquality data and models which surpasses stateoftheart rms in the 8b scale by adding more than 5 in complex preference prediction tasks by conducting rloo training with 8b rms alpacaeval 20 reduces generation length by 40 while adding a 7 increase in win rate further highlighting that robustness in rms induces robustness in rlhf training we release the code data and models httpsgithubcomlinkedinxfactrmrobustness
http://arxiv.org/abs/2505.07258v1,2025-05-12T06:19:59Z,"Wenqiang Wang, Siyuan Liang, Yangshijie Zhang, Xiaojun Jia, Hao Lin, Xiaochun Cao",no query no access,textual adversarial attacks mislead nlp models including large language models llms by subtly modifying text while effective existing attacks often require knowledge of the victim model extensive queries or access to training data limiting realworld feasibility to overcome these constraints we introduce the textbfvictim databased adversarial attack vdba which operates using only victim texts to prevent access to the victim model we create a shadow dataset with publicly available pretrained models and clustering methods as a foundation for developing substitute models to address the low attack success rate asr due to insufficient information feedback we propose the hierarchical substitution model design generating substitute models to mitigate the failure of a single substitute model at the decision boundary concurrently we use diverse adversarial example generation employing various attack methods to generate and select the adversarial example with better similarity and attack effectiveness experiments on the emotion and sst5 datasets show that vdba outperforms stateoftheart methods achieving an asr improvement of 5208 while significantly reducing attack queries to 0 more importantly we discover that vdba poses a significant threat to llms such as qwen2 and the gpt family and achieves the highest asr of 4599 even without access to the api confirming that advanced nlp models still face serious security risks our codes can be found at httpsanonymous4opensciencervdbavictimdatabasedadversarialattack36ec
http://arxiv.org/abs/2505.07247v2,2025-05-12T05:43:21Z,"Peichao Lai, Kexuan Zhang, Yi Lin, Linyihan Zhang, Feiyang Ye, Jinhao Yan, Yanwei Xu, Conghui He, Yilei Wang, Wentao Zhang, Bin Cui",sasbench a finegrained benchmark for evaluating short answer scoring with large language models,subjective answer grading sag plays a crucial role in education standardized testing and automated assessment systems particularly for evaluating shortform responses in short answer scoring sas however existing approaches often produce coarsegrained scores and lack detailed reasoning although large language models llms have demonstrated potential as zeroshot evaluators they remain susceptible to bias inconsistencies with human judgment and limited transparency in scoring decisions to overcome these limitations we introduce sasbench a benchmark specifically designed for llmbased sas tasks sasbench provides finegrained stepwise scoring expertannotated error categories and a diverse range of question types derived from realworld subjectspecific exams this benchmark facilitates detailed evaluation of model reasoning processes and explainability we also release an opensource dataset containing 1030 questions and 4109 student responses each annotated by domain experts furthermore we conduct comprehensive experiments with various llms identifying major challenges in scoring sciencerelated questions and highlighting the effectiveness of fewshot prompting in improving scoring accuracy our work offers valuable insights into the development of more robust fair and educationally meaningful llmbased evaluation systems
http://arxiv.org/abs/2505.07897v1,2025-05-12T05:38:03Z,"Stefano Rando, Luca Romani, Alessio Sampieri, Yuta Kyuragi, Luca Franco, Fabio Galasso, Tatsunori Hashimoto, John Yang",longcodebench evaluating coding llms at 1m context windows,context lengths for models have grown rapidly from thousands to millions of tokens in just a few years the extreme context sizes of modern longcontext models have made it difficult to construct realistic longcontext benchmarks not only due to the cost of collecting millioncontext tasks but also in identifying realistic scenarios that require significant contexts we identify code comprehension and repair as a natural testbed and challenge task for longcontext models and introduce longcodebench lcb a benchmark to test llm coding abilities in longcontext scenarios our benchmark tests both the comprehension and repair capabilities of lclms in realistic and important settings by drawing from realworld github issues and constructing qa longcodeqa and bug fixing longswebench tasks we carefully stratify the complexity of our benchmark enabling us to evaluate models across different scales ranging from qwen25 14b instruct to googles flagship gemini model we find that longcontext remains a weakness for all models with performance drops such as from 29 to 3 for claude 35 sonnet or from 702 to 40 for qwen25
http://arxiv.org/abs/2505.07233v2,2025-05-12T05:19:01Z,"Jiashuo Sun, Xianrui Zhong, Sizhe Zhou, Jiawei Han",dynamicrag leveraging outputs of large language model as feedback for dynamic reranking in retrievalaugmented generation,retrievalaugmented generation rag systems combine large language models llms with external knowledge retrieval making them highly effective for knowledgeintensive tasks a crucial but often underexplored component of these systems is the reranker since irrelevant documents in rag systems can mislead the generator the reranker plays a vital role in refining retrieved documents to enhance generation quality and explainability however it is challenging to determine the appropriate number of documents that the reranker should select too few may result in missing critical information while too many introduce noise and inefficiencies although recent studies have explored llmbased rerankers they primarily leverage internal model knowledge and overlook the rich supervisory signals that llms can provide such as using response quality as feedback for optimizing reranking decisions in this paper we propose dynamicrag a novel rag framework where the reranker dynamically adjusts both the order and number of retrieved documents based on the query we model the reranker as an agent optimized through reinforcement learning rl using rewards derived from llm output quality across seven knowledgeintensive datasets dynamicrag demonstrates superior performance achieving stateoftheart results among models of same parameter sizes the model data and code are available at httpsgithubcomgasolsun36dynamicrag
http://arxiv.org/abs/2505.07205v1,2025-05-12T03:28:05Z,"Mouxiao Bian, Rongzhao Zhang, Chao Ding, Xinwei Peng, Jie Xu",benchmarking ethical and safety risks of healthcare llms in chinatoward systemic governance under healthy china 2030,large language models llms are poised to transform healthcare under chinas healthy china 2030 initiative yet they introduce new ethical and patientsafety challenges we present a novel 12000item qa benchmark covering 11 ethics and 9 safety dimensions in medical contexts to quantitatively evaluate these risks using this dataset we assess stateoftheart chinese medical llms eg qwen 2532b deepseek revealing moderate baseline performance accuracy 427 for qwen 2532b and significant improvements after finetuning on our data up to 508 accuracy results show notable gaps in llm decisionmaking on ethics and safety scenarios reflecting insufficient institutional oversight we then identify systemic governance shortfallsincluding the lack of finegrained ethical audit protocols slow adaptation by hospital irbs and insufficient evaluation toolsthat currently hinder safe llm deployment finally we propose a practical governance framework for healthcare institutions embedding llm auditing teams enacting data ethics guidelines and implementing safety simulation pipelines to proactively manage llm risks our study highlights the urgent need for robust llm governance in chinese healthcare aligning ai innovation with patient safety and ethical standards
http://arxiv.org/abs/2505.07202v1,2025-05-12T03:19:55Z,"Hyouin Liu, Zhikuan Zhang",on the cost and benefits of training context with utterance or full conversation training a comparative stud,modern tts systems designed for conversations achieve highquality utterances but often remain inaccessible publicly are existing opensource architectures inadequate or are current training techniques insufficient this paper investigates prominent models and their underlying behaviors regarding conversational context using 20 gpuhours on an nvidia h100 we empirically examine two approaches contextbased utterancelevel training versus full conversation training results demonstrate that contextbased utterance training achieves superior mos scores 4350 vs 3750 and reduces training time by 37 while full conversation approaches suffer from speaker similarity hallucination issues these findings provide practical guidelines for conversational tts development favoring utterancelevel training with contextual conditioning for both resource efficiency and output quality
http://arxiv.org/abs/2505.07188v1,2025-05-12T02:36:50Z,"Chetan Pathade, Shubham Patil",securing genomic data against inference attacks in federated learning environments,federated learning fl offers a promising framework for collaboratively training machine learning models across decentralized genomic datasets without direct data sharing while this approach preserves data locality it remains susceptible to sophisticated inference attacks that can compromise individual privacy in this study we simulate a federated learning setup using synthetic genomic data and assess its vulnerability to three key attack vectors membership inference attack mia gradientbased membership inference attack and label inference attack lia our experiments reveal that gradientbased mia achieves the highest effectiveness with a precision of 079 and f1score of 087 underscoring the risk posed by gradient exposure in federated updates additionally we visualize comparative attack performance through radar plots and quantify model leakage across clients the findings emphasize the inadequacy of naive fl setups in safeguarding genomic privacy and motivate the development of more robust privacypreserving mechanisms tailored to the unique sensitivity of genomic data
http://arxiv.org/abs/2505.07184v1,2025-05-12T02:21:36Z,"Yifan Wei, Xiaoyan Yu, Tengfei Pan, Angsheng Li, Li Du",structural entropy guided agent for detecting and repairing knowledge deficiencies in llms,large language models llms have achieved unprecedented performance by leveraging vast pretraining corpora yet their performance remains suboptimal in knowledgeintensive domains such as medicine and scientific research where high factual precision is required while synthetic data provides a promising avenue for augmenting domain knowledge existing methods frequently generate redundant samples that do not align with the models true knowledge gaps to overcome this limitation we propose a novel structural entropyguided knowledge navigator senator framework that addresses the intrinsic knowledge deficiencies of llms our approach employs the structure entropy se metric to quantify uncertainty along knowledge graph paths and leverages monte carlo tree search mcts to selectively explore regions where the model lacks domainspecific knowledge guided by these insights the framework generates targeted synthetic data for supervised finetuning enabling continuous selfimprovement experimental results on llama3 and qwen2 across multiple domainspecific benchmarks show that senator effectively detects and repairs knowledge deficiencies achieving notable performance improvements the code and data for our methods and experiments are available at httpsgithubcomweiyifan1023senator
http://arxiv.org/abs/2505.07167v1,2025-05-12T01:26:50Z,"Haoran Gu, Handing Wang, Yi Mei, Mengjie Zhang, Yaochu Jin",one trigger token is enough a defense strategy for balancing safety and usability in large language models,large language models llms have been extensively used across diverse domains including virtual assistants automated code generation and scientific research however they remain vulnerable to jailbreak attacks which manipulate the models into generating harmful responses despite safety alignment recent studies have shown that current safetyaligned llms often undergo the shallow safety alignment where the first few tokens largely determine whether the response will be harmful through comprehensive observations we find that safetyaligned llms and various defense strategies generate highly similar initial tokens in their refusal responses which we define as safety trigger tokens building on this insight we propose textttdstt a simple yet effective defense algorithm that identifies and explicitly decodes safety trigger tokens of the given safetyaligned llm to trigger the models learned safety patterns in this process the safety trigger is constrained to a single token which effectively preserves model usability by introducing minimum intervention in the decoding process extensive experiments across diverse jailbreak attacks and benign prompts demonstrate that ours significantly reduces output harmfulness while preserving model usability and incurring negligible response time overhead outperforming ten baseline methods
http://arxiv.org/abs/2505.07166v1,2025-05-12T01:24:00Z,"Zheng Yao, Shuai Wang, Guido Zuccon",pretraining vs finetuning a reproducibility study on dense retrieval knowledge acquisition,dense retrievers utilize pretrained backbone language models eg bert llama that are finetuned via contrastive learning to perform the task of encoding text into sense representations that can be then compared via a shallow similarity operation eg inner product recent research has questioned the role of finetuning vs that of pretraining within dense retrievers specifically arguing that retrieval knowledge is primarily gained during pretraining meaning knowledge not acquired during pretraining cannot be subsequentially acquired via finetuning we revisit this idea here as the claim was only studied in the context of a bertbased encoder using dpr as representative dense retriever we extend the previous analysis by testing other representation approaches comparing the use of cls tokens with that of mean pooling backbone architectures encoderonly bert vs decoderonly llama and additional datasets msmarco in addition to natural questions our study confirms that in dpr tuning pretrained knowledge underpins retrieval performance with finetuning primarily adjusting neuron activation rather than reorganizing knowledge however this pattern does not hold universally such as in meanpooled contriever and decoderbased llama models we ensure full reproducibility and make our implementation publicly available at httpsgithubcomielabdenseretrieverknowledgeacquisition
http://arxiv.org/abs/2505.07162v1,2025-05-12T00:58:25Z,"Hajar Sakai, Sarah S. Lam",kdhmltc knowledge distillation for healthcare multilabel text classification,the increasing volume of healthcare textual data requires computationally efficient yet highly accurate classification approaches able to handle the nuanced and complex nature of medical terminology this research presents knowledge distillation for healthcare multilabel text classification kdhmltc a framework leveraging model compression and large language models llms the proposed approach addresses conventional healthcare multilabel text classification mltc challenges by integrating knowledge distillation and sequential finetuning subsequently optimized through particle swarm optimization pso for hyperparameter tuning kdhmltc transfers knowledge from a more complex teacher llm ie bert to a lighter student llm ie distilbert through sequential training adapted to mltc that preserves the teachers learned information while significantly reducing computational requirements as a result the classification is enabled to be conducted locally making it suitable for healthcare textual data characterized by sensitivity and therefore ensuring hipaa compliance the experiments conducted on three medical literature datasets of different sizes sampled from the hallmark of cancer hoc dataset demonstrate that kdhmltc achieves superior performance compared to existing approaches particularly for the largest dataset reaching an f1 score of 8270 additionally statistical validation and an ablation study are carried out proving the robustness of kdhmltc furthermore the psobased hyperparameter optimization process allowed the identification of optimal configurations the proposed approach contributes to healthcare text classification research balancing efficiency requirements in resourceconstrained healthcare settings with satisfactory accuracy demands
http://arxiv.org/abs/2505.07161v1,2025-05-12T00:48:17Z,"Jannatun Naim, Jie Cao, Fareen Tasneem, Jennifer Jacobs, Brent Milne, James Martin, Tamara Sumner",towards actionable pedagogical feedback a multiperspective analysis of mathematics teaching and tutoring dialogue,effective feedback is essential for refining instructional practices in mathematics education and researchers often turn to advanced natural language processing nlp models to analyze classroom dialogues from multiple perspectives however utterancelevel discourse analysis encounters two primary challenges 1 multifunctionality where a single utterance may serve multiple purposes that a single tag cannot capture and 2 the exclusion of many utterances from domainspecific discourse move classifications leading to their omission in feedback to address these challenges we proposed a multiperspective discourse analysis that integrates domainspecific talk moves with dialogue act using the flattened multifunctional swbdmasl schema with 43 tags and discourse relation applying segmented discourse representation theory with 16 relations our topdown analysis framework enables a comprehensive understanding of utterances that contain talk moves as well as utterances that do not contain talk moves this is applied to two mathematics education datasets talkmoves teaching and saga22 tutoring through distributional unigram analysis sequential talk move analysis and multiview deep dive we discovered meaningful discourse patterns and revealed the vital role of utterances without talk moves demonstrating that these utterances far from being mere fillers serve crucial functions in guiding acknowledging and structuring classroom discourse these insights underscore the importance of incorporating discourse relations and dialogue acts into aiassisted education systems to enhance feedback and create more responsive learning environments our framework may prove helpful for providing human educator feedback but also aiding in the development of ai agents that can effectively emulate the roles of both educators and students
http://arxiv.org/abs/2505.07157v1,2025-05-12T00:31:36Z,"Hajar Sakai, Sarah S. Lam",hamlet healthcarefocused adaptive multilingual learning embeddingbased topic modeling,traditional topic models often struggle with contextual nuances and fail to adequately handle polysemy and rare words this limitation typically results in topics that lack coherence and quality large language models llms can mitigate this issue by generating an initial set of topics however these raw topics frequently lack refinement and representativeness which leads to redundancy without lexical similarity and reduced interpretability this paper introduces hamlet a graphdriven architecture for crosslingual healthcare topic modeling that uses llms the proposed approach leverages neuralenhanced semantic fusion to refine the embeddings of topics generated by the llm instead of relying solely on statistical cooccurrence or human interpretation to extract topics from a document corpus this method introduces a topic embedding refinement that uses bidirectional encoder representations from transformers bert and graph neural networks gnn after topic generation a hybrid technique that involves bert and sentencebert sbert is employed for embedding the topic representations are further refined using a gnn which establishes connections between documents topics words similar topics and similar words a novel method is introduced to compute similarities consequently the topic embeddings are refined and the top k topics are extracted experiments were conducted using two healthcare datasets one in english and one in french from which six sets were derived the results demonstrate the effectiveness of hamlet
http://arxiv.org/abs/2505.07155v1,2025-05-12T00:15:02Z,"Shuai Wang, Harrisen Scells, Bevan Koopman, Guido Zuccon",reassessing large language model boolean query generation for systematic reviews,systematic reviews are comprehensive literature reviews that address highly focused research questions and represent the highest form of evidence in medicine a critical step in this process is the development of complex boolean queries to retrieve relevant literature given the difficulty of manually constructing these queries recent efforts have explored large language models llms to assist in their formulation one of the first studieswang et al investigated chatgpt for this task followed by staudinger et al which evaluated multiple llms in a reproducibility study however the latter overlooked several key aspects of the original work including i validation of generated queries ii output formatting constraints and iii selection of examples for chainofthought guided prompting as a result its findings diverged significantly from the original study in this work we systematically reproduce both studies while addressing these overlooked factors our results show that query effectiveness varies significantly across models and prompt designs with guided query formulation benefiting from wellchosen seed studies overall prompt design and model selection are key drivers of successful query formulation our findings provide a clearer understanding of llms potential in boolean query generation and highlight the importance of model and promptspecific optimisations the complex nature of systematic reviews adds to challenges in both developing and reproducing methods but also highlights the importance of reproducibility studies in this domain
http://arxiv.org/abs/2505.07891v1,2025-05-11T17:00:21Z,"Ching Nam Hang, Pei-Duo Yu, Chee Wei Tan",trumorgpt graphbased retrievalaugmented large language model for factchecking,in the age of social media the rapid spread of misinformation and rumors has led to the emergence of infodemics where false information poses a significant threat to society to combat this issue we introduce trumorgpt a novel generative artificial intelligence solution designed for factchecking in the health domain trumorgpt aims to distinguish trumors which are healthrelated rumors that turn out to be true providing a crucial tool in differentiating between mere speculation and verified facts this framework leverages a large language model llm with fewshot learning for semantic health knowledge graph construction and semantic reasoning trumorgpt incorporates graphbased retrievalaugmented generation graphrag to address the hallucination issue common in llms and the limitations of static training data graphrag involves accessing and utilizing information from regularly updated semantic health knowledge graphs that consist of the latest medical news and health information ensuring that factchecking by trumorgpt is based on the most recent data evaluating with extensive healthcare datasets trumorgpt demonstrates superior performance in factchecking for public health claims its ability to effectively conduct factchecking across various platforms marks a critical step forward in the fight against healthrelated misinformation enhancing trust and accuracy in the digital information age
http://arxiv.org/abs/2505.07027v1,2025-05-11T15:43:00Z,"Haorui Wang, Jeff Guo, Lingkai Kong, Rampi Ramprasad, Philippe Schwaller, Yuanqi Du, Chao Zhang",llmaugmented chemical synthesis and design decision programs,retrosynthesis the process of breaking down a target molecule into simpler precursors through a series of valid reactions stands at the core of organic chemistry and drug development although recent machine learning ml research has advanced singlestep retrosynthetic modeling and subsequent route searches these solutions remain restricted by the extensive combinatorial space of possible pathways concurrently large language models llms have exhibited remarkable chemical knowledge hinting at their potential to tackle complex decisionmaking tasks in chemistry in this work we explore whether llms can successfully navigate the highly constrained multistep retrosynthesis planning problem we introduce an efficient scheme for encoding reaction pathways and present a new routelevel search strategy moving beyond the conventional stepbystep reactant prediction through comprehensive evaluations we show that our llmaugmented approach excels at retrosynthesis planning and extends naturally to the broader challenge of synthesizable molecular design
http://arxiv.org/abs/2505.06993v1,2025-05-11T14:37:30Z,"Yuxuan He, Junpeng Zhang, Hongyuan Zhang, Quanshi Zhang",towards the threephase dynamics of generalization power of a dnn,this paper proposes a new perspective for analyzing the generalization power of deep neural networks dnns ie directly disentangling and analyzing the dynamics of generalizable and nongeneralizable interaction encoded by a dnn through the training process specifically this work builds upon the recent theoretical achievement in explainble ai which proves that the detailed inference logic of dnns can be can be strictly rewritten as a small number of andor interaction patterns based on this we propose an efficient method to quantify the generalization power of each interaction and we discover a distinct threephase dynamics of the generalization power of interactions during training in particular the early phase of training typically removes noisy and nongeneralizable interactions and learns simple and generalizable ones the second and the third phases tend to capture increasingly complex interactions that are harder to generalize experimental results verify that the learning of nongeneralizable interactions is the the direct cause for the gap between the training and testing losses
http://arxiv.org/abs/2505.07890v3,2025-05-11T14:30:56Z,"Kutay Ertürk, Furkan Altınışık, İrem Sarıaltın, Ömer Nezih Gerek",tslformer a lightweight transformer model for turkish sign language recognition using skeletal landmarks,this study presents tslformer a light and robust wordlevel turkish sign language tsl recognition model that treats sign gestures as ordered stringlike language instead of using raw rgb or depth videos our method only works with 3d joint positions articulation points extracted using googles mediapipe library which focuses on the hand and torso skeletal locations this creates efficient input dimensionality reduction while preserving important semantic gesture information our approach revisits sign language recognition as sequencetosequence translation inspired by the linguistic nature of sign languages and the success of transformers in natural language processing since tslformer uses the selfattention mechanism it effectively captures temporal cooccurrence within gesture sequences and highlights meaningful motion patterns as words unfold evaluated on the autsl dataset with over 36000 samples and 227 different words tslformer achieves competitive performance with minimal computational cost these results show that jointbased input is sufficient for enabling realtime mobile and assistive communication systems for hearingimpaired individuals
http://arxiv.org/abs/2505.06987v1,2025-05-11T14:13:58Z,"Xiaoyu Wang, Yue Zhao, Qingqing Gu, Zhonglin Jiang, Xiaokai Chen, Yong Chen, Luo Ji",convert language model into a valuebased strategic planner,emotional support conversation esc aims to alleviate the emotional distress of individuals through effective conversations although large language models llms have obtained remarkable progress on esc most of these studies might not define the diagram from the state model perspective therefore providing a suboptimal solution for longterm satisfaction to address such an issue we leverage the qlearning on llms and propose a framework called straq our framework allows a plugandplay llm to bootstrap the planning during esc determine the optimal strategy based on longterm returns and finally guide the llm to response substantial experiments on esc datasets suggest that straq outperforms many baselines including direct inference selfrefine chain of thought finetuning and finite state machines
http://arxiv.org/abs/2505.06974v1,2025-05-11T13:17:44Z,"Daichi Kohmoto, Katsutoshi Fukuda, Daisuke Yoshida, Takafumi Matsui, Sachihiro Omura",cnnbased image models verify a hypothesis that the writers of cuneiform texts improved their writing skills when studying at the age of hittite empire,a cuneiform tablet kbo 231 kub 3038 which is known to represent a text of kizzuwatna rituals was written by two writers with almost identical content in two iterations unlike other cuneiform tablets that contained information such as myths essays or business records the reason why ancient people left such tablets for posterity remains unclear to study this problem we develop a new methodology by analyzing images of a tablet quantitatively using cnn convolutional neural networkbased image models without segmenting cuneiforms onebyone our datadriven methodology implies that the writer writing the first half was a teacher and the other writer was a student who was training his skills of writing cuneiforms this result has not been reached by classical linguistics we also discuss related conclusions and possible further directions for applying our method and its generalizations
http://arxiv.org/abs/2505.06972v1,2025-05-11T13:07:15Z,"Yuichi Sasazawa, Yasuhiro Sogawa",web page classification using llms for crawling support,a web crawler is a system designed to collect web pages and efficient crawling of new pages requires appropriate algorithms while website features such as xml sitemaps and the frequency of past page updates provide important clues for accessing new pages their universal application across diverse conditions is challenging in this study we propose a method to efficiently collect new pages by classifying web pages into two types index pages and content pages using a large language model llm and leveraging the classification results to select index pages as starting points for accessing new pages we construct a dataset with automatically annotated web page types and evaluate our approach from two perspectives the page type classification performance and coverage of new pages experimental results demonstrate that the llmbased method outperformed baseline methods in both evaluation metrics
http://arxiv.org/abs/2505.06938v1,2025-05-11T11:05:16Z,Katarzyna Anna Kapitan,a digital perspective on the role of a stemma in materialphilological transmission studies,taking its point of departure in the recent developments in the field of digital humanities and the increasing automatisation of scholarly workflows this study explores the implications of digital approaches to textual traditions for the broader field of textual scholarship it argues that the relative simplicity of creating computergenerated stemmas allows us to view the stemma codicum as a research tool rather than the final product of our scholarly investigation using the old norse saga of hromundur as a case study this article demonstrates that stemmas can serve as a starting point for exploring textual traditions further in doing so they enable us to address research questions that otherwise remain unanswered the article is accompanied by datasets used to generate stemmas for the hromundar saga tradition as well as two custom python scripts the scripts are designed to convert xmlbased textual data encoded according to the tei guidelines into the input format used for the analysis in the phylip package to generate unrooted trees of relationships between texts
http://arxiv.org/abs/2505.07889v1,2025-05-11T09:42:24Z,"Yuyang Liu, Liuzhenghao Lv, Xiancheng Zhang, Li Yuan, Yonghong Tian",bioprobench comprehensive dataset and benchmark in biological protocol understanding and reasoning,biological protocols are fundamental to reproducible and safe life science research while llms excel on general tasks their systematic evaluation on these highly specialized accuracycritical and inherently procedural texts remains limited in this work we present bioprobench the first largescale integrated multitask benchmark for biological protocol understanding and reasoning while limited benchmarks have touched upon specific aspects like protocol qa bioprobench provides a comprehensive suite of five core tasks protocol question answering step ordering error correction protocol generation and protocol reasoning enabling a holistic evaluation of llms on procedural biological texts built upon 27k original protocols it yields nearly 556k highquality structured instances we evaluate 12 mainstream openclosedsource llms on bioprobench experimental results reveal that while top models preform well on surface understanding tasks struggle significantly with deep reasoning and structured generation tasks like ordering and generation furthermore model comparisons reveal diverse performance certain opensource models approach closedsource levels on some tasks yet biospecific small models lag behind general llms indicating limitations on complex procedural content overall our findings underscore that procedural reasoning within biological protocols represents a significant challenge for current llms bioprobench serves as a standardized framework to diagnose these specific limitations and guide the development of ai systems better equipped for safely automating complex scientific procedures the code and data are available at httpsgithubcomyuyangsunshinebioprotocolbench and httpshuggingfacecodatasetsgreatcaptainnemobioprobench
http://arxiv.org/abs/2505.06914v1,2025-05-11T09:25:05Z,"Chen Amiraz, Florin Cuconasu, Simone Filice, Zohar Karnin",the distracting effect understanding irrelevant passages in rag,a wellknown issue with retrieval augmented generation rag is that retrieved passages that are irrelevant to the query sometimes distract the answergenerating llm causing it to provide an incorrect response in this paper we shed light on this core issue and formulate the distracting effect of a passage wrt a query and an llm we provide a quantifiable measure of the distracting effect of a passage and demonstrate its robustness across llms our research introduces novel methods for identifying and using hard distracting passages to improve rag systems by finetuning llms with these carefully selected distracting passages we achieve up to a 75 increase in answering accuracy compared to counterparts finetuned on conventional rag datasets our contribution is twofold first we move beyond the simple binary classification of irrelevant passages as either completely unrelated vs distracting and second we develop and analyze multiple methods for finding hard distracting passages to our knowledge no other research has provided such a comprehensive framework for identifying and utilizing hard distracting passages
http://arxiv.org/abs/2505.06904v1,2025-05-11T08:51:56Z,"Xinyi Mou, Chen Qian, Wei Liu, Xuanjing Huang, Zhongyu Wei",ecolang efficient and effective agent communication language induction for social simulation,large language models llms have demonstrated an impressive ability to roleplay humans and replicate complex social dynamics while largescale social simulations are gaining increasing attention they still face significant challenges particularly regarding high time and computation costs existing solutions such as distributed mechanisms or hybrid agentbased model abm integrations either fail to address inference costs or compromise accuracy and generalizability to this end we propose ecolang efficient and effective agent communication language induction for social simulation ecolang operates in two stages 1 language evolution where we filter synonymous words and optimize sentencelevel rules through natural selection and 2 language utilization where agents in social simulations communicate using the evolved language experimental results demonstrate that ecolang reduces token consumption by over 20 enhancing efficiency without sacrificing simulation accuracy
http://arxiv.org/abs/2505.06898v1,2025-05-11T08:32:01Z,"Honglong Yang, Shanshan Song, Yi Qin, Lehan Wang, Haonan Wang, Xinpeng Ding, Qixiang Zhang, Bodong Du, Xiaomeng Li",multimodal explainable medical ai assistant for trustworthy humanai collaboration,generalist medical ai gmai systems have demonstrated expertlevel performance in biomedical perception tasks yet their clinical utility remains limited by inadequate multimodal explainability and suboptimal prognostic capabilities here we present xmedgpt a cliniciancentric multimodal ai assistant that integrates textual and visual interpretability to support transparent and trustworthy medical decisionmaking xmedgpt not only produces accurate diagnostic and descriptive outputs but also grounds referenced anatomical sites within medical images bridging critical gaps in interpretability and enhancing clinician usability to support realworld deployment we introduce a reliability indexing mechanism that quantifies uncertainty through consistencybased assessment via interactive questionanswering we validate xmedgpt across four pillars multimodal interpretability uncertainty quantification and prognostic modeling and rigorous benchmarking the model achieves an iou of 0703 across 141 anatomical regions and a kendalls taub of 0479 demonstrating strong alignment between visual rationales and clinical outcomes for uncertainty estimation it attains an auc of 0862 on visual question answering and 0764 on radiology report generation in survival and recurrence prediction for lung and glioma cancers it surpasses prior leading models by 269 and outperforms gpt4o by 250 rigorous benchmarking across 347 datasets covers 40 imaging modalities and external validation spans 4 anatomical systems confirming exceptional generalizability with performance gains surpassing existing gmai by 207 for indomain evaluation and 167 on 11530 inhouse data evaluation together xmedgpt represents a significant leap forward in cliniciancentric ai integration offering trustworthy and scalable support for diverse healthcare applications
http://arxiv.org/abs/2505.06889v1,2025-05-11T07:54:33Z,"Mihyeon Kim, Juhyoung Park, Youngbin Kim",imbert enhancing robustness of bert through the implicit euler method,pretrained language models plms have achieved remarkable performance on diverse nlp tasks through pretraining and finetuning however finetuning the model with a large number of parameters on limited downstream datasets often leads to vulnerability to adversarial attacks causing overfitting of the model on standard datasets to address these issues we propose imbert from the perspective of a dynamic system by conceptualizing a layer of bert as a solution of ordinary differential equations odes under the situation of initial value perturbation we analyze the numerical stability of two main numerical ode solvers the explicit and implicit euler approaches based on these analyses we introduce a numerically robust imconnection incorporating berts layers this strategy enhances the robustness of plms against adversarial attacks even in lowresource scenarios without introducing additional parameters or adversarial training strategies experimental results on the adversarial glue advglue dataset validate the robustness of imbert under various conditions compared to the original bert imbert exhibits a performance improvement of approximately 83p on the advglue dataset furthermore in lowresource scenarios imbert outperforms bert by achieving 59p higher accuracy
http://arxiv.org/abs/2505.06862v1,2025-05-11T06:14:39Z,Lhuqita Fazry,a splitthenjoin approach to abstractive summarization for very long documents in a low resource setting,model achieves on abstractive text summarization for long documents however its capacity still limited to maximum of tokens thus caused performance degradation on summarization for very long documents common method to deal with the issue is to truncate the documents in this reasearch well use different approach well use the pretrained model by fine tuned the model on other domain dataset first we filter out all documents which length less than tokens to focus on very long documents to prevent domain shifting problem and overfitting on transfer learning due to small dataset we augment the dataset by splitting documentsummary training pair into parts to fit the document into tokens source code available on
http://arxiv.org/abs/2505.07888v1,2025-05-11T05:53:33Z,"Yusen Wu, Xiaotie Deng",implementing long text style transfer with llms through duallayered sentence and paragraph structure extraction and mapping,this paper addresses the challenge in longtext style transfer using zeroshot learning of large language models llms proposing a hierarchical framework that combines sentencelevel stylistic adaptation with paragraphlevel structural coherence we argue that in the process of effective paragraphstyle transfer to preserve the consistency of original syntactic and semantic information it is essential to perform style transfer not only at the sentence level but also to incorporate paragraphlevel semantic considerations while ensuring structural coherence across intersentential relationships our proposed framework zerostylus operates through two systematic phases hierarchical template acquisition from reference texts and templateguided generation with multigranular matching the framework dynamically constructs sentence and paragraph template repositories enabling contextaware transformations while preserving intersentence logical relationships experimental evaluations demonstrate significant improvements over baseline methods with structured rewriting achieving 690 average score compared to 670 for direct prompting approaches in triaxial metrics assessing style consistency content preservation and expression quality ablation studies validate the necessity of both template hierarchies during style transfer showing higher content preservation win rate against sentenceonly approaches through paragraphlevel structural encoding as well as direct prompting method through sentencelevel pattern extraction and matching the results establish new capabilities for coherent longtext style transfer without requiring parallel corpora or llm finetuning
http://arxiv.org/abs/2505.06843v1,2025-05-11T04:59:20Z,"Zihan Guan, Mengxuan Hu, Ronghang Zhu, Sheng Li, Anil Vullikanti",benign samples matter finetuning on outlier benign samples severely breaks safety,recent studies have uncovered a troubling vulnerability in the finetuning stage of large language models llms even finetuning on entirely benign datasets can lead to a significant increase in the harmfulness of llm outputs building on this finding our red teaming study takes this threat one step further by developing a more effective attack specifically we analyze and identify samples within benign datasets that contribute most to safety degradation then finetune llms exclusively on these samples we approach this problem from an outlier detection perspective and propose selfinfn to detect and extract outliers for finetuning our findings reveal that finetuning llms on 100 outlier samples selected by selfinfn in the benign datasets severely compromises llm safety alignment extensive experiments across seven mainstream llms demonstrate that our attack exhibits high transferability across different architectures and remains effective in practical scenarios alarmingly our results indicate that most existing mitigation strategies fail to defend against this attack underscoring the urgent need for more robust alignment safeguards codes are available at httpsgithubcomguanzihanbenignsamplesmatter
http://arxiv.org/abs/2505.06814v1,2025-05-11T02:15:14Z,"Bin Li, Shenxi Liu, Yixuan Weng, Yue Du, Yuhang Tian, Shoujun Zhou",overview of the nlpcc 2025 shared task 4 multimodal multilingual and multihop medical instructional video question answering challenge,following the successful hosts of the 1st nlpcc 2023 foshan cmivqa and the 2rd nlpcc 2024 hangzhou mmivqa challenges this year a new task has been introduced to further advance research in multimodal multilingual and multihop medical instructional question answering m4ivqa systems with a specific focus on medical instructional videos the m4ivqa challenge focuses on evaluating models that integrate information from medical instructional videos understand multiple languages and answer multihop questions requiring reasoning over various modalities this task consists of three tracks multimodal multilingual and multihop temporal answer grounding in single video m4tagsv multimodal multilingual and multihop video corpus retrieval m4vcr and multimodal multilingual and multihop temporal answer grounding in video corpus m4tagvc participants in m4ivqa are expected to develop algorithms capable of processing both video and text data understanding multilingual queries and providing relevant answers to multihop medical questions we believe the newly introduced m4ivqa challenge will drive innovations in multimodal reasoning systems for healthcare scenarios ultimately contributing to smarter emergency response systems and more effective medical education platforms in multilingual communities our official website is httpscmivqagithubio
http://arxiv.org/abs/2505.06803v1,2025-05-11T01:01:44Z,"Xilin Jiang, Junkai Wu, Vishal Choudhari, Nima Mesgarani",bridging ears and eyes analyzing audio and visual large language models to humans in visible sound recognition and reducing their sensory gap via crossmodal distillation,audio large language models llms are considered experts at recognizing sound objects yet their performance relative to llms in other sensory modalities such as visual or audiovisual llms and to humans using their ears eyes or both remains unexplored to investigate this we systematically evaluate audio visual and audiovisual llms specifically qwen2audio qwen2vl and qwen25omni against humans in recognizing sound objects of different classes from audioonly silent video or sounded video inputs we uncover a performance gap between qwen2audio and qwen2vl that parallels the sensory discrepancy between human ears and eyes to reduce this gap we introduce a crossmodal distillation framework where an llm in one modality serves as the teacher and another as the student with knowledge transfer in sound classes predicted as more challenging to the student by a heuristic model distillation in both directions from qwen2vl to qwen2audio and vice versa leads to notable improvements particularly in challenging classes this work highlights the sensory gap in llms from a humanaligned perspective and proposes a principled approach to enhancing modalityspecific perception in multimodal llms
http://arxiv.org/abs/2505.07886v1,2025-05-11T00:56:03Z,"Chun-Pai Yang, Kan Zheng, Shou-De Lin",plhf prompt optimization with fewshot human feedback,automatic prompt optimization frameworks are developed to obtain suitable prompts for large language models llms with respect to desired output quality metrics although existing approaches can handle conventional tasks such as fixedsolution question answering defining the metric becomes complicated when the output quality cannot be easily assessed by comparisons with standard golden samples consequently optimizing the prompts effectively and efficiently without a clear metric becomes a critical challenge to address the issue we present plhf which stands for prompt learning with human feedback a fewshot prompt optimization framework inspired by the wellknown rlhf technique different from naive strategies plhf employs a specific evaluator module acting as the metric to estimate the output quality plhf requires only a single round of human feedback to complete the entire prompt optimization process empirical results on both public and industrial datasets show that plhf outperforms prior output grading strategies for llm prompt optimizations
http://arxiv.org/abs/2505.06782v1,2025-05-10T23:40:28Z,"Damian Curran, Brian Chapman, Mike Conway",utilizing llms to investigate the disputed role of evidence in electronic cigarette health policy formation in australia and the uk,australia and the uk have developed contrasting approaches to the regulation of electronic cigarettes with broadly speaking australia adopting a relatively restrictive approach and the uk adopting a more permissive approach notably these divergent policies were developed from the same broad evidence base in this paper to investigate differences in how the two jurisdictions manage and present evidence we developed and evaluated a large language modelbased sentence classifier to perform automated analyses of electronic cigaretterelated policy documents drawn from official australian and uk legislative processes 109 documents in total specifically we utilized gpt4 to automatically classify sentences based on whether they contained claims that ecigarettes were broadly helpful or harmful for public health our llmbased classifier achieved an fscore of 09 further when applying the classifier to our entire sentencelevel corpus we found that australian legislative documents show a much higher proportion of harmful statements and a lower proportion of helpful statements compared to the expected values with the opposite holding for the uk in conclusion this work utilized an llmbased approach to provide evidence to support the contention that drawing on the same evidence base australian endsrelated policy documents emphasize the harms associated with ends products and uk policy documents emphasize the benefits further our approach provides a starting point for using llmbased methods to investigate the complex relationship between evidence and health policy formation
http://arxiv.org/abs/2505.07884v1,2025-05-10T22:59:24Z,"S. E Emedem, I. E Onyenwe, E. G Onyedinma",development of a wazobianamed entity recognition system,named entity recognition ner is very crucial for various natural language processing applications including information extraction machine translation and sentiment analysis despite the everincreasing interest in african languages within computational linguistics existing ner systems focus mainly on english european and a few other global languages leaving a significant gap for underresourced languages this research presents the development of a wazobianer system tailored for the three most prominent nigerian languages hausa yoruba and igbo this research begins with a comprehensive compilation of annotated datasets for each language addressing data scarcity and linguistic diversity challenges exploring the stateoftheart machine learning technique conditional random fields crf and deep learning models such as bidirectional long shortterm memory bilstm bidirectional encoder representation from transformers bert and finetune with a recurrent neural network rnn the study evaluates the effectiveness of these approaches in recognizing three entities persons organizations and locations the system utilizes optical character recognition ocr technology to convert textual images into machinereadable text thereby enabling the wazobia system to accept both input text and textual images for extraction purposes the system achieved a performance of 09511 in precision 09400 in recall 09564 in f1score and 09301 in accuracy the models evaluation was conducted across three languages with precision recall f1score and accuracy as key assessment metrics the wazobianer system demonstrates that it is feasible to build robust ner tools for underresourced african languages using current nlp frameworks and transfer learning
http://arxiv.org/abs/2505.07883v1,2025-05-10T19:04:56Z,"Jian-Qiao Zhu, Haijiang Yan, Thomas L. Griffiths",recovering event probabilities from large language model embeddings via axiomatic constraints,rational decisionmaking under uncertainty requires coherent degrees of belief in events however event probabilities generated by large language models llms have been shown to exhibit incoherence violating the axioms of probability theory this raises the question of whether coherent event probabilities can be recovered from the embeddings used by the models if so those derived probabilities could be used as more accurate estimates in events involving uncertainty to explore this question we propose enforcing axiomatic constraints such as the additive rule of probability theory in the latent space learned by an extended variational autoencoder vae applied to llm embeddings this approach enables event probabilities to naturally emerge in the latent space as the vae learns to both reconstruct the original embeddings and predict the embeddings of semantically related events we evaluate our method on complementary events ie event a and its complement event nota where the true probabilities of the two events must sum to 1 experiment results on openweight language models demonstrate that probabilities recovered from embeddings exhibit greater coherence than those directly reported by the corresponding models and align closely with the true probabilities
http://arxiv.org/abs/2505.06708v1,2025-05-10T17:15:49Z,"Zihan Qiu, Zekun Wang, Bo Zheng, Zeyu Huang, Kaiyue Wen, Songlin Yang, Rui Men, Le Yu, Fei Huang, Suozhi Huang, Dayiheng Liu, Jingren Zhou, Junyang Lin",gated attention for large language models nonlinearity sparsity and attentionsinkfree,gating mechanisms have been widely utilized from early models like lstms and highway networks to recent state space models linear attention and also softmax attention yet existing literature rarely examines the specific effects of gating in this work we conduct comprehensive experiments to systematically investigate gatingaugmented softmax attention variants specifically we perform a comprehensive comparison over 30 variants of 15b mixtureofexperts moe models and 17b dense models trained on a 35 trillion token dataset our central finding is that a simple modificationapplying a headspecific sigmoid gate after the scaled dotproduct attention sdpaconsistently improves performance this modification also enhances training stability tolerates larger learning rates and improves scaling properties by comparing various gating positions and computational variants we attribute this effectiveness to two key factors 1 introducing nonlinearity upon the lowrank mapping in the softmax attention and 2 applying querydependent sparse gating scores to modulate the sdpa output notably we find this sparse gating mechanism mitigates attention sink and enhances longcontext extrapolation performance and we also release related and to facilitate future research
http://arxiv.org/abs/2505.06698v2,2025-05-10T16:52:40Z,"Zongqi Wang, Tianle Gu, Chen Gong, Xin Tian, Siqi Bao, Yujiu Yang",from rankings to insights evaluation should shift focus from leaderboard to feedback,automatic evaluation benchmarks such as mtbench arenahard and autoarena are seeing growing adoption for the evaluation of large language models llms existing research has primarily focused on approximating humanbased model rankings using limited data and llmasajudge however the fundamental premise of these studies which attempts to replicate human rankings is flawed specifically these benchmarks typically offer only overall scores limiting their utility to leaderboard rankings rather than providing feedback that can guide model optimization and support model profiling therefore we advocate for an evaluation paradigm shift from approximating humanbased model rankings to providing feedback with analytical value to this end we introduce textbffeedbacker an evaluation framework that provides comprehensive and finegrained results thereby enabling thorough identification of a models specific strengths and weaknesses such feedback not only supports the targeted optimization of the model but also enhances the understanding of its behavior feedbacker comprises three key components an extensible treebased query taxonomy builder an automated query synthesis scheme and a suite of visualization and analysis tools furthermore we propose a novel llmasajudge method pc precomparisonderived criteria pointwise evaluation this method derives evaluation criteria by precomparing the differences between several auxiliary responses achieving the accuracy of pairwise evaluation while maintaining the time complexity of pointwise evaluation finally leveraging the evaluation results of 17 mainstream llms we demonstrate the usage of feedbacker and highlight its effectiveness and potential our project homepage and dataset are available at httpsliudan193githubiofeedbacker
http://arxiv.org/abs/2505.06696v1,2025-05-10T16:47:08Z,"Dominik Koterwa, Maciej Świtała",enhancing bertopic with intermediate layer representations,bertopic is a topic modeling algorithm that leverages transformerbased embeddings to create dense clusters enabling the estimation of topic structures and the extraction of valuable insights from a corpus of documents this approach allows users to efficiently process largescale text data and gain meaningful insights into its structure while bertopic is a powerful tool embedding preparation can vary including extracting representations from intermediate model layers and applying transformations to these embeddings in this study we evaluate 18 different embedding representations and present findings based on experiments conducted on three diverse datasets to assess the algorithms performance we report topic coherence and topic diversity metrics across all experiments our results demonstrate that for each dataset it is possible to find an embedding configuration that performs better than the default setting of bertopic additionally we investigate the influence of stop words on different embedding configurations
http://arxiv.org/abs/2505.06660v1,2025-05-10T14:23:37Z,"Junyi Peng, Takanori Ashihara, Marc Delcroix, Tsubasa Ochiai, Oldrich Plchot, Shoko Araki, Jan Černocký",tssuperb a target speech processing benchmark for speech selfsupervised learning models,selfsupervised learning ssl models have significantly advanced speech processing tasks and several benchmarks have been proposed to validate their effectiveness however previous benchmarks have primarily focused on singlespeaker scenarios with less exploration of targetspeaker tasks in noisy multitalker conditions a more challenging yet practical case in this paper we introduce the targetspeaker speech processing universal performance benchmark tssuperb which includes four widely recognized targetspeaker processing tasks that require identifying the target speaker and extracting information from the speech mixture in our benchmark the speaker embedding extracted from enrollment speech is used as a clue to condition downstream models the benchmark result reveals the importance of evaluating ssl models in target speaker scenarios demonstrating that performance cannot be easily inferred from related singlespeaker tasks moreover by using a unified sslbased target speech encoder consisting of a speaker encoder and an extractor module we also investigate joint optimization across ts tasks to leverage mutual information and demonstrate its effectiveness
http://arxiv.org/abs/2505.06653v1,2025-05-10T14:00:15Z,"Patrick Blumenberg, Thomas Graave, Tim Fingscheidt",improving blockwise llm quantization by 4bit blockwise optimal float bof4 analysis and variations,large language models llms demand extensive memory capacity during both finetuning and inference to enable memoryefficient finetuning existing methods apply blockwise quantization techniques such as nf4 and af4 to the network weights we show that these quantization techniques incur suboptimal quantization errors therefore as a first novelty we propose an optimization approach for blockwise quantization using this method we design a family of quantizers named 4bit blockwise optimal float bof4 which consistently reduces the quantization error compared to both baseline methods we provide both a theoretical and a datadriven solution for the optimization process and prove their practical equivalence secondly we propose a modification to the employed normalization method based on the signed absolute block maximum bof4s enabling further reduction of the quantization error and empirically achieving less degradation in language modeling performance thirdly we explore additional variations of blockwise quantization methods applied to llms through an experimental study on the importance of accurately representing zero and largeamplitude weights on the one hand and optimization towards various error metrics on the other hand lastly we introduce a mixedprecision quantization strategy dubbed outlierpreserving quantization opq to address the distributional mismatch induced by outlier weights in blockwise quantization by storing outlier weights in 16bit precision opq while applying bof4s we achieve top performance among 4bit blockwise quantization techniques wrt perplexity
http://arxiv.org/abs/2505.06633v1,2025-05-10T12:54:21Z,Isaac Gerber,attention is not all you need the importance of feedforward networks in transformer models,decoderonly transformer networks have become incredibly popular for language modeling tasks stateoftheart models can have over a hundred transformer blocks containing billions of trainable parameters and are trained on trillions of tokens of text each transformer block typically consists of a multihead attention mha mechanism and a twolayer fully connected feedforward network ffn in this paper we examine the importance of the ffn during the model pretraining process through a series of experiments confirming that the ffn is important to model performance furthermore we show that models using a transformer block configuration with threelayer ffns with fewer such blocks outperform the standard twolayer configuration delivering lower training loss with fewer total parameters in less time
http://arxiv.org/abs/2505.06630v1,2025-05-10T12:36:00Z,"Chunyi Yue, Ang Li",dynamic domain information modulation algorithm for multidomain sentiment analysis,multidomain sentiment classification aims to mitigate poor performance models due to the scarcity of labeled data in a single domain by utilizing data labeled from various domains a series of models that jointly train domain classifiers and sentiment classifiers have demonstrated their advantages because domain classification helps generate necessary information for sentiment classification intuitively the importance of sentiment classification tasks is the same in all domains for multidomain sentiment classification but domain classification tasks are different because the impact of domain information on sentiment classification varies across different fields this can be controlled through adjustable weights or hyper parameters however as the number of domains increases existing hyperparameter optimization algorithms may face the following challenges 1 tremendous demand for computing resources 2 convergence problems and 3 high algorithm complexity to efficiently generate the domain information required for sentiment classification in each domain we propose a dynamic information modulation algorithm specifically the model training process is divided into two stages in the first stage a shared hyperparameter which would control the proportion of domain classification tasks across all fields is determined in the second stage we introduce a novel domainaware modulation algorithm to adjust the domain information contained in the input text which is then calculated based on a gradientbased and lossbased method in summary experimental results on a public sentiment analysis dataset containing 16 domains prove the superiority of the proposed method
http://arxiv.org/abs/2505.06624v1,2025-05-10T12:16:03Z,"Arezoo Hatefi, Xuan-Son Vu, Monowar Bhuyan, Frank Drewes",the efficiency of pretraining with objective masking in pseudo labeling for semisupervised text classification,we extend and study a semisupervised model for text classification proposed earlier by hatefi et al for classification tasks in which document classes are described by a small number of goldlabeled examples while the majority of training examples is unlabeled the model leverages the teacherstudent architecture of meta pseudo labels in which a teacher generates labels for originally unlabeled training data to train the student and updates its own model iteratively based on the performance of the student on the goldlabeled portion of the data we extend the original model of hatefi et al by an unsupervised pretraining phase based on objective masking and conduct indepth performance evaluations of the original model our extension and various independent baselines experiments are performed using three different datasets in two different languages english and swedish
http://arxiv.org/abs/2505.06607v1,2025-05-10T11:37:15Z,"Min Li, Chun Yuan",boosting neural language inference via cascaded interactive reasoning,natural language inference nli focuses on ascertaining the logical relationship entailment contradiction or neutral between a given premise and hypothesis this task presents significant challenges due to inherent linguistic features such as diverse phrasing semantic complexity and contextual nuances while pretrained language models plms built upon the transformer architecture have yielded substantial advancements in nli prevailing methods predominantly utilize representations from the terminal layer this reliance on finallayer outputs may overlook valuable information encoded in intermediate layers potentially limiting the capacity to model intricate semantic interactions effectively addressing this gap we introduce the cascaded interactive reasoning network cirn a novel architecture designed for deeper semantic comprehension in nli cirn implements a hierarchical feature extraction strategy across multiple network depths operating within an interactive space where crosssentence information is continuously integrated this mechanism aims to mimic a process of progressive reasoning transitioning from surfacelevel feature matching to uncovering more profound logical and semantic connections between the premise and hypothesis by systematically mining latent semantic relationships at various representational levels cirn facilitates a more thorough understanding of the input pair comprehensive evaluations conducted on several standard nli benchmark datasets reveal consistent performance gains achieved by cirn over competitive baseline approaches demonstrating the efficacy of leveraging multilevel interactive features for complex relational reasoning
http://arxiv.org/abs/2505.06605v1,2025-05-10T11:33:48Z,"Min Li, Chun Yuan",using external knowledge to enhanced plm for semantic matching,modeling semantic relevance has always been a challenging and critical task in natural language processing in recent years with the emergence of massive amounts of annotated data it has become feasible to train complex models such as neural networkbased reasoning models these models have shown excellent performance in practical applications and have achieved the current stateoftheart performance however even with such largescale annotated data we still need to think can machines learn all the knowledge necessary to perform semantic relevance detection tasks based on this data alone if not how can neural networkbased models incorporate external knowledge into themselves and how can relevance detection models be constructed to make full use of external knowledge in this paper we use external knowledge to enhance the pretrained semantic relevance discrimination model experimental results on 10 public datasets show that our method achieves consistent improvements in performance compared to the baseline model
http://arxiv.org/abs/2505.06599v1,2025-05-10T11:10:48Z,"Abbas Bertina, Shahab Beirami, Hossein Biniazian, Elham Esmaeilnia, Soheil Shahi, Mahdi Pirnia",bridging the gap an intermediate language for enhanced and costeffective graphemetophoneme conversion with homographs with multiple pronunciations disambiguation,graphemetophoneme g2p conversion for persian presents unique challenges due to its complex phonological features particularly homographs and ezafe which exist in formal and informal language contexts this paper introduces an intermediate language specifically designed for persian language processing that addresses these challenges through a multifaceted approach our methodology combines two key components large language model llm prompting techniques and a specialized sequencetosequence machine transliteration architecture we developed and implemented a systematic approach for constructing a comprehensive lexical database for homographs with multiple pronunciations disambiguation often termed polyphones utilizing formal concept analysis for semantic differentiation we train our model using two distinct datasets the llmgenerated dataset for formal and informal persian and the bplus podcasts for informal language variants the experimental results demonstrate superior performance compared to existing stateoftheart approaches particularly in handling the complexities of persian phoneme conversion our model significantly improves phoneme error rate per metrics establishing a new benchmark for persian g2p conversion accuracy this work contributes to the growing research in lowresource language processing and provides a robust solution for persian texttospeech systems and demonstrating its applicability beyond persian specifically the approach can extend to languages with rich homographic phenomena such as chinese and arabic
http://arxiv.org/abs/2505.06594v1,2025-05-10T10:52:23Z,"Galann Pennec, Zhengyuan Liu, Nicholas Asher, Philippe Muller, Nancy F. Chen",integrating video and text a balanced approach to multimodal summary generation and evaluation,visionlanguage models vlms often struggle to balance visual and textual information when summarizing complex multimodal inputs such as entire tv show episodes in this paper we propose a zeroshot videototext summarization approach that builds its own screenplay representation of an episode effectively integrating key video moments dialogue and character information into a unified document unlike previous approaches we simultaneously generate screenplays and name the characters in zeroshot using only the audio video and transcripts as input additionally we highlight that existing summarization metrics can fail to assess the multimodal content in summaries to address this we introduce mfactsum a multimodal metric that evaluates summaries with respect to both vision and text modalities using mfactsum we evaluate our screenplay summaries on the summscreen3d dataset demonstrating superiority against stateoftheart vlms such as gemini 15 by generating summaries containing 20 more relevant visual information while requiring 75 less of the video as input
http://arxiv.org/abs/2505.06591v1,2025-05-10T10:47:23Z,"Anna Wróblewska, Bartosz Grabek, Jakub Świstak, Daniel Dan",evaluating llmgenerated qa test a studentcentered study,this research prepares an automatic pipeline for generating reliable questionanswer qa tests using ai chatbots we automatically generated a gpt4ominibased qa test for a natural language processing course and evaluated its psychometric and perceivedquality metrics with students and experts a mixedformat irt analysis showed that the generated items exhibit strong discrimination and appropriate difficulty while student and expert star ratings reflect high overall quality a uniform dif check identified two items for review these findings demonstrate that llmgenerated assessments can match humanauthored tests in psychometric performance and user satisfaction illustrating a scalable approach to aiassisted assessment development
http://arxiv.org/abs/2505.06569v1,2025-05-10T08:50:44Z,"Woosang Lim, Zekun Li, Gyuwan Kim, Sungyoung Ji, HyeonJung Kim, Kyuri Choi, Jin Hyuk Lim, Kyungpyo Park, William Yang Wang",macrag compress slice and scaleup for multiscale adaptive context rag,longcontext lc large language models llms combined with retrievalaugmented generation rag hold strong potential for complex multihop and largedocument tasks however existing rag systems often suffer from imprecise retrieval incomplete context coverage under constrained context windows and fragmented information caused by suboptimal context construction we introduce multiscale adaptive context rag macrag a hierarchical retrieval framework that compresses and partitions documents into coarsetofine granularities then adaptively merges relevant contexts through chunk and documentlevel expansions in real time by starting from the finestlevel retrieval and progressively incorporating higherlevel and broader context macrag constructs effective queryspecific long contexts optimizing both precision and coverage evaluations on the challenging longbench expansions of hotpotqa 2wikimultihopqa and musique confirm that macrag consistently surpasses baseline rag pipelines on single and multistep generation with llama318b gemini15pro and gpt4o our results establish macrag as an efficient scalable solution for realworld longcontext multihop reasoning our code is available at httpsgithubcomleezekunmacrag
http://arxiv.org/abs/2505.06552v1,2025-05-10T07:43:23Z,"Doyoung Kim, Youngjun Lee, Joeun Kim, Jihwan Bang, Hwanjun Song, Susik Yoon, Jae-Gil Lee",references indeed matter referencefree preference optimization for conversational query reformulation,conversational query reformulation cqr has become indispensable for improving retrieval in dialoguebased applications however existing approaches typically rely on reference passages for optimization which are impractical to acquire in realworld scenarios to address this limitation we introduce a novel referencefree preference optimization framework dualreform that generates pseudo reference passages from commonlyencountered conversational datasets containing only queries and responses dualreform attains this goal through two key innovations 1 responsebased inference where responses serve as proxies to infer pseudo reference passages and 2 response refinement via the dualrole of cqr where a cqr model refines responses based on the shared objectives between response refinement and cqr despite not relying on reference passages dualreform achieves 969991 of the retrieval accuracy attainable only with reference passages and surpasses the stateoftheart method by up to 316
http://arxiv.org/abs/2505.06548v1,2025-05-10T07:23:19Z,"Aniruddha Roy, Pretam Ray, Abhilash Nandy, Somak Aditya, Pawan Goyal",refineaf a taskagnostic framework to align language models via selfgenerated instructions using reinforcement learning from automated feedback,instructionbased large language models llms have proven effective in numerous fewshot or zeroshot natural language processing nlp tasks however creating humanannotated instruction data is timeconsuming expensive and often limited in quantity and task diversity previous research endeavors have attempted to address this challenge by proposing frameworks capable of generating instructions in a semiautomated and taskagnostic manner directly from the model itself many of these efforts have relied on large apionly parameterbased models such as gpt35 175b which are expensive and subject to limits on a number of queries this paper explores the performance of three opensource small llms such as llama 27b llama 213b and mistral 7b using a semiautomated framework thereby reducing human intervention effort and cost required to generate an instruction dataset for finetuning llms furthermore we demonstrate that incorporating a reinforcement learning rl based training algorithm into this llmsbased framework leads to further enhancements our evaluation of the dataset reveals that these rlbased frameworks achieve a substantial improvements in 6366 of the tasks compared to previous approaches
http://arxiv.org/abs/2505.06538v1,2025-05-10T06:59:36Z,"Xinyue Lou, You Li, Jinan Xu, Xiangyu Shi, Chi Chen, Kaiyu Huang",think in safety unveiling and mitigating safety alignment collapse in multimodal large reasoning model,the rapid development of multimodal large reasoning models mlrms has demonstrated broad application potential yet their safety and reliability remain critical concerns that require systematic exploration to address this gap we conduct a comprehensive and systematic safety evaluation of 11 mlrms across 5 benchmarks and unveil prevalent safety degradation phenomena in most advanced models moreover our analysis reveals distinct safety patterns across different benchmarks significant safety degradation is observed across jailbreak robustness benchmarks whereas safetyawareness benchmarks demonstrate less pronounced degradation in particular a long thought process in some scenarios even enhances safety performance therefore it is a potential approach to addressing safety issues in mlrms by leveraging the intrinsic reasoning capabilities of the model to detect unsafe intent to operationalize this insight we construct a multimodal tuning dataset that incorporates a safetyoriented thought process experimental results from finetuning existing mlrms with this dataset effectively enhances the safety on both jailbreak robustness and safetyawareness benchmarks this study provides a new perspective for developing safe mlrms our dataset is available at httpsgithubcomxinyuelouthinkinsafety
http://arxiv.org/abs/2505.07874v1,2025-05-10T03:18:19Z,"Yu Wang, Runxi Yu, Zhongyuan Wang, Jing He",the sound of populism distinct linguistic features across populist variants,this study explores the sound of populism by integrating the classic linguistic inquiry and word count liwc features which capture the emotional and stylistic tones of language with a finetuned roberta model a stateoftheart contextaware language model trained to detect nuanced expressions of populism this approach allows us to uncover the auditory dimensions of political rhetoric in us presidential inaugural and state of the union addresses we examine how four key populist dimensions ie leftwing rightwing antielitism and peoplecentrism manifest in the linguistic markers of speech drawing attention to both commonalities and distinct tonal shifts across these variants our findings reveal that populist rhetoric consistently features a direct assertive sound that forges a connection with the people and constructs a charismatic leadership persona however this sound is not simply informal but strategically calibrated notably rightwing populism and peoplecentrism exhibit a more emotionally charged discourse resonating with themes of identity grievance and crisis in contrast to the relatively restrained emotional tones of leftwing and antielitist expressions
http://arxiv.org/abs/2505.06496v1,2025-05-10T02:54:16Z,"Erik Nijkamp, Bo Pang, Egor Pakhomov, Akash Gokul, Jin Qu, Silvio Savarese, Yingbo Zhou, Caiming Xiong",xgensmall technical report,we introduce xgensmall a family of 4b and 9b transformer decoder models optimized for longcontext applications our vertically integrated pipeline unites domainbalanced frequencyaware data curation multistage pretraining with quality annealing and length extension to 128k tokens and targeted posttraining via supervised finetuning preference learning and online reinforcement learning xgensmall delivers strong performance across various tasks especially in math and coding domains while excelling at long context benchmarks
http://arxiv.org/abs/2505.06418v1,2025-05-09T20:38:23Z,"Ming Liu, Liwen Wang, Wensheng Zhang",is your multimodal large language model a good science tutor,multimodal large language models mllms demonstrate impressive performance on scientific reasoning tasks eg scienceqa however most existing benchmarks focus narrowly on the accuracy of the final answer while ignoring other metrics in particular when applying mllms to educational contexts the goal is not only correctness but also the ability to teach in this paper we propose a framework that evaluates mllms as science tutors using a comprehensive educational rubric and a simulated student model that judges the teaching performance of the tutors given a list of candidate mllm science tutors we use rubricbased student judgments to produce a range of tutor performance scores identifying both strong and weak tutors using the training section of the scienceqa dataset we then construct a data set of pairwise comparisons between the outputs of strong and weak tutors this enables us to apply multiple preference optimization methods to finetune an underperforming tutor model qwen2vl2b into more effective ones our results also show that strong problemsolving skills do not guarantee highquality tutoring and that performance optimizationguided refinements can yield more educationally aligned tutor models this approach opens avenues for building mllms that serve not only as problem solvers but as genuinely helpful educational assistants
http://arxiv.org/abs/2505.06416v1,2025-05-09T20:30:37Z,"Elias Lumer, Anmol Gulati, Vamse Kumar Subbiah, Pradeep Honaganahalli Basavaraju, James A. Burke",scalemcp dynamic and autosynchronizing model context protocol tools for llm agents,recent advancements in large language models llms and the introduction of the model context protocol mcp have significantly expanded llm agents capability to interact dynamically with external tools and apis however existing tool selection frameworks do not integrate mcp servers instead relying heavily on errorprone manual updates to monolithic local tool repositories leading to duplication inconsistencies and inefficiencies additionally current approaches abstract tool selection before the llm agent is invoked limiting its autonomy and hindering dynamic requerying capabilities during multiturn interactions to address these issues we introduce scalemcp a novel tool selection approach that dynamically equips llm agents with a mcp tool retriever giving agents the autonomy to add tools into their memory as well as an autosynchronizing tool storage system pipeline through crud create read update delete operations with mcp servers as the single source of truth we also propose a novel embedding strategy tool document weighted average tdwa designed to selectively emphasize critical components of tool documents eg tool name or synthetic questions during the embedding process comprehensive evaluations conducted on a created dataset of 5000 financial metric mcp servers across 10 llm models 5 embedding models and 5 retriever types demonstrate substantial improvements in tool retrieval and agent invocation performance emphasizing scalemcps effectiveness in scalable dynamic tool selection and invocation
http://arxiv.org/abs/2505.07871v1,2025-05-09T19:44:04Z,"A M Muntasir Rahman, Ajim Uddin, Guiling ""Grace"" Wang",evaluating financial sentiment analysis with annotators instruction assisted prompting enhancing contextual interpretation and stock prediction accuracy,financial sentiment analysis fsa presents unique challenges to llms that surpass those in typical sentiment analysis due to the nuanced language used in financial contexts the prowess of these models is often undermined by the inherent subjectivity of sentiment classifications in existing benchmark datasets like financial phrasebank these datasets typically feature undefined sentiment classes that reflect the highly individualized perspectives of annotators leading to significant variability in annotations this variability results in an unfair expectation for llms during benchmarking where they are tasked to conjecture the subjective viewpoints of human annotators without sufficient context in this paper we introduce the annotators instruction assisted prompt a novel evaluation prompt designed to redefine the task definition of fsa for llms by integrating detailed task instructions originally intended for human annotators into the llms prompt framework aiap aims to standardize the understanding of sentiment across both human and machine interpretations providing a fair and contextrich foundation for sentiment analysis we utilize a new dataset wsbs derived from the wallstreetbets subreddit to demonstrate how aiap significantly enhances llm performance by aligning machine operations with the refined task definitions experimental results demonstrate that aiap enhances llm performance significantly with improvements up to 908 this contextaware approach not only yields incremental gains in performance but also introduces an innovative sentimentindexing method utilizing model confidence scores this method enhances stock price prediction models and extracts more value from the financial sentiment analysis underscoring the significance of wsb as a critical source of financial text our research offers insights into both improving fsa through better evaluation methods
http://arxiv.org/abs/2505.07870v1,2025-05-09T17:48:34Z,"Suavis Giramata, Madhusudan Srinivasan, Venkat Naidu Gudivada, Upulee Kanewala",efficient fairness testing in large language models prioritizing metamorphic relations for bias detection,large language models llms are increasingly deployed in various applications raising critical concerns about fairness and potential biases in their outputs this paper explores the prioritization of metamorphic relations mrs in metamorphic testing as a strategy to efficiently detect fairness issues within llms given the exponential growth of possible test cases exhaustive testing is impractical therefore prioritizing mrs based on their effectiveness in detecting fairness violations is crucial we apply a sentence diversitybased approach to compute and rank mrs to optimize fault detection experimental results demonstrate that our proposed prioritization approach improves fault detection rates by 22 compared to random prioritization and 12 compared to distancebased prioritization while reducing the time to the first failure by 15 and 8 respectively furthermore our approach performs within 5 of faultbased prioritization in effectiveness while significantly reducing the computational cost associated with fault labeling these results validate the effectiveness of diversitybased mr prioritization in enhancing fairness testing for llms
http://arxiv.org/abs/2505.06191v1,2025-05-09T17:02:51Z,"Jiayuan Mao, Joshua B. Tenenbaum, Jiajun Wu",neurosymbolic concepts,this article presents a conceptcentric paradigm for building agents that can learn continually and reason flexibly the conceptcentric agent utilizes a vocabulary of neurosymbolic concepts these concepts such as object relation and action concepts are grounded on sensory inputs and actuation outputs they are also compositional allowing for the creation of novel concepts through their structural combination to facilitate learning and reasoning the concepts are typed and represented using a combination of symbolic programs and neural network representations leveraging such neurosymbolic concepts the agent can efficiently learn and recombine them to solve various tasks across different domains ranging from 2d images videos 3d scenes and robotic manipulation tasks this conceptcentric framework offers several advantages including data efficiency compositional generalization continual learning and zeroshot transfer
http://arxiv.org/abs/2505.06186v2,2025-05-09T16:55:06Z,"Massimiliano Pronesti, Joao Bettencourt-Silva, Paul Flanagan, Alessandra Pascale, Oisin Redmond, Anya Belz, Yufang Hou",querydriven documentlevel scientific evidence extraction from biomedical studies,extracting scientific evidence from biomedical studies for clinical research questions eg does stem cell transplantation improve quality of life in patients with medically refractory crohns disease compared to placebo is a crucial step in synthesising biomedical evidence in this paper we focus on the task of documentlevel scientific evidence extraction for clinical questions with conflicting evidence to support this task we create a dataset called cochraneforest leveraging forest plots from cochrane systematic reviews it comprises 202 annotated forest plots associated clinical research questions full texts of studies and studyspecific conclusions building on cochraneforest we propose urca uniform retrieval clustered augmentation a retrievalaugmented generation framework designed to tackle the unique challenges of evidence extraction our experiments show that urca outperforms the best existing methods by up to 103 in f1 score on this task however the results also underscore the complexity of cochraneforest establishing it as a challenging testbed for advancing automated evidence synthesis systems
http://arxiv.org/abs/2505.06184v1,2025-05-09T16:51:24Z,"Vahid Rahimzadeh, Ali Hamzehpour, Azadeh Shakery, Masoud Asadpour",from millions of tweets to actionable insights leveraging llms for user profiling,social media user profiling through content analysis is crucial for tasks like misinformation detection engagement prediction hate speech monitoring and user behavior modeling however existing profiling techniques including tweet summarization attributebased profiling and latent representation learning face significant limitations they often lack transferability produce noninterpretable features require large labeled datasets or rely on rigid predefined categories that limit adaptability we introduce a novel large language model llmbased approach that leverages domaindefining statements which serve as key characteristics outlining the important pillars of a domain as foundations for profiling our twostage method first employs semisupervised filtering with a domainspecific knowledge base then generates both abstractive synthesized descriptions and extractive representative tweet selections user profiles by harnessing llms inherent knowledge with minimal human validation our approach is adaptable across domains while reducing the need for large labeled datasets our method generates interpretable natural language user profiles condensing extensive user data into a scale that unlocks llms reasoning and knowledge capabilities for downstream social network tasks we contribute a persian political twitter x dataset and an llmbased evaluation framework with human validation experimental results show our method significantly outperforms stateoftheart llmbased and traditional methods by 98 demonstrating its effectiveness in creating flexible adaptable and interpretable user profiles
http://arxiv.org/abs/2505.06151v1,2025-05-09T16:03:14Z,"Alice Rueda, Argyrios Perivolaris, Niloy Roy, Dylan Weston, Sarmed Shaya, Zachary Cote, Martin Ivanov, Bazen G. Teferra, Yuqi Wu, Sirisha Rambhatla, Divya Sharma, Andrew Greenshaw, Rakesh Jetly, Yanbo Zhang, Bo Cao, Reza Samavi, Sridhar Krishnan, Venkat Bhat",estimating quality in therapeutic conversations a multidimensional natural language processing framework,engagement between client and therapist is a critical determinant of therapeutic success we propose a multidimensional natural language processing nlp framework that objectively classifies engagement quality in counseling sessions based on textual transcripts using 253 motivational interviewing transcripts 150 highquality 103 lowquality we extracted 42 features across four domains conversational dynamics semantic similarity as topic alignment sentiment classification and question detection classifiers including random forest rf catboost and support vector machines svm were hyperparameter tuned and trained using a stratified 5fold crossvalidation and evaluated on a holdout test set on balanced nonaugmented data rf achieved the highest classification accuracy 767 and svm achieved the highest auc 854 after smotetomek augmentation performance improved significantly rf achieved up to 889 accuracy 900 f1score and 946 auc while svm reached 811 accuracy 831 f1score and 936 auc the augmented data results reflect the potential of the framework in future largerscale applications feature contribution revealed conversational dynamics and semantic similarity between clients and therapists were among the top contributors led by words uttered by the client mean and standard deviation the framework was robust across the original and augmented datasets and demonstrated consistent improvements in f1 scores and recall while currently textbased the framework supports future multimodal extensions eg vocal tone facial affect for more holistic assessments this work introduces a scalable datadriven method for evaluating engagement quality of the therapy session offering clinicians realtime feedback to enhance the quality of both virtual and inperson therapeutic interactions
http://arxiv.org/abs/2505.06150v1,2025-05-09T16:02:23Z,"Ryan Lagasse, Aidan Kiernans, Avijit Ghosh, Shiri Dori-Hacohen",a scaling law for token efficiency in llm finetuning under fixed compute budgets,we introduce a scaling law for finetuning large language models llms under fixed compute budgets that explicitly accounts for data composition conventional approaches measure training data solely by total tokens yet the number of examples and their average token length what we term emphdataset volume play a decisive role in model performance our formulation is tuned following established procedures experiments on the bricc dataset citesalavati2024reducing and subsets of the mmlu dataset citehendrycks2021measuringmassivemultitasklanguage evaluated under multiple subsampling strategies reveal that data composition significantly affects token efficiency these results motivate refined scaling laws for practical llm finetuning in resourceconstrained settings
http://arxiv.org/abs/2505.06149v1,2025-05-09T16:00:01Z,"Faeze Ghorbanpour, Daryna Dementieva, Alexander Fraser",can prompting llms unlock hate speech detection across languages a zeroshot and fewshot study,despite growing interest in automated hate speech detection most existing approaches overlook the linguistic diversity of online content multilingual instructiontuned large language models such as llama aya qwen and bloomz offer promising capabilities across languages but their effectiveness in identifying hate speech through zeroshot and fewshot prompting remains underexplored this work evaluates llm promptingbased detection across eight nonenglish languages utilizing several prompting techniques and comparing them to finetuned encoder models we show that while zeroshot and fewshot prompting lag behind finetuned encoder models on most of the realworld evaluation sets they achieve better generalization on functional tests for hate speech detection our study also reveals that prompt design plays a critical role with each language often requiring customized prompting techniques to maximize performance
http://arxiv.org/abs/2505.06145v1,2025-05-09T15:54:08Z,"Xu Han, Yumeng Sun, Weiqiang Huang, Hongye Zheng, Junliang Du",towards robust fewshot text classification using transformer architectures and dual loss strategies,fewshot text classification has important application value in lowresource environments this paper proposes a strategy that combines adaptive finetuning contrastive learning and regularization optimization to improve the classification performance of transformerbased models experiments on the fewrel 20 dataset show that t5small debertav3 and robertabase perform well in fewshot tasks especially in the 5shot setting which can more effectively capture text features and improve classification accuracy the experiment also found that there are significant differences in the classification difficulty of different relationship categories some categories have fuzzy semantic boundaries or complex feature distributions making it difficult for the standard cross entropy loss to learn the discriminative information required to distinguish categories by introducing contrastive loss and regularization loss the generalization ability of the model is enhanced effectively alleviating the overfitting problem in fewshot environments in addition the research results show that the use of transformer models or generative architectures with stronger selfattention mechanisms can help improve the stability and accuracy of fewshot classification
http://arxiv.org/abs/2505.06120v1,2025-05-09T15:21:44Z,"Philippe Laban, Hiroaki Hayashi, Yingbo Zhou, Jennifer Neville",llms get lost in multiturn conversation,large language models llms are conversational interfaces as such llms have the potential to assist their users not only when they can fully specify the task at hand but also to help them define explore and refine what they need through multiturn conversational exchange although analysis of llm conversation logs has confirmed that underspecification occurs frequently in user instructions llm evaluation has predominantly focused on the singleturn fullyspecified instruction setting in this work we perform largescale simulation experiments to compare llm performance in single and multiturn settings our experiments confirm that all the top open and closedweight llms we test exhibit significantly lower performance in multiturn conversations than singleturn with an average drop of 39 across six generation tasks analysis of 200000 simulated conversations decomposes the performance degradation into two components a minor loss in aptitude and a significant increase in unreliability we find that llms often make assumptions in early turns and prematurely attempt to generate final solutions on which they overly rely in simpler terms we discover that when llms take a wrong turn in a conversation they get lost and do not recover
http://arxiv.org/abs/2505.06110v1,2025-05-09T15:10:57Z,"Jugal Gajjar, Kaustik Ranaware",multimodal sentiment analysis on cmumosei dataset using transformerbased models,this project performs multimodal sentiment analysis using the cmumosei dataset using transformerbased models with early fusion to integrate text audio and visual modalities we employ bertbased encoders for each modality extracting embeddings that are concatenated before classification the model achieves strong performance with 9787 7class accuracy and a 09682 f1score on the test set demonstrating the effectiveness of early fusion in capturing crossmodal interactions the training utilized adam optimization lr1e4 dropout 03 and early stopping to ensure generalization and robustness results highlight the superiority of transformer architectures in modeling multimodal sentiment with a low mae 01060 indicating precise sentiment intensity prediction future work may compare fusion strategies or enhance interpretability this approach utilizes multimodal learning by effectively combining linguistic acoustic and visual cues for sentiment analysis
http://arxiv.org/abs/2505.06107v1,2025-05-09T15:03:39Z,"Faeze Ghorbanpour, Thiago Zordan Malaguth, Aliakbar Akbaritabar",differentiating emigration from return migration of scholars using namebased nationality detection models,most web and digital trace data do not include information about an individuals nationality due to privacy concerns the lack of data on nationality can create challenges for migration research it can lead to a leftcensoring issue since we are uncertain about the migrants country of origin once we observe an emigration event if we know the nationality we can differentiate it from return migration we propose methods to detect the nationality with the least available data ie full names we use the detected nationality in comparison with the country of academic origin which is a common approach in studying the migration of researchers we gathered 26 million unique namenationality pairs from wikipedia and categorized them into families of nationalities with three granularity levels to use as our training data using a characterbased machine learning model we achieved a weighted f1 score of 84 for the broadest and 67 for the most granular countrylevel categorization in our empirical study we used the trained and tested model to assign nationality to 8 million scholars full names in scopus data our results show that using the country of first publication as a proxy for nationality underestimates the size of return flows especially for countries with a more diverse academic workforce such as the usa australia and canada we found that around 48 of emigration from the usa was return migration once we used the country of name origin in contrast to 33 based on academic origin in the most recent period 79 of scholars whose affiliation has consistently changed from the usa to china and are considered emigrants have chinese names in contrast to 41 with a chinese academic origin our proposed methods for addressing leftcensoring issues are beneficial for other research that uses digital trace data to study migration
http://arxiv.org/abs/2505.06062v1,2025-05-09T13:57:56Z,"Iuliia Zaitova, Vitalii Hirak, Badr M. Abdullah, Dietrich Klakow, Bernd Möbius, Tania Avgustinova",attention on multiword expressions a multilingual study of bertbased models with regard to idiomaticity and microsyntax,this study analyzes the attention patterns of finetuned encoderonly models based on the bert architecture bertbased models towards two distinct types of multiword expressions mwes idioms and microsyntactic units msus idioms present challenges in semantic noncompositionality whereas msus demonstrate unconventional syntactic behavior that does not conform to standard grammatical categorizations we aim to understand whether finetuning bertbased models on specific tasks influences their attention to mwes and how this attention differs between semantic and syntactic tasks we examine attention scores to mwes in both pretrained and finetuned bertbased models we utilize monolingual models and datasets in six indoeuropean languages english german dutch polish russian and ukrainian our results show that finetuning significantly influences how models allocate attention to mwes specifically models finetuned on semantic tasks tend to distribute attention to idiomatic expressions more evenly across layers models finetuned on syntactic tasks show an increase in attention to msus in the lower layers corresponding with syntactic processing requirements
http://arxiv.org/abs/2505.06046v2,2025-05-09T13:42:59Z,"Joshua Harris, Fan Grayson, Felix Feldman, Timothy Laurence, Toby Nonnenmacher, Oliver Higgins, Leo Loman, Selina Patel, Thomas Finnie, Samuel Collins, Michael Borowitz",healthy llms benchmarking llm knowledge of uk government public health information,as large language models llms become widely accessible a detailed understanding of their knowledge within specific domains becomes necessary for successful real world use this is particularly critical in public health where failure to retrieve relevant accurate and current information could significantly impact uk residents however currently little is known about llm knowledge of uk government public health information to address this issue this paper introduces a new benchmark pubhealthbench with over 8000 questions for evaluating llms multiple choice question answering mcqa and free form responses to public health queries to create pubhealthbench we extract free text from 687 current uk government guidance documents and implement an automated pipeline for generating mcqa samples assessing 24 llms on pubhealthbench we find the latest private llms gpt45 gpt41 and o1 have a high degree of knowledge achieving 90 accuracy in the mcqa setup and outperform humans with cursory search engine use however in the free form setup we see lower performance with no model scoring 75 importantly we find in both setups llms have higher accuracy on guidance intended for the general public therefore there are promising signs that state of the art sota llms are an increasingly accurate source of public health information but additional safeguards or tools may still be needed when providing free form responses on public health topics
http://arxiv.org/abs/2505.06032v1,2025-05-09T13:26:21Z,"Leon Eshuijs, Shihan Wang, Antske Fokkens",shortcircuiting shortcuts mechanistic investigation of shortcuts in text classification,reliance on spurious correlations shortcuts has been shown to underlie many of the successes of language models previous work focused on identifying the input elements that impact prediction we investigate how shortcuts are actually processed within the models decisionmaking mechanism we use actor names in movie reviews as controllable shortcuts with known impact on the outcome we use mechanistic interpretability methods and identify specific attention heads that focus on shortcuts these heads gear the model towards a label before processing the complete input effectively making premature decisions that bypass contextual analysis based on these findings we introduce headbased token attribution hta which traces intermediate decisions back to input tokens we show that hta is effective in detecting shortcuts in llms and enables targeted mitigation by selectively deactivating shortcutrelated attention heads
http://arxiv.org/abs/2505.06027v1,2025-05-09T13:19:09Z,"Stefan Vasilev, Christian Herold, Baohao Liao, Seyyed Hadi Hashemi, Shahram Khadivi, Christof Monz",unilogit robust machine unlearning for llms using uniformtarget selfdistillation,this paper introduces unilogit a novel selfdistillation method for machine unlearning in large language models unilogit addresses the challenge of selectively forgetting specific information while maintaining overall model utility a critical task in compliance with data privacy regulations like gdpr unlike prior methods that rely on static hyperparameters or starting model outputs unilogit dynamically adjusts target logits to achieve a uniform probability for the target token leveraging the current models outputs for more accurate selfdistillation targets this approach not only eliminates the need for additional hyperparameters but also enhances the models ability to approximate the golden targets extensive experiments on public benchmarks and an inhouse ecommerce dataset demonstrate unilogits superior performance in balancing forget and retain objectives outperforming stateoftheart methods such as npo and undial our analysis further reveals unilogits robustness across various scenarios highlighting its practical applicability and effectiveness in achieving efficacious machine unlearning
http://arxiv.org/abs/2505.06010v1,2025-05-09T12:47:13Z,"Dawid Wisniewski, Mikolaj Pokrywka, Zofia Rostek",do not change me on transferring entities without modification in neural machine translation a multilingual perspective,current machine translation models provide us with highquality outputs in most scenarios however they still face some specific problems such as detecting which entities should not be changed during translation in this paper we explore the abilities of popular nmt models including models from the opus project google translate madlad and eurollm to preserve entities such as url addresses iban numbers or emails when producing translations between four languages english german polish and ukrainian we investigate the quality of popular nmt models in terms of accuracy discuss errors made by the models and examine the reasons for errors our analysis highlights specific categories such as emojis that pose significant challenges for many models considered in addition to the analysis we propose a new multilingual synthetic dataset of 36000 sentences that can help assess the quality of entity transfer across nine categories and four aforementioned languages
http://arxiv.org/abs/2505.06004v1,2025-05-09T12:35:26Z,"Dawid Wisniewski, Antoni Solarski, Artur Nowakowski",exploring the feasibility of multilingual grammatical error correction with a single llm up to 9b parameters a comparative study of 17 models,recent language models can successfully solve various languagerelated tasks and many understand inputs stated in different languages in this paper we explore the performance of 17 popular models used to correct grammatical issues in texts stated in english german italian and swedish when using a single model to correct texts in all those languages we analyze the outputs generated by these models focusing on decreasing the number of grammatical errors while keeping the changes small the conclusions drawn help us understand what problems occur among those models and which models can be recommended for multilingual grammatical error correction tasks we list six models that improve grammatical correctness in all four languages and show that gemma 9b is currently the best performing one for the languages considered
http://arxiv.org/abs/2505.05973v1,2025-05-09T11:57:10Z,"M. Maziyah Mohamed, R. H. Baayen",an exploratory analysis on the explanatory potential of embeddingbased measures of semantic transparency for malay word recognition,studies of morphological processing have shown that semantic transparency is crucial for word recognition its computational operationalization is still under discussion our primary objectives are to explore embeddingbased measures of semantic transparency and assess their impact on reading first we explored the geometry of complex words in semantic space to do so we conducted a tdistributed stochastic neighbor embedding clustering analysis on 4226 malay prefixed words several clusters were observed for complex words varied by their prefix class then we derived five simple measures and investigated whether they were significant predictors of lexical decision latencies two sets of linear discriminant analyses were run in which the prefix of a word is predicted from either word embeddings or shift vectors ie a vector subtraction of the base word from the derived word the accuracy with which the model predicts the prefix of a word indicates the degree of transparency of the prefix three further measures were obtained by comparing embeddings between each word and all other words containing the same prefix ie centroid between each word and the shift from their base word and between each word and the predicted word of the functional representations of affixes in compositional semantic space model in a series of generalized additive mixed models all measures predicted decision latencies after accounting for word frequency word length and morphological family size the model that included the correlation between each word and their centroid as a predictor provided the best fit to the data
http://arxiv.org/abs/2505.05970v1,2025-05-09T11:48:36Z,"Lennart Stöpler, Rufat Asadli, Mitja Nikolaus, Ryan Cotterell, Alex Warstadt",towards developmentally plausible rewards communicative success as a learning signal for interactive language models,we propose a method for training language models in an interactive setting inspired by child language acquisition in our setting a speaker attempts to communicate some information to a listener in a singleturn dialogue and receives a reward if communicative success is achieved unlike earlier related work using imagecaption data for interactive reference games we operationalize communicative success in a more abstract languageonly questionanswering setting first we present a feasibility study demonstrating that our reward provides an indirect signal about grammaticality second we conduct experiments using reinforcement learning to finetune language models we observe that cognitively plausible constraints on the communication channel lead to interpretable changes in speaker behavior however we do not yet see improvements on linguistic evaluations from our training regime we outline potential modifications to the task design and training configuration that could better position future work to use our methodology to observe the benefits of interaction on language learning in computational cognitive models
http://arxiv.org/abs/2505.05949v1,2025-05-09T10:51:29Z,"Max Glockner, Xiang Jiang, Leonardo F. R. Ribeiro, Iryna Gurevych, Markus Dreyer",neoqa evidencebased question answering with generated news events,evaluating retrievalaugmented generation rag in large language models llms is challenging because benchmarks can quickly become stale questions initially requiring retrieval may become answerable from pretraining knowledge as newer models incorporate more recent information during pretraining making it difficult to distinguish evidencebased reasoning from recall we introduce neoqa news events for outoftraining question answering a benchmark designed to address this issue to construct neoqa we generated timelines and knowledge bases of fictional news events and entities along with news articles and qa pairs to prevent llms from leveraging pretraining knowledge ensuring that no prior evidence exists in their training data we propose our dataset as a new platform for evaluating evidencebased question answering as it requires llms to generate responses exclusively from retrieved evidence and only when sufficient evidence is available neoqa enables controlled evaluation across various evidence scenarios including cases with missing or misleading details our findings indicate that llms struggle to distinguish subtle mismatches between questions and evidence and suffer from shortcut reasoning when key information required to answer a question is missing from the evidence underscoring key limitations in evidencebased reasoning
http://arxiv.org/abs/2505.05947v1,2025-05-09T10:44:34Z,"Bianca Steffes, Nils Torben Wiedemann, Alexander Gratz, Pamela Hochreither, Jana Elina Meyer, Katharina Luise Schilke",summarisation of german judgments in conjunction with a classbased evaluation,the automated summarisation of long legal documents can be a great aid for legal experts in their daily work we automatically create summaries guiding principles of german judgments by finetuning a decoderbased large language model we enrich the judgments with information about legal entities before the training for the evaluation of the created summaries we define a set of evaluation classes which allows us to measure their language pertinence completeness and correctness our results show that employing legal entities helps the generative model to find the relevant content but the quality of the created summaries is not yet sufficient for a use in practice
http://arxiv.org/abs/2505.05946v1,2025-05-09T10:43:37Z,"Vytenis Šliogeris, Povilas Daniušis, Artūras Nakvosas",elastic weight consolidation for fullparameter continual pretraining of gemma2,this technical report describes an experiment on autoregressive pretraining of gemma2 2 billion parameter large language model llm with 10 on the lithuanian language component of culturax from the point of view of continual learning we apply elastic weight consolidation ewc to the full set of the models parameters and investigate language understanding benchmarks consisting of arc belebele gsm8k hellaswag mmlu truthfulqa and winogrande sets both in english and lithuanian versions and perplexity benchmarks we empirically demonstrate that ewc regularisation allows us not only to mitigate catastrophic forgetting effects but also that it is potentially beneficial for learning of the new task with llms
http://arxiv.org/abs/2505.05864v1,2025-05-09T07:58:30Z,"Junhyeong Lee, Jong Min Yuk, Chan-Woo Lee",symbolbased entity marker highlighting for enhanced text mining in materials science with generative ai,the construction of experimental datasets is essential for expanding the scope of datadriven scientific discovery recent advances in natural language processing nlp have facilitated automatic extraction of structured data from unstructured scientific literature while existing approachesmultistep and direct methodsoffer valuable capabilities they also come with limitations when applied independently here we propose a novel hybrid textmining framework that integrates the advantages of both methods to convert unstructured scientific text into structured data our approach first transforms raw text into entityrecognized text and subsequently into structured form furthermore beyond the overall data structuring framework we also enhance entity recognition performance by introducing an entity markera simple yet effective technique that uses symbolic annotations to highlight target entities specifically our entity markerbased hybrid approach not only consistently outperforms previous entity recognition approaches across three benchmark datasets matscholar sofc and sofc slot ner but also improve the quality of final structured datayielding up to a 58 improvement in entitylevel f1 score and up to 83 improvement in relationlevel f1 score compared to direct approach
http://arxiv.org/abs/2505.05863v1,2025-05-09T07:57:10Z,"Reiji Suzuki, Takaya Arita",evolutionary ecology of words,we propose a model for the evolutionary ecology of words as one attempt to extend evolutionary game theory and agentbased models by utilizing the rich linguistic expressions of large language models llms our model enables the emergence and evolution of diverse and infinite options for interactions among agents within the population each agent possesses a short word or phrase generated by an llm and moves within a spatial environment when agents become adjacent the outcome of their interaction is determined by the llm based on the relationship between their words with the losers word being replaced by the winners word mutations also based on llm outputs may occur we conducted preliminary experiments assuming that strong animal species would survive the results showed that from an initial population consisting of wellknown species many species emerged both gradually and in a punctuated equilibrium manner each trial demonstrated the unique evolution of diverse populations with one type of large species becoming dominant such as terrestrial animals marine life or extinct species which were ecologically specialized and adapted ones across diverse extreme habitats we also conducted a longterm experiment with a large population demonstrating the emergence and coexistence of diverse species
http://arxiv.org/abs/2505.05828v1,2025-05-09T06:55:51Z,"Alba María Mármol-Romero, Manuel García-Vega, Miguel Ángel García-Cumbreras, Arturo Montejo-Ráez",an empathic gptbased chatbot to talk about mental disorders with spanish teenagers,this paper presents a chatbotbased system to engage young spanish people in the awareness of certain mental disorders through a selfdisclosure technique the study was carried out in a population of teenagers aged between 12 and 18 years the dialogue engine mixes closed and open conversations so certain controlled messages are sent to focus the chat on a specific disorder which will change over time once a set of trial questions is answered the system can initiate the conversation on the disorder under the focus according to the users sensibility to that disorder in an attempt to establish a more empathetic communication then an open conversation based on the gpt3 language model is initiated allowing the user to express themselves with more freedom the results show that these systems are of interest to young people and could help them become aware of certain mental disorders
http://arxiv.org/abs/2505.07865v1,2025-05-09T06:47:23Z,"Fan Zhang, Tianyu Liu, Zhihong Zhu, Hao Wu, Haixin Wang, Donghao Zhou, Yefeng Zheng, Kun Wang, Xian Wu, Pheng-Ann Heng",cellverse do large language models really understand cell biology,recent studies have demonstrated the feasibility of modeling singlecell data as natural languages and the potential of leveraging powerful large language models llms for understanding cell biology however a comprehensive evaluation of llms performance on languagedriven singlecell analysis tasks still remains unexplored motivated by this challenge we introduce cellverse a unified languagecentric questionanswering benchmark that integrates four types of singlecell multiomics data and encompasses three hierarchical levels of singlecell analysis tasks cell type annotation celllevel drug response prediction druglevel and perturbation analysis genelevel going beyond this we systematically evaluate the performance across 14 opensource and closedsource llms ranging from 160m to 671b on cellverse remarkably the experimental results reveal 1 existing specialist models c2spythia fail to make reasonable decisions across all subtasks within cellverse while generalist models such as qwen llama gpt and deepseek family models exhibit preliminary understanding capabilities within the realm of cell biology 2 the performance of current llms falls short of expectations and has substantial room for improvement notably in the widely studied drug response prediction task none of the evaluated llms demonstrate significant performance improvement over random guessing cellverse offers the first largescale empirical demonstration that significant challenges still remain in applying llms to cell biology by introducing cellverse we lay the foundation for advancing cell biology through natural languages and hope this paradigm could facilitate nextgeneration singlecell analysis
http://arxiv.org/abs/2505.05815v1,2025-05-09T06:33:55Z,"Machi Shimmei, Masaki Uto, Yuichiroh Matsubayashi, Kentaro Inui, Aditi Mallavarapu, Noboru Matsuda",tell me who your students are gpt can generate valid multiplechoice questions when students misunderstanding is hinted,the primary goal of this study is to develop and evaluate an innovative prompting technique anaquest for generating multiplechoice questions mcqs using a pretrained large language model in anaquest the choice items are sentencelevel assertions about complex concepts the technique integrates formative and summative assessments in the formative phase students answer openended questions for target concepts in free text for summative assessment anaquest analyzes these responses to generate both correct and incorrect assertions to evaluate the validity of the generated mcqs item response theory irt was applied to compare item characteristics between mcqs generated by anaquest a baseline chatgpt prompt and humancrafted items an empirical study found that expert instructors rated mcqs generated by both ai models to be as valid as those created by human instructors however irtbased analysis revealed that anaquestgenerated questions particularly those with incorrect assertions foils more closely resembled humancrafted items in terms of difficulty and discrimination than those produced by chatgpt
http://arxiv.org/abs/2505.07864v1,2025-05-09T04:27:36Z,"Takamitsu Omasa, Ryo Koshihara, Masumi Morishige",arrowguided vlm enhancing flowchart understanding via arrow direction encoding,flowcharts are indispensable tools in software design and businessprocess analysis yet current visionlanguage models vlms frequently misinterpret the directional arrows and graph topology that set these diagrams apart from natural images we introduce a sevenstage pipeline grouped into three broader processes 1 arrowaware detection of nodes and arrow endpoints 2 optical character recognition ocr to extract node text and 3 construction of a structured prompt that guides the vlms tested on a 90question benchmark distilled from 30 annotated flowcharts the method raises overall accuracy from 80 to 89 9 percentage points without any taskspecific finetuning the gain is most pronounced for nextstep queries 2530 3030 100 17 pp branchresult questions improve more modestly and beforestep questions remain difficult a parallel evaluation with an llmasajudge protocol shows the same trends reinforcing the advantage of explicit arrow encoding limitations include dependence on detector and ocr precision the small evaluation set and residual errors at nodes with multiple incoming edges future work will enlarge the benchmark with synthetic and handwritten flowcharts and assess the approach on business process model and notation bpmn and unified modeling language uml
http://arxiv.org/abs/2505.05772v1,2025-05-09T04:17:05Z,"Zehao Fan, Garrett Gagnon, Zhenyu Liu, Liu Liu",sparse attention remapping with clustering for efficient llm decoding on pim,transformerbased models are the foundation of modern machine learning but their execution particularly during autoregressive decoding in large language models llms places significant pressure on memory systems due to frequent memory accesses and growing keyvalue kv caches this creates a bottleneck in memory bandwidth especially as context lengths increase processinginmemory pim architectures are a promising solution offering high internal bandwidth and compute parallelism near memory however current pim designs are primarily optimized for dense attention and struggle with the dynamic irregular access patterns introduced by modern kv cache sparsity techniques consequently they suffer from workload imbalance reducing throughput and resource utilization in this work we propose starc a novel sparsityoptimized data mapping scheme tailored specifically for efficient llm decoding on pim architectures starc clusters kv pairs by semantic similarity and maps them to contiguous memory regions aligned with pim bank structures during decoding queries retrieve relevant tokens at cluster granularity by matching against precomputed centroids enabling selective attention and parallel processing without frequent reclustering or data movement overhead experiments on the hbmpim system show that compared to common tokenwise sparsity methods starc reduces attentionlayer latency by 1931 and energy consumption by 1927 under a kv cache budget of 1024 it achieves up to 5474 latency reduction and 4567 energy reduction compared to full kv cache retrieval meanwhile starc maintains model accuracy comparable to stateoftheart sparse attention methods demonstrating its effectiveness in enabling efficient and hardwarefriendly longcontext llm inference on pim architectures
http://arxiv.org/abs/2505.05763v1,2025-05-09T03:53:10Z,"Yize Zhou, Jie Zhang, Meijie Wang, Lun Yu",bmmdetect a multimodal deep learning framework for comprehensive biomedical misconduct detection,academic misconduct detection in biomedical research remains challenging due to algorithmic narrowness in existing methods and fragmented analytical pipelines we present bmmdetect a multimodal deep learning framework that integrates journal metadata sjr institutional data semantic embeddings pubmedbert and gpt4omined textual attributes methodological statistics data anomalies for holistic manuscript evaluation key innovations include 1 multimodal fusion of domainspecific features to reduce detection bias 2 quantitative evaluation of feature importance identifying journal authority metrics eg sjrindex and textual anomalies eg statistical outliers as dominant predictors and 3 the biomcd dataset a largescale benchmark with 13160 retracted articles and 53411 controls bmmdetect achieves 7433 auc outperforming singlemodality baselines by 86 and demonstrates transferability across biomedical subfields this work advances scalable interpretable tools for safeguarding research integrity
http://arxiv.org/abs/2505.05755v2,2025-05-09T03:29:15Z,"Dhruvesh Patel, Aishwarya Sahoo, Avinash Amballa, Tahira Naseem, Tim G. J. Rudner, Andrew McCallum",insertion language models sequence generation with arbitraryposition insertions,autoregressive models arms which predict subsequent tokens onebyone from left to right have achieved significant success across a wide range of sequence generation tasks however they struggle to accurately represent sequences that require satisfying sophisticated constraints or whose sequential dependencies are better addressed by outoforder generation masked diffusion models mdms address some of these limitations but the process of unmasking multiple tokens simultaneously in mdms can introduce incoherences and mdms cannot handle arbitrary infilling constraints when the number of tokens to be filled in is not known in advance in this work we introduce insertion language models ilms which learn to insert tokens at arbitrary positions in a sequence that is they select jointly both the position and the vocabulary element to be inserted by inserting tokens one at a time ilms can represent strong dependencies between tokens and their ability to generate sequences in arbitrary order allows them to accurately model sequences where token dependencies do not follow a lefttoright sequential structure to train ilms we propose a tailored network parameterization and use a simple denoising objective our empirical evaluation demonstrates that ilms outperform both arms and mdms on common planning tasks furthermore we show that ilms outperform mdms and perform on par with arms in an unconditional text generation task while offering greater flexibility than mdms in arbitrarylength text infilling
http://arxiv.org/abs/2505.07863v1,2025-05-09T03:15:45Z,"Ziliang Wang, Xiaohong Zhang, Ze Shi Li, Meng Yan",qosbert an uncertaintyaware approach based on pretrained language models for service quality prediction,accurate prediction of quality of service qos metrics is fundamental for selecting and managing cloud based services traditional qos models rely on manual feature engineering and yield only point estimates offering no insight into the confidence of their predictions in this paper we propose qosbert the first framework that reformulates qos prediction as a semantic regression task based on pre trained language models unlike previous approaches relying on sparse numerical features qosbert automatically encodes user service metadata into natural language descriptions enabling deep semantic understanding furthermore we integrate a monte carlo dropout based uncertainty estimation module allowing for trustworthy and riskaware service quality prediction which is crucial yet underexplored in existing qos models qosbert applies attentive pooling over contextualized embeddings and a lightweight multilayer perceptron regressor fine tuned jointly to minimize absolute error we further exploit the resulting uncertainty estimates to select high quality training samples improving robustness in low resource settings on standard qos benchmark datasets qosbert achieves an average reduction of 117 in mae and 67 in rmse for response time prediction and 69 in mae for throughput prediction compared to the strongest baselines while providing well calibrated confidence intervals for robust and trustworthy service quality estimation our approach not only advances the accuracy of service quality prediction but also delivers reliable uncertainty quantification paving the way for more trustworthy data driven service selection and optimization
http://arxiv.org/abs/2505.05744v1,2025-05-09T02:57:39Z,"Ruxue Shi, Hengrui Gu, Xu Shen, Xin Wang",harnessing llms explanations to boost surrogate models in tabular data classification,large language models llms have shown remarkable ability in solving complex tasks making them a promising tool for enhancing tabular learning however existing llmbased methods suffer from high resource requirements suboptimal demonstration selection and limited interpretability which largely hinder their prediction performance and application in the real world to overcome these problems we propose a novel incontext learning framework for tabular prediction the core idea is to leverage the explanations generated by llms to guide a smaller locally deployable surrogate language model slm to make interpretable tabular predictions specifically our framework mainly involves three stages i post hoc explanation generation where llms are utilized to generate explanations for questionanswer pairs in candidate demonstrations providing insights into the reasoning behind the answer ii post hoc explanationguided demonstrations selection which utilizes explanations generated by llms to guide the process of demonstration selection from candidate demonstrations iii post hoc explanationguided interpretable slm prediction which utilizes the demonstrations obtained in step ii as incontext and merges corresponding explanations as rationales to improve the performance of slm and guide the model to generate interpretable outputs experimental results highlight the frameworks effectiveness with an average accuracy improvement of 531 across various tabular datasets in diverse domains
http://arxiv.org/abs/2505.05736v1,2025-05-09T02:28:41Z,"Da Wu, Zhanliang Wang, Quan Nguyen, Zhuoran Xu, Kai Wang",multimodal integrated knowledge transfer to large language models through preference optimization with biomedical applications,the scarcity of highquality multimodal biomedical data limits the ability to effectively finetune pretrained large language models llms for specialized biomedical tasks to address this challenge we introduce mint multimodal integrated knowledge transfer a framework that aligns unimodal large decoder models with domainspecific decision patterns from multimodal biomedical data through preference optimization while mint supports different optimization techniques we primarily implement it with the odds ratio preference optimization orpo framework as its backbone this strategy enables the aligned llms to perform predictive tasks using textonly or imageonly inputs while retaining knowledge learnt from multimodal data mint leverages an upstream multimodal machine learning mml model trained on highquality multimodal data to transfer domainspecific insights to downstream textonly or imageonly llms we demonstrate its effectiveness through two key applications 1 rare genetic disease prediction from texts where mint uses a multimodal encoder model trained on facial photos and clinical notes to generate a preference dataset for aligning a lightweight llama 323binstruct despite relying on text input only the mintderived model outperforms models trained with sft rag or dpo and even outperforms llama 31405binstruct 2 tissue type classification using cell nucleus images where mint uses a visionlanguage foundation model as the preference generator containing knowledge learnt from both text and histopathological images to align downstream imageonly models the resulting mintderived model significantly improves the performance of llama 32vision11binstruct on tissue type classification in summary mint provides an effective strategy to align unimodal llms with highquality multimodal expertise through preference optimization
http://arxiv.org/abs/2505.05714v1,2025-05-09T01:31:02Z,"Jinze Lv, Jian Chen, Zi Long, Xianghua Fu, Yin Chen",topicvd a topicbased dataset of videoguided multimodal machine translation for documentaries,most existing multimodal machine translation mmt datasets are predominantly composed of static images or short video clips lacking extensive video data across diverse domains and topics as a result they fail to meet the demands of realworld mmt tasks such as documentary translation in this study we developed topicvd a topicbased dataset for videosupported multimodal machine translation of documentaries aiming to advance research in this field we collected videosubtitle pairs from documentaries and categorized them into eight topics such as economy and nature to facilitate research on domain adaptation in videoguided mmt additionally we preserved their contextual information to support research on leveraging the global context of documentaries in videoguided mmt to better capture the shared semantics between text and video we propose an mmt model based on a crossmodal bidirectional attention module extensive experiments on the topicvd dataset demonstrate that visual information consistently improves the performance of the nmt model in documentary translation however the mmt models performance significantly declines in outofdomain scenarios highlighting the need for effective domain adaptation methods additionally experiments demonstrate that global context can effectively improve translation performance dataset and our implementations are available at httpsgithubcomjinzelvtopicvd
http://arxiv.org/abs/2505.05704v1,2025-05-09T00:39:43Z,"Julia Shuieh, Prasann Singhal, Apaar Shanker, John Heyer, George Pu, Samuel Denton",assessing robustness to spurious correlations in posttraining language models,supervised and preferencebased finetuning techniques have become popular for aligning large language models llms with user intent and correctness criteria however realworld training data often exhibits spurious correlations arising from biases dataset artifacts or other shortcut features that can compromise a models performance or generalization in this paper we systematically evaluate three posttraining algorithms supervised finetuning sft direct preference optimization dpo and kto kahnemantversky optimization across a diverse set of synthetic tasks and spuriousness conditions our tasks span mathematical reasoning constrained instructionfollowing and documentgrounded question answering we vary the degree of spurious correlation 10 vs 90 and investigate two forms of artifacts feature ambiguity and distributional narrowness our results show that the models often but not always degrade under higher spuriousness the preferencebased methods dpokto can demonstrate relative robustness in mathematical reasoning tasks by contrast sft maintains stronger performance in complex contextintensive tasks these findings highlight that no single posttraining strategy universally outperforms in all scenarios the best choice depends on the type of target task and the nature of spurious correlations
http://arxiv.org/abs/2505.07862v1,2025-05-09T00:13:23Z,"Andrew Kiruluta, Eric Lundy, Priscilla Burity",graph laplacian wavelet transformer via learnable spectral decomposition,existing sequence to sequence models for structured language tasks rely heavily on the dot product self attention mechanism which incurs quadratic complexity in both computation and memory for input length n we introduce the graph wavelet transformer gwt a novel architecture that replaces this bottleneck with a learnable multi scale wavelet transform defined over an explicit graph laplacian derived from syntactic or semantic parses our analysis shows that multi scale spectral decomposition offers an interpretable efficient and expressive alternative to quadratic self attention for graph structured sequence modeling
http://arxiv.org/abs/2505.05687v1,2025-05-08T23:17:03Z,"Cindy Kim, Daniela Puchall, Jiangyi Liang, Jiwon Kim",exploration of covid19 discourse on twitter american politician edition,the advent of the covid19 pandemic has undoubtedly affected the political scene worldwide and the introduction of new terminology and public opinions regarding the virus has further polarized partisan stances using a collection of tweets gathered from leading american political figures online republican and democratic we explored the partisan differences in approach response and attitude towards handling the international crisis implementation of the bagofwords bigram and tfidf models was used to identify and analyze keywords topics and overall sentiments from each party results suggest that democrats are more concerned with the casualties of the pandemic and give more medical precautions and recommendations to the public whereas republicans are more invested in political responsibilities such as keeping the public updated through media and carefully watching the progress of the virus we propose a systematic approach to predict and distinguish a tweets political stance left or right leaning based on its covid19 related terms using different classification algorithms on different language models
http://arxiv.org/abs/2505.05684v1,2025-05-08T22:59:42Z,"Han Wu, Jie Yin",prompted metalearning for fewshot knowledge graph completion,fewshot knowledge graph completion kgc has obtained significant attention due to its practical applications in realworld scenarios where new knowledge often emerges with limited available data while most existing methods for fewshot kgc have predominantly focused on leveraging relational information rich semantics inherent in kgs have been largely overlooked to address this gap we propose a novel prompted metalearning promptmeta framework that seamlessly integrates metasemantics with relational information for fewshot kgc prompmeta has two key innovations 1 a metasemantic prompt pool that captures and consolidates highlevel metasemantics enabling effective knowledge transfer and adaptation to rare and newly emerging relations 2 a learnable fusion prompt that dynamically combines metasemantic information with taskspecific relational information tailored to different fewshot tasks both components are optimized together with model parameters within a metalearning framework extensive experiments on two benchmark datasets demonstrate the effectiveness of our approach
http://arxiv.org/abs/2505.06320v1,2025-05-08T21:54:49Z,"Jan Kościałkowski, Paweł Marcinkowski",divide text and conquer sentiment improved sentiment classification by constituent conflict resolution,sentiment classification a complex task in natural language processing becomes even more challenging when analyzing passages with multiple conflicting tones typically longer passages exacerbate this issue leading to decreased model performance the aim of this paper is to introduce novel methodologies for isolating conflicting sentiments and aggregating them to effectively predict the overall sentiment of such passages one of the aggregation strategies involves a multilayer perceptron mlp model which outperforms baseline models across various datasets including amazon twitter and sst while costing 1100 of what finetuning the baseline would take
http://arxiv.org/abs/2505.05665v1,2025-05-08T21:50:43Z,"Neeloy Chakraborty, John Pohovey, Melkior Ornik, Katherine Driggs-Campbell",adaptive stress testing blackbox llm planners,large language models llms have recently demonstrated success in generalizing across decisionmaking tasks including planning control and prediction but their tendency to hallucinate unsafe and undesired outputs poses risks we argue that detecting such failures is necessary especially in safetycritical scenarios existing blackbox methods often detect hallucinations by identifying inconsistencies across multiple samples many of these approaches typically introduce prompt perturbations like randomizing detail order or generating adversarial inputs with the intuition that a confident model should produce stable outputs we first perform a manual case study showing that other forms of perturbations eg adding noise removing sensor details cause llms to hallucinate in a driving environment we then propose a novel method for efficiently searching the space of prompt perturbations using adaptive stress testing ast with montecarlo tree search mcts our ast formulation enables discovery of scenarios and prompts that cause language models to act with high uncertainty by generating mcts prompt perturbation trees across diverse scenarios we show that offline analyses can be used at runtime to automatically generate prompts that influence model uncertainty and to inform realtime trust assessments of an llm
http://arxiv.org/abs/2505.05648v1,2025-05-08T21:08:04Z,"Abdelrahman Abouelenin, Mohamed Abdelrehim, Raffy Fahim, Amr Hendy, Mohamed Afify",privacypreserving transformers swiftkeys differential privacy implementation,in this paper we train a transformer using differential privacy dp for language modeling in swiftkey we run multiple experiments to balance the tradeoff between the model size runtime speed and accuracy we show that we get small and consistent gains in the nextwordprediction and accuracy with graceful increase in memory and speed compared to the production gru this is obtained by scaling down a gpt2 architecture to fit the required size and a two stage training process that builds a seed model on general data and dp finetunes it on typing data the transformer is integrated using onnx offering both flexibility and efficiency
http://arxiv.org/abs/2505.06313v1,2025-05-08T18:42:01Z,Bohdan M. Pavlyshenko,ai approaches to qualitative and quantitative news analytics on nato unity,the paper considers the use of gpt models with retrievalaugmented generation rag for qualitative and quantitative analytics on nato sentiments nato unity and nato article 5 trust opinion scores in different web sources news sites found via google search api youtube videos with comments and reddit discussions a rag approach using gpt41 model was applied to analyse news where nato related topics were discussed two levels of rag analytics were used on the first level the gpt model generates qualitative news summaries and quantitative opinion scores using zeroshot prompts on the second level the gpt model generates the summary of news summaries quantitative news opinion scores generated by the gpt model were analysed using bayesian regression to get trend lines the distributions found for the regression parameters make it possible to analyse an uncertainty in specified news opinion score trends obtained results show a downward trend for analysed scores of opinion related to nato unity this approach does not aim to conduct real political analysis rather it consider ai based approaches which can be used for further analytics as a part of a complex analytical approach the obtained results demonstrate that the use of gpt models for news analysis can give informative qualitative and quantitative analytics providing important insights the dynamic model based on neural ordinary differential equations was considered for modelling public opinions this approach makes it possible to analyse different scenarios for evolving public opinions
http://arxiv.org/abs/2505.05583v1,2025-05-08T18:27:27Z,"Qianbo Zang, Christophe Zgrzendek, Igor Tchappi, Afshin Khadangi, Johannes Sedlmeir",kghtc integrating knowledge graphs into llms for effective zeroshot hierarchical text classification,hierarchical text classification htc involves assigning documents to labels organized within a taxonomy most previous research on htc has focused on supervised methods however in realworld scenarios employing supervised htc can be challenging due to a lack of annotated data moreover htc often faces issues with large label spaces and longtail distributions in this work we present knowledge graphs for zeroshot hierarchical text classification kghtc which aims to address these challenges of htc in applications by integrating knowledge graphs with large language models llms to provide structured semantic context during classification our method retrieves relevant subgraphs from knowledge graphs related to the input text using a retrievalaugmented generation rag approach our kghtc can enhance llms to understand label semantics at various hierarchy levels we evaluate kghtc on three opensource htc datasets wos dbpedia and amazon our experimental results show that kghtc significantly outperforms three baselines in the strict zeroshot setting particularly achieving substantial improvements at deeper levels of the hierarchy this evaluation demonstrates the effectiveness of incorporating structured knowledge into llms to address htcs challenges in large label spaces and longtailed label distributions our code is available at httpsgithubcomqianbozangkghtc
http://arxiv.org/abs/2505.05467v1,2025-05-08T17:57:40Z,"Haibo Wang, Bo Feng, Zhengfeng Lai, Mingze Xu, Shiyu Li, Weifeng Ge, Afshin Dehghan, Meng Cao, Ping Huang",streambridge turning your offline video large language model into a proactive streaming assistant,we present streambridge a simple yet effective framework that seamlessly transforms offline videollms into streamingcapable models it addresses two fundamental challenges in adapting existing models into online scenarios 1 limited capability for multiturn realtime understanding and 2 lack of proactive response mechanisms specifically streambridge incorporates 1 a memory buffer combined with a rounddecayed compression strategy supporting longcontext multiturn interactions and 2 a decoupled lightweight activation model that can be effortlessly integrated into existing videollms enabling continuous proactive responses to further support streambridge we construct streamit a largescale dataset tailored for streaming video understanding featuring interleaved videotext sequences and diverse instruction formats extensive experiments show that streambridge significantly improves the streaming understanding capabilities of offline videollms across various tasks outperforming even proprietary models such as gpt4o and gemini 15 pro simultaneously it achieves competitive or superior performance on standard video understanding benchmarks
http://arxiv.org/abs/2505.05465v1,2025-05-08T17:56:57Z,"Peter Chen, Xi Chen, Wotao Yin, Tianyi Lin",compo preference alignment via comparison oracles,direct alignment methods are increasingly used for aligning large language models llms with human preferences however these methods suffer from the issues of verbosity and likelihood displacement which can be driven by the noisy preference pairs that induce similar likelihood for preferred and dispreferred responses the contributions of this paper are twofold first we propose a new preference alignment method based on comparison oracles and provide the convergence guarantee for its basic scheme second we improve our method using some heuristics and conduct the experiments to demonstrate the flexibility and compatibility of practical scheme in improving the performance of llms using noisy preference pairs evaluations are conducted across multiple base and instructiontuned models mistral7b llama38b and gemma29b with benchmarks alpacaeval 2 mtbench and arenahard experimental results show the effectiveness of our method as an alternative to addressing the limitations of existing direct alignment methods a highlight of our work is that we evidence the importance of designing specialized methods for preference pairs with distinct likelihood margin which complements the recent findings in citetrazin2025unintentional
http://arxiv.org/abs/2505.05464v1,2025-05-08T17:56:23Z,"Shiqi Chen, Jinghan Zhang, Tongyao Zhu, Wei Liu, Siyang Gao, Miao Xiong, Manling Li, Junxian He",bring reason to vision understanding perception and reasoning through model merging,visionlanguage models vlms combine visual perception with the general capabilities such as reasoning of large language models llms however the mechanisms by which these two abilities can be combined and contribute remain poorly understood in this work we explore to compose perception and reasoning through model merging that connects parameters of different models unlike previous works that often focus on merging models of the same kind we propose merging models across modalities enabling the incorporation of the reasoning capabilities of llms into vlms through extensive experiments we demonstrate that model merging offers a successful pathway to transfer reasoning abilities from llms to vlms in a trainingfree manner moreover we utilize the merged models to understand the internal mechanism of perception and reasoning and how merging affects it we find that perception capabilities are predominantly encoded in the early layers of the model whereas reasoning is largely facilitated by the middletolate layers after merging we observe that all layers begin to contribute to reasoning whereas the distribution of perception abilities across layers remains largely unchanged these observations shed light on the potential of model merging as a tool for multimodal integration and interpretation
http://arxiv.org/abs/2505.07861v1,2025-05-08T17:51:24Z,"Harry Dong, Bilge Acun, Beidi Chen, Yuejie Chi",scalable llm math reasoning acceleration with lowrank distillation,due to long generations large language model llm math reasoning demands significant computational resources and time while many existing efficient inference methods have been developed with excellent performance preservation on language tasks they often severely degrade math performance in this paper we propose caprese a lowcost distillation method to recover lost capabilities from deploying efficient inference methods focused primarily in feedforward blocks with original weights unperturbed roughly 1 of additional parameters and only 20k synthetic training samples we are able to recover much if not all of the math capabilities lost from efficient inference for thinking llms and without harm to language tasks for instruct llms moreover caprese slashes the number of active parameters 2b cut for gemma 2 9b and llama 31 8b and integrates cleanly into existing model layers to reduce latency 11 reduction to generate 2048 tokens with qwen 25 14b while encouraging response brevity
http://arxiv.org/abs/2505.05459v1,2025-05-08T17:51:20Z,"Fatima Haouari, Carolina Scarton, Nicolò Faggiani, Nikolaos Nikolaidis, Bonka Kotseva, Ibrahim Abu Farha, Jens Linge, Kalina Bontcheva",ukelectionnarratives a dataset of misleading narratives surrounding recent uk general elections,misleading narratives play a crucial role in shaping public opinion during elections as they can influence how voters perceive candidates and political parties this entails the need to detect these narratives accurately to address this we introduce the first taxonomy of common misleading narratives that circulated during recent elections in europe based on this taxonomy we construct and analyse ukelectionnarratives the first dataset of humanannotated misleading narratives which circulated during the uk general elections in 2019 and 2024 we also benchmark pretrained and large language models focusing on gpt4o studying their effectiveness in detecting electionrelated misleading narratives finally we discuss potential use cases and make recommendations for future research directions using the proposed codebook and dataset
http://arxiv.org/abs/2505.05446v1,2025-05-08T17:37:36Z,"Han Xiao, Yina Xie, Guanxin Tan, Yinghao Chen, Rui Hu, Ke Wang, Aojun Zhou, Hao Li, Hao Shao, Xudong Lu, Peng Gao, Yafei Wen, Xiaoxin Chen, Shuai Ren, Hongsheng Li",adaptive markup language generation for contextuallygrounded visual document understanding,visual document understanding has become essential with the increase of textrich visual content this field poses significant challenges due to the need for effective integration of visual perception and textual comprehension particularly across diverse document types with complex layouts moreover existing finetuning datasets for this domain often fall short in providing the detailed contextual information for robust understanding leading to hallucinations and limited comprehension of spatial relationships among visual elements to address these challenges we propose an innovative pipeline that utilizes adaptive generation of markup languages such as markdown json html and tikz to build highly structured document representations and deliver contextuallygrounded responses we introduce two finegrained structured datasets docmarkpile comprising approximately 38m pretraining data pairs for document parsing and docmarkinstruct featuring 624k finetuning data annotations for grounded instruction following extensive experiments demonstrate that our proposed model significantly outperforms existing stateoftheart mllms across a range of visual document understanding benchmarks facilitating advanced reasoning and comprehension capabilities in complex visual scenarios our code and models are released at httpsgithub comeuphoria16docmark
http://arxiv.org/abs/2505.05445v1,2025-05-08T17:36:36Z,"Chalamalasetti Kranti, Sherzod Hakimov, David Schlangen",clemtodd a framework for the systematic benchmarking of llmbased taskoriented dialogue system realisations,the emergence of instructiontuned large language models llms has advanced the field of dialogue systems enabling both realistic user simulations and robust multiturn conversational agents however existing research often evaluates these components in isolationeither focusing on a single user simulator or a specific system designlimiting the generalisability of insights across architectures and configurations in this work we propose clem todd chatoptimized llms for taskoriented dialogue systems development a flexible framework for systematically evaluating dialogue systems under consistent conditions clem todd enables detailed benchmarking across combinations of user simulators and dialogue systems whether existing models from literature or newly developed ones it supports plugandplay integration and ensures uniform datasets evaluation metrics and computational constraints we showcase clem todds flexibility by reevaluating existing taskoriented dialogue systems within this unified setup and integrating three newly proposed dialogue systems into the same evaluation pipeline our results provide actionable insights into how architecture scale and prompting strategies affect dialogue performance offering practical guidance for building efficient and effective conversational ai systems
http://arxiv.org/abs/2505.05427v1,2025-05-08T17:15:20Z,"Yudong Wang, Zixuan Fu, Jie Cai, Peijun Tang, Hongya Lyu, Yewei Fang, Zhi Zheng, Jie Zhou, Guoyang Zeng, Chaojun Xiao, Xu Han, Zhiyuan Liu",ultrafineweb efficient data filtering and verification for highquality llm training data,data quality has become a key factor in enhancing model performance with the rapid development of large language models llms modeldriven data filtering has increasingly become a primary approach for acquiring highquality data however it still faces two main challenges 1 the lack of an efficient data verification strategy makes it difficult to provide timely feedback on data quality and 2 the selection of seed data for training classifiers lacks clear criteria and relies heavily on human expertise introducing a degree of subjectivity to address the first challenge we introduce an efficient verification strategy that enables rapid evaluation of the impact of data on llm training with minimal computational cost to tackle the second challenge we build upon the assumption that highquality seed data is beneficial for llm training and by integrating the proposed verification strategy we optimize the selection of positive and negative samples and propose an efficient data filtering pipeline this pipeline not only improves filtering efficiency classifier quality and robustness but also significantly reduces experimental and inference costs in addition to efficiently filter highquality data we employ a lightweight classifier based on fasttext and successfully apply the filtering pipeline to two widelyused pretraining corpora fineweb and chinese fineweb datasets resulting in the creation of the higherquality ultrafineweb dataset ultrafineweb contains approximately 1 trillion english tokens and 120 billion chinese tokens empirical results demonstrate that the llms trained on ultrafineweb exhibit significant performance improvements across multiple benchmark tasks validating the effectiveness of our pipeline in enhancing both data quality and training efficiency
http://arxiv.org/abs/2505.05423v2,2025-05-08T17:12:56Z,"Ran Zhang, Wei Zhao, Lieve Macken, Steffen Eger",litransproqa an llmbased literary translation evaluation metric with professional question answering,the impact of large language models llms has extended into literary domains however existing evaluation metrics prioritize mechanical accuracy over artistic expression and tend to overrate machine translation mt as being superior to experienced professional human translation in the long run this bias could result in a permanent decline in translation quality and cultural authenticity in response to the urgent need for a specialized literary evaluation metric we introduce litransproqa a novel referencefree llmbased questionanswering framework designed specifically for literary translation evaluation litransproqa uniquely integrates insights from professional literary translators and researchers focusing on critical elements in literary quality assessment such as literary devices cultural understanding and authorial voice our extensive evaluation shows that while literaryfinetuned xcometxl yields marginal gains litransproqa substantially outperforms current metrics achieving up to 007 gain in correlation acceq and kendalls tau and surpassing the best stateoftheart metrics by over 15 points in adequacy assessments incorporating professional translator insights as weights further improves performance highlighting the value of translator inputs notably litransproqa approaches humanlevel evaluation performance comparable to trained linguistic annotators it demonstrates broad applicability to opensource models such as llama3370b and qwen2532b indicating its potential as an accessible and trainingfree literary evaluation metric and a valuable tool for evaluating texts that require local processing due to copyright or ethical considerations
http://arxiv.org/abs/2505.05422v1,2025-05-08T17:12:19Z,"Haokun Lin, Teng Wang, Yixiao Ge, Yuying Ge, Zhichao Lu, Ying Wei, Qingfu Zhang, Zhenan Sun, Ying Shan",toklip marry visual tokens to clip for multimodal comprehension and generation,pioneering tokenbased works such as chameleon and emu3 have established a foundation for multimodal unification but face challenges of high training computational overhead and limited comprehension performance due to a lack of highlevel semantics in this paper we introduce toklip a visual tokenizer that enhances comprehension by semanticizing vectorquantized vq tokens and incorporating cliplevel semantics while enabling endtoend multimodal autoregressive training with standard vq tokens toklip integrates a lowlevel discrete vq tokenizer with a vitbased token encoder to capture highlevel continuous semantics unlike previous approaches eg vilau that discretize highlevel features toklip disentangles training objectives for comprehension and generation allowing the direct application of advanced vq tokenizers without the need for tailored quantization operations our empirical results demonstrate that toklip achieves exceptional data efficiency empowering visual tokens with highlevel semantic understanding while enhancing lowlevel generative capacity making it wellsuited for autoregressive transformers in both comprehension and generation tasks the code and models are available at httpsgithubcomtencentarctoklip
http://arxiv.org/abs/2505.05410v1,2025-05-08T16:51:43Z,"Yanda Chen, Joe Benton, Ansh Radhakrishnan, Jonathan Uesato, Carson Denison, John Schulman, Arushi Somani, Peter Hase, Misha Wagner, Fabien Roger, Vlad Mikulik, Samuel R. Bowman, Jan Leike, Jared Kaplan, Ethan Perez",reasoning models dont always say what they think,chainofthought cot offers a potential boon for ai safety as it allows monitoring a models cot to try to understand its intentions and reasoning processes however the effectiveness of such monitoring hinges on cots faithfully representing models actual reasoning processes we evaluate cot faithfulness of stateoftheart reasoning models across 6 reasoning hints presented in the prompts and find 1 for most settings and models tested cots reveal their usage of hints in at least 1 of examples where they use the hint but the reveal rate is often below 20 2 outcomebased reinforcement learning initially improves faithfulness but plateaus without saturating and 3 when reinforcement learning increases how frequently hints are used reward hacking the propensity to verbalize them does not increase even without training against a cot monitor these results suggest that cot monitoring is a promising way of noticing undesired behaviors during training and evaluations but that it is not sufficient to rule them out they also suggest that in settings like ours where cot reasoning is not necessary testtime monitoring of cots is unlikely to reliably catch rare and catastrophic unexpected behaviors
http://arxiv.org/abs/2505.05408v1,2025-05-08T16:50:06Z,"Zheng-Xin Yong, M. Farid Adilazuarda, Jonibek Mansurov, Ruochen Zhang, Niklas Muennighoff, Carsten Eickhoff, Genta Indra Winata, Julia Kreutzer, Stephen H. Bach, Alham Fikri Aji",crosslingual reasoning through testtime scaling,reasoning capabilities of large language models are primarily studied for english even when pretrained models are multilingual in this work we investigate to what extent english reasoning finetuning with long chainofthoughts cots can generalize across languages first we find that scaling up inference compute for englishcentric reasoning language models rlms improves multilingual mathematical reasoning across many languages including lowresource languages to an extent where they outperform models twice their size second we reveal that while englishcentric rlms cots are naturally predominantly english they consistently follow a quoteandthink pattern to reason about quoted nonenglish inputs third we discover an effective strategy to control the language of long cot reasoning and we observe that models reason better and more efficiently in highresource languages finally we observe poor outofdomain reasoning generalization in particular from stem to cultural commonsense knowledge even for english overall we demonstrate the potentials study the mechanisms and outline the limitations of crosslingual generalization of english reasoning testtime scaling we conclude that practitioners should let englishcentric rlms reason in highresource languages while further work is needed to improve reasoning in lowresource languages and outofdomain contexts
http://arxiv.org/abs/2505.05406v1,2025-05-08T16:46:24Z,"Valeria Pastorino, Nafise Sadat Moosavi",frame in frame out do llms generate more biased news headlines than humans,framing in media critically shapes public perception by selectively emphasizing some details while downplaying others with the rise of large language models in automated news and content creation there is growing concern that these systems may introduce or even amplify framing biases compared to human authors in this paper we explore how framing manifests in both outofthebox and finetuned llmgenerated news content our analysis reveals that particularly in politically and socially sensitive contexts llms tend to exhibit more pronounced framing than their human counterparts in addition we observe significant variation in framing tendencies across different model architectures with some models displaying notably higher biases these findings point to the need for effective posttraining mitigation strategies and tighter evaluation frameworks to ensure that automated news content upholds the standards of balanced reporting
http://arxiv.org/abs/2505.05327v2,2025-05-08T15:17:37Z,"Yixin Yang, Qingxiu Dong, Linli Yao, Fangwei Zhu, Zhifang Sui",rico refined incontext contribution for automatic instructiontuning data selection,data selection for instruction tuning is crucial for improving the performance of large language models llms while reducing training costs in this paper we propose refined contribution measurement with incontext learning rico a novel gradientfree method that quantifies the finegrained contribution of individual samples to both tasklevel and globallevel model performance rico enables more accurate identification of highcontribution data leading to better instruction tuning we further introduce a lightweight selection paradigm trained on rico scores enabling scalable data selection with a strictly linear inference complexity extensive experiments on three llms across 12 benchmarks and 5 pairwise evaluation sets demonstrate the effectiveness of rico remarkably on llama318b models trained on 15 of ricoselected data outperform full datasets by 542 points and exceed the best performance of widely used selection methods by 206 points we further analyze highcontribution samples selected by rico which show both diverse tasks and appropriate difficulty levels rather than just the hardest ones
http://arxiv.org/abs/2505.05315v1,2025-05-08T15:01:06Z,"Yuhui Xu, Hanze Dong, Lei Wang, Doyen Sahoo, Junnan Li, Caiming Xiong",scalable chain of thoughts via elastic reasoning,large reasoning models lrms have achieved remarkable progress on complex tasks by generating extended chains of thought cot however their uncontrolled output lengths pose significant challenges for realworld deployment where inferencetime budgets on tokens latency or compute are strictly constrained we propose elastic reasoning a novel framework for scalable chain of thoughts that explicitly separates reasoning into two phasesthinking and solutionwith independently allocated budgets at test time elastic reasoning prioritize that completeness of solution segments significantly improving reliability under tight resource constraints to train models that are robust to truncated thinking we introduce a lightweight budgetconstrained rollout strategy integrated into grpo which teaches the model to reason adaptively when the thinking process is cut short and generalizes effectively to unseen budget constraints without additional training empirical results on mathematical aime math500 and programming livecodebench codeforces benchmarks demonstrate that elastic reasoning performs robustly under strict budget constraints while incurring significantly lower training cost than baseline methods remarkably our approach also produces more concise and efficient reasoning even in unconstrained settings elastic reasoning offers a principled and practical solution to the pressing challenge of controllable reasoning at scale
http://arxiv.org/abs/2505.05298v1,2025-05-08T14:41:07Z,"Elena Musi, Nadin Kokciyan, Khalid Al-Khatib, Davide Ceolin, Emmanuelle Dietz, Klara Gutekunst, Annette Hautli-Janisz, Cristian Manuel Santibañez Yañez, Jodi Schneider, Jonas Scholz, Cor Steging, Jacky Visser, Henning Wachsmuth",toward reasonable parrots why large language models should argue with us by design,in this position paper we advocate for the development of conversational technology that is inherently designed to support and facilitate argumentative processes we argue that at present large language models llms are inadequate for this purpose and we propose an ideal technology design aimed at enhancing argumentative skills this involves reframing llms as tools to exercise our critical thinking rather than replacing them we introduce the concept of reasonable parrots that embody the fundamental principles of relevance responsibility and freedom and that interact through argumentative dialogical moves these principles and moves arise out of millennia of work in argumentation theory and should serve as the starting point for llmbased technology that incorporates basic principles of argumentation
http://arxiv.org/abs/2505.05271v1,2025-05-08T14:17:27Z,"Kun Peng, Chaodong Tong, Cong Cao, Hao Peng, Qian Li, Guanlin Wu, Lei Jiang, Yanbing Liu, Philip S. Yu",tt table transformer for taggingbased aspect sentiment triplet extraction,aspect sentiment triplet extraction aste aims to extract triplets composed of aspect terms opinion terms and sentiment polarities from given sentences the table tagging method is a popular approach to addressing this task which encodes a sentence into a 2dimensional table allowing for the tagging of relations between any two words previous efforts have focused on designing various downstream relation learning modules to better capture interactions between tokens in the table revealing that a stronger capability to capture relations can lead to greater improvements in the model motivated by this we attempt to directly utilize transformer layers as downstream relation learning modules due to the powerful semantic modeling capability of transformers it is foreseeable that this will lead to excellent improvement however owing to the quadratic relation between the length of the table and the length of the input sentence sequence using transformers directly faces two challenges overly long table sequences and unfair local attention interaction to address these challenges we propose a novel tabletransformer tt for the taggingbased aste method specifically we introduce a stripe attention mechanism with a loopshift strategy to tackle these challenges the former modifies the global attention mechanism to only attend to a 2dimensional local attention window while the latter facilitates interaction between different attention windows extensive and comprehensive experiments demonstrate that the tt as a downstream relation learning module achieves stateoftheart performance with lower computational costs
http://arxiv.org/abs/2505.05225v1,2025-05-08T13:16:49Z,"Mengze Hong, Wailing Ng, Di Jiang, Chen Jason Zhang",qualbench benchmarking chinese llms with localized professional qualifications for vertical domain evaluation,the rapid advancement of chinese large language models llms underscores the need for domainspecific evaluations to ensure reliable applications however existing benchmarks often lack coverage in vertical domains and offer limited insights into the chinese working context leveraging qualification exams as a unified framework for human expertise evaluation we introduce qualbench the first multidomain chinese qa benchmark dedicated to localized assessment of chinese llms the dataset includes over 17000 questions across six vertical domains with data selections grounded in 24 chinese qualifications to closely align with national policies and working standards through comprehensive evaluation the qwen25 model outperformed the more advanced gpt4o with chinese llms consistently surpassing nonchinese models highlighting the importance of localized domain knowledge in meeting qualification requirements the best performance of 7526 reveals the current gaps in domain coverage within model capabilities furthermore we present the failure of llm collaboration with crowdsourcing mechanisms and suggest the opportunities for multidomain rag knowledge enhancement and vertical domain llm training with federated learning
http://arxiv.org/abs/2505.05190v2,2025-05-08T12:39:00Z,"Yixin Cheng, Hongcheng Guo, Yangming Li, Leonid Sigal",revealing weaknesses in text watermarking through selfinformation rewrite attacks,text watermarking aims to subtly embed statistical signals into text by controlling the large language model llms sampling process enabling watermark detectors to verify that the output was generated by the specified model the robustness of these watermarking algorithms has become a key factor in evaluating their effectiveness current text watermarking algorithms embed watermarks in highentropy tokens to ensure text quality in this paper we reveal that this seemingly benign design can be exploited by attackers posing a significant risk to the robustness of the watermark we introduce a generic efficient paraphrasing attack the selfinformation rewrite attack sira which leverages the vulnerability by calculating the selfinformation of each token to identify potential pattern tokens and perform targeted attack our work exposes a widely prevalent vulnerability in current watermarking algorithms the experimental results show sira achieves nearly 100 attack success rates on seven recent watermarking methods with only 088 usd per million tokens cost our approach does not require any access to the watermark algorithms or the watermarked llm and can seamlessly transfer to any llm as the attack model even mobilelevel models our findings highlight the urgent need for more robust watermarking
http://arxiv.org/abs/2505.05528v1,2025-05-08T11:59:13Z,"Hanxun Huang, Sarah Erfani, Yige Li, Xingjun Ma, James Bailey",xtransfer attacks towards super transferable adversarial attacks on clip,as contrastive languageimage pretraining clip models are increasingly adopted for diverse downstream tasks and integrated into large visionlanguage models vlms their susceptibility to adversarial perturbations has emerged as a critical concern in this work we introduce textbfxtransfer a novel attack method that exposes a universal adversarial vulnerability in clip xtransfer generates a universal adversarial perturbation uap capable of deceiving various clip encoders and downstream vlms across different samples tasks and domains we refer to this property as textbfsuper transferabilitya single perturbation achieving crossdata crossdomain crossmodel and crosstask adversarial transferability simultaneously this is achieved through textbfsurrogate scaling a key innovation of our approach unlike existing methods that rely on fixed surrogate models which are computationally intensive to scale xtransfer employs an efficient surrogate scaling strategy that dynamically selects a small subset of suitable surrogates from a large search space extensive evaluations demonstrate that xtransfer significantly outperforms previous stateoftheart uap methods establishing a new benchmark for adversarial transferability across clip models the code is publicly available in our hrefhttpsgithubcomhanxunhxtransferbenchgithub repository
http://arxiv.org/abs/2505.05148v1,2025-05-08T11:38:20Z,"Hussain Ahmad, Qingyang Zeng, Jing Wan",a benchmark dataset and a framework for urdu multimodal named entity recognition,the emergence of multimodal content particularly text and images on social media has positioned multimodal named entity recognition mner as an increasingly important area of research within natural language processing despite progress in highresource languages such as english mner remains underexplored for lowresource languages like urdu the primary challenges include the scarcity of annotated multimodal datasets and the lack of standardized baselines to address these challenges we introduce the umner framework and release the twitter2015urdu dataset a pioneering resource for urdu mner adapted from the widely used twitter2015 dataset it is annotated with urduspecific grammar rules we establish benchmark baselines by evaluating both textbased and multimodal models on this dataset providing comparative analyses to support future research on urdu mner the umner framework integrates textual and visual context using urdubert for text embeddings and resnet for visual feature extraction with a crossmodal fusion module to align and fuse information our model achieves stateoftheart performance on the twitter2015urdu dataset laying the groundwork for further mner research in lowresource languages
http://arxiv.org/abs/2505.05145v2,2025-05-08T11:32:46Z,"Xinyan Hu, Kayo Yin, Michael I. Jordan, Jacob Steinhardt, Lijie Chen",understanding incontext learning of addition via activation subspaces,to perform incontext learning language models must extract signals from individual fewshot examples aggregate these into a learned prediction rule and then apply this rule to new examples how is this implemented in the forward pass of modern transformer models to study this we consider a structured family of fewshot learning tasks for which the true prediction rule is to add an integer to the input we find that llama38b attains high accuracy on this task for a range of and localize its fewshot ability to just three attention heads via a novel optimization approach we further show the extracted signals lie in a sixdimensional subspace where four of the dimensions track the unit digit and the other two dimensions track overall magnitude we finally examine how these heads extract information from individual fewshot examples identifying a selfcorrection mechanism in which mistakes from earlier examples are suppressed by later examples our results demonstrate how tracking lowdimensional subspaces across a forward pass can provide insight into finegrained computational structures
http://arxiv.org/abs/2505.07859v1,2025-05-08T11:17:10Z,"Daniel Franzen, Jan Disselhoff, David Hartmann",boosting performance on arc is a matter of perspective,the abstraction and reasoning corpus arcagi poses a significant challenge for large language models llms exposing limitations in their abstract reasoning abilities in this work we leverage taskspecific data augmentations throughout the training generation and scoring phases and employ a depthfirst search algorithm to generate diverse highprobability candidate solutions furthermore we utilize the llm not only as a generator but also as a scorer using its output probabilities to select the most promising solutions our method achieves a score of 716 2865400 solved tasks on the public arcagi evaluation set demonstrating stateoftheart performance among publicly available approaches while concurrent closedsource work has reported higher scores our method distinguishes itself through its transparency reproducibility and remarkably low inference cost averaging only around 2ct per task on readily available hardware we assume a price of 36cthour for a nvidia 4090 gpu
http://arxiv.org/abs/2505.07858v1,2025-05-08T11:10:15Z,"Siyuan Yan, Mo Zhu, Guo-qing Jiang, Jianfei Wang, Jiaxing Chen, Wentai Zhang, Xiang Liao, Xiao Cui, Chen Zhang, Zhuoran Song, Ran Zhu",scaling laws for speculative decoding,the escalating demand for efficient decoding in large language models llms is particularly critical for reasoningintensive architectures like openaio3 and deepseekr1 which depend on extended chainofthought reasoning this study investigates speculative decoding techniques through dense llm architectures to establish foundational insights for accelerating reasoning tasks while speculative decoding methods leveraging parallel draftverification cycles have emerged as promising acceleration techniques the scaling laws governing decoding efficiency remain underexplored compared to conventional backbone llms developed through pretrainingsftrlhf training paradigms in this work we discover loglinear scaling laws theorem 11 12 and 13 governing draft model acceptance rate or decoding speed across three dimensions pretraining token volume draft model capacity and decoding batch size building on these laws we achieve scylla which coordinates multidimensional scaling for popular llms llama23 qwen25 empirical validation shows scylla achieves 1522 higher acceptance rate than eagle2 and 03 higher than eagle3 at temperature t 0 with peak performance gains on summarization and qa tasks figure 2 industrial inference engine deployments demonstrate 2x decoding throughput improvements over eagle2 table 5 validating the transformative potential of systematic scaling for efficient llm inference code will be released later
http://arxiv.org/abs/2505.05111v1,2025-05-08T10:24:44Z,"Boyi Deng, Yu Wan, Yidan Zhang, Baosong Yang, Fuli Feng",unveiling languagespecific features in large language models via sparse autoencoders,the mechanisms behind multilingual capabilities in large language models llms have been examined using neuronbased or internalactivationbased methods however these methods often face challenges such as superposition and layerwise activation variance which limit their reliability sparse autoencoders saes offer a more nuanced analysis by decomposing the activations of llms into sparse linear combination of sae features we introduce a novel metric to assess the monolinguality of features obtained from saes discovering that some features are strongly related to specific languages additionally we show that ablating these sae features only significantly reduces abilities in one language of llms leaving others almost unaffected interestingly we find some languages have multiple synergistic sae features and ablating them together yields greater improvement than ablating individually moreover we leverage these saederived languagespecific features to enhance steering vectors achieving control over the language generated by llms
http://arxiv.org/abs/2505.05098v1,2025-05-08T09:52:55Z,"Wei Liu, Jiyuan Zhang, Binxiong Zheng, Yufeng Hu, Yingzhan Lin, Zengfeng Zeng",xdriver explainable autonomous driving with visionlanguage models,endtoend autonomous driving has advanced significantly offering benefits such as system simplicity and stronger driving performance in both openloop and closedloop settings than conventional pipelines however existing frameworks still suffer from low success rates in closedloop evaluations highlighting their limitations in realworld deployment in this paper we introduce xdriver a unified multimodal large language modelsmllms framework designed for closedloop autonomous driving leveraging chainofthoughtcot and autoregressive modeling to enhance perception and decisionmaking we validate xdriver across multiple autonomous driving tasks using public benchmarks in carla simulation environment including bench2drive6 our experimental results demonstrate superior closedloop performance surpassing the current stateoftheartsota while improving the interpretability of driving decisions these findings underscore the importance of structured reasoning in endtoend driving and establish xdriver as a strong baseline for future research in closedloop autonomous driving
http://arxiv.org/abs/2505.05084v2,2025-05-08T09:32:38Z,"Xiaowei Zhu, Yubing Ren, Yanan Cao, Xixun Lin, Fang Fang, Yangxi Li",reliably bounding false positives a zeroshot machinegenerated text detection framework via multiscaled conformal prediction,the rapid advancement of large language models has raised significant concerns regarding their potential misuse by malicious actors as a result developing effective detectors to mitigate these risks has become a critical priority however most existing detection methods focus excessively on detection accuracy often neglecting the societal risks posed by high false positive rates fprs this paper addresses this issue by leveraging conformal prediction cp which effectively constrains the upper bound of fprs while directly applying cp constrains fprs it also leads to a significant reduction in detection performance to overcome this tradeoff this paper proposes a zeroshot machinegenerated text detection framework via multiscaled conformal prediction mcp which both enforces the fpr constraint and improves detection performance this paper also introduces realdet a highquality dataset that spans a wide range of domains ensuring realistic calibration and enabling superior detection performance when combined with mcp empirical evaluations demonstrate that mcp effectively constrains fprs significantly enhances detection performance and increases robustness against adversarial attacks across multiple detectors and datasets
http://arxiv.org/abs/2505.05070v1,2025-05-08T09:06:28Z,"Ajwad Abrar, Farzana Tabassum, Sabbir Ahmed",performance evaluation of large language models in bangla consumer health query summarization,consumer health queries chqs in bengali bangla a lowresource language often contain extraneous details complicating efficient medical responses this study investigates the zeroshot performance of nine advanced large language models llms gpt35turbo gpt4 claude35sonnet llama370binstruct mixtral8x22binstruct gemini15pro qwen272binstruct gemma227b and athene70b in summarizing bangla chqs using the banglachqsumm dataset comprising 2350 annotated querysummary pairs we benchmarked these llms using rouge metrics against bangla t5 a finetuned stateoftheart model mixtral8x22binstruct emerged as the top performing model in rouge1 and rougel while bangla t5 excelled in rouge2 the results demonstrate that zeroshot llms can rival finetuned models achieving highquality summaries even without taskspecific training this work underscores the potential of llms in addressing challenges in lowresource languages providing scalable solutions for healthcare query summarization
http://arxiv.org/abs/2505.05063v1,2025-05-08T08:55:32Z,"Manik Sheokand, Parth Sawant",codemixbench evaluating large language models on code generation with codemixed prompts,large language models llms have achieved remarkable success in code generation tasks powering various applications like code completion debugging and programming assistance however existing benchmarks such as humaneval mbpp and bigcodebench primarily evaluate llms on englishonly prompts overlooking the realworld scenario where multilingual developers often use codemixed language while interacting with llms to address this gap we introduce codemixbench a novel benchmark designed to evaluate the robustness of llms on code generation from codemixed prompts built upon bigcodebench codemixbench introduces controlled codemixing cmd into the natural language parts of prompts across three language pairs hinglish hindienglish spanishenglish and chinese pinyinenglish we comprehensively evaluate a diverse set of opensource code generation models ranging from 15b to 15b parameters our results show that codemixed prompts consistently degrade pass1 performance compared to their englishonly counterparts with performance drops increasing under higher cmd levels for smaller models codemixbench provides a realistic evaluation framework for studying multilingual code generation and highlights new challenges and directions for building robust code generation models that generalize well across diverse linguistic settings
http://arxiv.org/abs/2505.05056v1,2025-05-08T08:47:11Z,"Linrong Pan, Chenglong Jiang, Gaoze Hou, Ying Gao",teochewwild the first inthewild teochew dataset with orthographic annotations,this paper reports the construction of the teochewwild a speech corpus of the teochew dialect the corpus includes 189 hours of inthewild teochew speech data from multiple speakers covering both formal and colloquial expressions with precise orthographic and pinyin annotations additionally we provide supplementary text processing tools and resources to propel research and applications in speech tasks for this lowresource language such as automatic speech recognition asr and texttospeech tts to the best of our knowledge this is the first publicly available teochew dataset with accurate orthographic annotations we conduct experiments on the corpus and the results validate its effectiveness in asr and tts tasks
http://arxiv.org/abs/2505.07857v1,2025-05-08T08:38:40Z,"Faiza Hassan, Summra Saleem, Kashif Javed, Muhammad Nabeel Asim, Abdur Rehman, Andreas Dengel",enhanced urdu intent detection with large language models and prototypeinformed predictive pipelines,multifarious intent detection predictors are developed for different languages including english chinese and french however the field remains underdeveloped for urdu the 10th most spoken language in the realm of wellknown languages intent detection predictors utilize the strategy of fewshot learning and prediction of unseen classes based on the model training on seen classes however urdu language lacks fewshot strategy based intent detection predictors and traditional predictors are focused on prediction of the same classes which models have seen in the train set to empower urdu language specific intent detection this introduces a unique contrastive learning approach that leverages unlabeled urdu data to retrain pretrained language models this retraining empowers llms representation learning for the downstream intent detection task finally it reaps the combined potential of pretrained llms and the prototypeinformed attention mechanism to create a comprehensive endtoend llmpia intent detection pipeline under the paradigm of proposed predictive pipeline it explores the potential of 6 distinct language models and 13 distinct similarity computation methods the proposed framework is evaluated on 2 public benchmark datasets namely atis encompassing 5836 samples and web queries having 8519 samples across atis dataset under 4way 1 shot and 4way 5 shot experimental settings llmpia achieved 8328 and 9825 f1score and on web queries dataset produced 7623 and 8442 f1score respectively in an additional case study on the web queries dataset under same classes train and test set settings llmpia outperformed stateoftheart predictor by 5355 f1score
http://arxiv.org/abs/2505.05040v1,2025-05-08T08:23:20Z,"Matīss Rikters, Edison Marrese-Taylor",imagetext relation prediction for multilingual tweets,various social networks have been allowing media uploads for over a decade now still it has not always been clear what is their relation with the posted text or even if there is any at all in this work we explore how multilingual visionlanguage models tackle the task of imagetext relation prediction in different languages and construct a dedicated balanced benchmark data set from twitter posts in latvian along with their manual translations into english we compare our results to previous work and show that the more recently released visionlanguage model checkpoints are becoming increasingly capable at this task but there is still much room for further improvement
http://arxiv.org/abs/2505.05026v2,2025-05-08T08:00:32Z,"Jaehyun Jeon, Jang Han Yoon, Min Soo Kim, Sumin Shim, Yejin Choi, Hanbin Kim, Youngjae Yu",gfocus towards a robust method for assessing ui design persuasiveness,evaluating user interface ui design effectiveness extends beyond aesthetics to influencing user behavior a principle central to design persuasiveness ab testing is the predominant method for determining which ui variations drive higher user engagement but it is costly and timeconsuming while recent visionlanguage models vlms can process automated ui analysis current approaches focus on isolated design attributes rather than comparative persuasivenessthe key factor in optimizing user interactions to address this we introduce wiseruibench a benchmark designed for pairwise ui design persuasiveness assessment task featuring 300 realworld ui image pairs labeled with ab test results and expert rationales additionally we propose gfocus a novel inferencetime reasoning strategy that enhances vlmbased persuasiveness assessment by reducing position bias and improving evaluation accuracy experimental results show that gfocus surpasses existing inference strategies in consistency and accuracy for pairwise ui evaluation through promoting vlmdriven evaluation of ui persuasiveness our work offers an approach to complement ab testing propelling progress in scalable ui preference modeling and design optimization code and data will be released publicly
http://arxiv.org/abs/2505.07856v1,2025-05-08T08:00:03Z,"Paweł Walkowiak, Marek Klonowski, Marcin Oleksy, Arkadiusz Janz",unpacking robustness in inflectional languages adversarial evaluation and mechanistic insights,various techniques are used in the generation of adversarial examples including methods such as textbugger which introduce minor hardly visible perturbations to words leading to changes in model behaviour another class of techniques involves substituting words with their synonyms in a way that preserves the texts meaning but alters its predicted class with textfooler being a prominent example of such attacks most adversarial example generation methods are developed and evaluated primarily on noninflectional languages typically english in this work we evaluate and explain how adversarial attacks perform in inflectional languages to explain the impact of inflection on model behaviour and its robustness under attack we designed a novel protocol inspired by mechanistic interpretability based on edge attribution patching eap method the proposed evaluation protocol relies on parallel taskspecific corpora that include both inflected and syncretic variants of texts in two languages polish and english to analyse the models and explain the relationship between inflection and adversarial robustness we create a new benchmark based on taskoriented dataset multiemo enabling the identification of mechanistic inflectionrelated elements of circuits within the model and analyse their behaviour under attack
http://arxiv.org/abs/2505.05017v1,2025-05-08T07:43:44Z,"Yuntai Bao, Xuhong Zhang, Tianyu Du, Xinkui Zhao, Jiang Zong, Hao Peng, Jianwei Yin",scalable multistage influence function for large language models via eigenvaluecorrected kroneckerfactored parameterization,pretrained large language models llms are commonly finetuned to adapt to downstream tasks since the majority of knowledge is acquired during pretraining attributing the predictions of finetuned llms to their pretraining data may provide valuable insights influence functions have been proposed as a means to explain model predictions based on training data however existing approaches fail to compute multistage influence and lack scalability to billionscale llms in this paper we propose the multistage influence function to attribute the downstream predictions of finetuned llms to pretraining data under the fullparameter finetuning paradigm to enhance the efficiency and practicality of our multistage influence function we leverage eigenvaluecorrected kroneckerfactored ekfac parameterization for efficient approximation empirical results validate the superior scalability of ekfac approximation and the effectiveness of our multistage influence function additionally case studies on a realworld llm dollyv23b demonstrate its interpretive power with exemplars illustrating insights provided by multistage influence estimates our code is public at httpsgithubcomcoloreddyemultistageinfluencefunction
http://arxiv.org/abs/2505.05016v1,2025-05-08T07:43:01Z,"Cedric Waterschoot, Nava Tintarev, Francesco Barile",the pitfalls of growing group complexity llms and social choicebased aggregation for group recommendations,large language models llms are increasingly applied in recommender systems aimed at both individuals and groups previously group recommender systems grs often used social choicebased aggregation strategies to derive a single recommendation based on the preferences of multiple people in this paper we investigate under which conditions language models can perform these strategies correctly based on zeroshot learning and analyse whether the formatting of the group scenario in the prompt affects accuracy we specifically focused on the impact of group complexity number of users and items different llms different prompting conditions including incontext learning or generating explanations and the formatting of group preferences our results show that performance starts to deteriorate when considering more than 100 ratings however not all language models were equally sensitive to growing group complexity additionally we showed that incontext learning icl can significantly increase the performance at higher degrees of group complexity while adding other prompt modifications specifying domain cues or prompting for explanations did not impact accuracy we conclude that future research should include group complexity as a factor in grs evaluation due to its effect on llm performance furthermore we showed that formatting the group scenarios differently such as rating lists per user or per item affected accuracy all in all our study implies that smaller llms are capable of generating group recommendations under the right conditions making the case for using smaller models that require less computing power and costs
http://arxiv.org/abs/2505.04994v1,2025-05-08T06:59:14Z,"Lizhe Fang, Yifei Wang, Khashayar Gatmiry, Lei Fang, Yisen Wang",rethinking invariance in incontext learning,incontext learning icl has emerged as a pivotal capability of autoregressive large language models yet it is hindered by a notable sensitivity to the ordering of context examples regardless of their mutual independence to address this issue recent studies have introduced several variant algorithms of icl that achieve permutation invariance however many of these do not exhibit comparable performance with the standard autoregressive icl algorithm in this work we identify two crucial elements in the design of an invariant icl algorithm information nonleakage and context interdependence which are not simultaneously achieved by any of the existing methods these investigations lead us to the proposed invariant icl invicl a methodology designed to achieve invariance in icl while ensuring the two properties empirically our findings reveal that invicl surpasses previous models both invariant and noninvariant in most benchmark datasets showcasing superior generalization capabilities across varying input lengths code is available at httpsgithubcompkumlinvicl
http://arxiv.org/abs/2505.04993v1,2025-05-08T06:59:06Z,"Zhuocheng Gong, Jian Guan, Wei Wu, Huishuai Zhang, Dongyan Zhao",latent preference coding aligning large language models via discrete latent codes,large language models llms have achieved remarkable success yet aligning their generations with human preferences remains a critical challenge existing approaches to preference modeling often rely on an explicit or implicit reward function overlooking the intricate and multifaceted nature of human preferences that may encompass conflicting factors across diverse tasks and populations to address this limitation we introduce latent preference coding lpc a novel framework that models the implicit factors as well as their combinations behind holistic preferences using discrete latent codes lpc seamlessly integrates with various offline alignment algorithms automatically inferring the underlying factors and their importance from data without relying on predefined reward functions and handcrafted combination weights extensive experiments on multiple benchmarks demonstrate that lpc consistently improves upon three alignment algorithms dpo simpo and ipo using three base models mistral7b llama38b and llama38binstruct furthermore deeper analysis reveals that the learned latent codes effectively capture the differences in the distribution of human preferences and significantly enhance the robustness of alignment against noise in data by providing a unified representation for the multifarious preference factors lpc paves the way towards developing more robust and versatile alignment techniques for the responsible deployment of powerful llms
http://arxiv.org/abs/2505.04984v1,2025-05-08T06:41:46Z,"Kai Nakaishi, Ryo Yoshida, Kohei Kajikawa, Koji Hukushima, Yohei Oseki",rethinking the relationship between the power law and hierarchical structures,statistical analysis of corpora provides an approach to quantitatively investigate natural languages this approach has revealed that several power laws consistently emerge across different corpora and languages suggesting the universal principles underlying languages particularly the powerlaw decay of correlation has been interpreted as evidence for underlying hierarchical structures in syntax semantics and discourse this perspective has also been extended to child languages and animal signals however the argument supporting this interpretation has not been empirically tested to address this problem this study examines the validity of the argument for syntactic structures specifically we test whether the statistical properties of parse trees align with the implicit assumptions in the argument using english corpora we analyze the mutual information deviations from probabilistic contextfree grammars pcfgs and other properties in parse trees as well as in the pcfg that approximates these trees our results indicate that the assumptions do not hold for syntactic structures and that it is difficult to apply the proposed argument to child languages and animal signals highlighting the need to reconsider the relationship between the power law and hierarchical structures
http://arxiv.org/abs/2505.04969v1,2025-05-08T06:01:11Z,"Gekko Budiutama, Shunsuke Daimon, Hirofumi Nishi, Yu-ichiro Matsushita",general transform a unified framework for adaptive transform to enhance representations,discrete transforms such as the discrete fourier transform are widely used in machine learning to improve model performance by extracting meaningful features however with numerous transforms available selecting an appropriate one often depends on understanding the datasets properties making the approach less effective when such knowledge is unavailable in this work we propose general transform gt an adaptive transformbased representation designed for machine learning applications unlike conventional transforms gt learns datadriven mapping tailored to the dataset and task of interest here we demonstrate that models incorporating gt outperform conventional transformbased approaches across computer vision and natural language processing tasks highlighting its effectiveness in diverse learning scenarios
http://arxiv.org/abs/2505.04955v1,2025-05-08T05:32:36Z,"Fangwei Zhu, Peiyi Wang, Zhifang Sui",chainofthought tokens are computer program variables,chainofthoughts cot requires large language models llms to generate intermediate steps before reaching the final answer and has been proven effective to help llms solve complex reasoning tasks however the inner mechanism of cot still remains largely unclear in this paper we empirically study the role of cot tokens in llms on two compositional tasks multidigit multiplication and dynamic programming while cot is essential for solving these problems we find that preserving only tokens that store intermediate results would achieve comparable performance furthermore we observe that storing intermediate results in an alternative latent form will not affect model performance we also randomly intervene some values in cot and notice that subsequent cot tokens and the final answer would change correspondingly these findings suggest that cot tokens may function like variables in computer programs but with potential drawbacks like unintended shortcuts and computational complexity limits between tokens the code and data are available at httpsgithubcomsolitaryzerocotsarevariables
http://arxiv.org/abs/2505.04948v1,2025-05-08T05:01:44Z,"Md Aminul Islam, Ahmed Sayeed Faruk",promptbased llms for position biasaware reranking in personalized recommendations,recommender systems are essential for delivering personalized content across digital platforms by modeling user preferences and behaviors recently large language models llms have been adopted for promptbased recommendation due to their ability to generate personalized outputs without taskspecific training however llmbased methods face limitations such as limited context window size inefficient pointwise and pairwise prompting and difficulty handling listwise ranking due to token constraints llms can also be sensitive to position bias as they may overemphasize earlier items in the prompt regardless of their true relevance to address and investigate these issues we propose a hybrid framework that combines a traditional recommendation model with an llm for reranking topk items using structured prompts we evaluate the effects of user history reordering and instructional prompts for mitigating position bias experiments on movielens100k show that randomizing user history improves ranking quality but llmbased reranking does not outperform the base model explicit instructions to reduce position bias are also ineffective our evaluations reveal limitations in llms ability to model ranking context and mitigate bias our code is publicly available at httpsgithubcomaminul7506llmforreranking
http://arxiv.org/abs/2505.04946v1,2025-05-08T04:49:52Z,"Xuyang Guo, Jiayan Huo, Zhenmei Shi, Zhao Song, Jiahao Zhang, Jiale Zhao",t2vtextbench a human evaluation benchmark for textual control in video generation models,thanks to recent advancements in scalable deep architectures and largescale pretraining texttovideo generation has achieved unprecedented capabilities in producing highfidelity instructionfollowing content across a wide range of styles enabling applications in advertising entertainment and education however these models ability to render precise onscreen text such as captions or mathematical formulas remains largely untested posing significant challenges for applications requiring exact textual accuracy in this work we introduce t2vtextbench the first humanevaluation benchmark dedicated to evaluating onscreen text fidelity and temporal consistency in texttovideo models our suite of prompts integrates complex text strings with dynamic scene changes testing each models ability to maintain detailed instructions across frames we evaluate ten stateoftheart systems ranging from opensource solutions to commercial offerings and find that most struggle to generate legible consistent text these results highlight a critical gap in current video generators and provide a clear direction for future research aimed at enhancing textual manipulation in video synthesis
http://arxiv.org/abs/2505.04921v1,2025-05-08T03:35:23Z,"Yunxin Li, Zhenyu Liu, Zitao Li, Xuanyu Zhang, Zhenran Xu, Xinyu Chen, Haoyuan Shi, Shenyuan Jiang, Xintong Wang, Jifang Wang, Shouzheng Huang, Xinping Zhao, Borui Jiang, Lanqing Hong, Longyue Wang, Zhuotao Tian, Baoxing Huai, Wenhan Luo, Weihua Luo, Zheng Zhang, Baotian Hu, Min Zhang",perception reason think and plan a survey on large multimodal reasoning models,reasoning lies at the heart of intelligence shaping the ability to make decisions draw conclusions and generalize across domains in artificial intelligence as systems increasingly operate in open uncertain and multimodal environments reasoning becomes essential for enabling robust and adaptive behavior large multimodal reasoning models lmrms have emerged as a promising paradigm integrating modalities such as text images audio and video to support complex reasoning capabilities and aiming to achieve comprehensive perception precise understanding and deep reasoning as research advances multimodal reasoning has rapidly evolved from modular perceptiondriven pipelines to unified languagecentric frameworks that offer more coherent crossmodal understanding while instruction tuning and reinforcement learning have improved model reasoning significant challenges remain in omnimodal generalization reasoning depth and agentic behavior to address these issues we present a comprehensive and structured survey of multimodal reasoning research organized around a fourstage developmental roadmap that reflects the fields shifting design philosophies and emerging capabilities first we review early efforts based on taskspecific modules where reasoning was implicitly embedded across stages of representation alignment and fusion next we examine recent approaches that unify reasoning into multimodal llms with advances such as multimodal chainofthought mcot and multimodal reinforcement learning enabling richer and more structured reasoning chains finally drawing on empirical insights from challenging benchmarks and experimental cases of openai o3 and o4mini we discuss the conceptual direction of native large multimodal reasoning models nlmrms which aim to support scalable agentic and adaptive reasoning and planning in complex realworld environments
http://arxiv.org/abs/2505.04916v1,2025-05-08T03:14:14Z,"Ramteja Sajja, Yusuf Sermet, Ibrahim Demir",an opensource dualloss embedding model for semantic retrieval in higher education,recent advances in ai have catalyzed the adoption of intelligent educational tools yet many semantic retrieval systems remain illsuited to the unique linguistic and structural characteristics of academic content this study presents two opensource embedding models finetuned for educational question answering particularly in the context of course syllabi a synthetic dataset of 3197 sentence pairs spanning synonymous terminology paraphrased questions and implicitexplicit mappings was constructed through a combination of manual curation and large language model llmassisted generation two training strategies were evaluated 1 a baseline model finetuned using multiplenegativesrankingloss mnrl and 2 a dualloss model that combines mnrl with cosinesimilarityloss to improve both semantic ranking and similarity calibration evaluations were conducted on 28 university course syllabi using a fixed set of natural language questions categorized into course faculty and teaching assistant information results demonstrate that both finetuned models outperform strong opensource baselines including allminilml6v2 and multiqaminilml6cosv1 and that the dualloss model narrows the performance gap with highperforming proprietary embeddings such as openais textembedding3 series this work contributes reusable domainaligned embedding models and provides a replicable framework for educational semantic retrieval supporting downstream applications such as academic chatbots retrievalaugmented generation rag systems and learning management system lms integrations
http://arxiv.org/abs/2505.04914v1,2025-05-08T03:09:57Z,John Hawkins,enigme generative text puzzles for evaluating reasoning in language models,transformerdecoder language models are a core innovation in text based generative artificial intelligence these models are being deployed as generalpurpose intelligence systems in many applications central to their utility is the capacity to understand natural language commands and exploit the reasoning embedded in human text corpora to apply some form of reasoning process to a wide variety of novel tasks to understand the limitations of this approach to generating reasoning we argue that we need to consider the architectural constraints of these systems consideration of the latent variable structure of transformerdecoder models allows us to design reasoning tasks that should probe the boundary of their capacity to reason we present enigme an opensource library for generating textbased puzzles to be used in training and evaluating reasoning skills within transformerdecoder models and future ai architectures
http://arxiv.org/abs/2505.04911v1,2025-05-08T02:59:01Z,"Shun Taguchi, Hideki Deguchi, Takumi Hamazaki, Hiroyuki Sakai",spatialprompting keyframedriven zeroshot spatial reasoning with offtheshelf multimodal large language models,this study introduces spatialprompting a novel framework that harnesses the emergent reasoning capabilities of offtheshelf multimodal large language models to achieve zeroshot spatial reasoning in threedimensional 3d environments unlike existing methods that rely on expensive 3dspecific finetuning with specialized 3d inputs such as point clouds or voxelbased features spatialprompting employs a keyframedriven prompt generation strategy this framework uses metrics such as visionlanguage similarity mahalanobis distance field of view and image sharpness to select a diverse and informative set of keyframes from image sequences and then integrates them with corresponding camera pose data to effectively abstract spatial relationships and infer complex 3d structures the proposed framework not only establishes a new paradigm for flexible spatial reasoning that utilizes intuitive visual and positional cues but also achieves stateoftheart zeroshot performance on benchmark datasets such as scanqa and sqa3d across several metrics the proposed method effectively eliminates the need for specialized 3d inputs and finetuning offering a simpler and more scalable alternative to conventional approaches
http://arxiv.org/abs/2505.04881v1,2025-05-08T01:40:40Z,"Ziqing Qiao, Yongheng Deng, Jiali Zeng, Dong Wang, Lai Wei, Fandong Meng, Jie Zhou, Ju Ren, Yaoxue Zhang",concise confidenceguided compression in stepbystep efficient reasoning,large reasoning models lrms perform strongly in complex reasoning tasks via chainofthought cot prompting but often suffer from verbose outputs caused by redundant content increasing computational overhead and degrading user experience existing compression methods either operate posthoc pruning risking disruption to reasoning coherence or rely on samplingbased selection which fails to intervene effectively during generation in this work we introduce a confidenceguided perspective to explain the emergence of redundant reflection in lrms identifying two key patterns confidence deficit where the model reconsiders correct steps due to low internal confidence and termination delay where reasoning continues even after reaching a confident answer based on this analysis we propose concise confidenceguided compression in stepbystep efficient reasoning a framework that simplifies reasoning chains by reinforcing the models confidence during inference thus preventing the generation of redundant reflection steps it integrates confidence injection to stabilize intermediate steps and early stopping to terminate reasoning when confidence is sufficient extensive experiments demonstrate that finetuning lrms on concisegenerated data yields significantly shorter outputs reducing length by up to approximately 50 under simpo while maintaining high task accuracy concise consistently outperforms existing baselines across multiple reasoning benchmarks
http://arxiv.org/abs/2505.07853v1,2025-05-08T00:23:18Z,"Hao Zhen, Jidong J. Yang",crashsage a large language modelcentered framework for contextual and interpretable traffic crash analysis,road crashes claim over 13 million lives annually worldwide and incur global economic losses exceeding 18 trillion such profound societal and financial impacts underscore the urgent need for road safety research that uncovers crash mechanisms and delivers actionable insights conventional statistical models and tree ensemble approaches typically rely on structured crash data overlooking contextual nuances and struggling to capture complex relationships and underlying semantics moreover these approaches tend to incur significant information loss particularly in narrative elements related to multivehicle interactions crash progression and rare event characteristics this study presents crashsage a novel large language model llmcentered framework designed to advance crash analysis and modeling through four key innovations first we introduce a tabulartotext transformation strategy paired with relational data integration schema enabling the conversion of raw heterogeneous crash data into enriched structured textual narratives that retain essential structural and relational context second we apply contextaware data augmentation using a base llm model to improve narrative coherence while preserving factual integrity third we finetune the llama38b model for crash severity inference demonstrating superior performance over baseline approaches including zeroshot zeroshot with chainofthought prompting and fewshot learning with multiple models gpt4o gpt4omini llama370b finally we employ a gradientbased explainability technique to elucidate model decisions at both the individual crash level and across broader risk factor dimensions this interpretability mechanism enhances transparency and enables targeted road safety interventions by providing deeper insights into the most influential factors
http://arxiv.org/abs/2505.04851v1,2025-05-07T23:29:28Z,"Viacheslav Vasilev, Vladimir Arkhipkin, Julia Agafonova, Tatiana Nikulina, Evelina Mironova, Alisa Shichanina, Nikolai Gerasimenko, Mikhail Shoytov, Denis Dimitrov",craft cultural russianoriented dataset adaptation for focused texttoimage generation,despite the fact that popular texttoimage generation models cope well with international and general cultural queries they have a significant knowledge gap regarding individual cultures this is due to the content of existing large training datasets collected on the internet which are predominantly based on western european or american popular culture meanwhile the lack of cultural adaptation of the model can lead to incorrect results a decrease in the generation quality and the spread of stereotypes and offensive content in an effort to address this issue we examine the concept of cultural code and recognize the critical importance of its understanding by modern image generation models an issue that has not been sufficiently addressed in the research community to date we propose the methodology for collecting and processing the data necessary to form a dataset based on the cultural code in particular the russian one we explore how the collected data affects the quality of generations in the national domain and analyze the effectiveness of our approach using the kandinsky 31 texttoimage model human evaluation results demonstrate an increase in the level of awareness of russian culture in the model
http://arxiv.org/abs/2505.04847v1,2025-05-07T22:50:33Z,"Manveer Singh Tamber, Forrest Sheng Bao, Chenyu Xu, Ge Luo, Suleman Kazi, Minseok Bae, Miaoran Li, Ofer Mendelevitch, Renyi Qu, Jimmy Lin",benchmarking llm faithfulness in rag with evolving leaderboards,hallucinations remain a persistent challenge for llms rag aims to reduce hallucinations by grounding responses in contexts however even when provided context llms still frequently introduce unsupported information or contradictions this paper presents our efforts to measure llm hallucinations with a focus on summarization tasks assessing how often various llms introduce hallucinations when summarizing documents we discuss vectaras existing llm hallucination leaderboard based on the hughes hallucination evaluation model hhem while hhem and vectaras hallucination leaderboard have garnered great research interest we examine challenges faced by hhem and current hallucination detection methods by analyzing the effectiveness of these methods on existing hallucination datasets to address these limitations we propose faithjudge an llmasajudge approach guided by fewshot human hallucination annotations which substantially improves automated llm hallucination evaluation over current methods we introduce an enhanced hallucination leaderboard centered on faithjudge alongside our current hallucination leaderboard enabling more reliable benchmarking of llms for hallucinations in rag
http://arxiv.org/abs/2505.04846v1,2025-05-07T22:50:23Z,"Ozan Gokdemir, Carlo Siebenschuh, Alexander Brace, Azton Wells, Brian Hsu, Kyle Hippe, Priyanka V. Setty, Aswathy Ajith, J. Gregory Pauloski, Varuni Sastry, Sam Foreman, Huihuo Zheng, Heng Ma, Bharat Kale, Nicholas Chia, Thomas Gibbs, Michael E. Papka, Thomas Brettin, Francis J. Alexander, Anima Anandkumar, Ian Foster, Rick Stevens, Venkatram Vishwanath, Arvind Ramanathan",hiperrag highperformance retrieval augmented generation for scientific insights,the volume of scientific literature is growing exponentially leading to underutilized discoveries duplicated efforts and limited crossdisciplinary collaboration retrieval augmented generation rag offers a way to assist scientists by improving the factuality of large language models llms in processing this influx of information however scaling rag to handle millions of articles introduces significant challenges including the high computational costs associated with parsing documents and embedding scientific knowledge as well as the algorithmic complexity of aligning these representations with the nuanced semantics of scientific content to address these issues we introduce hiperrag a rag workflow powered by high performance computing hpc to index and retrieve knowledge from more than 36 million scientific articles at its core are oreo a highthroughput model for multimodal document parsing and coltrast a queryaware encoder finetuning algorithm that enhances retrieval accuracy by using contrastive learning and lateinteraction techniques hiperrag delivers robust performance on existing scientific question answering benchmarks and two new benchmarks introduced in this work achieving 90 accuracy on sciq and 76 on pubmedqaoutperforming both domainspecific models like pubmedgpt and commercial llms such as gpt4 scaling to thousands of gpus on the polaris sunspot and frontier supercomputers hiperrag delivers million documentscale rag workflows for unifying scientific knowledge and fostering interdisciplinary innovation
http://arxiv.org/abs/2505.04844v1,2025-05-07T22:45:59Z,"Alex Shan, John Bauer, Christopher D. Manning",osiris a lightweight opensource hallucination detection system,retrievalaugmented generation rag systems have gained widespread adoption by application builders because they leverage sources of truth to enable large language models llms to generate more factually sound responses however hallucinations instances of llm responses that are unfaithful to the provided context often prevent these systems from being deployed in production environments current hallucination detection methods typically involve human evaluation or the use of closedsource models to review rag system outputs for hallucinations both human evaluators and closedsource models suffer from scaling issues due to their high costs and slow inference speeds in this work we introduce a perturbed multihop qa dataset with induced hallucinations via supervised finetuning on our dataset we achieve better recall with a 7b model than gpt4o on the ragtruth hallucination detection benchmark and offer competitive performance on precision and accuracy all while using a fraction of the parameters code is released at our repository
http://arxiv.org/abs/2505.07852v1,2025-05-07T22:30:53Z,"Ali Senol, Garima Agrawal, Huan Liu",joint detection of fraud and concept drift inonline conversations with llmassisted judgment,detecting fake interactions in digital communication platforms remains a challenging and insufficiently addressed problem these interactions may appear as harmless spam or escalate into sophisticated scam attempts making it difficult to flag malicious intent early traditional detection methods often rely on static anomaly detection techniques that fail to adapt to dynamic conversational shifts one key limitation is the misinterpretation of benign topic transitions referred to as concept drift as fraudulent behavior leading to either false alarms or missed threats we propose a two stage detection framework that first identifies suspicious conversations using a tailored ensemble classification model to improve the reliability of detection we incorporate a concept drift analysis step using a one class drift detector ocdd to isolate conversational shifts within flagged dialogues when drift is detected a large language model llm assesses whether the shift indicates fraudulent manipulation or a legitimate topic change in cases where no drift is found the behavior is inferred to be spam like we validate our framework using a dataset of social engineering chat scenarios and demonstrate its practical advantages in improving both accuracy and interpretability for real time fraud detection to contextualize the trade offs we compare our modular approach against a dual llm baseline that performs detection and judgment using different language models
http://arxiv.org/abs/2505.04806v2,2025-05-07T21:15:40Z,Chetan Pathade,red teaming the mind of the machine a systematic evaluation of prompt injection and jailbreak vulnerabilities in llms,large language models llms are increasingly integrated into consumer and enterprise applications despite their capabilities they remain susceptible to adversarial attacks such as prompt injection and jailbreaks that override alignment safeguards this paper provides a systematic investigation of jailbreak strategies against various stateoftheart llms we categorize over 1400 adversarial prompts analyze their success against gpt4 claude 2 mistral 7b and vicuna and examine their generalizability and construction logic we further propose layered mitigation strategies and recommend a hybrid redteaming and sandboxing approach for robust llm security
http://arxiv.org/abs/2505.08795v1,2025-05-07T20:41:06Z,"Andres Anabalon, Hugo Garces, Julio Oliva, Jose Cifuentes",the geometry of meaning perfect spacetime representations of hierarchical structures,we show that there is a fast algorithm that embeds hierarchical structures in threedimensional minkowski spacetime the correlation of data ends up purely encoded in the causal structure our model relies solely on oriented token pairs local hierarchical signals with no access to global symbolic structure we apply our method to the corpus of textitwordnet we provide a perfect embedding of the mammal subtree including ambiguities more than one hierarchy per node in such a way that the hierarchical structures get completely codified in the geometry and exactly reproduce the groundtruth we extend this to a perfect embedding of the maximal unambiguous subset of the textitwordnet with 82115 noun tokens and a single hierarchy per token we introduce a novel retrieval mechanism in which causality not distance governs hierarchical access our results seem to indicate that all discrete data has a perfect geometrical representation that is threedimensional the resulting embeddings are nearly conformally invariant indicating deep connections with general relativity and field theory these results suggest that concepts categories and their interrelations namely hierarchical meaning itself is geometric
http://arxiv.org/abs/2505.04785v1,2025-05-07T20:27:38Z,"Shuai Gong, Tiange Zhou",flower across time and media sentiment analysis of tang song poetry and visual correspondence,the tang 618 to 907 and song 960 to 1279 dynasties witnessed an extraordinary flourishing of chinese cultural expression where floral motifs served as a dynamic medium for both poetic sentiment and artistic design while previous scholarship has examined these domains independently the systematic correlation between evolving literary emotions and visual culture remains underexplored this study addresses that gap by employing bertbased sentiment analysis to quantify emotional patterns in floral imagery across tang song poetry then validating these patterns against contemporaneous developments in decorative artsour approach builds upon recent advances in computational humanities while remaining grounded in traditional sinological methods by applying a fine tuned bert model to analyze peony and plum blossom imagery in classical poetry we detect measurable shifts in emotional connotations between the tang and song periods these textual patterns are then cross berenced with visual evidence from textiles ceramics and other material culture revealing previously unrecognized synergies between literary expression and artistic representation
http://arxiv.org/abs/2505.07850v1,2025-05-07T20:12:48Z,"Pranav Narayanan Venkit, Jiayi Li, Yingfan Zhou, Sarah Rajtmajer, Shomir Wilson",a tale of two identities an ethical audit of human and aicrafted personas,as llms large language models are increasingly used to generate synthetic personas particularly in datalimited domains such as health privacy and hci it becomes necessary to understand how these narratives represent identity especially that of minority communities in this paper we audit synthetic personas generated by 3 llms gpt4o gemini 15 pro deepseek 25 through the lens of representational harm focusing specifically on racial identity using a mixed methods approach combining close reading lexical analysis and a parameterized creativity framework we compare 1512 llm generated personas to humanauthored responses our findings reveal that llms disproportionately foreground racial markers overproduce culturally coded language and construct personas that are syntactically elaborate yet narratively reductive these patterns result in a range of sociotechnical harms including stereotyping exoticism erasure and benevolent bias that are often obfuscated by superficially positive narrations we formalize this phenomenon as algorithmic othering where minoritized identities are rendered hypervisible but less authentic based on these findings we offer design recommendations for narrativeaware evaluation metrics and communitycentered validation protocols for synthetic identity generation
http://arxiv.org/abs/2505.04741v1,2025-05-07T19:17:49Z,"Kenneth Li, Yida Chen, Fernanda Viégas, Martin Wattenberg",when bad data leads to good models,in large language model llm pretraining data quality is believed to determine model quality in this paper we reexamine the notion of quality from the perspective of pre and posttraining codesign specifically we explore the possibility that pretraining on more toxic data can lead to better control in posttraining ultimately decreasing a models output toxicity first we use a toy experiment to study how data composition affects the geometry of features in the representation space next through controlled experiments with olmo1b models trained on varying ratios of clean and toxic data we find that the concept of toxicity enjoys a less entangled linear representation as the proportion of toxic data increases furthermore we show that although toxic data increases the generational toxicity of the base model it also makes the toxicity easier to remove evaluations on toxigen and real toxicity prompts demonstrate that models trained on toxic data achieve a better tradeoff between reducing generational toxicity and preserving general capabilities when detoxifying techniques such as inferencetime intervention iti are applied our findings suggest that with posttraining taken into account bad data may lead to good models
http://arxiv.org/abs/2505.04723v1,2025-05-07T18:21:47Z,"Jingyang Deng, Ran Chen, Jo-Ku Cheng, Jinwen Ma",soaesv27b72b fullpipeline optimization for stateowned enterprise llms via continual pretraining domainprogressive sft and distillationenhanced speculative decoding,this study addresses key challenges in developing domainspecific large language models llms for chinese stateowned assets and enterprises soaes where current approaches face three limitations 1 constrained model capacity that limits knowledge integration and crosstask adaptability 2 excessive reliance on domainspecific supervised finetuning sft data which neglects the broader applicability of general language patterns and 3 inefficient inference acceleration for large models processing long contexts in this work we propose soaesv27b72b a specialized llm series developed via a threephase framework 1 continual pretraining integrates domain knowledge while retaining base capabilities 2 domainprogressive sft employs curriculumbased learning strategy transitioning from weakly relevant conversational data to expertannotated soaes datasets to optimize domainspecific tasks 3 distillationenhanced speculative decoding accelerates inference via logit distillation between 72b target and 7b draft models achieving 139152 speedup without quality loss experimental results demonstrate that our domainspecific pretraining phase maintains 998 of original general language capabilities while significantly improving domain performance resulting in a 108 improvement in rouge1 score and a 117 enhancement in bleu4 score ablation studies further show that domainprogressive sft outperforms singlestage training achieving 102 improvement in rouge1 and 106 in bleu4 our work introduces a comprehensive fullpipeline approach for optimizing soaes llms bridging the gap between general language capabilities and domainspecific expertise
http://arxiv.org/abs/2505.06297v1,2025-05-07T17:42:35Z,"Yu Mao, Holger Pirk, Chun Jason Xue",lossless compression of large language modelgenerated text via nexttoken prediction,as large language models llms continue to be deployed and utilized across domains the volume of llmgenerated data is growing rapidly this trend highlights the increasing importance of effective and lossless compression for such data in modern text management systems however compressing llmgenerated data presents unique challenges compared to traditional human or machinegenerated content traditional machinegenerated data is typically derived from computational processes or device outputs often highly structured and limited to lowlevel elements like labels or numerical values this structure enables conventional lossless compressors to perform efficiently in contrast llmgenerated data is more complex and diverse requiring new approaches for effective compression in this work we conduct the first systematic investigation of lossless compression techniques tailored specifically to llmgenerated data notably because llms are trained via nexttoken prediction we find that llmgenerated data is highly predictable for the models themselves this predictability enables llms to serve as efficient compressors of their own outputs through extensive experiments with 14 representative llms and 8 llmgenerated datasets from diverse domains we show that llmbased prediction methods achieve remarkable compression rates exceeding 20x far surpassing the 3x rate achieved by gzip a widely used generalpurpose compressor furthermore this advantage holds across different llm sizes and dataset types demonstrating the robustness and practicality of llmbased methods in lossless text compression under generative ai workloads
http://arxiv.org/abs/2505.04588v2,2025-05-07T17:30:22Z,"Hao Sun, Zile Qiao, Jiayan Guo, Xuanbo Fan, Yingyan Hou, Yong Jiang, Pengjun Xie, Yan Zhang, Fei Huang, Jingren Zhou",zerosearch incentivize the search capability of llms without searching,effective information searching is essential for enhancing the reasoning and generation capabilities of large language models llms recent research has explored using reinforcement learning rl to improve llms search capabilities by interacting with live search engines in realworld environments while these approaches show promising results they face two major challenges 1 uncontrolled document quality the quality of documents returned by search engines is often unpredictable introducing noise and instability into the training process 2 prohibitively high api costs rl training requires frequent rollouts potentially involving hundreds of thousands of search requests which incur substantial api expenses and severely constrain scalability to address these challenges we introduce zerosearch a novel rl framework that incentivizes the capabilities of llms to use a real search engine with simulated searches during training our approach begins with lightweight supervised finetuning to transform the llm into a retrieval module capable of generating both useful and noisy documents in response to a query during rl training we employ a curriculumbased rollout strategy that incrementally degrades the quality of generated documents progressively eliciting the models reasoning ability by exposing it to increasingly challenging retrieval scenarios extensive experiments demonstrate that zerosearch effectively incentivizes the search capabilities of llms using a 3b llm as the retrieval module remarkably a 7b retrieval module achieves comparable performance to the real search engine while a 14b retrieval module even surpasses it furthermore it generalizes well across both base and instructiontuned models of various parameter sizes and is compatible with a wide range of rl algorithms
http://arxiv.org/abs/2505.04531v1,2025-05-07T16:04:45Z,"Josh McGiff, Nikola S. Nikolov",overcoming data scarcity in generative language modelling for lowresource languages a systematic review,generative language modelling has surged in popularity with the emergence of services such as chatgpt and google gemini while these models have demonstrated transformative potential in productivity and communication they overwhelmingly cater to highresource languages like english this has amplified concerns over linguistic inequality in natural language processing nlp this paper presents the first systematic review focused specifically on strategies to address data scarcity in generative language modelling for lowresource languages lrl drawing from 54 studies we identify categorise and evaluate technical approaches including monolingual data augmentation backtranslation multilingual training and prompt engineering across generative tasks we also analyse trends in architecture choices language family representation and evaluation methods our findings highlight a strong reliance on transformerbased models a concentration on a small subset of lrls and a lack of consistent evaluation across studies we conclude with recommendations for extending these methods to a wider range of lrls and outline open challenges in building equitable generative language systems ultimately this review aims to support researchers and developers in building inclusive ai tools for underrepresented languages a necessary step toward empowering lrl speakers and the preservation of linguistic diversity in a world increasingly shaped by largescale language technologies
http://arxiv.org/abs/2505.04528v1,2025-05-07T16:02:14Z,"Qi Liu, Xinhao Zheng, Renqiu Xia, Xingzhi Qi, Qinxiang Cao, Junchi Yan",beyond theorem proving formulation framework and benchmark for formal problemsolving,as a seemingly selfexplanatory task problemsolving has been a significant component of science and engineering however a general yet concrete formulation of problemsolving itself is missing with the recent development of aibased problemsolving agents the demand for processlevel verifiability is rapidly increasing yet underexplored to fill these gaps we present a principled formulation of problemsolving as a deterministic markov decision process a novel framework fps formal problemsolving which utilizes existing ftp formal theorem proving environments to perform processverified problemsolving and dfps deductive fps decoupling solving and answer verification for better humanalignment the expressiveness soundness and completeness of the frameworks are proven we construct three benchmarks on problemsolving formalmath500 a formalization of a subset of the math500 benchmark minif2fsolving and putnambenchsolving adaptations of ftp benchmarks minif2f and putnambench for faithful interpretable and humanaligned evaluation we propose rpe restricted propositional equivalence a symbolic approach to determine the correctness of answers by formal verification we evaluate four prevalent ftp models and two prompting methods as baselines solving at most 2377 of formalmath500 2747 of minif2fsolving and 031 of putnambenchsolving
http://arxiv.org/abs/2505.04519v1,2025-05-07T15:46:36Z,"Yehui Tang, Yichun Yin, Yaoyuan Wang, Hang Zhou, Yu Pan, Wei Guo, Ziyang Zhang, Miao Rang, Fangcheng Liu, Naifu Zhang, Binghan Li, Yonghan Dong, Xiaojun Meng, Yasheng Wang, Dong Li, Yin Li, Dandan Tu, Can Chen, Youliang Yan, Fisher Yu, Ruiming Tang, Yunhe Wang, Botian Huang, Bo Wang, Boxiao Liu, Changzheng Zhang, Da Kuang, Fei Liu, Gang Huang, Jiansheng Wei, Jiarui Qin, Jie Ran, Jinpeng Li, Jun Zhao, Liang Dai, Lin Li, Liqun Deng, Peifeng Qin, Pengyuan Zeng, Qiang Gu, Shaohua Tang, Shengjun Cheng, Tao Gao, Tao Yu, Tianshu Li, Tianyu Bi, Wei He, Weikai Mao, Wenyong Huang, Wulong Liu, Xiabing Li, Xianzhi Yu, Xueyu Wu, Xu He, Yangkai Du, Yan Xu, Ye Tian, Yimeng Wu, Yongbing Huang, Yong Tian, Yong Zhu, Yue Li, Yufei Wang, Yuhang Gai, Yujun Li, Yu Luo, Yunsheng Ni, Yusen Sun, Zelin Chen, Zhe Liu, Zhicheng Liu, Zhipeng Tu, Zilin Ding, Zongyuan Zhan",pangu ultra moe how to train your big moe on ascend npus,sparse large language models llms with mixture of experts moe and close to a trillion parameters are dominating the realm of most capable language models however the massive model scale poses significant challenges for the underlying software and hardware systems in this paper we aim to uncover a recipe to harness such scale on ascend npus the key goals are better usage of the computing resources under the dynamic sparse model structures and materializing the expected performance gain on the actual hardware to select model configurations suitable for ascend npus without repeatedly running the expensive experiments we leverage simulation to compare the tradeoff of various model hyperparameters this study led to pangu ultra moe a sparse llm with 718 billion parameters and we conducted experiments on the model to verify the simulation results on the system side we dig into expert parallelism to optimize the communication between npu devices to reduce the synchronization overhead we also optimize the memory efficiency within the devices to further reduce the parameter and activation management overhead in the end we achieve an mfu of 300 when training pangu ultra moe with performance comparable to that of deepseek r1 on 6k ascend npus and demonstrate that the ascend system is capable of harnessing all the training stages of the stateoftheart language models extensive experiments indicate that our recipe can lead to efficient training of largescale sparse language models with moe we also study the behaviors of such models for future reference
http://arxiv.org/abs/2505.04507v1,2025-05-07T15:27:59Z,Ilya Koziev,detecting spelling and grammatical anomalies in russian poetry texts,the quality of natural language texts in finetuning datasets plays a critical role in the performance of generative models particularly in computational creativity tasks such as poem or song lyric generation fluency defects in generated poems significantly reduce their value however training texts are often sourced from internetbased platforms without stringent quality control posing a challenge for data engineers to manage defect levels effectively to address this issue we propose the use of automated linguistic anomaly detection to identify and filter out lowquality texts from training datasets for creative models in this paper we present a comprehensive comparison of unsupervised and supervised text anomaly detection approaches utilizing both synthetic and humanlabeled datasets we also introduce the rupor dataset a collection of russianlanguage humanlabeled poems designed for crosssentence grammatical error detection and provide the full evaluation code our work aims to empower the community with tools and insights to improve the quality of training datasets for generative models in creative domains
http://arxiv.org/abs/2505.04457v2,2025-05-07T14:27:46Z,"Shigeki Karita, Yuma Koizumi, Heiga Zen, Haruko Ishikawa, Robin Scheibler, Michiel Bacchiani",miipher2 a universal speech restoration model for millionhour scale data restoration,training data cleaning is a new application for generative modelbased speech restoration sr this paper introduces miipher2 an sr model designed for millionhour scale data for training data cleaning for largescale generative models like large language models key challenges addressed include generalization to unseen languages operation without explicit conditioning eg text speaker id and computational efficiency miipher2 utilizes a frozen pretrained universal speech model usm supporting over 300 languages as a robust conditioningfree feature extractor to optimize efficiency and minimize memory miipher2 incorporates parallel adapters for predicting clean usm features from noisy inputs and employs the wavefit neural vocoder for waveform synthesis these components were trained on 3000 hours of multilingual studioquality recordings with augmented degradations while usm parameters remained fixed experimental results demonstrate miipher2s superior or comparable performance to conventional sr models in worderrorrate speaker similarity and both objective and subjective sound quality scores across all tested languages miipher2 operates efficiently on consumergrade accelerators achieving a realtime factor of 00078 enabling the processing of a millionhour speech dataset in approximately three days using only 100 such accelerators
http://arxiv.org/abs/2505.04416v1,2025-05-07T13:51:42Z,"Xiaoyu Xu, Minxin Du, Qingqing Ye, Haibo Hu",obliviate robust and practical machine unlearning for large language models,large language models llms trained over extensive corpora risk memorizing sensitive copyrighted or toxic content to address this we propose obliviate a robust unlearning framework that removes targeted data while preserving model utility the framework follows a structured process extracting target tokens building retain sets and finetuning with a tailored loss function comprising three components masking distillation and world fact using lowrank adapters lora it ensures efficiency without compromising unlearning quality we conduct experiments on multiple datasets including the harry potter series wmdp and tofu using a comprehensive suite of metrics forget quality new documentlevel memorization score model utility and fluency results demonstrate its effectiveness in resisting membership inference attacks minimizing the impact on retained data and maintaining robustness across diverse scenarios
http://arxiv.org/abs/2505.04406v1,2025-05-07T13:42:23Z,"Aidar Valeev, Roman Garaev, Vadim Lomshakov, Irina Piontkovskaya, Vladimir Ivanov, Israel Adewuyi",yabloco yet another benchmark for long context code generation,large language models demonstrate the ability to solve various programming tasks including code generation typically the performance of llms is measured on benchmarks with small or mediumsized context windows of thousands of lines of code at the same time in realworld software projects repositories can span up to millions of loc this paper closes this gap by contributing to the long context code generation benchmark yabloco the benchmark featured a test set of 215 functions selected from four large repositories with thousands of functions the dataset contained metadata of functions contexts of the functions with different levels of dependencies docstrings functions bodies and call graphs for each repository this paper presents three key aspects of the contribution first the benchmark aims at function body generation in large repositories in c and c two languages not covered by previous benchmarks second the benchmark contains large repositories from 200k to 2000k loc third we contribute a scalable evaluation pipeline for efficient computing of the target metrics and a tool for visual analysis of generated code overall these three aspects allow for evaluating code generation in large repositories in c and c
http://arxiv.org/abs/2505.04393v1,2025-05-07T13:18:41Z,"David Exler, Mark Schutera, Markus Reischl, Luca Rettenberger",large means left political bias in large language models increases with their number of parameters,with the increasing prevalence of artificial intelligence careful evaluation of inherent biases needs to be conducted to form the basis for alleviating the effects these predispositions can have on users large language models llms are predominantly used by many as a primary source of information for various topics llms frequently make factual errors fabricate data hallucinations or present biases exposing users to misinformation and influencing opinions educating users on their risks is key to responsible use as bias unlike hallucinations cannot be caught through data verification we quantify the political bias of popular llms in the context of the recent vote of the german bundestag using the score produced by the wahlomat this metric measures the alignment between an individuals political views and the positions of german political parties we compare the models alignment scores to identify factors influencing their political preferences doing so we discover a bias toward leftleaning parties most dominant in larger llms also we find that the language we use to communicate with the models affects their political views additionally we analyze the influence of a models origin and release date and compare the results to the outcome of the recent vote of the bundestag our results imply that llms are prone to exhibiting political bias large corporations with the necessary means to develop llms thus knowingly or unknowingly have a responsibility to contain these biases as they can influence each voters decisionmaking process and inform public opinion in general and at scale
http://arxiv.org/abs/2505.04388v1,2025-05-07T13:13:14Z,"Dario Garcia-Gasulla, Jordi Bayarri-Planas, Ashwin Kumar Gururajan, Enrique Lopez-Cuena, Adrian Tormos, Daniel Hinjos, Pablo Bernabeu-Perez, Anna Arias-Duart, Pablo Agustin Martin-Torres, Marta Gonzalez-Mallo, Sergio Alvarez-Napagao, Eduard Ayguadé-Parra, Ulises Cortés",the aloe family recipe for open and specialized healthcare llms,purpose with advancements in large language models llms for healthcare the need arises for competitive opensource models to protect the public interest this work contributes to the field of open medical llms by optimizing key stages of data preprocessing and training while showing how to improve model safety through dpo and efficacy through rag the evaluation methodology used which includes four different types of tests defines a new standard for the field the resultant models shown to be competitive with the best private alternatives are released with a permisive license methods building on top of strong base models like llama 31 and qwen 25 aloe beta uses a custom dataset to enhance public data with synthetic chain of thought examples the models undergo alignment with direct preference optimization emphasizing ethical and policyaligned performance in the presence of jailbreaking attacks evaluation includes closeended openended safety and human assessments to maximize the reliability of results results recommendations are made across the entire pipeline backed by the solid performance of the aloe family these models deliver competitive performance across healthcare benchmarks and medical fields and are often preferred by healthcare professionals on bias and toxicity the aloe beta models significantly improve safety showing resilience to unseen jailbreaking attacks for a responsible release a detailed risk assessment specific to healthcare is attached to the aloe family models conclusion the aloe beta models and the recipe that leads to them are a significant contribution to the opensource medical llm field offering topoftheline performance while maintaining high ethical requirements this work sets a new standard for developing and reporting aligned llms in healthcare
http://arxiv.org/abs/2505.04364v2,2025-05-07T12:32:01Z,"Kai Ruan, Mowen Huang, Ji-Rong Wen, Hao Sun",benchmarking llms swarm intelligence,large language models llms show potential for complex reasoning yet their capacity for emergent coordination in multiagent systems mas when operating under strict swarmlike constraintslimited local perception and communicationremains largely unexplored existing benchmarks often do not fully capture the unique challenges of decentralized coordination when agents operate with incomplete spatiotemporal information to bridge this gap we introduce swarmbench a novel benchmark designed to systematically evaluate the swarm intelligence capabilities of llms acting as decentralized agents swarmbench features five foundational mas coordination tasks pursuit synchronization foraging flocking transport within a configurable 2d grid environment forcing agents to rely solely on local sensory input view and local communication we propose metrics for coordination effectiveness and analyze emergent group dynamics zeroshot evaluations of leading llms eg deepseekv3 o4mini reveal significant taskdependent performance variations while some rudimentary coordination is observed our results indicate that current llms significantly struggle with robust longrange planning and adaptive strategy formation under the uncertainty inherent in these decentralized scenarios assessing llms under such swarmlike constraints is crucial for understanding their utility in future decentralized intelligent systems we release swarmbench as an open extensible toolkitbuilt on a customizable physical systemproviding environments prompts evaluation scripts and comprehensive datasets this aims to foster reproducible research into llmbased mas coordination and the theoretical underpinnings of emergent collective behavior under severe informational decentralization our code repository is available at httpsgithubcomx66ccffswarmbench
http://arxiv.org/abs/2505.04678v1,2025-05-07T12:05:23Z,"Shahad Elshehaby, Alavikunhu Panthakkan, Hussain Al-Ahmad, Mina Al-Saad",advanced deep learning approaches for automated recognition of cuneiform symbols,this paper presents a thoroughly automated method for identifying and interpreting cuneiform characters via advanced deeplearning algorithms five distinct deeplearning models were trained on a comprehensive dataset of cuneiform characters and evaluated according to critical performance metrics including accuracy and precision two models demonstrated outstanding performance and were subsequently assessed using cuneiform symbols from the hammurabi law acquisition notably hammurabi law 1 each model effectively recognized the relevant akkadian meanings of the symbols and delivered precise english translations future work will investigate ensemble and stacking approaches to optimize performance utilizing hybrid architectures to improve detection accuracy and reliability this research explores the linguistic relationships between akkadian an ancient mesopotamian language and arabic emphasizing their historical and cultural linkages this study demonstrates the capability of deep learning to decipher ancient scripts by merging computational linguistics with archaeology therefore providing significant insights for the comprehension and conservation of human history
http://arxiv.org/abs/2505.04673v1,2025-05-07T10:09:55Z,"Madhur Jindal, Saurabh Deshpande",reveal multiturn evaluation of imageinput harms for vision llm,vision large language models vllms represent a significant advancement in artificial intelligence by integrating imageprocessing capabilities with textual understanding thereby enhancing user interactions and expanding application domains however their increased complexity introduces novel safety and ethical challenges particularly in multimodal and multiturn conversations traditional safety evaluation frameworks designed for textbased singleturn interactions are inadequate for addressing these complexities to bridge this gap we introduce the reveal responsible evaluation of visionenabled ai llms framework a scalable and automated pipeline for evaluating imageinput harms in vllms reveal includes automated image mining synthetic adversarial data generation multiturn conversational expansion using crescendo attack strategies and comprehensive harm assessment through evaluators like gpt4o we extensively evaluated five stateoftheart vllms gpt4o llama32 qwen2vl phi35v and pixtral across three important harm categories sexual harm violence and misinformation our findings reveal that multiturn interactions result in significantly higher defect rates compared to singleturn evaluations highlighting deeper vulnerabilities in vllms notably gpt4o demonstrated the most balanced performance as measured by our safetyusability index sui followed closely by pixtral additionally misinformation emerged as a critical area requiring enhanced contextual defenses llama32 exhibited the highest mt defect rate while qwen2vl showed the highest mt refusal rate
http://arxiv.org/abs/2505.04284v1,2025-05-07T09:40:18Z,"Sofia Jamil, Aryan Dabad, Bollampalli Areen Reddy, Sriparna Saha, Rajiv Misra, Adil A. Shakur",gascade grouped summarization of adverse drug event for enhanced cancer pharmacovigilance,in the realm of cancer treatment summarizing adverse drug events ades reported by patients using prescribed drugs is crucial for enhancing pharmacovigilance practices and improving drugrelated decisionmaking while the volume and complexity of pharmacovigilance data have increased existing research in this field has predominantly focused on general diseases rather than specifically addressing cancer this work introduces the task of grouped summarization of adverse drug events reported by multiple patients using the same drug for cancer treatment to address the challenge of limited resources in cancer pharmacovigilance we present the multilabeled cancer adverse drug reaction and summarization mcadrs dataset this dataset includes pharmacovigilance posts detailing patient concerns regarding drug efficacy and adverse effects along with extracted labels for drug names adverse drug events severity and adversity of reactions as well as summaries of ades for each drug additionally we propose the grouping and abstractive summarization of cancer adverse drug events gascade framework a novel pipeline that combines the information extraction capabilities of large language models llms with the summarization power of the encoderdecoder t5 model our work is the first to apply alignment techniques including advanced algorithms like direct preference optimization to encoderdecoder models using synthetic datasets for summarization tasks through extensive experiments we demonstrate the superior performance of gascade across various metrics validated through both automated assessments and human evaluations this multitasking approach enhances drugrelated decisionmaking and fosters a deeper understanding of patient concerns paving the way for advancements in personalized and responsive cancer care the code and dataset used in this work are publicly available
http://arxiv.org/abs/2505.04253v1,2025-05-07T08:58:52Z,"Maria Marina, Nikolay Ivanov, Sergey Pletenev, Mikhail Salnikov, Daria Galimzianova, Nikita Krayko, Vasily Konovalov, Alexander Panchenko, Viktor Moskvoretskii",llmindependent adaptive rag let the question speak for itself,large language modelsllms are prone to hallucinations and retrievalaugmented generation rag helps mitigate this but at a high computational cost while risking misinformation adaptive retrieval aims to retrieve only when necessary but existing approaches rely on llmbased uncertainty estimation which remain inefficient and impractical in this study we introduce lightweight llmindependent adaptive retrieval methods based on external information we investigated 27 features organized into 7 groups and their hybrid combinations we evaluated these methods on 6 qa datasets assessing the qa performance and efficiency the results show that our approach matches the performance of complex llmbased methods while achieving significant efficiency gains demonstrating the potential of external information for adaptive retrieval
http://arxiv.org/abs/2505.04671v2,2025-05-07T08:32:22Z,"Yuxin Zhang, Meihao Fan, Ju Fan, Mingyang Yi, Yuyu Luo, Jian Tan, Guoliang Li",rewardsql boosting texttosql via stepwise reasoning and processsupervised rewards,recent advances in large language models llms have significantly improved performance on the texttosql task by leveraging their powerful reasoning capabilities to enhance accuracy during the reasoning process external process reward models prms can be introduced during training and inference to provide finegrained supervision however if misused prms may distort the reasoning trajectory and lead to suboptimal or incorrect sql generation to address this challenge we propose rewardsql a framework that systematically explores how to incorporate prms into the texttosql reasoning process effectively our approach follows a cold start then prm supervision paradigm specifically we first train the model to decompose sql queries into structured stepwise reasoning chains using common table expressions chainofctes establishing a strong and interpretable reasoning baseline then we investigate four strategies for integrating prms and find that combining prm as an online training signal eggrpo with prmguided inference eg bestofn sampling yields the best results empirically on the bird benchmark rewardsql enables models supervised by prm 7b to achieve a 131 performance gain across various guidance strategies notably our grpoaligned policy model based on qwen25coder7binstruct achieves 689 accuracy on the bird development set outperforming all baseline methods under the same model size these results demonstrate the effectiveness of rewardsql in leveraging rewardbased supervision for texttosql reasoning
http://arxiv.org/abs/2505.04192v1,2025-05-07T07:41:19Z,"Trinh T. L. Vuong, Jin Tae Kwak",videopathllava pathology diagnostic reasoning through video instruction tuning,we present videopathllava the first large multimodal model lmm in computational pathology that integrates three distinct image scenarios single patch images automatically keyframeextracted clips and manually segmented video pathology images to mimic the natural diagnostic process of pathologists by generating detailed histological descriptions and culminating in a definitive signout diagnosis videopathllava bridges visual narratives with diagnostic reasoning central to our approach is the videopathinstruct dataset comprising 4278 video and diagnosisspecific chainofthought instructional pairs sourced from educational histopathology videos on youtube although highquality data is critical for enhancing diagnostic reasoning its creation is timeintensive and limited in volume to overcome this challenge we transfer knowledge from existing singleimage instruction datasets to train on weakly annotated keyframeextracted clips followed by finetuning on manually segmented videos videopathllava establishes a new benchmark in pathology video analysis and offers a promising foundation for future ai systems that support clinical decisionmaking through integrated visual and diagnostic reasoning our code data and model are publicly available at httpsgithubcomtrinhvgvideopathllava
http://arxiv.org/abs/2505.04171v1,2025-05-07T06:53:59Z,"Nouar Aldahoul, Hazem Ibrahim, Matteo Varvello, Aaron Kaufman, Talal Rahwan, Yasir Zaki",large language models are often politically extreme usually ideologically inconsistent and persuasive even in informational contexts,large language models llms are a transformational technology fundamentally changing how people obtain information and interact with the world as people become increasingly reliant on them for an enormous variety of tasks a body of academic research has developed to examine these models for inherent biases especially political biases often finding them small we challenge this prevailing wisdom first by comparing 31 llms to legislators judges and a nationally representative sample of us voters we show that llms apparently small overall partisan preference is the net result of offsetting extreme views on specific topics much like moderate voters second in a randomized experiment we show that llms can promulgate their preferences into political persuasiveness even in informationseeking contexts voters randomized to discuss political issues with an llm chatbot are as much as 5 percentage points more likely to express the same preferences as that chatbot contrary to expectations these persuasive effects are not moderated by familiarity with llms news consumption or interest in politics llms especially those controlled by private companies or governments may become a powerful and targeted vector for political influence
http://arxiv.org/abs/2505.04152v1,2025-05-07T06:03:37Z,"Manas Satish Bedmutha, Feng Chen, Andrea Hartzler, Trevor Cohen, Nadir Weibel",can language models understand social behavior in clinical conversations,effective communication between providers and their patients influences health and care outcomes the effectiveness of such conversations has been linked not only to the exchange of clinical information but also to a range of interpersonal behaviors commonly referred to as social signals which are often conveyed through nonverbal cues and shape the quality of the patientprovider relationship recent advances in large language models llms have demonstrated an increasing ability to infer emotional and social behaviors even when analyzing only textual information as automation increases also in clinical settings such as for transcription of patientprovider conversations there is growing potential for llms to automatically analyze and extract social behaviors from these interactions to explore the foundational capabilities of llms in tracking social signals in clinical dialogue we designed taskspecific prompts and evaluated model performance across multiple architectures and prompting styles using a highly imbalanced annotated dataset spanning 20 distinct social signals such as provider dominance patient warmth etc we present the first system capable of tracking all these 20 coded signals and uncover patterns in llm behavior further analysis of model configurations and clinical context provides insights for enhancing llm performance on social signal processing tasks in healthcare settings
http://arxiv.org/abs/2505.04146v1,2025-05-07T05:54:04Z,"Variath Madhupal Gautham Nair, Vishal Varma Dantuluri",unmasking the canvas a dynamic benchmark for image generation jailbreaking and llm content safety,existing large language models llms are advancing rapidly and produce outstanding results in image generation tasks yet their content safety checks remain vulnerable to promptbased jailbreaks through preliminary testing on platforms such as chatgpt metaai and grok we observed that even short natural prompts could lead to the generation of compromising images ranging from realistic depictions of forged documents to manipulated images of public figures we introduce unmasking the canvas utc benchmark utcb a dynamic and scalable benchmark dataset to evaluate llm vulnerability in image generation our methodology combines structured prompt engineering multilingual obfuscation eg zulu gaelic base64 and evaluation using groqhosted llama3 the pipeline supports both zeroshot and fallback prompting strategies risk scoring and automated tagging all generations are stored with rich metadata and curated into bronze nonverified silver llmaided verification and gold manually verified tiers utcb is designed to evolve over time with new data sources prompt templates and model behaviors warning this paper includes visual examples of adversarial inputs designed to test model safety all outputs have been redacted to ensure responsible disclosure
http://arxiv.org/abs/2505.04135v1,2025-05-07T05:13:15Z,"Vihaan Miriyala, Smrithi Bukkapatnam, Lavanya Prahallad",enhancing granular sentiment classification with chainofthought prompting in large language models,we explore the use of chainofthought cot prompting with large language models llms to improve the accuracy of granular sentiment categorization in app store reviews traditional numeric and polaritybased ratings often fail to capture the nuanced sentiment embedded in user feedback we evaluated the effectiveness of cot prompting versus simple prompting on 2000 amazon app reviews by comparing each methods predictions to human judgements cot prompting improved classification accuracy from 84 to 93 highlighting the benefit of explicit reasoning in enhancing sentiment analysis performance
http://arxiv.org/abs/2505.04132v1,2025-05-07T05:07:38Z,"Mingruo Yuan, Ben Kao, Tien-Hsuan Wu, Michael M. K. Cheung, Henry W. H. Chan, Anne S. Y. Cheung, Felix W. H. Chan, Yongxi Chen",bringing legal knowledge to the public by constructing a legal question bank using largescale pretrained language model,access to legal information is fundamental to access to justice yet accessibility refers not only to making legal documents available to the public but also rendering legal information comprehensible to them a vexing problem in bringing legal information to the public is how to turn formal legal documents such as legislation and judgments which are often highly technical to easily navigable and comprehensible knowledge to those without legal education in this study we formulate a threestep approach for bringing legal knowledge to laypersons tackling the issues of navigability and comprehensibility first we translate selected sections of the law into snippets called clicpages each being a small piece of article that focuses on explaining certain technical legal concept in laypersons terms second we construct a legal question bank lqb which is a collection of legal questions whose answers can be found in the clicpages third we design an interactive clic recommender crec given a users verbal description of a legal situation that requires a legal solution crec interprets the users input and shortlists questions from the question bank that are most likely relevant to the given legal situation and recommends their corresponding clic pages where relevant legal knowledge can be found in this paper we focus on the technical aspects of creating an lqb we show how largescale pretrained language models such as gpt3 can be used to generate legal questions we compare machinegenerated questions mgqs against humancomposed questions hcqs and find that mgqs are more scalable costeffective and more diversified while hcqs are more precise we also show a prototype of crec and illustrate through an example how our 3step approach effectively brings relevant legal knowledge to the public
http://arxiv.org/abs/2505.04666v1,2025-05-07T05:04:30Z,"Mohammad Aqib, Mohd Hamza, Qipei Mei, Ying Hei Chui",finetuning large language models and evaluating retrieval methods for improved question answering on building codes,building codes are regulations that establish standards for the design construction and safety of buildings to ensure structural integrity fire protection and accessibility they are often extensive complex and subject to frequent updates making manual querying challenging and timeconsuming key difficulties include navigating large volumes of text interpreting technical language and identifying relevant clauses across different sections a potential solution is to build a questionanswering qa system that answers user queries based on building codes among the various methods for building a qa system retrievalaugmented generation rag stands out in performance rag consists of two components a retriever and a language model this study focuses on identifying a suitable retriever method for building codes and optimizing the generational capability of the language model using finetuning techniques we conducted a detailed evaluation of various retrieval methods by performing the retrieval on the national building code of canada nbcc and explored the impact of domainspecific finetuning on several language models using the dataset derived from nbcc our analysis included a comparative assessment of different retrievers and the performance of both pretrained and finetuned models to determine the efficacy and domainspecific adaptation of language models using finetuning on the nbcc dataset experimental results showed that elasticsearch proved to be the most robust retriever among all the findings also indicate that finetuning language models on an nbccspecific dataset can enhance their ability to generate contextually relevant responses when combined with context retrieved by a powerful retriever like elasticsearch this improvement in llm performance can optimize the rag system enabling it to better navigate the complexities of the nbcc
http://arxiv.org/abs/2505.04665v1,2025-05-07T04:25:41Z,"Haoyang Feng, Yanjun Dai, Yuan Gao",personalized risks and regulatory strategies of large language models in digital advertising,although large language models have demonstrated the potential for personalized advertising recommendations in experimental environments in actual operations how advertising recommendation systems can be combined with measures such as user privacy protection and data security is still an area worthy of indepth discussion to this end this paper studies the personalized risks and regulatory strategies of large language models in digital advertising this study first outlines the principles of large language model llm especially the selfattention mechanism based on the transformer architecture and how to enable the model to understand and generate natural language text then the bert bidirectional encoder representations from transformers model and the attention mechanism are combined to construct an algorithmic model for personalized advertising recommendations and user factor risk protection the specific steps include data collection and preprocessing feature selection and construction using large language models such as bert for advertising semantic embedding and ad recommendations based on user portraits then local model training and data encryption are used to ensure the security of user privacy and avoid the leakage of personal data this paper designs an experiment for personalized advertising recommendation based on a large language model of bert and verifies it with real user data the experimental results show that bertbased advertising push can effectively improve the clickthrough rate and conversion rate of advertisements at the same time through local model training and privacy protection mechanisms the risk of user privacy leakage can be reduced to a certain extent
http://arxiv.org/abs/2505.04110v1,2025-05-07T03:56:26Z,"David Noever, Forrest McKee",alpha excel benchmark,this study presents a novel benchmark for evaluating large language models llms using challenges derived from the financial modeling world cup fmwc excel competitions we introduce a methodology for converting 113 existing fmwc challenges into programmatically evaluable json formats and use this dataset to compare the performance of several leading llms our findings demonstrate significant variations in performance across different challenge categories with models showing specific strengths in pattern recognition tasks but struggling with complex numerical reasoning the benchmark provides a standardized framework for assessing llm capabilities in realistic businessoriented tasks rather than abstract academic problems this research contributes to the growing field of ai benchmarking by establishing proficiency among the 15 billion people who daily use microsoft excel as a meaningful evaluation metric that bridges the gap between academic ai benchmarks and practical business applications
http://arxiv.org/abs/2505.04660v1,2025-05-07T02:30:33Z,"Sana Alamgeer, Yasine Souissi, Anne H. H. Ngu",aigenerated fall data assessing llms and diffusion model for wearable fall detection,training fall detection systems is challenging due to the scarcity of realworld fall data particularly from elderly individuals to address this we explore the potential of large language models llms for generating synthetic fall data this study evaluates texttomotion t2m sato parco and texttotext models gpt4o gpt4 gemini in simulating realistic fall scenarios we generate synthetic datasets and integrate them with four realworld baseline datasets to assess their impact on fall detection performance using a long shortterm memory lstm model additionally we compare llmgenerated synthetic data with a diffusionbased method to evaluate their alignment with real accelerometer distributions results indicate that dataset characteristics significantly influence the effectiveness of synthetic data with llmgenerated data performing best in lowfrequency settings eg 20hz while showing instability in highfrequency datasets eg 200hz while texttomotion models produce more realistic biomechanical data than texttotext models their impact on fall detection varies diffusionbased synthetic data demonstrates the closest alignment to real data but does not consistently enhance model performance an ablation study further confirms that the effectiveness of synthetic data depends on sensor placement and fall representation these findings provide insights into optimizing synthetic data generation for fall detection models
http://arxiv.org/abs/2505.04073v1,2025-05-07T02:25:29Z,"Mengxian Lyu, Xiaohan Li, Ziyi Chen, Jinqian Pan, Cheng Peng, Sankalp Talankar, Yonghui Wu",natural language generation in healthcare a review of methods and applications,natural language generation nlg is the key technology to achieve generative artificial intelligence ai with the breakthroughs in large language models llms nlg has been widely used in various medical applications demonstrating the potential to enhance clinical workflows support clinical decisionmaking and improve clinical documentation heterogeneous and diverse medical data modalities such as medical text images and knowledge bases are utilized in nlg researchers have proposed many generative models and applied them in a number of healthcare applications there is a need for a comprehensive review of nlg methods and applications in the medical domain in this study we systematically reviewed 113 scientific publications from a total of 3988 nlgrelated articles identified using a literature search focusing on data modality model architecture clinical applications and evaluation methods following prisma preferred reporting items for systematic reviews and metaanalyses guidelines we categorize key methods identify clinical applications and assess their capabilities limitations and emerging challenges this timely review covers the key nlg technologies and medical applications and provides valuable insights for future studies to leverage nlg to transform medical discovery and healthcare
http://arxiv.org/abs/2505.04072v1,2025-05-07T02:25:20Z,"Xu Huang, Yuefeng Huang, Weiwen Liu, Xingshan Zeng, Yasheng Wang, Ruiming Tang, Hong Xie, Defu Lian",advancing and benchmarking personalized tool invocation for llms,tool invocation is a crucial mechanism for extending the capabilities of large language models llms and has recently garnered significant attention it enables llms to solve complex problems through tool calls while accessing uptodate world knowledge however existing work primarily focuses on the fundamental ability of llms to invoke tools for problemsolving without considering personalized constraints in tool invocation in this work we introduce the concept of personalized tool invocation and define two key tasks tool preference and profiledependent query tool preference addresses user preferences when selecting among functionally similar tools while profiledependent query considers cases where a user query lacks certain tool parameters requiring the model to infer them from the user profile to tackle these challenges we propose ptool a data synthesis framework designed for personalized tool invocation additionally we construct textbfptbench the first benchmark for evaluating personalized tool invocation we then finetune various opensource models demonstrating the effectiveness of our framework and providing valuable insights our benchmark is public at httpsgithubcomhyfshadowptbench
http://arxiv.org/abs/2505.04066v1,2025-05-07T02:08:56Z,"Tuochao Chen, Nicholas Batchelder, Alisa Liu, Noah Smith, Shyamnath Gollakota",llamapie proactive inear conversation assistants,we introduce llamapie the first realtime proactive assistant designed to enhance human conversations through discreet concise guidance delivered via hearable devices unlike traditional language models that require explicit user invocation this assistant operates in the background anticipating user needs without interrupting conversations we address several challenges including determining when to respond crafting concise responses that enhance conversations leveraging knowledge of the user for contextaware assistance and realtime ondevice processing to achieve this we construct a semisynthetic dialogue dataset and propose a twomodel pipeline a small model that decides when to respond and a larger model that generates the response we evaluate our approach on realworld datasets demonstrating its effectiveness in providing helpful unobtrusive assistance user studies with our assistant implemented on apple silicon m2 hardware show a strong preference for the proactive assistant over both a baseline with no assistance and a reactive model highlighting the potential of llamapie to enhance live conversations
http://arxiv.org/abs/2505.04016v1,2025-05-06T23:29:43Z,"Darren Yow-Bang Wang, Zhengyuan Shen, Soumya Smruti Mishra, Zhichao Xu, Yifei Teng, Haibo Ding",slot structuring the output of large language models,structured outputs are essential for large language models llms in critical applications like agents and information extraction despite their capabilities llms often generate outputs that deviate from predefined schemas significantly hampering reliable application development we present slot structured llm output transformer a modelagnostic approach that transforms unstructured llm outputs into precise structured formats while existing solutions predominantly rely on constrained decoding techniques or are tightly coupled with specific models slot employs a finetuned lightweight language model as a postprocessing layer achieving flexibility across various llms and schema specifications we introduce a systematic pipeline for data curation and synthesis alongside a formal evaluation methodology that quantifies both schema accuracy and content fidelity our results demonstrate that finetuned mistral7b model with constrained decoding achieves near perfect schema accuracy 995 and content similarity 940 outperforming claude35sonnet by substantial margins 25 and 20 percentage points respectively notably even compact models like llama321b can match or exceed the structured output capabilities of much larger proprietary models when equipped with slot enabling reliable structured generation in resourceconstrained environments
http://arxiv.org/abs/2505.04655v1,2025-05-06T23:11:59Z,"Paul Landes, Jimeng Sun, Adam Cross",integration of large language models and traditional deep learning for social determinants of health prediction,social determinants of health sdoh are economic social and personal circumstances that affect or influence an individuals health status sdohs have shown to be correlated to wellness outcomes and therefore are useful to physicians in diagnosing diseases and in decisionmaking in this work we automatically extract sdohs from clinical text using traditional deep learning and large language models llms to find the advantages and disadvantages of each on an existing publicly available dataset our models outperform a previous reference point on a multilabel sdoh classification by 10 points and we present a method and model to drastically speed up classification 12x execution time by eliminating expensive llm processing the method we present combines a more nimble and efficient solution that leverages the power of the llm for precision and traditional deep learning methods for efficiency we also show highly performant results on a dataset supplemented with synthetic data and several traditional deep learning models that outperform llms our models and methods offer the next iteration of automatic prediction of sdohs that impact atrisk patients
http://arxiv.org/abs/2505.03997v1,2025-05-06T22:18:50Z,"Prudhviraj Naidu, Zixian Wang, Leon Bergen, Ramamohan Paturi",quiet feature learning in algorithmic tasks,we train transformerbased language models on ten foundational algorithmic tasks and observe pronounced phase transitions in their loss curves that deviate from established powerlaw scaling trends over large ranges of compute the validation loss barely improves then abruptly decreases probing the models internal representations reveals the learning of quiet features during the stagnant phase followed by sudden acquisition of loud features that coincide with the sharp drop in loss our ablation experiments show that disrupting a single learned feature can dramatically degrade performance providing evidence of their causal role in task performance these findings challenge the prevailing assumption that nexttoken predictive loss reliably tracks incremental progress instead key internal features may be developing below the surface until they coalesce triggering a rapid performance gain
http://arxiv.org/abs/2505.03981v1,2025-05-06T21:08:27Z,"Qianchu Liu, Sheng Zhang, Guanghui Qin, Timothy Ossowski, Yu Gu, Ying Jin, Sid Kiblawi, Sam Preston, Mu Wei, Paul Vozila, Tristan Naumann, Hoifung Poon",xreasoner towards generalizable reasoning across modalities and domains,recent proprietary models eg o3 have begun to demonstrate strong multimodal reasoning capabilities yet most existing opensource research concentrates on training textonly reasoning models with evaluations limited to mainly mathematical and generaldomain tasks therefore it remains unclear how to effectively extend reasoning capabilities beyond text input and general domains this paper explores a fundamental research question is reasoning generalizable across modalities and domains our findings support an affirmative answer generaldomain textbased posttraining can enable such strong generalizable reasoning leveraging this finding we introduce xreasoner a visionlanguage model posttrained solely on generaldomain text for generalizable reasoning using a twostage approach an initial supervised finetuning phase with distilled long chainofthoughts followed by reinforcement learning with verifiable rewards experiments show that xreasoner successfully transfers reasoning capabilities to both multimodal and outofdomain settings outperforming existing stateoftheart models trained with indomain and multimodal data across various general and medical benchmarks figure 1 additionally we find that xreasoners performance in specialized domains can be further enhanced through continued training on domainspecific textonly data building upon this we introduce xreasonermed a medicalspecialized variant that achieves new state of the art on numerous textonly and multimodal medical benchmarks
http://arxiv.org/abs/2505.04654v1,2025-05-06T20:58:04Z,"Yehor Tereshchenko, Mika Hämäläinen",a comparative analysis of ethical and safety gaps in llms using relative danger coefficient,artificial intelligence ai and large language models llms have rapidly evolved in recent years showcasing remarkable capabilities in natural language understanding and generation however these advancements also raise critical ethical questions regarding safety potential misuse discrimination and overall societal impact this article provides a comparative analysis of the ethical performance of various ai models including the brand new deepseekv3r1 with reasoning and without various gpt variants 4o 35 turbo 4 turbo o1o3 mini and gemini 15 flash 20 flash and 20 flash exp and highlights the need for robust human oversight especially in situations with high stakes furthermore we present a new metric for calculating harm in llms called relative danger coefficient rdc
http://arxiv.org/abs/2505.04653v1,2025-05-06T20:52:01Z,"Khaled Saab, Jan Freyberg, Chunjong Park, Tim Strother, Yong Cheng, Wei-Hung Weng, David G. T. Barrett, David Stutz, Nenad Tomasev, Anil Palepu, Valentin Liévin, Yash Sharma, Roma Ruparel, Abdullah Ahmed, Elahe Vedadi, Kimberly Kanada, Cian Hughes, Yun Liu, Geoff Brown, Yang Gao, Sean Li, S. Sara Mahdavi, James Manyika, Katherine Chou, Yossi Matias, Avinatan Hassidim, Dale R. Webster, Pushmeet Kohli, S. M. Ali Eslami, Joëlle Barral, Adam Rodman, Vivek Natarajan, Mike Schaekermann, Tao Tu, Alan Karthikesalingam, Ryutaro Tanno",advancing conversational diagnostic ai with multimodal reasoning,large language models llms have demonstrated great potential for conducting diagnostic conversations but evaluation has been largely limited to languageonly interactions deviating from the realworld requirements of remote care delivery instant messaging platforms permit clinicians and patients to upload and discuss multimodal medical artifacts seamlessly in medical consultation but the ability of llms to reason over such data while preserving other attributes of competent diagnostic conversation remains unknown here we advance the conversational diagnosis and management performance of the articulate medical intelligence explorer amie through a new capability to gather and interpret multimodal data and reason about this precisely during consultations leveraging gemini 20 flash our system implements a stateaware dialogue framework where conversation flow is dynamically controlled by intermediate model outputs reflecting patient states and evolving diagnoses followup questions are strategically directed by uncertainty in such patient states leading to a more structured multimodal historytaking process that emulates experienced clinicians we compared amie to primary care physicians pcps in a randomized blinded oscestyle study of chatbased consultations with patient actors we constructed 105 evaluation scenarios using artifacts like smartphone skin photos ecgs and pdfs of clinical documents across diverse conditions and demographics our rubric assessed multimodal capabilities and other clinically meaningful axes like historytaking diagnostic accuracy management reasoning communication and empathy specialist evaluation showed amie to be superior to pcps on 79 multimodal and 2932 nonmultimodal axes including diagnostic accuracy the results show clear progress in multimodal conversational diagnostic ai but realworld translation needs further research
http://arxiv.org/abs/2505.03973v1,2025-05-06T20:50:27Z,"Jiale Liu, Yifan Zeng, Shaokun Zhang, Chi Zhang, Malte Højmark-Bertelsen, Marie Normann Gadeberg, Huazheng Wang, Qingyun Wu",divide optimize merge finegrained llm agent optimization at scale,llmbased optimization has shown remarkable potential in enhancing agentic systems however the conventional approach of prompting llm optimizer with the whole training trajectories on training dataset in a single pass becomes untenable as datasets grow leading to context window overflow and degraded pattern recognition to address these challenges we propose finegrained optimization fgo a scalable framework that divides large optimization tasks into manageable subsets performs targeted optimizations and systematically combines optimized components through progressive merging evaluation across alfworld logisticsqa and gaia benchmarks demonstrate that fgo outperforms existing approaches by 1686 while reducing average prompt token consumption by 563 our framework provides a practical solution for scaling up llmbased optimization of increasingly sophisticated agent systems further analysis demonstrates that fgo achieves the most consistent performance gain in all training dataset sizes showcasing its scalability and efficiency
http://arxiv.org/abs/2505.03970v1,2025-05-06T20:44:03Z,"Lucia Zheng, Neel Guha, Javokhir Arifov, Sarah Zhang, Michal Skreta, Christopher D. Manning, Peter Henderson, Daniel E. Ho",a reasoningfocused legal retrieval benchmark,as the legal community increasingly examines the use of large language models llms for various legal applications legal ai developers have turned to retrievalaugmented llms rag systems to improve system performance and robustness an obstacle to the development of specialized rag systems is the lack of realistic legal rag benchmarks which capture the complexity of both legal retrieval and downstream legal questionanswering to address this we introduce two novel legal rag benchmarks bar exam qa and housing statute qa our tasks correspond to realworld legal research tasks and were produced through annotation processes which resemble legal research we describe the construction of these benchmarks and the performance of existing retriever pipelines our results suggest that legal rag remains a challenging application thus motivating future research
http://arxiv.org/abs/2505.03961v2,2025-05-06T20:23:25Z,"Gerrit Großmann, Larisa Ivanova, Sai Leela Poduru, Mohaddeseh Tabrizian, Islam Mesabah, David A. Selby, Sebastian J. Vollmer",the power of stories narrative priming shapes how llm agents collaborate and compete,according to yuval noah harari largescale human cooperation is driven by shared narratives that encode common beliefs and values this study explores whether such narratives can similarly nudge llm agents toward collaboration we use a finitely repeated public goods game in which llm agents choose either cooperative or egoistic spending strategies we prime agents with stories highlighting teamwork to different degrees and test how this influences negotiation outcomes our experiments explore four questions1 how do narratives influence negotiation behavior 2 what differs when agents share the same story versus different ones 3 what happens when the agent numbers grow 4 are agents resilient against selfserving negotiators we find that storybased priming significantly affects negotiation strategies and success rates common stories improve collaboration benefiting each agent by contrast priming agents with different stories reverses this effect and those agents primed toward selfinterest prevail we hypothesize that these results carry implications for multiagent system design and ai alignment
http://arxiv.org/abs/2505.04651v1,2025-05-06T19:22:23Z,"Adithya Kulkarni, Fatimah Alotaibi, Xinyue Zeng, Longfeng Wu, Tong Zeng, Barry Menglong Yao, Minqian Liu, Shuaicheng Zhang, Lifu Huang, Dawei Zhou",scientific hypothesis generation and validation methods datasets and future directions,large language models llms are transforming scientific hypothesis generation and validation by enabling information synthesis latent relationship discovery and reasoning augmentation this survey provides a structured overview of llmdriven approaches including symbolic frameworks generative models hybrid systems and multiagent architectures we examine techniques such as retrievalaugmented generation knowledgegraph completion simulation causal inference and toolassisted reasoning highlighting tradeoffs in interpretability novelty and domain alignment we contrast early symbolic discovery systems eg bacon kekada with modern llm pipelines that leverage incontext learning and domain adaptation via finetuning retrieval and symbolic grounding for validation we review simulation humanai collaboration causal modeling and uncertainty quantification emphasizing iterative assessment in openworld contexts the survey maps datasets across biomedicine materials science environmental science and social science introducing new resources like ahtech and cskg600 finally we outline a roadmap emphasizing noveltyaware generation multimodalsymbolic integration humanintheloop systems and ethical safeguards positioning llms as agents for principled scalable scientific discovery
http://arxiv.org/abs/2505.04649v1,2025-05-06T18:50:02Z,"Chengzhang Yu, Yiming Zhang, Zhixin Liu, Zenghui Ding, Yining Sun, Zhanpeng Jin",frame feedbackrefined agent methodology for enhancing medical research insights,the automation of scientific research through large language models llms presents significant opportunities but faces critical challenges in knowledge synthesis and quality assurance we introduce feedbackrefined agent methodology frame a novel framework that enhances medical paper generation through iterative refinement and structured feedback our approach comprises three key innovations 1 a structured dataset construction method that decomposes 4287 medical papers into essential research components through iterative refinement 2 a tripartite architecture integrating generator evaluator and reflector agents that progressively improve content quality through metricdriven feedback and 3 a comprehensive evaluation framework that combines statistical metrics with humangrounded benchmarks experimental results demonstrate frames effectiveness achieving significant improvements over conventional approaches across multiple models 991 average gain with deepseek v3 comparable improvements with gpt4o mini and evaluation dimensions human evaluation confirms that framegenerated papers achieve quality comparable to humanauthored works with particular strength in synthesizing future research directions the results demonstrated our work could efficiently assist medical research by building a robust foundation for automated medical research paper generation while maintaining rigorous academic standards
http://arxiv.org/abs/2505.03910v1,2025-05-06T18:34:37Z,"Gianluca Manzo, Julia Ive",hesitation is defeat connecting linguistic and predictive uncertainty,automating chest radiograph interpretation using deep learning dl models has the potential to significantly improve clinical workflows decisionmaking and largescale health screening however in medical settings merely optimising predictive performance is insufficient as the quantification of uncertainty is equally crucial this paper investigates the relationship between predictive uncertainty derived from bayesian deep learning approximations and humanlinguistic uncertainty as estimated from freetext radiology reports labelled by rulebased labellers utilising bert as the model of choice this study evaluates different binarisation methods for uncertainty labels and explores the efficacy of monte carlo dropout and deep ensembles in estimating predictive uncertainty the results demonstrate good model performance but also a modest correlation between predictive and linguistic uncertainty highlighting the challenges in aligning machine uncertainty with human interpretation nuances our findings suggest that while bayesian approximations provide valuable uncertainty estimates further refinement is necessary to fully capture and utilise the subtleties of human uncertainty in clinical applications
http://arxiv.org/abs/2505.03739v1,2025-05-06T17:59:53Z,"Zuwei Long, Yunhang Shen, Chaoyou Fu, Heting Gao, Lijiang Li, Peixian Chen, Mengdan Zhang, Hang Shao, Jian Li, Jinlong Peng, Haoyu Cao, Ke Li, Rongrong Ji, Xing Sun",vitaaudio fast interleaved crossmodal token generation for efficient large speechlanguage model,with the growing requirement for natural humancomputer interaction speechbased systems receive increasing attention as speech is one of the most common forms of daily communication however the existing speech models still experience high latency when generating the first audio token during streaming which poses a significant bottleneck for deployment to address this issue we propose vitaaudio an endtoend large speech model with fast audiotext token generation specifically we introduce a lightweight multiple crossmodal token prediction mctp module that efficiently generates multiple audio tokens within a single model forward pass which not only accelerates the inference but also significantly reduces the latency for generating the first audio in streaming scenarios in addition a fourstage progressive training strategy is explored to achieve model acceleration with minimal loss of speech quality to our knowledge vitaaudio is the first multimodal large language model capable of generating audio output during the first forward pass enabling realtime conversational capabilities with minimal latency vitaaudio is fully reproducible and is trained on opensource data only experimental results demonstrate that our model achieves an inference speedup of 35x at the 7b parameter scale but also significantly outperforms opensource models of similar model size on multiple benchmarks for automatic speech recognition asr texttospeech tts and spoken question answering sqa tasks
http://arxiv.org/abs/2505.03733v1,2025-05-06T17:59:15Z,"Zimu Lu, Yunqiao Yang, Houxing Ren, Haotian Hou, Han Xiao, Ke Wang, Weikang Shi, Aojun Zhou, Mingjie Zhan, Hongsheng Li",webgenbench evaluating llms on generating interactive and functional websites from scratch,llmbased agents have demonstrated great potential in generating and managing code within complex codebases in this paper we introduce webgenbench a novel benchmark designed to measure an llmbased agents ability to create multifile website codebases from scratch it contains diverse instructions for website generation created through the combined efforts of human annotators and gpt4o these instructions span three major categories and thirteen minor categories encompassing nearly all important types of web applications to assess the quality of the generated websites we use gpt4o to generate test cases targeting each functionality described in the instructions and then manually filter adjust and organize them to ensure accuracy resulting in 647 test cases each test case specifies an operation to be performed on the website and the expected result after the operation to automate testing and improve reproducibility we employ a powerful webnavigation agent to execute tests on the generated websites and determine whether the observed responses align with the expected results we evaluate three highperformance codeagent frameworks boltdiy openhands and aider using multiple proprietary and opensource llms as engines the bestperforming combination boltdiy powered by deepseekr1 achieves only 278 accuracy on the test cases highlighting the challenging nature of our benchmark additionally we construct webgeninstruct a training set consisting of 6667 websitegeneration instructions training qwen25coder32binstruct on boltdiy trajectories generated from a subset of this training set achieves an accuracy of 382 surpassing the performance of the best proprietary model
http://arxiv.org/abs/2505.03711v1,2025-05-06T17:33:46Z,"Baharul Islam, Nasim Ahmad, Ferdous Ahmed Barbhuiya, Kuntal Dey",nbf at semeval2025 task 5 lightburst attention enhanced system for multilingual subject recommendation,we present our system submission for semeval 2025 task 5 which focuses on crosslingual subject classification in the english and german academic domains our approach leverages bilingual data during training employing negative sampling and a marginbased retrieval objective we demonstrate that a dimensionastoken selfattention mechanism designed with significantly reduced internal dimensions can effectively encode sentence embeddings for subject retrieval in quantitative evaluation our system achieved an average recall rate of 3224 in the general quantitative setting all subjects 4316 and 3153 of the general qualitative evaluation methods with minimal gpu usage highlighting their competitive performance our results demonstrate that our approach is effective in capturing relevant subject information under resource constraints although there is still room for improvement
http://arxiv.org/abs/2505.03688v2,2025-05-06T16:42:54Z,"Sharvi Endait, Ruturaj Ghatage, Aditya Kulkarni, Rajlaxmi Patil, Raviraj Joshi",indicsquad a comprehensive multilingual question answering dataset for indic languages,the rapid progress in questionanswering qa systems has predominantly benefited highresource languages leaving indic languages largely underrepresented despite their vast native speaker base in this paper we present indicsquad a comprehensive multilingual extractive qa dataset covering nine major indic languages systematically derived from the squad dataset building on previous work with mahasquad for marathi our approach adapts and extends translation techniques to maintain high linguistic fidelity and accurate answerspan alignment across diverse languages indicsquad comprises extensive training validation and test sets for each language providing a robust foundation for model development we evaluate baseline performances using languagespecific monolingual bert models and the multilingual murilbert the results indicate some challenges inherent in lowresource settings moreover our experiments suggest potential directions for future work including expanding to additional languages developing domainspecific datasets and incorporating multimodal data the dataset and models are publicly shared at httpsgithubcoml3cubepuneindicnlp
http://arxiv.org/abs/2505.03675v1,2025-05-06T16:21:10Z,"Anuja Tayal, Devika Salunke, Barbara Di Eugenio, Paula G Allen-Meares, Eulalia P Abril, Olga Garcia-Bedoya, Carolyn A Dickens, Andrew D. Boyd",towards conversational assistants for health applications using chatgpt to generate conversations about heart failure,we explore the potential of chatgpt 35turbo and 4 to generate conversations focused on selfcare strategies for africanamerican heart failure patients a domain with limited specialized datasets to simulate patienthealth educator dialogues we employed four prompting strategies domain african american vernacular english aave social determinants of health sdoh and sdohinformed reasoning conversations were generated across key selfcare domains of food exercise and fluid intake with varying turn lengths 5 10 15 and incorporated patientspecific sdoh attributes such as age gender neighborhood and socioeconomic status our findings show that effective prompt design is essential while incorporating sdoh and reasoning improves dialogue quality chatgpt still lacks the empathy and engagement needed for meaningful healthcare communication
http://arxiv.org/abs/2505.03676v1,2025-05-06T16:21:10Z,"Arthur Satouf, Gabriel Ben Zenou, Benjamin Piwowarski, Habiboulaye Amadou Boubacar, Pablo Piantanida",rational retrieval acts leveraging pragmatic reasoning to improve sparse retrieval,current sparse neural information retrieval ir methods and to a lesser extent more traditional models such as bm25 do not take into account the document collection and the complex interplay between different term weights when representing a single document in this paper we show how the rational speech acts rsa a linguistics framework used to minimize the number of features to be communicated when identifying an object in a set can be adapted to the ir case and in particular to the high number of potential features here tokens rsa dynamically modulates tokendocument interactions by considering the influence of other documents in the dataset better contrasting document representations experiments show that incorporating rsa consistently improves multiple sparse retrieval models and achieves stateoftheart performance on outofdomain datasets from the beir benchmark httpsgithubcomarthur75rationalretrievalacts
http://arxiv.org/abs/2505.03563v1,2025-05-06T14:17:30Z,"Cléa Chataigner, Rebecca Ma, Prakhar Ganesh, Afaf Taïk, Elliot Creager, Golnoosh Farnadi",say it another way a framework for usergrounded paraphrasing,small changes in how a prompt is worded can lead to meaningful differences in the behavior of large language models llms raising concerns about the stability and reliability of their evaluations while prior work has explored simple formatting changes these rarely capture the kinds of natural variation seen in realworld language use we propose a controlled paraphrasing framework based on a taxonomy of minimal linguistic transformations to systematically generate natural prompt variations using the bbq dataset we validate our method with both human annotations and automated checks then use it to study how llms respond to paraphrased prompts in stereotype evaluation tasks our analysis shows that even subtle prompt modifications can lead to substantial changes in model behavior these results highlight the need for robust paraphraseaware evaluation protocols
http://arxiv.org/abs/2505.03531v1,2025-05-06T13:41:17Z,"Haoqi Yang, Luohe Shi, Qiwei Li, Zuchao Li, Ping Wang, Bo Du, Mengjia Shen, Hai Zhao",faster moe llm inference for extremely large models,sparse mixture of experts moe large language models llms are gradually becoming the mainstream approach for ultralargescale models existing optimization efforts for moe models have focused primarily on coarsegrained moe architectures with the emergence of deepseek models finegrained moe models are gaining popularity yet research on them remains limited therefore we want to discuss the efficiency dynamic under different service loads additionally finegrained models allow deployers to reduce the number of routed experts both activated counts and total counts raising the question of how this reduction affects the tradeoff between moe efficiency and performance our findings indicate that while deploying moe models presents greater challenges it also offers significant optimization opportunities reducing the number of activated experts can lead to substantial efficiency improvements in certain scenarios with only minor performance degradation reducing the total number of experts provides limited efficiency gains but results in severe performance degradation our method can increase throughput by at least 10 without any performance degradation overall we conclude that moe inference optimization remains an area with substantial potential for exploration and improvement
http://arxiv.org/abs/2505.03501v1,2025-05-06T13:07:57Z,"Zihan Wang, Hongwei Li, Rui Zhang, Wenbo Jiang, Kangjie Chen, Tianwei Zhang, Qingchuan Zhao, Guowen Xu",badlingual a novel lingualbackdoor attack against large language models,in this paper we present a new form of backdoor attack against large language models llms lingualbackdoor attacks the key novelty of lingualbackdoor attacks is that the language itself serves as the trigger to hijack the infected llms to generate inflammatory speech they enable the precise targeting of a specific languagespeaking group exacerbating racial discrimination by malicious entities we first implement a baseline lingualbackdoor attack which is carried out by poisoning a set of training data for specific downstream tasks through translation into the trigger language however this baseline attack suffers from poor task generalization and is impractical in realworld settings to address this challenge we design badlingual a novel taskagnostic lingualbackdoor capable of triggering any downstream tasks within the chat llms regardless of the specific questions of these tasks we design a new approach using pplconstrained greedy coordinate gradientbased search pgcg based adversarial training to expand the decision boundary of lingualbackdoor thereby enhancing the generalization ability of lingualbackdoor across various tasks we perform extensive experiments to validate the effectiveness of our proposed attacks specifically the baseline attack achieves an asr of over 90 on the specified tasks however its asr reaches only 3761 across six tasks in the taskagnostic scenario in contrast badlingual brings up to 3735 improvement over the baseline our study sheds light on a new perspective of vulnerabilities in llms with multilingual capabilities and is expected to promote future research on the potential defenses to enhance the llms robustness
http://arxiv.org/abs/2505.03481v1,2025-05-06T12:34:59Z,"Maciej Zembrzuski, Saad Mahamood",sentence embeddings as an intermediate target in endtoend summarisation,current neural networkbased methods to the problem of document summarisation struggle when applied to datasets containing large inputs in this paper we propose a new approach to the challenge of contentselection when dealing with endtoend summarisation of user reviews of accommodations we show that by combining an extractive approach with externally pretrained sentence level embeddings in an addition to an abstractive summarisation model we can outperform existing methods when this is applied to the task of summarising a large input dataset we also prove that predicting sentence level embedding of a summary increases the quality of an endtoend system for loosely aligned source to target corpora than compared to commonly predicting probability distributions of sentence selection
http://arxiv.org/abs/2505.03473v1,2025-05-06T12:25:15Z,"Marta Boscariol, Luana Bulla, Lia Draetta, Beatrice Fiumanò, Emanuele Lenzi, Leonardo Piano",evaluation of llms on longtail entity linking in historical documents,entity linking el plays a crucial role in natural language processing nlp applications enabling the disambiguation of entity mentions by linking them to their corresponding entries in a reference knowledge base kb thanks to their deep contextual understanding capabilities llms offer a new perspective to tackle el promising better results than traditional methods despite the impressive generalization capabilities of llms linking less popular longtail entities remains challenging as these entities are often underrepresented in training data and knowledge bases furthermore the longtail el task is an understudied problem and limited studies address it with llms in the present work we assess the performance of two popular llms gpt and llama3 in a longtail entity linking scenario using mhercl v01 a manually annotated benchmark of sentences from domainspecific historical texts we quantitatively compare the performance of llms in identifying and linking entities to their corresponding wikidata entries against that of relik a stateoftheart entity linking and relation extraction framework our preliminary experiments reveal that llms perform encouragingly well in longtail el indicating that this technology can be a valuable adjunct in filling the gap between head and longtail el
http://arxiv.org/abs/2505.03469v1,2025-05-06T12:18:11Z,"Bin Yu, Hang Yuan, Yuliang Wei, Bailing Wang, Weizhen Qi, Kai Chen",longshort chainofthought mixture supervised finetuning eliciting efficient reasoning in large language models,recent advances in large language models have demonstrated that supervised finetuning sft with chainofthought cot reasoning data distilled from large reasoning models eg deepseek r1 can effectively transfer reasoning capabilities to nonreasoning models however models finetuned with this approach inherit the overthinking problem from teacher models producing verbose and redundant reasoning chains during inference to address this challenge we propose textbflongtextbfshort chainofthought textbfmixture textbfsupervised textbffinetextbftuning textbflsmixture sft which combines long cot reasoning dataset with their short counterparts obtained through structurepreserved rewriting our experiments demonstrate that models trained using the lsmixture sft method compared to those trained with direct sft achieved an average accuracy improvement of 23 across various benchmarks while substantially reducing model response length by approximately 4761 this work offers an approach to endow nonreasoning models with reasoning capabilities through supervised finetuning while avoiding the inherent overthinking problems inherited from teacher models thereby enabling efficient reasoning in the finetuned models
http://arxiv.org/abs/2505.03467v1,2025-05-06T12:12:48Z,"Shuang Zhou, Jiashuo Wang, Zidu Xu, Song Wang, David Brauer, Lindsay Welton, Jacob Cogan, Yuen-Hei Chung, Lei Tian, Zaifu Zhan, Yu Hou, Mingquan Lin, Genevieve B. Melton, Rui Zhang",uncertaintyaware large language models for explainable disease diagnosis,explainable disease diagnosis which leverages patient information eg signs and symptoms and computational models to generate probable diagnoses and reasonings offers clear clinical values however when clinical notes encompass insufficient evidence for a definite diagnosis such as the absence of definitive symptoms diagnostic uncertainty usually arises increasing the risk of misdiagnosis and adverse outcomes although explicitly identifying and explaining diagnostic uncertainties is essential for trustworthy diagnostic systems it remains underexplored to fill this gap we introduce confidx an uncertaintyaware large language model llm created by finetuning opensource llms with diagnostic criteria we formalized the task and assembled richly annotated datasets that capture varying degrees of diagnostic ambiguity evaluating confidx on realworld datasets demonstrated that it excelled in identifying diagnostic uncertainties achieving superior diagnostic performance and generating trustworthy explanations for diagnoses and uncertainties to our knowledge this is the first study to jointly address diagnostic uncertainty recognition and explanation substantially enhancing the reliability of automatic diagnostic systems
http://arxiv.org/abs/2505.03452v1,2025-05-06T11:47:52Z,"Matan Orbach, Ohad Eytan, Benjamin Sznajder, Ariel Gera, Odellia Boni, Yoav Kantor, Gal Bloch, Omri Levy, Hadas Abraham, Nitzan Barzilay, Eyal Shnarch, Michael E. Factor, Shila Ofek-Koifman, Paula Ta-Shma, Assaf Toledo",an analysis of hyperparameter optimization methods for retrieval augmented generation,finding the optimal retrievalaugmented generation rag configuration for a given use case can be complex and expensive motivated by this challenge frameworks for rag hyperparameter optimization hpo have recently emerged yet their effectiveness has not been rigorously benchmarked to address this gap we present a comprehensive study involving 5 hpo algorithms over 5 datasets from diverse domains including a new one collected for this work on realworld product documentation our study explores the largest hpo search space considered to date with two optimized evaluation metrics analysis of the results shows that rag hpo can be done efficiently either greedily or with iterative random search and that it significantly boosts rag performance for all datasets for greedy hpo approaches we show that optimizing models first is preferable to the prevalent practice of optimizing sequentially according to the rag pipeline order
http://arxiv.org/abs/2505.03443v1,2025-05-06T11:30:16Z,Valerio Bellandi,elevating semantic exploration a novel approach utilizing distributed repositories,centralized and distributed systems are two main approaches to organizing ict infrastructure each with its pros and cons centralized systems concentrate resources in one location making management easier but creating single points of failure distributed systems on the other hand spread resources across multiple nodes offering better scalability and fault tolerance but requiring more complex management the choice between them depends on factors like application needs scalability and data sensitivity centralized systems suit applications with limited scalability and centralized control while distributed systems excel in largescale environments requiring high availability and performance this paper explores a distributed document repository system developed for the italian ministry of justice using edge repositories to analyze textual data and metadata enhancing semantic exploration capabilities
http://arxiv.org/abs/2505.03427v1,2025-05-06T11:07:26Z,"Mouath Abu Daoud, Chaimae Abouzahir, Leen Kharouf, Walid Al-Eisawi, Nizar Habash, Farah E. Shamout",medarabiq benchmarking large language models on arabic medical tasks,large language models llms have demonstrated significant promise for various applications in healthcare however their efficacy in the arabic medical domain remains unexplored due to the lack of highquality domainspecific datasets and benchmarks this study introduces medarabiq a novel benchmark dataset consisting of seven arabic medical tasks covering multiple specialties and including multiple choice questions fillintheblank and patientdoctor question answering we first constructed the dataset using past medical exams and publicly available datasets we then introduced different modifications to evaluate various llm capabilities including bias mitigation we conducted an extensive evaluation with five stateoftheart opensource and proprietary llms including gpt4o claude 35sonnet and gemini 15 our findings highlight the need for the creation of new highquality benchmarks that span different languages to ensure fair deployment and scalability of llms in healthcare by establishing this benchmark and releasing the dataset we provide a foundation for future research aimed at evaluating and enhancing the multilingual capabilities of llms for the equitable use of generative ai in healthcare
http://arxiv.org/abs/2505.03414v3,2025-05-06T10:41:53Z,"Fangming Cui, Yonggang Zhang, Xuan Wang, Xinmei Tian, Jun Yu",enhancing targetunspecific tasks through a features matrix,recent developments in prompt learning of large visionlanguage models have significantly improved performance in targetspecific tasks however these prompt optimizing methods often struggle to tackle the targetunspecific or generalizable tasks effectively it may be attributed to the fact that overfitting training causes the model to forget its general knowledge having strong promotion on targetunspecific tasks to alleviate this issue we propose a novel features matrix fm regularization approach designed to enhance these models on targetunspecific tasks our method extracts and leverages general knowledge shaping a features matrix fm specifically the fm captures the semantics of diverse inputs from a deep and fine perspective preserving essential general knowledge which mitigates the risk of overfitting representative evaluations demonstrate that 1 the fm is compatible with existing frameworks as a generic and flexible module and 2 the fm significantly showcases its effectiveness in enhancing targetunspecific tasks achieving stateoftheart performance
http://arxiv.org/abs/2505.03406v1,2025-05-06T10:31:54Z,"Mohammad Shoaib Ansari, Mohd Sohail Ali Khan, Shubham Revankar, Aditya Varma, Anil S. Mokhade",lightweight clinical decision support system using qlorafinetuned llms and retrievalaugmented generation,this research paper investigates the application of large language models llms in healthcare specifically focusing on enhancing medical decision support through retrievalaugmented generation rag integrated with hospitalspecific data and finetuning using quantized lowrank adaptation qlora the system utilizes llama 323binstruct as its foundation model by embedding and retrieving contextrelevant healthcare information the system significantly improves response accuracy qlora facilitates notable parameter efficiency and memory optimization preserving the integrity of medical information through specialized quantization techniques our research also shows that our model performs relatively well on various medical benchmarks indicating that it can be used to make basic medical suggestions this paper details the systems technical components including its architecture quantization methods and key healthcare applications such as enhanced disease prediction from patient symptoms and medical history treatment suggestions and efficient summarization of complex medical reports we touch on the ethical considerationspatient privacy data security and the need for rigorous clinical validationas well as the practical challenges of integrating such systems into realworld healthcare workflows furthermore the lightweight quantized weights ensure scalability and ease of deployment even in lowresource hospital environments finally the paper concludes with an analysis of the broader impact of llms on healthcare and outlines future directions for llms in medical settings
http://arxiv.org/abs/2505.03335v2,2025-05-06T09:08:00Z,"Andrew Zhao, Yiran Wu, Yang Yue, Tong Wu, Quentin Xu, Yang Yue, Matthieu Lin, Shenzhi Wang, Qingyun Wu, Zilong Zheng, Gao Huang",absolute zero reinforced selfplay reasoning with zero data,reinforcement learning with verifiable rewards rlvr has shown promise in enhancing the reasoning capabilities of large language models by learning directly from outcomebased rewards recent rlvr works that operate under the zero setting avoid supervision in labeling the reasoning process but still depend on manually curated collections of questions and answers for training the scarcity of highquality humanproduced examples raises concerns about the longterm scalability of relying on human supervision a challenge already evident in the domain of language model pretraining furthermore in a hypothetical future where ai surpasses human intelligence tasks provided by humans may offer limited learning potential for a superintelligent system to address these concerns we propose a new rlvr paradigm called absolute zero in which a single model learns to propose tasks that maximize its own learning progress and improves reasoning by solving them without relying on any external data under this paradigm we introduce the absolute zero reasoner azr a system that selfevolves its training curriculum and reasoning ability by using a code executor to both validate proposed code reasoning tasks and verify answers serving as an unified source of verifiable reward to guide openended yet grounded learning despite being trained entirely without external data azr achieves overall sota performance on coding and mathematical reasoning tasks outperforming existing zerosetting models that rely on tens of thousands of indomain humancurated examples furthermore we demonstrate that azr can be effectively applied across different model scales and is compatible with various model classes
http://arxiv.org/abs/2505.03320v1,2025-05-06T08:47:58Z,"Junyu Ma, Tianqing Fang, Zhisong Zhang, Hongming Zhang, Haitao Mi, Dong Yu",recall with reasoning chainofthought distillation for mambas longcontext memory and extrapolation,mambas theoretical infinitecontext potential is limited in practice when sequences far exceed training lengths this work explores unlocking mambas longcontext memory ability by a simpleyeteffective method recall with reasoning rwr by distilling chainofthought cot summarization from a teacher model specifically rwr prepends these summarization as cot prompts during finetuning teaching mamba to actively recall and reason over long contexts experiments on longmemeval and helmet show rwr boosts mambas longcontext performance against comparable transformerhybrid baselines under similar pretraining conditions while preserving shortcontext capabilities all without architectural changes
http://arxiv.org/abs/2505.03293v1,2025-05-06T08:22:51Z,"Shijing Zhu, Zhuang Chen, Guanqun Bi, Binghang Li, Yaxi Deng, Dazhen Wan, Libiao Peng, Xiyao Xiao, Rongsheng Zhang, Tangjie Lv, Zhipeng Hu, FangFang Li, Minlie Huang",arena interactive assessment and optimization of llmbased psychological counselors with tripartite feedback,large language models llms have shown promise in providing scalable mental health support while evaluating their counseling capability remains crucial to ensure both efficacy and safety existing evaluations are limited by the static assessment that focuses on knowledge tests the single perspective that centers on user experience and the openloop framework that lacks actionable feedback to address these issues we propose psiarena an interactive framework for comprehensive assessment and optimization of llmbased counselors featuring three key characteristics 1 realistic arena interactions that simulate realworld counseling through multistage dialogues with psychologically profiled npc clients 2 tripartite evaluation that integrates assessments from the client counselor and supervisor perspectives and 3 closedloop optimization that iteratively improves llm counselors using diagnostic feedback experiments across eight stateoftheart llms show significant performance variations in different realworld scenarios and evaluation perspectives moreover reflectionbased optimization results in up to a 141 improvement in counseling performance we hope psychoarena provides a foundational resource for advancing reliable and humanaligned llm applications in mental healthcare
http://arxiv.org/abs/2505.03273v1,2025-05-06T08:04:37Z,"Zhaoxi Mu, Xinyu Yang, Gang Wang",sepalm audio language models are error correctors for robust speech separation,while contemporary speech separation technologies adeptly process lengthy mixed audio waveforms they are frequently challenged by the intricacies of realworld environments including noisy and reverberant settings which can result in artifacts or distortions in the separated speech to overcome these limitations we introduce sepalm a pioneering approach that employs audio language models alms to rectify and resynthesize speech within the text domain following preliminary separation sepalm comprises four core components a separator a corrector a synthesizer and an aligner by integrating an almbased endtoend error correction mechanism we mitigate the risk of error accumulation and circumvent the optimization hurdles typically encountered in conventional methods that amalgamate automatic speech recognition asr with large language models llms additionally we have developed chainofthought cot prompting and knowledge distillation techniques to facilitate the reasoning and training processes of the alm our experiments substantiate that sepalm not only elevates the precision of speech separation but also markedly bolsters adaptability in novel acoustic environments
http://arxiv.org/abs/2505.03229v1,2025-05-06T06:45:40Z,Behrooz Mansouri,survey of abstract meaning representation then now future,this paper presents a survey of abstract meaning representation amr a semantic representation framework that captures the meaning of sentences through a graphbased structure amr represents sentences as rooted directed acyclic graphs where nodes correspond to concepts and edges denote relationships effectively encoding the meaning of complex sentences this survey investigates amr and its extensions focusing on amr capabilities it then explores the parsing texttoamr and generation amrtotext tasks by showing traditional current and possible futures approaches it also reviews various applications of amr including text generation text classification and information extraction and information seeking by analyzing recent developments and challenges in the field this survey provides insights into future directions for research and the potential impact of amr on enhancing machine understanding of human language
http://arxiv.org/abs/2505.03059v1,2025-05-05T22:40:23Z,"Junlin Wang, Roy Xie, Shang Zhu, Jue Wang, Ben Athiwaratkun, Bhuwan Dhingra, Shuaiwen Leon Song, Ce Zhang, James Zou",improving model alignment through collective intelligence of opensource llms,building helpful and harmless large language models llms requires effective model alignment approach based on human instructions and feedback which necessitates highquality humanlabeled data constructing such datasets is often expensive and hard to scale and may face potential limitations on diversity and generalization to address these challenges we introduce mixture of agents alignment moaa that leverages the collective strengths of various language models to provide highquality data for model alignment by employing moaa we enhance both supervised finetuning and preference optimization leading to improved performance compared to using a single model alone to generate alignment data eg using gpt4o alone evaluation results show that our approach can improve win rate of llama318binstruct from 195 to 483 on arenahard and from 2233 to 5723 on alpacaeval2 highlighting a promising direction for model alignment through this new scalable and diverse synthetic data recipe furthermore we demonstrate that moaa enables a selfimprovement pipeline where models finetuned on moagenerated data surpass their own initial capabilities providing evidence that our approach can push the frontier of opensource llms without reliance on stronger external supervision data and code will be released
http://arxiv.org/abs/2505.03054v2,2025-05-05T22:28:53Z,"Orevaoghene Ahia, Martijn Bartelds, Kabir Ahuja, Hila Gonen, Valentin Hofmann, Siddhant Arora, Shuyue Stella Li, Vishal Puttagunta, Mofetoluwa Adeyemi, Charishma Buchireddy, Ben Walls, Noah Bennett, Shinji Watanabe, Noah A. Smith, Yulia Tsvetkov, Sachin Kumar",blab brutally long audio bench,developing large audio language models lms capable of understanding diverse spoken interactions is essential for accommodating the multimodal nature of human communication and can increase the accessibility of language technologies across different user populations recent work on audio lms has primarily evaluated their performance on short audio segments typically under 30 seconds with limited exploration of longform conversational speech segments that more closely reflect natural user interactions with these models we introduce brutally long audio bench blab a challenging longform audio benchmark that evaluates audio lms on localization duration estimation emotion and counting tasks using audio segments averaging 51 minutes in length blab consists of 833 hours of diverse fulllength audio clips each paired with humanannotated textbased natural language questions and answers our audio data were collected from permissively licensed sources and underwent a humanassisted filtering process to ensure task compliance we evaluate six opensource and proprietary audio lms on blab and find that all of them including advanced models such as gemini 20 pro and gpt4o struggle with the tasks in blab our comprehensive analysis reveals key insights into the tradeoffs between task difficulty and audio duration in general we find that audio lms struggle with longform speech with performance declining as duration increases they perform poorly on localization temporal reasoning counting and struggle to understand nonphonemic information relying more on prompts than audio content blab serves as a challenging evaluation framework to develop audio lms with robust longform audio understanding capabilities
http://arxiv.org/abs/2505.03053v1,2025-05-05T22:26:55Z,"Jennifer Healey, Laurie Byrum, Md Nadeem Akhtar, Surabhi Bhargava, Moumita Sinha",developing a framework to support human evaluation of bias in generated free response text,llm evaluation is challenging even the case of base models in real world deployments evaluation is further complicated by the interplay of task specific prompts and experiential context at scale bias evaluation is often based on short context fixed choice benchmarks that can be rapidly evaluated however these can lose validity when the llms deployed context differs large scale human evaluation is often seen as too intractable and costly here we present our journey towards developing a semiautomated bias evaluation framework for free text responses that has human insights at its core we discuss how we developed an operational definition of bias that helped us automate our pipeline and a methodology for classifying bias beyond multiple choice we additionally comment on how human evaluation helped us uncover problematic templates in a bias benchmark
http://arxiv.org/abs/2505.03052v1,2025-05-05T22:24:06Z,"Ryan Wang, Matthew Finlayson, Luca Soldaini, Swabha Swayamdipta, Robin Jia",teaching models to understand but not generate highrisk data,language model developers typically filter out highrisk content such as toxic or copyrighted text from their pretraining data to prevent models from generating similar outputs however removing such data altogether limits models ability to recognize and appropriately respond to harmful or sensitive content in this paper we introduce selective loss to understand but not generate slung a pretraining paradigm through which models learn to understand highrisk data without learning to generate it instead of uniformly applying the nexttoken prediction loss slung selectively avoids incentivizing the generation of highrisk tokens while ensuring they remain within the models context window as the model learns to predict lowrisk tokens that follow highrisk ones it is forced to understand the highrisk content through our experiments we show that slung consistently improves models understanding of highrisk data eg ability to recognize toxic content without increasing its generation eg toxicity of model responses overall our slung paradigm enables models to benefit from highrisk text that would otherwise be filtered out
http://arxiv.org/abs/2505.03031v1,2025-05-05T21:17:14Z,Sean I. Young,radio ratedistortion optimization for large language model compression,in recent years the compression of large language models llms has emerged as a key problem in facilitating llm deployment on resourcelimited devices reducing compute costs and mitigating the environmental footprint due to largescale ai infrastructure here we establish the foundations of llm quantization from a ratedistortion theory perspective and propose a quantization technique based on simple ratedistortion optimization our technique scales to models containing hundreds of billions of weight parameters and offers users the flexibility to compress models posttraining to a model size or accuracy specified by the user
http://arxiv.org/abs/2505.03030v1,2025-05-05T21:15:40Z,"Sicong Huang, Jincheng He, Shiyuan Huang, Karthik Raja Anandan, Arkajyoti Chakraborty, Ian Lane",ucsc at semeval2025 task 3 context models and prompt optimization for automated hallucination detection in llm output,hallucinations pose a significant challenge for large language models when answering knowledgeintensive queries as llms become more widely adopted it is crucial not only to detect if hallucinations occur but also to pinpoint exactly where in the llm output they occur semeval 2025 task 3 mushroom multilingual sharedtask on hallucinations and related observable overgeneration mistakes is a recent effort in this direction this paper describes the ucsc system submission to the shared mushroom task we introduce a framework that first retrieves relevant context next identifies false content from the answer and finally maps them back to spans in the llm output the process is further enhanced by automatically optimizing prompts our system achieves the highest overall performance ranking 1 in average position across all languages we release our code and experiment results
http://arxiv.org/abs/2505.03025v1,2025-05-05T20:58:08Z,"Steven Bedrick, A. Seza Doğruöz, Sergiu Nisioi",a typology of synthetic datasets for dialogue processing in clinical contexts,synthetic data sets are used across linguistic domains and nlp tasks particularly in scenarios where authentic data is limited or even nonexistent one such domain is that of clinical healthcare contexts where there exist significant and longstanding challenges eg privacy anonymization and data governance which have led to the development of an increasing number of synthetic datasets one increasingly important category of clinical dataset is that of clinical dialogues which are especially sensitive and difficult to collect and as such are commonly synthesized while such synthetic datasets have been shown to be sufficient in some situations little theory exists to inform how they may be best used and generalized to new applications in this paper we provide an overview of how synthetic datasets are created evaluated and being used for dialogue related tasks in the medical domain additionally we propose a novel typology for use in classifying types and degrees of data synthesis to facilitate comparison and evaluation
http://arxiv.org/abs/2505.03019v1,2025-05-05T20:42:34Z,"Albérick Euraste Djiré, Abdoul Kader Kaboré, Earl T. Barr, Jacques Klein, Tegawendé F. Bissyandé",memorization or interpolation detecting llm memorization through input perturbation analysis,while large language models llms achieve remarkable performance through training on massive datasets they can exhibit concerning behaviors such as verbatim reproduction of training data rather than true generalization this memorization phenomenon raises significant concerns about data privacy intellectual property rights and the reliability of model evaluations this paper introduces pearl a novel approach for detecting memorization in llms pearl assesses how sensitive an llms performance is to input perturbations enabling memorization detection without requiring access to the models internals we investigate how input perturbations affect the consistency of outputs enabling us to distinguish between true generalization and memorization our findings following extensive experiments on the pythia open model provide a robust framework for identifying when the model simply regurgitates learned information applied on the gpt 4o models the pearl framework not only identified cases of memorization of classic texts from the bible or common code from humaneval but also demonstrated that it can provide supporting evidence that some data such as from the new york times news articles were likely part of the training data of a given model
http://arxiv.org/abs/2505.03005v2,2025-05-05T20:03:28Z,"Daniel Goldstein, Eric Alcaide, Janna Lu, Eugene Cheah",radlads rapid attention distillation to linear attention decoders at scale,we present rapid attention distillation to linear attention decoders at scale radlads a protocol for rapidly converting softmax attention transformers into linear attention decoder models along with two new rwkvvariant architectures and models converted from popular qwen25 open source models in 7b 32b and 72b sizes our conversion process requires only 350700m tokens less than 0005 of the token count used to train the original teacher models converting to our 72b linear attention model costs less than 2000 usd at todays prices yet quality at inference remains close to the original transformer these models achieve stateoftheart downstream performance across a set of standard benchmarks for linear attention models of their size we release all our models on huggingface under the apache 20 license with the exception of our 72b models which are also governed by the qwen license agreement models at httpshuggingfacecocollectionsrecursalradlads6818ee69e99e729ba8a87102 training code at httpsgithubcomrecursalradladspaper
http://arxiv.org/abs/2505.02983v1,2025-05-05T19:23:16Z,"Wenjie Hua, Shenghan Xu",logitsconstrained framework with roberta for ancient chinese ner,this paper presents a logitsconstrained lc framework for ancient chinese named entity recognition ner evaluated on the evahan 2025 benchmark our twostage model integrates gujiroberta for contextual encoding and a differentiable decoding mechanism to enforce valid bmes label transitions experiments demonstrate that lc improves performance over traditional crf and bilstmbased approaches especially in highlabel or largedata settings we also propose a model selection criterion balancing label complexity and dataset size providing practical guidance for realworld ancient chinese nlp tasks
http://arxiv.org/abs/2505.04645v1,2025-05-05T19:04:25Z,"Tejas Jade, Alex Yartsev",chatgpt for automated grading of short answer questions in mechanical ventilation,standardised tests using short answer questions saqs are common in postgraduate education large language models llms simulate conversational language and interpret unstructured freetext responses in ways aligning with applying saq grading rubrics making them attractive for automated grading we evaluated chatgpt 4o to grade saqs in a postgraduate medical setting using data from 215 students 557 shortanswer responses enrolled in an online course on mechanical ventilation 20202024 deidentified responses to three casebased scenarios were presented to chatgpt with a standardised grading prompt and rubric outputs were analysed using mixedeffects modelling variance component analysis intraclass correlation coefficients iccs cohens kappa kendalls w and blandaltman statistics chatgpt awarded systematically lower marks than human graders with a mean difference bias of 134 on a 10point scale icc values indicated poor individuallevel agreement icc1 0086 and cohens kappa 00786 suggested no meaningful agreement variance component analysis showed minimal variability among the five chatgpt sessions gvalue 087 indicating internal consistency but divergence from the human grader the poorest agreement was observed for evaluative and analytic items whereas checklist and prescriptive rubric items had less disagreement we caution against the use of llms in grading postgraduate coursework over 60 of chatgptassigned grades differed from human grades by more than acceptable boundaries for highstakes assessments
http://arxiv.org/abs/2505.02952v1,2025-05-05T18:31:18Z,Fabrizio Marozzo,iterative resolution of prompt ambiguities using a progressive cuttingsearch approach,generative ai systems have revolutionized human interaction by enabling natural languagebased coding and problem solving however the inherent ambiguity of natural language often leads to imprecise instructions forcing users to iteratively test correct and resubmit their prompts we propose an iterative approach that systematically narrows down these ambiguities through a structured series of clarification questions and alternative solution proposals illustrated with inputoutput examples as well once every uncertainty is resolved a final precise solution is generated evaluated on a diverse dataset spanning coding data analysis and creative writing our method demonstrates superior accuracy competitive resolution times and higher user satisfaction compared to conventional oneshot solutions which typically require multiple manual iterations to achieve a correct output
http://arxiv.org/abs/2505.02931v1,2025-05-05T18:06:51Z,"Fernando Vallecillos Ruiz, Max Hort, Leon Moonen",the art of repair optimizing iterative program repair with instructiontuned models,automatic program repair apr aims to reduce the manual efforts required to identify and fix errors in source code before the rise of llmbased agents a common strategy was to increase the number of generated patches sometimes to the thousands to achieve better repair results on benchmarks more recently selfiterative capabilities enabled llms to refine patches over multiple rounds guided by feedback however literature often focuses on many iterations and disregards different numbers of outputs we investigate an apr pipeline that balances these two approaches the generation of multiple outputs and multiple rounds of iteration while imposing a limit of 10 total patches per bug we apply three sota instructiontuned llms deepseekcoderinstruct codellamainstruct llama31instruct to the apr task we further finetune each model on an apr dataset with three sizes 1k 30k 65k and two techniques full finetuning and lora allowing us to assess their repair capabilities on two apr benchmarks humanevaljava and defects4j our results show that by using only a fraction 1 of the finetuning dataset we can achieve improvements of up to 78 in the number of plausible patches generated challenging prior studies that reported limited gains using full finetuning however we find that exceeding certain thresholds leads to diminishing outcomes likely due to overfitting moreover we show that base models greatly benefit from creating patches in an iterative fashion rather than generating them all at once in addition the benefit of iterative strategies becomes more pronounced in complex benchmarks even finetuned models while benefiting less from iterations still gain advantages particularly on complex benchmarks the research underscores the need for balanced apr strategies that combine multioutput generation and iterative refinement
http://arxiv.org/abs/2505.02835v2,2025-05-05T17:59:50Z,"Yi-Fan Zhang, Xingyu Lu, Xiao Hu, Chaoyou Fu, Bin Wen, Tianke Zhang, Changyi Liu, Kaiyu Jiang, Kaibing Chen, Kaiyu Tang, Haojie Ding, Jiankang Chen, Fan Yang, Zhang Zhang, Tingting Gao, Liang Wang",r1reward training multimodal reward model through stable reinforcement learning,multimodal reward models mrms play a crucial role in enhancing the performance of multimodal large language models mllms while recent advancements have primarily focused on improving the model structure and training data of mrms there has been limited exploration into the effectiveness of longterm reasoning capabilities for reward modeling and how to activate these capabilities in mrms in this paper we explore how reinforcement learning rl can be used to improve reward modeling specifically we reformulate the reward modeling problem as a rulebased rl task however we observe that directly applying existing rl algorithms such as reinforce to reward modeling often leads to training instability or even collapse due to the inherent limitations of these algorithms to address this issue we propose the stablereinforce algorithm which refines the training loss advantage estimation strategy and reward design of existing rl methods these refinements result in more stable training dynamics and superior performance to facilitate mrm training we collect 200k preference data from diverse datasets our reward model r1reward trained using the stablereinforce algorithm on this dataset significantly improves performance on multimodal reward modeling benchmarks compared to previous sota models r1reward achieves a improvement on the vl rewardbench and a improvement on the multimodal reward bench moreover with more inference compute r1rewards performance is further enhanced highlighting the potential of rl algorithms in optimizing mrms
http://arxiv.org/abs/2505.02830v1,2025-05-05T17:57:07Z,"Qingqiu Li, Zihang Cui, Seongsu Bae, Jilan Xu, Runtian Yuan, Yuejie Zhang, Rui Feng, Quanli Shen, Xiaobo Zhang, Junjun He, Shujun Wang",aor anatomical ontologyguided reasoning for medical large multimodal model in chest xray interpretation,chest xrays cxrs are the most frequently performed imaging examinations in clinical settings recent advancements in large multimodal models lmms have enabled automated cxr interpretation enhancing diagnostic accuracy and efficiency however despite their strong visual understanding current medical lmms mlmms still face two major challenges 1 insufficient regionlevel understanding and interaction and 2 limited accuracy and interpretability due to singlestep reasoning in this paper we empower mlmms with anatomycentric reasoning capabilities to enhance their interactivity and explainability specifically we first propose an anatomical ontologyguided reasoning aor framework which centers on crossmodal regionlevel information to facilitate multistep reasoning next under the guidance of expert physicians we develop aorinstruction a large instruction dataset for mlmms training our experiments demonstrate aors superior performance in both vqa and report generation tasks
http://arxiv.org/abs/2505.02820v1,2025-05-05T17:47:49Z,"Hao Zhu, Phil Cuvin, Xinkai Yu, Charlotte Ka Yee Yan, Jason Zhang, Diyi Yang",autolibra agent metric induction from openended feedback,agents are predominantly evaluated and optimized via task success metrics which are coarse rely on manual design from experts and fail to reward intermediate emergent behaviors we propose autolibra a framework for agent evaluation that transforms openended human feedback eg if you find that the button is disabled dont click it again or this agent has too much autonomy to decide what to do on its own into metrics for evaluating finegrained behaviors in agent trajectories autolibra accomplishes this by grounding feedback to an agents behavior clustering similar positive and negative behaviors and creating concrete metrics with clear definitions and concrete examples which can be used for prompting llmasajudge as evaluators we further propose two metametrics to evaluate the alignment of a set of induced metrics with open feedback coverage and redundancy through optimizing these metametrics we experimentally demonstrate autolibras ability to induce more concrete agent evaluation metrics than the ones proposed in previous agent evaluation benchmarks and discover new metrics to analyze agents we also present two applications of autolibra in agent improvement first we show that autolibrainduced metrics serve as better promptengineering targets than the task success rate on a wide range of text game tasks improving agent performance over baseline by a mean of 20 second we show that autolibra can iteratively select highquality finetuning data for web navigation agents our results suggest that autolibra is a powerful taskagnostic tool for evaluating and improving language agents
http://arxiv.org/abs/2505.02819v2,2025-05-05T17:47:42Z,"Dmitriy Shopkhoev, Ammar Ali, Magauiya Zhussip, Valentin Malykh, Stamatios Lefkimmiatis, Nikos Komodakis, Sergey Zagoruyko",replaceme network simplification via layer pruning and linear transformations,we introduce replaceme a generalized trainingfree depth pruning method that effectively replaces transformer blocks with a linear operation while maintaining high performance for low compression ratios in contrast to conventional pruning approaches that require additional training or finetuning our approach requires only a small calibration dataset that is used to estimate a linear transformation to approximate the pruned blocks this estimated linear mapping can be seamlessly merged with the remaining transformer blocks eliminating the need for any additional network parameters our experiments show that replaceme consistently outperforms other trainingfree approaches and remains highly competitive with stateoftheart pruning methods that involve extensive retrainingfinetuning and architectural modifications applied to several large language models llms replaceme achieves up to 25 pruning while retaining approximately 90 of the original models performance on open benchmarks without any training or healing steps resulting in minimal computational overhead see fig1 we provide an opensource library implementing replaceme alongside several stateoftheart depth pruning techniques available at this repository
http://arxiv.org/abs/2505.02811v1,2025-05-05T17:39:35Z,"Diji Yang, Linda Zeng, Jinmeng Rao, Yi Zhang",knowing you dont know learning when to continue search in multiround rag through selfpracticing,retrieval augmented generation rag has shown strong capability in enhancing language models knowledge and reducing ai generative hallucinations driving its widespread use however complex tasks requiring multiround retrieval remain challenging and early attempts tend to be overly optimistic without a good sense of selfskepticism current multiround rag systems may continue searching even when enough information has already been retrieved or they may provide incorrect answers without having sufficient information or knowledge existing solutions either require large amounts of expensive humanlabeled process supervision data or lead to subpar performance this paper aims to address these limitations by introducing a new framework textbfsimrag to explicitly enhance rag systems selfawareness and multiround retrieval capabilities to train simrag we first let a rag system selfpractice multiround retrieval augmenting existing questionanswer pairs with intermediate inner monologue reasoning steps to generate synthetic training data for each pair the system may explore multiple retrieval paths which are labeled as successful if they reach the correct answer and unsuccessful otherwise using this data we train a lightweight information sufficiency critic at inference time the critic evaluates whether the rag system has retrieved sufficient information at each round guiding retrieval decisions and improving systemlevel selfawareness through incontext reinforcement learning experiments across multiple prominent rag benchmarks show that simrag is an effective multiround rag solution furthermore this framework is systemefficient adding a lightweight component to rag without requiring modifications to existing llms or search engines and dataefficient eliminating the need for costly humanannotated midstep retrieval process supervision data
http://arxiv.org/abs/2505.02888v1,2025-05-05T17:03:07Z,Rintaro Ando,when your own output becomes your training data noisetomeaning loops and a formal rsi trigger,we present noisetomeaning recursive selfimprovement n2mrsi a minimal formal model showing that once an ai agent feeds its own outputs back as inputs and crosses an explicit informationintegration threshold its internal complexity will grow without bound under our assumptions the framework unifies earlier ideas on selfprompting large language models godelian selfreference and automl yet remains implementationagnostic the model furthermore scales naturally to interacting swarms of agents hinting at superlinear effects once communication among instances is permitted for safety reasons we omit systemspecific implementation details and release only a brief modelagnostic toy prototype in appendix c
http://arxiv.org/abs/2505.04643v1,2025-05-05T16:39:24Z,"Hannes Waldetoft, Jakob Torgander, Måns Magnusson",predictionpowered estimators for finite population statistics in highly imbalanced textual data public hate crime estimation,estimating population parameters in finite populations of text documents can be challenging when obtaining the labels for the target variable requires manual annotation to address this problem we combine predictions from a transformer encoder neural network with wellestablished survey sampling estimators using the model predictions as an auxiliary variable the applicability is demonstrated in swedish hate crime statistics based on swedish police reports estimates of the yearly number of hate crimes and the polices underreporting are derived using the hansenhurwitz estimator difference estimation and stratified random sampling estimation we conclude that if labeled training data is available the proposed method can provide very efficient estimates with reduced time spent on manual annotation
http://arxiv.org/abs/2505.02763v1,2025-05-05T16:18:07Z,Matthew Dahl,byebye bluebook automating legal procedure with large language models,legal practice requires careful adherence to procedural rules in the united states few are more complex than those found in the bluebook a uniform system of citation compliance with this systems 500 pages of byzantine formatting instructions is the raison detre of thousands of student law review editors and the bete noire of lawyers everywhere to evaluate whether large language models llms are able to adhere to the procedures of such a complicated system we construct an original dataset of 866 bluebook tasks and test flagship llms from openai anthropic google meta and deepseek we show 1 that these models produce fully compliant bluebook citations only 6974 of the time and 2 that incontext learning on the bluebooks underlying system of rules raises accuracy only to 77 these results caution against using offtheshelf llms to automate aspects of the law where fidelity to procedure is paramount
http://arxiv.org/abs/2505.02746v1,2025-05-05T15:56:25Z,"Simon Ging, Sebastian Walter, Jelena Bratulić, Johannes Dienert, Hannah Bast, Thomas Brox",using knowledge graphs to harvest datasets for efficient clip model training,training highquality clip models typically requires enormous datasets which limits the development of domainspecific models especially in areas that even the largest clip models do not cover well and drives up training costs this poses challenges for scientific research that needs finegrained control over the training procedure of clip models in this work we show that by employing smart web search strategies enhanced with knowledge graphs a robust clip model can be trained from scratch with considerably less data specifically we demonstrate that an expert foundation model for living organisms can be built using just 10m images moreover we introduce entitynet a dataset comprising 33m images paired with 46m text descriptions which enables the training of a generic clip model in significantly reduced time
http://arxiv.org/abs/2505.02707v1,2025-05-05T15:05:01Z,"Yemin Shi, Yu Shu, Siwei Dong, Guangyi Liu, Jaward Sesay, Jingwen Li, Zhiting Hu",voila voicelanguage foundation models for realtime autonomous interaction and voice roleplay,a voice ai agent that blends seamlessly into daily life would interact with humans in an autonomous realtime and emotionally expressive manner rather than merely reacting to commands it would continuously listen reason and respond proactively fostering fluid dynamic and emotionally resonant interactions we introduce voila a family of large voicelanguage foundation models that make a step towards this vision voila moves beyond traditional pipeline systems by adopting a new endtoend architecture that enables fullduplex lowlatency conversations while preserving rich vocal nuances such as tone rhythm and emotion it achieves a response latency of just 195 milliseconds surpassing the average human response time its hierarchical multiscale transformer integrates the reasoning capabilities of large language models llms with powerful acoustic modeling enabling natural personaaware voice generation where users can simply write text instructions to define the speakers identity tone and other characteristics moreover voila supports over one million prebuilt voices and efficient customization of new ones from brief audio samples as short as 10 seconds beyond spoken dialogue voila is designed as a unified model for a wide range of voicebased applications including automatic speech recognition asr texttospeech tts and with minimal adaptation multilingual speech translation voila is fully opensourced to support open research and accelerate progress toward nextgeneration humanmachine interactions
http://arxiv.org/abs/2505.02693v1,2025-05-05T14:43:20Z,"Shaghayegh Agah, Yejin Kim, Neeraj Sharma, Mayur Nankani, Kevin Foley, H. Howie Huang, Sardar Hamidian",predicting movie hits before they happen with llms,addressing the coldstart issue in content recommendation remains a critical ongoing challenge in this work we focus on tackling the coldstart problem for movies on a large entertainment platform our primary goal is to forecast the popularity of coldstart movies using large language models llms leveraging movie metadata this method could be integrated into retrieval systems within the personalization pipeline or could be adopted as a tool for editorial teams to ensure fair promotion of potentially overlooked movies that may be missed by traditional or algorithmic solutions our study validates the effectiveness of this approach compared to established baselines and those we developed
http://arxiv.org/abs/2505.02692v1,2025-05-05T14:43:01Z,"Maxime Poli, Emmanuel Chemla, Emmanuel Dupoux",fastabx a library for efficient computation of abx discriminability,we introduce fastabx a highperformance python library for building abx discrimination tasks abx is a measure of the separation between generic categories of interest it has been used extensively to evaluate phonetic discriminability in selfsupervised speech representations however its broader adoption has been limited by the absence of adequate tools fastabx addresses this gap by providing a framework capable of constructing any type of abx task while delivering the efficiency necessary for rapid development cycles both in task creation and in calculating distances between representations we believe that fastabx will serve as a valuable resource for the broader representation learning community enabling researchers to systematically investigate what information can be directly extracted from learned representations across several domains beyond speech processing the source code is available at httpsgithubcombootphonfastabx
http://arxiv.org/abs/2505.02686v1,2025-05-05T14:33:49Z,Xiaobao Wu,sailing ai by the stars a survey of learning from rewards in posttraining and testtime scaling of large language models,recent developments in large language models llms have shifted from pretraining scaling to posttraining and testtime scaling across these developments a key unified paradigm has arisen learning from rewards where reward signals act as the guiding stars to steer llm behavior it has underpinned a wide range of prevalent techniques such as reinforcement learning in rlhf dpo and grpo rewardguided decoding and posthoc correction crucially this paradigm enables the transition from passive learning from static data to active learning from dynamic feedback this endows llms with aligned preferences and deep reasoning capabilities in this survey we present a comprehensive overview of the paradigm of learning from rewards we categorize and analyze the strategies under this paradigm across training inference and postinference stages we further discuss the benchmarks for reward models and the primary applications finally we highlight the challenges and future directions we maintain a paper collection at httpsgithubcombobxwulearningfromrewardsllmpapers
http://arxiv.org/abs/2505.02666v1,2025-05-05T14:15:02Z,"Miaomiao Ji, Yanqiu Wu, Zhibin Wu, Shoujin Wang, Jian Yang, Mark Dras, Usman Naseem",a survey on progress in llm alignment from the perspective of reward design,the alignment of large language models llms with human values and intentions represents a core challenge in current ai research where reward mechanism design has become a critical factor in shaping model behavior this study conducts a comprehensive investigation of reward mechanisms in llm alignment through a systematic theoretical framework categorizing their development into three key phases 1 feedback diagnosis 2 reward design prescription and 3 optimization treatment through a fourdimensional analysis encompassing construction basis format expression and granularity this research establishes a systematic classification framework that reveals evolutionary trends in reward modeling the field of llm alignment faces several persistent challenges while recent advances in reward design are driving significant paradigm shifts notable developments include the transition from reinforcement learningbased frameworks to novel optimization paradigms as well as enhanced capabilities to address complex alignment scenarios involving multimodal integration and concurrent task coordination finally this survey outlines promising future research directions for llm alignment through innovative reward design strategies
http://arxiv.org/abs/2505.02656v2,2025-05-05T14:03:22Z,"Rawan Bondok, Mayar Nassar, Salam Khalifa, Kurt Micallef, Nizar Habash",proper name diacritization for arabic wikipedia a benchmark dataset,proper names in arabic wikipedia are frequently undiacritized creating ambiguity in pronunciation and interpretation especially for transliterated named entities of foreign origin while transliteration and diacritization have been wellstudied separately in arabic nlptheir intersection remains underexplored in this paper we introduce a new manually diacritized dataset of arabic proper names of various origins with their english wikipedia equivalent glosses and present the challenges and guidelines we followed to create it we benchmark gpt4o on the task of recovering full diacritization given the undiacritized arabic and english forms and analyze its performance achieving 73 accuracy our results underscore both the difficulty of the task and the need for improved models and resources we release our dataset to facilitate further research on arabic wikipedia proper name diacritization
http://arxiv.org/abs/2505.02639v1,2025-05-05T13:31:36Z,"Xuan Lin, Qingrui Liu, Hongxin Xiang, Daojian Zeng, Xiangxiang Zeng",enhancing chemical reaction and retrosynthesis prediction with large language model and dualtask learning,chemical reaction and retrosynthesis prediction are fundamental tasks in drug discovery recently large language models llms have shown potential in many domains however directly applying llms to these tasks faces two major challenges i lacking a largescale chemical synthesisrelated instruction dataset ii ignoring the close correlation between reaction and retrosynthesis prediction for the existing finetuning strategies to address these challenges we propose chemdual a novel llm framework for accurate chemical synthesis specifically considering the high cost of data acquisition for reaction and retrosynthesis chemdual regards the reactionandretrosynthesis of molecules as a related recombinationandfragmentation process and constructs a largescale of 44 million instruction dataset furthermore chemdual introduces an enhanced llama equipped with a multiscale tokenizer and dualtask learning strategy to jointly optimize the process of recombination and fragmentation as well as the tasks between reaction and retrosynthesis prediction extensive experiments on molinstruction and uspto50k datasets demonstrate that chemdual achieves stateoftheart performance in both predictions of reaction and retrosynthesis outperforming the existing conventional singletask approaches and the general opensource llms through molecular docking analysis chemdual generates compounds with diverse and strong protein binding affinity further highlighting its strong potential in drug design
http://arxiv.org/abs/2505.02625v1,2025-05-05T12:53:09Z,"Qingkai Fang, Yan Zhou, Shoutao Guo, Shaolei Zhang, Yang Feng",llamaomni2 llmbased realtime spoken chatbot with autoregressive streaming speech synthesis,realtime intelligent and natural speech interaction is an essential part of the nextgeneration humancomputer interaction recent advancements have showcased the potential of building intelligent spoken chatbots based on large language models llms in this paper we introduce llamaomni 2 a series of speech language models speechlms ranging from 05b to 14b parameters capable of achieving highquality realtime speech interaction llamaomni 2 is built upon the qwen25 series models integrating a speech encoder and an autoregressive streaming speech decoder despite being trained on only 200k multiturn speech dialogue samples llamaomni 2 demonstrates strong performance on several spoken question answering and speech instruction following benchmarks surpassing previous stateoftheart speechlms like glm4voice which was trained on millions of hours of speech data
http://arxiv.org/abs/2505.02615v1,2025-05-05T12:36:03Z,"Armita Mohammadi, Alessandro Lameiras Koerich, Laureano Moro-Velazquez, Patrick Cardinal",automatic proficiency assessment in l2 english learners,second language proficiency l2 in english is usually perceptually evaluated by english teachers or expert evaluators with the inherent intra and interrater variability this paper explores deep learning techniques for comprehensive l2 proficiency assessment addressing both the speech signal and its correspondent transcription we analyze spoken proficiency classification prediction using diverse architectures including 2d cnn frequencybased cnn resnet and a pretrained wav2vec 20 model additionally we examine textbased proficiency assessment by finetuning a bert language model within resource constraints finally we tackle the complex task of spontaneous dialogue assessment managing longform audio and speaker interactions through separate applications of wav2vec 20 and bert models results from experiments on efcamdat and anglish datasets and a private dataset highlight the potential of deep learning especially the pretrained wav2vec 20 model for robust automated l2 proficiency evaluation
http://arxiv.org/abs/2505.02590v1,2025-05-05T11:56:12Z,"Diksha Bhandari, Alessandro Lopopolo, Milena Rabovsky, Sebastian Reich",ensemble kalman filter for uncertainty in human language comprehension,artificial neural networks anns are widely used in modeling sentence processing but often exhibit deterministic behavior contrasting with human sentence comprehension which manages uncertainty during ambiguous or unexpected inputs this is exemplified by reversal anomaliessentences with unexpected role reversals that challenge syntax and semanticshighlighting the limitations of traditional ann models such as the sentence gestalt sg model to address these limitations we propose a bayesian framework for sentence comprehension applying an extension of the ensemble kalman filter enkf for bayesian inference to quantify uncertainty by framing language comprehension as a bayesian inverse problem this approach enhances the sg models ability to reflect human sentence processing with respect to the representation of uncertainty numerical experiments and comparisons with maximum likelihood estimation mle demonstrate that bayesian methods improve uncertainty representation enabling the model to better approximate human cognitive processing when dealing with linguistic ambiguities
http://arxiv.org/abs/2505.02579v2,2025-05-05T11:30:46Z,"Lingxiao Kong, Cong Yang, Susanne Neufang, Oya Deniz Beyan, Zeyd Boukhers",emorl ensemble multiobjective reinforcement learning for efficient and flexible llm finetuning,recent advances in reinforcement learning rl for large language model llm finetuning show promise in addressing multiobjective tasks but still face significant challenges including complex objective balancing low training efficiency poor scalability and limited explainability leveraging ensemble learning principles we introduce an ensemble multiobjective rl emorl framework that finetunes multiple models with individual objectives while optimizing their aggregation after the training to improve efficiency and flexibility our method is the first to aggregate the last hidden states of individual models incorporating contextual information from multiple objectives this approach is supported by a hierarchical grid search algorithm that identifies optimal weighted combinations we evaluate emorl on counselor reflection generation tasks using textscoring llms to evaluate the generations and provide rewards during rl finetuning through comprehensive experiments on the pair and psych8k datasets we demonstrate the advantages of emorl against existing baselines significantly lower and more stable training consumption data points and seconds improved scalability and explainability and comparable performance across multiple objectives
http://arxiv.org/abs/2505.02550v2,2025-05-05T10:39:51Z,"Krzysztof Ociepa, Łukasz Flis, Remigiusz Kinas, Krzysztof Wróbel, Adrian Gwoździej",bielik v3 small technical report,we introduce bielik v3 a series of parameterefficient generative text models 15b and 45b optimized for polish language processing these models demonstrate that smaller welloptimized architectures can achieve performance comparable to much larger counterparts while requiring substantially fewer computational resources our approach incorporates several key innovations a custom polish tokenizer apt4 that significantly improves token efficiency weighted instruction crossentropy loss to balance learning across instruction types and adaptive learning rate that dynamically adjusts based on training progress trained on a meticulously curated corpus of 292 billion tokens spanning 303 million documents these models excel across multiple benchmarks including the open pl llm leaderboard complex polish text understanding benchmark polish eqbench and polish medical leaderboard the 45b parameter model achieves results competitive with models 23 times its size while the 15b model delivers strong performance despite its extremely compact profile these advances establish new benchmarks for parameterefficient language modeling in lessrepresented languages making highquality polish language ai more accessible for resourceconstrained applications
http://arxiv.org/abs/2505.02518v1,2025-05-05T09:51:56Z,"Muhammad Hazim Al Farouq, Aman Kassahun Wassie, Yasmin Moslem",bemba speech translation exploring a lowresource african language,this paper describes our system submission to the international conference on spoken language translation iwslt 2025 lowresource languages track namely for bembatoenglish speech translation we built cascaded speech translation systems based on whisper and nllb200 and employed data augmentation techniques such as backtranslation we investigate the effect of using synthetic data and discuss our experimental setup
http://arxiv.org/abs/2505.02463v1,2025-05-05T08:47:52Z,"Richard Kimera, Dongnyeong Heo, Daniela N. Rim, Heeyoul Choi",data augmentation with back translation for low resource languages a case of english and luganda,in this paperwe explore the application of back translation bt as a semisupervised technique to enhance neural machine translationnmt models for the englishluganda language pair specifically addressing the challenges faced by lowresource languages the purpose of our study is to demonstrate how bt can mitigate the scarcity of bilingual data by generating synthetic data from monolingual corpora our methodology involves developing custom nmt models using both publicly available and webcrawled data and applying iterative and incremental back translation techniques we strategically select datasets for incremental back translation across multiple small datasets which is a novel element of our approach the results of our study show significant improvements with translation performance for the englishluganda pair exceeding previous benchmarks by more than 10 bleu score units across all translation directions additionally our evaluation incorporates comprehensive assessment metrics such as sacrebleu chrf2 and ter providing a nuanced understanding of translation quality the conclusion drawn from our research confirms the efficacy of bt when strategically curated datasets are utilized establishing new performance benchmarks and demonstrating the potential of bt in enhancing nmt models for lowresource languages
http://arxiv.org/abs/2505.02462v1,2025-05-05T08:45:26Z,"Enpei Zhang, Jingyi Chai, Rui Ye, Yanfeng Wang, Siheng Chen",incentivizing inclusive contributions in model sharing markets,while data plays a crucial role in training contemporary ai models it is acknowledged that valuable public data will be exhausted in a few years directing the worlds attention towards the massive decentralized private data however the privacysensitive nature of raw data and lack of incentive mechanism prevent these valuable data from being fully exploited addressing these challenges this paper proposes inclusive and incentivized personalized federated learning ipfl which incentivizes data holders with diverse purposes to collaboratively train personalized models without revealing raw data ipfl constructs a modelsharing market by solving a graphbased training optimization and incorporates an incentive mechanism based on game theory principles theoretical analysis shows that ipfl adheres to two key incentive properties individual rationality and truthfulness empirical studies on eleven ai tasks eg large language models instructionfollowing tasks demonstrate that ipfl consistently achieves the highest economic utility and better or comparable model performance compared to baseline methods we anticipate that our ipfl can serve as a valuable technique for boosting future ai models on decentralized private data while making everyone satisfied
http://arxiv.org/abs/2505.02456v1,2025-05-05T08:40:51Z,"Elisa Forcada Rodríguez, Olatz Perez-de-Viñaspre, Jon Ander Campos, Dietrich Klakow, Vagrant Gautam",colombian waitresses y jueces canadienses gender and country biases in occupation recommendations from llms,one of the goals of fairness research in nlp is to measure and mitigate stereotypical biases that are propagated by nlp systems however such work tends to focus on single axes of bias most often gender and the english language addressing these limitations we contribute the first study of multilingual intersecting country and gender biases with a focus on occupation recommendations generated by large language models we construct a benchmark of prompts in english spanish and german where we systematically vary country and gender using 25 countries and four pronoun sets then we evaluate a suite of 5 llamabased models on this benchmark finding that llms encode significant gender and country biases notably we find that even when models show parity for gender or country individually intersectional occupational biases based on both country and gender persist we also show that the prompting language significantly affects bias and instructiontuned models consistently demonstrate the lowest and most stable levels of bias our findings highlight the need for fairness researchers to use intersectional and multilingual lenses in their work
http://arxiv.org/abs/2505.02410v2,2025-05-05T07:03:41Z,"Krzysztof Ociepa, Łukasz Flis, Krzysztof Wróbel, Adrian Gwoździej, Remigiusz Kinas",bielik 11b v2 technical report,we present bielik 11b v2 a stateoftheart language model optimized for polish text processing built on the mistral 7b v02 architecture and scaled to 11b parameters using depth upscaling this model demonstrates exceptional performance across polish language benchmarks while maintaining strong crosslingual capabilities we introduce two key technical innovations weighted instruction crossentropy loss which optimizes learning across diverse instruction types by assigning qualitybased weights to training examples and adaptive learning rate which dynamically adjusts based on context length comprehensive evaluation across multiple benchmarks demonstrates that bielik 11b v2 outperforms many larger models including those with 26 times more parameters and significantly surpasses other specialized polish language models on tasks ranging from linguistic understanding to complex reasoning the models parameter efficiency and extensive quantization options enable deployment across various hardware configurations advancing polish language ai capabilities and establishing new benchmarks for resourceefficient language modeling in lessrepresented languages
http://arxiv.org/abs/2505.02391v1,2025-05-05T06:26:00Z,"Jiarui Yao, Yifan Hao, Hanning Zhang, Hanze Dong, Wei Xiong, Nan Jiang, Tong Zhang",optimizing chainofthought reasoners via gradient variance minimization in rejection sampling and rl,chainofthought cot reasoning in large language models llms can be formalized as a latent variable problem where the model needs to generate intermediate reasoning steps while prior approaches such as iterative rewardranked finetuning raft have relied on such formulations they typically apply uniform inference budgets across prompts which fails to account for variability in difficulty and convergence behavior this work identifies the main bottleneck in cot training as inefficient stochastic gradient estimation due to static sampling strategies we propose gvmraft a promptspecific dynamic sample allocation strategy designed to minimize stochastic gradient variance under a computational budget constraint the method dynamically allocates computational resources by monitoring prompt acceptance rates and stochastic gradient norms ensuring that the resulting gradient variance is minimized our theoretical analysis shows that the proposed dynamic sampling strategy leads to accelerated convergence guarantees under suitable conditions experiments on mathematical reasoning show that gvmraft achieves a 24x speedup and considerable accuracy improvements over vanilla raft the proposed dynamic sampling strategy is general and can be incorporated into other reinforcement learning algorithms such as grpo leading to similar improvements in convergence and test accuracy our code is available at httpsgithubcomrlhflowgvm
http://arxiv.org/abs/2505.02387v3,2025-05-05T06:11:12Z,"Xiusi Chen, Gaotang Li, Ziqi Wang, Bowen Jin, Cheng Qian, Yu Wang, Hongru Wang, Yu Zhang, Denghui Zhang, Tong Zhang, Hanghang Tong, Heng Ji",rmr1 reward modeling as reasoning,reward modeling is essential for aligning large language models with human preferences through reinforcement learning from human feedback to provide accurate reward signals a reward model rm should stimulate deep thinking and conduct interpretable reasoning before assigning a score or a judgment inspired by recent advances of long chainofthought on reasoningintensive tasks we hypothesize and validate that integrating reasoning capabilities into reward modeling significantly enhances rms interpretability and performance to this end we introduce a new class of generative reward models reasoning reward models reasrms which formulate reward modeling as a reasoning task we propose a reasoningoriented training pipeline and train a family of reasrms rmr1 rmr1 features a chainofrubrics cor mechanism selfgenerating samplelevel chat rubrics or mathcode solutions and evaluating candidate responses against them the training of rmr1 consists of two key stages 1 distillation of highquality reasoning chains and 2 reinforcement learning with verifiable rewards empirically our models achieve stateoftheart performance across three reward model benchmarks on average outperforming much larger openweight models eg informllama3170b and proprietary ones eg gpt4o by up to 49 beyond final performance we perform thorough empirical analyses to understand the key ingredients of successful reasrm training to facilitate future research we release six reasrm models along with code and data at httpsgithubcomrmr1uiucrmr1
http://arxiv.org/abs/2505.03839v1,2025-05-05T05:25:08Z,"Utsav Kumar Nareti, Soumi Chattopadhyay, Prolay Mallick, Suraj Kumar, Ayush Vikas Daga, Chandranath Adak, Adarsh Wase, Arjab Roy",an adaptive dataresilient multimodal framework for hierarchical multilabel book genre identification,identifying the finer details of a books genres enhances user experience by enabling efficient book discovery and personalized recommendations ultimately improving reader engagement and satisfaction it also provides valuable insights into market trends and consumer preferences allowing publishers and marketers to make datadriven decisions regarding book production and marketing strategies while traditional book genre classification methods primarily rely on review data or textual analysis incorporating additional modalities such as book covers blurbs and metadata can offer richer context and improve prediction accuracy however the presence of incomplete or noisy information across these modalities presents a significant challenge this paper introduces imagine intelligent multimodal adaptive genre identification network a framework designed to address these complexities imagine extracts robust feature representations from multiple modalities and dynamically selects the most informative sources based on data availability it employs a hierarchical classification strategy to capture genre relationships and remains adaptable to varying input conditions additionally we curate a hierarchical genre classification dataset that structures genres into a welldefined taxonomy accommodating the diverse nature of literary works imagine integrates information from multiple sources and assigns multiple genre labels to each book ensuring a more comprehensive classification a key feature of our framework is its resilience to incomplete data enabling accurate predictions even when certain modalities such as text images or metadata are missing or incomplete experimental results show that imagine outperformed existing baselines in genre classification accuracy particularly in scenarios with insufficient modalityspecific data
http://arxiv.org/abs/2505.02366v2,2025-05-05T05:09:21Z,"Tianyu Zong, Hongzhu Yi, Bingkang Shi, Yuanxiang Wang, Jungang Xu",jtcse joint tensormodulus constraints and crossattention for unsupervised contrastive learning of sentence embeddings,unsupervised contrastive learning has become a hot research topic in natural language processing existing works usually aim at constraining the orientation distribution of the representations of positive and negative samples in the highdimensional semantic space in contrastive learning but the semantic representation tensor possesses both modulus and orientation features and the existing works ignore the modulus feature of the representations and cause insufficient contrastive learning therefore we firstly propose a training objective that aims at modulus constraints on the semantic representation tensor to strengthen the alignment between the positive samples in contrastive learning therefore we first propose a training objective that is designed to impose modulus constraints on the semantic representation tensor to strengthen the alignment between positive samples in contrastive learning then the bertlike model suffers from the phenomenon of sinking attention leading to a lack of attention to cls tokens that aggregate semantic information in response we propose a crossattention structure among the twintower ensemble models to enhance the models attention to cls token and optimize the quality of cls pooling combining the above two motivations we propose a new textbfjoint textbftensor representation modulus constraint and textbfcrossattention unsupervised contrastive learning textbfsentence textbfembedding representation framework jtcse which we evaluate in seven semantic text similarity computation tasks and the experimental results show that jtcses twintower ensemble model and singletower distillation model outperform the other baselines and become the current sota in addition we have conducted an extensive zeroshot downstream task evaluation which shows that jtcse outperforms other baselines overall on more than 130 tasks
http://arxiv.org/abs/2505.02363v1,2025-05-05T04:54:44Z,"Tianjian Li, Daniel Khashabi",simplemix frustratingly simple mixing of off and onpolicy data in language model preference learning,aligning language models with human preferences relies on pairwise preference datasets while some studies suggest that onpolicy data consistently outperforms off policy data for preference learning others indicate that the advantages of onpolicy data may be taskdependent highlighting the need for a systematic exploration of their interplay in this work we show that onpolicy and offpolicy data offer complementary strengths in preference optimization onpolicy data is particularly effective for reasoning tasks like math and coding while offpolicy data performs better on openended tasks such as creative writing and making personal recommendations guided by these findings we introduce simplemix an approach to combine the complementary strengths of onpolicy and offpolicy preference learning by simply mixing these two data sources our empirical results across diverse tasks and benchmarks demonstrate that simplemix substantially improves language model alignment specifically simplemix improves upon onpolicy dpo and offpolicy dpo by an average of 603 on alpaca eval 20 moreover it outperforms prior approaches that are much more complex in combining on and offpolicy data such as hypo and dpomixp by an average of 305
http://arxiv.org/abs/2505.04642v1,2025-05-05T02:31:11Z,"Nischal Mandal, Yang Li",rethinking multimodal sentiment analysis a highaccuracy simplified fusion architecture,multimodal sentiment analysis a pivotal task in affective computing seeks to understand human emotions by integrating cues from language audio and visual signals while many recent approaches leverage complex attention mechanisms and hierarchical architectures we propose a lightweight yet effective fusionbased deep learning model tailored for utterancelevel emotion classification using the benchmark iemocap dataset which includes aligned text audioderived numeric features and visual descriptors we design a modalityspecific encoder using fully connected layers followed by dropout regularization the modalityspecific representations are then fused using simple concatenation and passed through a dense fusion layer to capture crossmodal interactions this streamlined architecture avoids computational overhead while preserving performance achieving a classification accuracy of 92 across six emotion categories our approach demonstrates that with careful feature engineering and modular design simpler fusion strategies can outperform or match more complex models particularly in resourceconstrained environments
http://arxiv.org/abs/2505.02311v1,2025-05-05T01:45:56Z,"Jihao Zhao, Chunlai Zhou, Biao Qin",invoke interfaces only when needed adaptive invocation for large language models in question answering,the collaborative paradigm of large and small language models lms effectively balances performance and cost yet its pivotal challenge lies in precisely pinpointing the moment of invocation when hallucinations arise in small lms previous optimization efforts primarily focused on postprocessing techniques which were separate from the reasoning process of lms resulting in high computational costs and limited effectiveness in this paper we propose a practical invocation evaluation metric called attenhscore which calculates the accumulation and propagation of hallucinations during the generation process of small lms continuously amplifying potential reasoning errors by dynamically adjusting the detection threshold we achieve more accurate realtime invocation of large lms additionally considering the limited reasoning capacity of small lms we leverage uncertaintyaware knowledge reorganization to assist them better capture critical information from different text chunks extensive experiments reveal that our attenhscore outperforms most baseline in enhancing realtime hallucination detection capabilities across multiple qa datasets especially when addressing complex queries moreover our strategies eliminate the need for additional model training and display flexibility in adapting to various transformerbased lms
http://arxiv.org/abs/2505.04640v1,2025-05-05T01:28:04Z,Hicham Assoudi,a comparative benchmark of a moroccan darija toxicity detection model typicaai and major llmbased moderation apis openai mistral anthropic,this paper presents a comparative benchmark evaluating the performance of typicaais custom moroccan darija toxicity detection model against major llmbased moderation apis openai omnimoderationlatest mistral mistralmoderationlatest and anthropic claude claude3haiku20240307 we focus on culturally grounded toxic content including implicit insults sarcasm and culturally specific aggression often overlooked by generalpurpose systems using a balanced test set derived from the omcdtypicaaimix dataset we report precision recall f1score and accuracy offering insights into challenges and opportunities for moderation in underrepresented languages our results highlight typicaais superior performance underlining the importance of culturally adapted models for reliable content moderation
http://arxiv.org/abs/2505.02309v2,2025-05-05T01:27:47Z,"Sanjay Surendranath Girija, Shashank Kapoor, Lakshit Arora, Dipen Pradhan, Aman Raj, Ankit Shetgaonkar",optimizing llms for resourceconstrained environments a survey of model compression techniques,large language models llms have revolutionized many areas of artificial intelligence ai but their substantial resource requirements limit their deployment on mobile and edge devices this survey paper provides a comprehensive overview of techniques for compressing llms to enable efficient inference in resourceconstrained environments we examine three primary approaches knowledge distillation model quantization and model pruning for each technique we discuss the underlying principles present different variants and provide examples of successful applications we also briefly discuss complementary techniques such as mixtureofexperts and earlyexit strategies finally we highlight promising future directions aiming to provide a valuable resource for both researchers and practitioners seeking to optimize llms for edge deployment
http://arxiv.org/abs/2505.02304v1,2025-05-05T00:57:57Z,"Siyu Liang, Yunan Li, Wentian Xin, Huizhou Chen, Xujie Liu, Kang Liu, Qiguang Miao",generative signdescription prompts with multipositive contrastive learning for sign language recognition,sign language recognition slr faces fundamental challenges in creating accurate annotations due to the inherent complexity of simultaneous manual and nonmanual signals to the best of our knowledge this is the first work to integrate generative large language models llms into slr tasks we propose a novel generative signdescription prompts multipositive contrastive learning gspmc method that leverages retrievalaugmented generation rag with domainspecific llms incorporating multistep prompt engineering and expertvalidated sign language corpora to produce precise multipart descriptions the gspmc method also employs a dualencoder architecture to bidirectionally align hierarchical skeleton features with multiple text descriptions global synonym and part level through probabilistic matching our approach combines global and partlevel losses optimizing kl divergence to ensure robust alignment across all relevant textskeleton pairs while capturing both signlevel semantics and detailed part dynamics experiments demonstrate stateoftheart performance against existing methods on the chinese slr500 reaching 971 and turkish autsl datasets 9707 accuracy the methods crosslingual effectiveness highlight its potential for developing inclusive communication technologies
http://arxiv.org/abs/2505.04639v1,2025-05-04T23:23:46Z,"Abhishek Mishra, Ritesh Sur Chowdhury, Vartul Bahuguna, Isha Pandey, Ganesh Ramakrishnan",language translation and change of accent for speechtospeech task using diffusion model,speechtospeech translation s2st aims to convert spoken input in one language to spoken output in another typically focusing on either language translation or accent adaptation however effective crosscultural communication requires handling both aspects simultaneously translating content while adapting the speakers accent to match the target language context in this work we propose a unified approach for simultaneous speech translation and change of accent a task that remains underexplored in current literature our method reformulates the problem as a conditional generation task where target speech is generated based on phonemes and guided by target speech features leveraging the power of diffusion models known for highfidelity generative capabilities we adapt texttoimage diffusion strategies by conditioning on source speech transcriptions and generating mel spectrograms representing the target speech with desired linguistic and accentual attributes this integrated framework enables joint optimization of translation and accent adaptation offering a more parameterefficient and effective model compared to traditional pipelines
http://arxiv.org/abs/2505.02273v1,2025-05-04T22:04:14Z,"Rimon Melamed, Lucas H. McCabe, H. Howie Huang",demystifying optimized prompts in language models,modern language models lms are not robust to outofdistribution inputs machine generated optimized prompts can be used to modulate lm outputs and induce specific behaviors while appearing completely uninterpretable in this work we investigate the composition of optimized prompts as well as the mechanisms by which lms parse and build predictions from optimized prompts we find that optimized prompts primarily consist of punctuation and noun tokens which are more rare in the training data internally optimized prompts are clearly distinguishable from natural language counterparts based on sparse subsets of the models activations across various families of instructiontuned models optimized prompts follow a similar path in how their representations form through the network
http://arxiv.org/abs/2505.02266v1,2025-05-04T21:47:18Z,"Henry Ndubuaku, Mouad Talhi",parameterefficient transformer embeddings,embedding layers in transformerbased nlp models typically account for the largest share of model parameters scaling with vocabulary size but not yielding performance gains proportional to scale we propose an alternative approach in which token embedding vectors are first generated deterministically directly from the token ids using a fourier expansion of their normalized values followed by a lightweight multilayer perceptron mlp that captures higherorder interactions we train standard transformers and our architecture on natural language inference tasks snli and mnli and evaluate zeroshot performance on sentence textual similarity stsb our results demonstrate that the proposed method achieves competitive performance using significantly fewer parameters trains faster and operates effectively without the need for dropout this proofofconcept study highlights the potential for scalable memoryefficient language models and motivates further largescale experimentation based on our findings
http://arxiv.org/abs/2505.02252v1,2025-05-04T21:22:20Z,"Paloma Piot, Patricia Martín-Rodilla, Javier Parapar",personalisation or prejudice addressing geographic bias in hate speech detection using debias tuning in large language models,commercial large language models llms have recently incorporated memory features to deliver personalised responses this memory retains details such as user demographics and individual characteristics allowing llms to adjust their behaviour based on personal information however the impact of integrating personalised information into the context has not been thoroughly assessed leading to questions about its influence on llm behaviour personalisation can be challenging particularly with sensitive topics in this paper we examine various stateoftheart llms to understand their behaviour in different personalisation scenarios specifically focusing on hate speech we prompt the models to assume countryspecific personas and use different languages for hate speech detection our findings reveal that context personalisation significantly influences llms responses in this sensitive area to mitigate these unwanted biases we finetune the llms by penalising inconsistent hate speech classifications made with and without country or languagespecific context the refined models demonstrate improved performance in both personalised contexts and when no context is provided
http://arxiv.org/abs/2505.02235v1,2025-05-04T20:16:08Z,"Tanguy Herserant, Vincent Guigue",sevalex a statementlevel framework for explainable summarization evaluation,evaluating text summarization quality remains a critical challenge in natural language processing current approaches face a tradeoff between performance and interpretability we present sevalex a framework that bridges this gap by decomposing summarization evaluation into atomic statements enabling both high performance and explainability sevalex employs a twostage pipeline first extracting atomic statements from text source and summary using llm then a matching between generated statements unlike existing approaches that provide only summarylevel scores our method generates detailed evidence for its decisions through statementlevel alignments experiments on the summeval benchmark demonstrate that sevalex achieves stateoftheart performance with 0580 correlation on consistency with human consistency judgments surpassing gpt4 based evaluators 0521 while maintaining interpretability finally our framework shows robustness against hallucination
http://arxiv.org/abs/2505.02215v1,2025-05-04T18:57:57Z,Mannan Bhardwaj,interpretable emergent language using interagent transformers,this paper explores the emergence of language in multiagent reinforcement learning marl using transformers existing methods such as rial dial and commnet enable agent communication but lack interpretability we propose differentiable interagent transformers diat which leverage selfattention to learn symbolic humanunderstandable communication protocols through experiments diat demonstrates the ability to encode observations into interpretable vocabularies and meaningful embeddings effectively solving cooperative tasks these results highlight the potential of diat for interpretable communication in complex multiagent environments
http://arxiv.org/abs/2505.02206v1,2025-05-04T18:02:28Z,"Lei Mao, Yuanhe Tian, Yan Song",dnazen enhanced gene sequence representations via mixed granularities of coding units,genome modeling conventionally treats gene sequence as a language reflecting its structured motifs and longrange dependencies analogous to linguistic units and organization principles such as words and syntax recent studies utilize advanced neural networks ranging from convolutional and recurrent models to transformerbased models to capture contextual information of gene sequence with the primary goal of obtaining effective gene sequence representations and thus enhance the models understanding of various running gene samples however these approaches often directly apply language modeling techniques to gene sequences and do not fully consider the intrinsic information organization in them where they do not consider how units at different granularities contribute to representation in this paper we propose dnazen an enhanced genomic representation framework designed to learn from various granularities in gene sequences including small polymers and ggrams that are combinations of several contiguous polymers specifically we extract the ggrams from largescale genomic corpora through an unsupervised approach to construct the ggram vocabulary which is used to provide ggrams in the learning process of dna sequences through dynamically matching from running gene samples a transformerbased ggram encoder is also proposed and the matched ggrams are fed into it to compute their representations and integrated into the encoder for basic unit e4bu which is responsible for encoding small units and maintaining the learning and inference process to further enhance the learning process we propose whole ggram masking to train dnazen where the model largely favors the selection of each entire ggram to mask rather than an ordinary masking mechanism performed on basic units experiments on benchmark datasets demonstrate the effectiveness of dnazen on various downstream tasks
http://arxiv.org/abs/2505.02199v1,2025-05-04T17:37:26Z,"Manak Raj, Nidhi Mishra",exploring new approaches for information retrieval through natural language processing,this review paper explores recent advancements and emerging approaches in information retrieval ir applied to natural language processing nlp we examine traditional ir models such as boolean vector space probabilistic and inference network models and highlight modern techniques including deep learning reinforcement learning and pretrained transformer models like bert we discuss key tools and libraries lucene anserini and pyserini for efficient text indexing and search a comparative analysis of sparse dense and hybrid retrieval methods is presented along with applications in web search engines crosslanguage ir argument mining private information retrieval and hate speech detection finally we identify open challenges and future research directions to enhance retrieval accuracy scalability and ethical considerations
http://arxiv.org/abs/2505.02177v1,2025-05-04T16:39:12Z,"Chuxue Cao, Zhenghao Zhu, Junqi Zhu, Guoying Lu, Siyu Peng, Juntao Dai, Weijie Shi, Sirui Han, Yike Guo",measuring hong kong massive multitask language understanding,multilingual understanding is crucial for the crosscultural applicability of large language models llms however evaluation benchmarks designed for hong kongs unique linguistic landscape which combines traditional chinese script with cantonese as the spoken form and its cultural context remain underdeveloped to address this gap we introduce hkmmlu a multitask language understanding benchmark that evaluates hong kongs linguistic competence and sociocultural knowledge the hkmmlu includes 26698 multichoice questions across 66 subjects organized into four categories science technology engineering and mathematics stem social sciences humanities and other to evaluate the multilingual understanding ability of llms 90550 mandarincantonese translation tasks were additionally included we conduct comprehensive experiments on gpt4o claude 37 sonnet and 18 opensource llms of varying sizes on hkmmlu the results show that the bestperforming model deepseekv3 struggles to achieve an accuracy of 75 significantly lower than that of mmlu and cmmlu this performance gap highlights the need to improve llms capabilities in hong kongspecific language and knowledge domains furthermore we investigate how question language model size prompting strategies and question and reasoning token lengths affect model performance we anticipate that hkmmlu will significantly advance the development of llms in multilingual and crosscultural contexts thereby enabling broader and more impactful applications
http://arxiv.org/abs/2505.02172v1,2025-05-04T16:24:12Z,Chuck Arvin,identifying legal holdings with llms a systematic study of performance scale and memorization,as large language models llms continue to advance in capabilities it is essential to assess how they perform on established benchmarks in this study we present a suite of experiments to assess the performance of modern llms ranging from 3b to 90b parameters on casehold a legal benchmark dataset for identifying case holdings our experiments demonstrate scaling effects performance on this task improves with model size with more capable models like gpt4o and amazonnovapro achieving macro f1 scores of 0744 and 0720 respectively these scores are competitive with the best published results on this dataset and do not require any technically sophisticated model training finetuning or fewshot prompting to ensure that these strong results are not due to memorization of judicial opinions contained in the training data we develop and utilize a novel citation anonymization test that preserves semantic meaning while ensuring case names and citations are fictitious models maintain strong performance under these conditions macro f1 of 0728 suggesting the performance is not due to rote memorization these findings demonstrate both the promise and current limitations of llms for legal tasks with important implications for the development and measurement of automated legal analytics and legal benchmarks
http://arxiv.org/abs/2505.02171v1,2025-05-04T16:22:27Z,"Henrik Brådland, Morten Goodwin, Per-Arne Andersen, Alexander S. Nossum, Aditya Gupta",a new hope domainagnostic automatic evaluation of text chunking,document chunking fundamentally impacts retrievalaugmented generation rag by determining how source materials are segmented before indexing despite evidence that large language models llms are sensitive to the layout and structure of retrieved data there is currently no framework to analyze the impact of different chunking methods in this paper we introduce a novel methodology that defines essential characteristics of the chunking process at three levels intrinsic passage properties extrinsic passage properties and passagesdocument coherence we propose hope holistic passage evaluation a domainagnostic automatic evaluation metric that quantifies and aggregates these characteristics our empirical evaluations across seven domains demonstrate that the hope metric correlates significantly p 013 with various rag performance indicators revealing contrasts between the importance of extrinsic and intrinsic properties of passages semantic independence between passages proves essential for system performance with a performance gain of up to 562 in factual correctness and 211 in answer correctness on the contrary traditional assumptions about maintaining concept unity within passages show minimal impact these findings provide actionable insights for optimizing chunking strategies thus improving rag system design to produce more factually correct responses
http://arxiv.org/abs/2505.02164v1,2025-05-04T15:53:49Z,"Justin Ho, Alexandra Colby, William Fisher",incorporating legal structure in retrievalaugmented generation a case study on copyright fair use,this paper presents a domainspecific implementation of retrievalaugmented generation rag tailored to the fair use doctrine in us copyright law motivated by the increasing prevalence of dmca takedowns and the lack of accessible legal support for content creators we propose a structured approach that combines semantic search with legal knowledge graphs and court citation networks to improve retrieval quality and reasoning reliability our prototype models legal precedents at the statutory factor level eg purpose nature amount market effect and incorporates citationweighted graph representations to prioritize doctrinally authoritative sources we use chainofthought reasoning and interleaved retrieval steps to better emulate legal reasoning preliminary testing suggests this method improves doctrinal relevance in the retrieval process laying groundwork for future evaluation and deployment of llmbased legal assistance tools
http://arxiv.org/abs/2505.02156v2,2025-05-04T15:39:58Z,"Minzheng Wang, Yongbin Li, Haobo Wang, Xinghua Zhang, Nan Xu, Bingli Wu, Fei Huang, Haiyang Yu, Wenji Mao",think on your feet adaptive thinking via reinforcement learning for social agents,effective social intelligence simulation requires language agents to dynamically adjust reasoning depth a capability notably absent in current approaches while existing methods either lack this kind of reasoning capability or enforce uniform long chainofthought reasoning across all scenarios resulting in excessive token usage and inappropriate social simulation in this paper we propose daptive ode earning that strategically selects from four thinking modes intuitive reaction deep contemplation based on realtime context our frameworks core innovation the daptive ode olicy ptimization algorithm introduces three key advancements over existing methods 1 multigranular thinking mode design 2 contextaware mode switching across social interaction and 3 tokenefficient reasoning via depthadaptive processing extensive experiments on social intelligence tasks confirm that aml achieves 156 higher task performance than stateoftheart methods notably our method outperforms grpo by 70 with 328 shorter reasoning chains these results demonstrate that contextsensitive thinking mode selection as implemented in ampo enables more humanlike adaptive reasoning than grpos fixeddepth approach
http://arxiv.org/abs/2505.02146v1,2025-05-04T15:14:27Z,"Shouyang Dong, Yuanbo Wen, Jun Bi, Di Huang, Jiaming Guo, Jianxing Xu, Ruibai Xu, Xinkai Song, Yifan Hao, Xuehai Zhou, Tianshi Chen, Qi Guo, Yunji Chen",qimengxpiler transcompiling tensor programs for deep learning systems with a neuralsymbolic approach,heterogeneous deep learning systems dls such as gpus and asics have been widely deployed in industrial data centers which requires to develop multiple lowlevel tensor programs for different platforms an attractive solution to relieve the programming burden is to transcompile the legacy code of one platform to others however current transcompilation techniques struggle with either tremendous manual efforts or functional incorrectness rendering write once run anywhere of tensor programs an open question we propose a novel transcompiler ie qimengxpiler for automatically translating tensor programs across dls via both large language models llms and symbolic program synthesis ie neuralsymbolic synthesis the key insight is leveraging the powerful code generation ability of llm to make costly searchbased symbolic synthesis computationally tractable concretely we propose multiple llmassisted compilation passes via predefined metaprompts for program transformation during each program transformation efficient symbolic program synthesis is employed to repair incorrect code snippets with a limited scale to attain high performance we propose a hierarchical autotuning approach to systematically explore both the parameters and sequences of transformation passes experiments on 4 dls with distinct programming interfaces ie intel dl boost with vnni nvidia gpu with cuda amd mi with hip and cambricon mlu with bang demonstrate that qimengxpiler correctly translates different tensor programs at the accuracy of 95 on average and the performance of translated programs achieves up to 20x over vendorprovided manuallyoptimized libraries as a result the programming productivity of dls is improved by up to 960x via transcompiling legacy tensor programs
http://arxiv.org/abs/2505.02142v1,2025-05-04T15:09:49Z,"Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li",exploring the potential of offline rl for reasoning in llms a preliminary study,despite significant advances in longcontext reasoning by large language models llms primarily through online reinforcement learning rl methods these approaches incur substantial computational costs and complexity in contrast simpler and more economical offline rl methods remain underexplored to address this gap we investigate the effectiveness of offline rl methods specifically direct preference optimization dpo and its lengthdesensitized variant lddpo in enhancing the reasoning capabilities of llms extensive experiments across multiple reasoning benchmarks demonstrate that these simpler offline rl methods substantially improve model performance achieving an average enhancement of 33 with a particularly notable increase of 101 on the challenging arenahard benchmark furthermore we analyze dpos sensitivity to output length emphasizing that increasing reasoning length should align with semantic richness as indiscriminate lengthening may adversely affect model performance we provide comprehensive descriptions of our data processing and training methodologies offering empirical evidence and practical insights for developing more costeffective offline rl approaches
http://arxiv.org/abs/2505.02130v1,2025-05-04T14:40:31Z,"Zhong Guan, Likang Wu, Hongke Zhao, Ming He, Jianpin Fan",attention mechanisms perspective exploring llm processing of graphstructured data,attention mechanisms are critical to the success of large language models llms driving significant advancements in multiple fields however for graphstructured data which requires emphasis on topological connections they fall short compared to messagepassing mechanisms on fixed links such as those employed by graph neural networks gnns this raises a question does attention fail for graphs in natural language settings motivated by these observations we embarked on an empirical study from the perspective of attention mechanisms to explore how llms process graphstructured data the goal is to gain deeper insights into the attention behavior of llms over graph structures we uncovered unique phenomena regarding how llms apply attention to graphstructured data and analyzed these findings to improve the modeling of such data by llms the primary findings of our research are 1 while llms can recognize graph data and capture textnode interactions they struggle to model internode relationships within graph structures due to inherent architectural constraints 2 the attention distribution of llms across graph nodes does not align with ideal structural patterns indicating a failure to adapt to graph topology nuances 3 neither fully connected attention nor fixed connectivity is optimal each has specific limitations in its application scenarios instead intermediatestate attention windows improve llm training performance and seamlessly transition to fully connected windows during inference source code hrefhttpsgithubcommillionironllmexplorationllm4exploration
http://arxiv.org/abs/2505.02872v1,2025-05-04T13:23:48Z,"Cfir Avraham Hadar, Omer Shubi, Yoav Meiri, Yevgeni Berzak",decoding openended information seeking goals from eye movements in reading,when reading we often have specific information that interests us in a text for example you might be reading this paper because you are curious about llms for eye movements in reading the experimental design or perhaps you only care about the question but does it work more broadly in daily life people approach texts with any number of textspecific goals that guide their reading behavior in this work we ask for the first time whether openended reading goals can be automatically decoded from eye movements in reading to address this question we introduce goal classification and goal reconstruction tasks and evaluation frameworks and use largescale eye tracking for reading data in english with hundreds of textspecific information seeking tasks we develop and compare several discriminative and generative multimodal llms that combine eye movements and text for goal classification and goal reconstruction our experiments show considerable success on both tasks suggesting that llms can extract valuable information about the readers textspecific goals from eye movements
http://arxiv.org/abs/2505.02091v1,2025-05-04T12:53:04Z,"Xinyue Peng, Yanming Liu, Yihan Cang, Chaoqun Cao, Ming Chen",llmoptira llmdriven optimization of resource allocation for nonconvex problems in wireless communications,solving nonconvex resource allocation problems poses significant challenges in wireless communication systems often beyond the capability of traditional optimization techniques to address this issue we propose llmoptira the first framework that leverages large language models llms to automatically detect and transform nonconvex components into solvable forms enabling fully automated resolution of nonconvex resource allocation problems in wireless communication systems llmoptira not only simplifies problemsolving by reducing reliance on expert knowledge but also integrates error correction and feasibility validation mechanisms to ensure robustness experimental results show that llmoptira achieves an execution rate of 96 and a success rate of 80 on gpt4 significantly outperforming baseline approaches in complex optimization tasks across diverse scenarios
http://arxiv.org/abs/2505.02078v1,2025-05-04T12:06:47Z,"Joy Lim Jia Yin, Daniel Zhang-Li, Jifan Yu, Haoxuan Li, Shangqing Tu, Yuanchun Wang, Zhiyuan Liu, Huiqin Liu, Lei Hou, Juanzi Li, Bin Xu",leceval an automated metric for multimodal knowledge acquisition in multimedia learning,evaluating the quality of slidebased multimedia instruction is challenging existing methods like manual assessment referencebased metrics and large language model evaluators face limitations in scalability context capture or bias in this paper we introduce leceval an automated metric grounded in mayers cognitive theory of multimedia learning to evaluate multimodal knowledge acquisition in slidebased learning leceval assesses effectiveness using four rubrics content relevance cr expressive clarity ec logical structure ls and audience engagement ae we curate a largescale dataset of over 2000 slides from more than 50 online course videos annotated with finegrained human ratings across these rubrics a model trained on this dataset demonstrates superior accuracy and adaptability compared to existing metrics bridging the gap between automated and human assessments we release our dataset and toolkits at httpsgithubcomjoylimjyleceval
http://arxiv.org/abs/2505.02072v1,2025-05-04T11:46:48Z,"Eitan Wagner, Omri Abend",what do language model probabilities represent from distribution estimation to response prediction,the notion of language modeling has gradually shifted in recent years from a distribution over finitelength strings to generalpurpose prediction models for textual inputs and outputs following appropriate alignment phases this paper analyzes the distinction between distribution estimation and response prediction in the context of llms and their often conflicting goals we examine the training phases of llms which include pretraining incontext learning and preference tuning and also the common use cases for their output probabilities which include completion probabilities and explicit probabilities as output we argue that the different settings lead to three distinct intended output distributions we demonstrate that nlp works often assume that these distributions should be similar which leads to misinterpretations of their experimental findings our work sets firmer formal foundations for the interpretation of llms which will inform ongoing work on the interpretation and use of llms induced distributions
http://arxiv.org/abs/2505.02032v1,2025-05-04T08:43:00Z,Anisia Katinskaia,an overview of artificial intelligence in computerassisted language learning,computerassisted language learning call is an established research field we review how artificial intelligence can be applied to support language learning and teaching the need for intelligent agents that assist language learners and teachers is increasing the human teachers time is a scarce and costly resource which does not scale with growing demand further factors contribute to the need for call pandemics and increasing demand for distance learning migration of large populations the need for sustainable and affordable support for learning etc call systems are made up of many components that perform various functions and ai is applied to many different aspects in call corresponding to their own expansive research areas most of what we find in the research literature and in practical use are prototypes or partial implementations systems that perform some aspects of the overall desired functionality complete solutions most of them commercial are few because they require massive resources recent advances in ai should result in improvements in call yet there is a lack of surveys that focus on ai in the context of this research field this paper aims to present a perspective on the ai methods that can be employed for language learning from a position of a developer of a call system we also aim to connect work from different disciplines to build bridges for interdisciplinary work
http://arxiv.org/abs/2505.02009v1,2025-05-04T06:37:20Z,"Sai Krishna Mendu, Harish Yenala, Aditi Gulati, Shanu Kumar, Parag Agrawal",towards safer pretraining analyzing and filtering harmful content in webscale datasets for responsible llms,large language models llms have become integral to various realworld applications leveraging massive websourced datasets like common crawl c4 and fineweb for pretraining while these datasets provide linguistic data essential for highquality natural language generation they often contain harmful content such as hate speech misinformation and biased narratives training llms on such unfiltered data risks perpetuating toxic behaviors spreading misinformation and amplifying societal biases which can undermine trust in llmdriven applications and raise ethical concerns about their use this paper presents a largescale analysis of inappropriate content across these datasets offering a comprehensive taxonomy that categorizes harmful webpages into topical and toxic based on their intent we also introduce a prompt evaluation dataset a highaccuracy topical and toxic prompt ttp and a transformerbased model harmformer for content filtering additionally we create a new multiharm openended toxicity benchmark havoc and provide crucial insights into how models respond to adversarial toxic inputs upon publishing we will also opensource our model signal on the entire c4 dataset our work offers insights into ensuring safer llm pretraining and serves as a resource for responsible ai rai compliance
http://arxiv.org/abs/2505.01980v1,2025-05-04T04:00:53Z,"Theo Guidroz, Diego Ardila, Jimmy Li, Adam Mansour, Paul Jhun, Nina Gonzalez, Xiang Ji, Mike Sanchez, Sujay Kakarmath, Mathias MJ Bellaiche, Miguel Ángel Garrido, Faruk Ahmed, Divyansh Choudhary, Jay Hartford, Chenwei Xu, Henry Javier Serrano Echeverria, Yifan Wang, Jeff Shaffer,  Eric,  Cao, Yossi Matias, Avinatan Hassidim, Dale R Webster, Yun Liu, Sho Fujiwara, Peggy Bui, Quang Duong",llmbased text simplification and its effect on user comprehension and cognitive load,information on the web such as scientific publications and wikipedia often surpasses users reading level to help address this we used a selfrefinement approach to develop a llm capability for minimally lossy text simplification to validate our approach we conducted a randomized study involving 4563 participants and 31 texts spanning 6 broad subject areas pubmed biomedical scientific articles biology law finance literaturephilosophy and aerospacecomputer science participants were randomized to viewing original or simplified texts in a subject area and answered multiplechoice questions mcqs that tested their comprehension of the text the participants were also asked to provide qualitative feedback such as task difficulty our results indicate that participants who read the simplified text answered more mcqs correctly than their counterparts who read the original text 39 absolute increase p005 this gain was most striking with pubmed 146 while more moderate gains were observed for finance 55 aerospacecomputer science 38 domains and legal 35 notably the results were robust to whether participants could refer back to the text while answering mcqs the absolute accuracy decreased by up to 9 for both original and simplified setups where participants could not refer back to the text but the 4 overall improvement persisted finally participants selfreported perceived ease based on a simplified nasa task load index was greater for those who read the simplified text absolute change on a 5point scale 033 p005 this randomized study involving an order of magnitude more participants than prior works demonstrates the potential of llms to make complex information easier to understand our work aims to enable a broader audience to better learn and make use of expert knowledge available on the web improving information accessibility
http://arxiv.org/abs/2505.01967v1,2025-05-04T02:35:24Z,"Jiatao Li, Yanheng Li, Xiaojun Wan",analyzing cognitive differences among large language models through the lens of social worldview,large language models llms have become integral to daily life widely adopted in communication decisionmaking and information retrieval raising critical questions about how these systems implicitly form and express sociocognitive attitudes or worldviews while existing research extensively addresses demographic and ethical biases broader dimensionssuch as attitudes toward authority equality autonomy and fateremain underexplored in this paper we introduce the social worldview taxonomy swt a structured framework grounded in cultural theory operationalizing four canonical worldviews hierarchy egalitarianism individualism fatalism into measurable subdimensions using swt we empirically identify distinct and interpretable cognitive profiles across 28 diverse llms further inspired by social referencing theory we experimentally demonstrate that explicit social cues systematically shape these cognitive attitudes revealing both general response patterns and nuanced modelspecific variations our findings enhance the interpretability of llms by revealing implicit sociocognitive biases and their responsiveness to social feedback thus guiding the development of more transparent and socially responsible language technologies
http://arxiv.org/abs/2505.01958v1,2025-05-04T01:47:58Z,"Liqiang Jing, Guiming Hardy Chen, Ehsan Aghazadeh, Xin Eric Wang, Xinya Du",a comprehensive analysis for visual object hallucination in large visionlanguage models,large visionlanguage models lvlms demonstrate remarkable capabilities in multimodal tasks but visual object hallucination remains a persistent issue it refers to scenarios where models generate inaccurate visual objectrelated information based on the query input potentially leading to misinformation and concerns about safety and reliability previous works focus on the evaluation and mitigation of visual hallucinations but the underlying causes have not been comprehensively investigated in this paper we analyze each component of llavalike lvlms the large language model the vision backbone and the projector to identify potential sources of error and their impact based on our observations we propose methods to mitigate hallucination for each problematic component additionally we developed two hallucination benchmarks qavisualgenome which emphasizes attribute and relation hallucinations and qafb15k which focuses on cognitionbased hallucinations
http://arxiv.org/abs/2505.01944v1,2025-05-03T23:18:05Z,"Matteo Cristani, Guido Governatori, Francesco Olivieri, Monica Palmirani, Gabriele Buriola",explainability by design an experimental analysis of the legal coding process,behind a set of rules in deontic defeasible logic there is a mapping process of normative background fragments this process goes from text to rules and implicitly encompasses an explanation of the coded fragments in this paper we deliver a methodology for textitlegal coding that starts with a fragment and goes onto a set of deontic defeasible logic rules involving a set of textitscenarios to test the correctness of the coded fragments the methodology is illustrated by the coding process of an example text we then show the results of a series of experiments conducted with humans encoding a variety of normative backgrounds and corresponding cases in which we have measured the efforts made in the coding process as related to some measurable features to process these examples a recently developed technology houdini that allows reasoning in deontic defeasible logic has been employed finally we provide a technique to forecast time required in coding that depends on factors such as knowledge of the legal domain knowledge of the coding processes length of the text and a measure of textitdepth that refers to the length of the paths of legal references
http://arxiv.org/abs/2505.03828v1,2025-05-03T19:36:27Z,Yogesh Gajula,sentimentaware recommendation systems in ecommerce a review from a natural language processing perspective,ecommerce platforms generate vast volumes of user feedback such as star ratings written reviews and comments however most recommendation engines rely primarily on numerical scores often overlooking the nuanced opinions embedded in free text this paper comprehensively reviews sentimentaware recommendation systems from a natural language processing perspective covering advancements from 2023 to early 2025 it highlights the benefits of integrating sentiment analysis into ecommerce recommenders to enhance prediction accuracy and explainability through detailed opinion extraction our survey categorizes recent work into four main approaches deep learning classifiers that combine sentiment embeddings with user item interactions transformer based methods for nuanced feature extraction graph neural networks that propagate sentiment signals and conversational recommenders that adapt in real time to user feedback we summarize model architectures and demonstrate how sentiment flows through recommendation pipelines impacting dialoguebased suggestions key challenges include handling noisy or sarcastic text dynamic user preferences and bias mitigation finally we outline research gaps and provide a roadmap for developing smarter fairer and more usercentric recommendation tools
http://arxiv.org/abs/2505.01900v1,2025-05-03T19:14:24Z,"Mazal Bethany, Nishant Vishwamitra, Cho-Yu Jason Chiang, Peyman Najafirad",camouflage exploiting misinformation detection systems through llmdriven adversarial claim transformation,automated evidencebased misinformation detection systems which evaluate the veracity of short claims against evidence lack comprehensive analysis of their adversarial vulnerabilities existing blackbox textbased adversarial attacks are illsuited for evidencebased misinformation detection systems as these attacks primarily focus on tokenlevel substitutions involving gradient or logitbased optimization strategies which are incapable of fooling the multicomponent nature of these detection systems these systems incorporate both retrieval and claimevidence comparison modules which requires attacks to break the retrieval of evidence andor the comparison module so that it draws incorrect inferences we present camouflage an iterative llmdriven approach that employs a twoagent system a prompt optimization agent and an attacker agent to create adversarial claim rewritings that manipulate evidence retrieval and mislead claimevidence comparison effectively bypassing the system without altering the meaning of the claim the attacker agent produces semantically equivalent rewrites that attempt to mislead detectors while the prompt optimization agent analyzes failed attack attempts and refines the prompt of the attacker to guide subsequent rewrites this enables larger structural and stylistic transformations of the text rather than tokenlevel substitutions adapting the magnitude of changes based on previous outcomes unlike existing approaches camouflage optimizes its attack solely based on binary model decisions to guide its rewriting process eliminating the need for classifier logits or extensive querying we evaluate camouflage on four systems including two recent academic systems and two realworld apis with an average attack success rate of 4692 while preserving textual coherence and semantic equivalence to the original claims
http://arxiv.org/abs/2505.01883v1,2025-05-03T18:04:57Z,"Yiwen Lu, Siheng Xiong, Zhaowei Li",automated sentiment classification and topic discovery in largescale social media streams,we present a framework for largescale sentiment and topic analysis of twitter discourse our pipeline begins with targeted data collection using conflictspecific keywords followed by automated sentiment labeling via multiple pretrained models to improve annotation robustness we examine the relationship between sentiment and contextual features such as timestamp geolocation and lexical content to identify latent themes we apply latent dirichlet allocation lda on partitioned subsets grouped by sentiment and metadata attributes finally we develop an interactive visualization interface to support exploration of sentiment trends and topic distributions across time and regions this work contributes a scalable methodology for social media analysis in dynamic geopolitical contexts
http://arxiv.org/abs/2505.01877v3,2025-05-03T17:42:49Z,"Jiří Milička, Anna Marklová, Ondřej Drobil, Eva Pospíšilová",humans can learn to detect aigenerated texts or at least learn when they cant,this study investigates whether individuals can learn to accurately discriminate between humanwritten and aiproduced texts when provided with immediate feedback and if they can use this feedback to recalibrate their selfperceived competence we also explore the specific criteria individuals rely upon when making these decisions focusing on textual style and perceived readability we used gpt4o to generate several hundred texts across various genres and text types comparable to koditex a multiregister corpus of humanwritten texts we then presented randomized text pairs to 254 czech native speakers who identified which text was humanwritten and which was aigenerated participants were randomly assigned to two conditions one receiving immediate feedback after each trial the other receiving no feedback until experiment completion we recorded accuracy in identification confidence levels response times and judgments about text readability along with demographic data and participants engagement with ai technologies prior to the experiment participants receiving immediate feedback showed significant improvement in accuracy and confidence calibration participants initially held incorrect assumptions about aigenerated text features including expectations about stylistic rigidity and readability notably without feedback participants made the most errors precisely when feeling most confident an issue largely resolved among the feedback group the ability to differentiate between human and aigenerated texts can be effectively learned through targeted training with explicit feedback which helps correct misconceptions about ai stylistic features and readability as well as potential other variables that were not explored while facilitating more accurate selfassessment this finding might be particularly important in educational contexts
http://arxiv.org/abs/2505.01868v1,2025-05-03T17:17:05Z,"Mo Sun, Siheng Xiong, Yuankai Cai, Bowen Zuo",positional attention for efficient bertbased named entity recognition,this paper presents a framework for named entity recognition ner leveraging the bidirectional encoder representations from transformers bert model in natural language processing nlp ner is a fundamental task in nlp with broad applicability across downstream applications while bert has established itself as a stateoftheart model for entity recognition finetuning it from scratch for each new application is computationally expensive and timeconsuming to address this we propose a costefficient approach that integrates positional attention mechanisms into the entity recognition process and enables effective customization using pretrained parameters the framework is evaluated on a kaggle dataset derived from the groningen meaning bank corpus and achieves strong performance with fewer training epochs this work contributes to the field by offering a practical solution for reducing the training cost of bertbased ner systems while maintaining high accuracy
http://arxiv.org/abs/2505.01855v1,2025-05-03T16:16:55Z,"Anthony Nguyen, Wenjun Lin",intralayer recurrence in transformers for language modeling,transformer models have established new benchmarks in natural language processing however their increasing depth results in substantial growth in parameter counts while existing recurrent transformer methods address this issue by reprocessing layers multiple times they often apply recurrence indiscriminately across entire blocks of layers in this work we investigate intralayer recurrence ilr a more targeted approach that applies recurrence selectively to individual layers within a single forward pass our experiments show that allocating more iterations to earlier layers yields optimal results these findings suggest that ilr offers a promising direction for optimizing recurrent structures in transformer architectures
http://arxiv.org/abs/2505.04638v1,2025-05-03T14:21:48Z,"Tianyu Liu, Simeng Han, Xiao Luo, Hanchen Wang, Pan Lu, Biqing Zhu, Yuge Wang, Keyi Li, Jiapeng Chen, Rihao Qu, Yufeng Liu, Xinyue Cui, Aviv Yaish, Yuhang Chen, Minsheng Hao, Chuhan Li, Kexing Li, Arman Cohan, Hua Xu, Mark Gerstein, James Zou, Hongyu Zhao",towards artificial intelligence research assistant for expertinvolved learning,large language models llms and large multimodal models lmms have emerged as transformative tools in scientific research yet their reliability and specific contributions to biomedical applications remain insufficiently characterized in this study we present textbfartificial textbfintelligence research assistant for textbfexpertinvolved textbflearning ariel a multimodal dataset designed to benchmark and enhance two critical capabilities of llms and lmms in biomedical research summarizing extensive scientific texts and interpreting complex biomedical figures to facilitate rigorous assessment we create two opensource sets comprising biomedical articles and figures with designed questions we systematically benchmark both open and closedsource foundation models incorporating expertdriven human evaluations conducted by doctorallevel experts furthermore we improve model performance through targeted prompt engineering and finetuning strategies for summarizing research papers and apply testtime computational scaling to enhance the reasoning capabilities of lmms achieving superior accuracy compared to humanexpert corrections we also explore the potential of using lmm agents to generate scientific hypotheses from diverse multimodal inputs overall our results delineate clear strengths and highlight significant limitations of current foundation models providing actionable insights and guiding future advancements in deploying largescale language and multimodal models within biomedical research
http://arxiv.org/abs/2505.01812v1,2025-05-03T12:49:35Z,"Core Francisco Park, Zechen Zhang, Hidenori Tanaka",system2 finetuning for robust integration of new knowledge,humans and intelligent animals can effortlessly internalize new information news and accurately extract the implications for performing downstream tasks while large language models llms can achieve this through incontext learning icl when the news is explicitly given as context finetuning remains challenging for the models to consolidate learning in weights in this paper we introduce a dataset composed of hypothetical yet plausible news spanning multiple domains mathematics coding discoveries leaderboards events accompanied by downstream evaluation questions whose correct answers critically depend on understanding and internalizing the news we first demonstrate a substantial gap between naive finetuning and incontext learning fticl gap on our news dataset to address this gap we explore a suite of selfplay data generation protocols paraphrases implications and selfqas designed to distill the knowledge from the model with context into the weights of the model without the context which we term textitsystem2 finetuning sys2ft we systematically evaluate icl and sys2ft performance across data domains and model scales with the qwen 25 family of models our results demonstrate that the selfqa protocol of sys2ft significantly improves models inweight learning of the news furthermore we discover the where training with the news textitin context followed by its rephrases or qas degrade learning of the news finally we show preliminary evidence of an emerging scaling law of sys2ft
http://arxiv.org/abs/2505.02865v1,2025-05-03T12:14:08Z,"Zhihai Wang, Jie Wang, Jilai Pan, Xilin Xia, Huiling Zhen, Mingxuan Yuan, Jianye Hao, Feng Wu",accelerating large language model reasoning via speculative search,treesearchbased reasoning methods have significantly enhanced the reasoning capability of large language models llms by facilitating the exploration of multiple intermediate reasoning steps ie thoughts however these methods suffer from substantial inference latency as they have to generate numerous reasoning thoughts severely limiting llm applicability to address this challenge we propose a novel speculative search specsearch framework that significantly accelerates llm reasoning by optimizing thought generation specifically specsearch utilizes a small model to strategically collaborate with a large model at both thought and token levels efficiently generating highquality reasoning thoughts the major pillar of specsearch is a novel qualitypreserving rejection mechanism which effectively filters out thoughts whose quality falls below that of the large models outputs moreover we show that specsearch preserves comparable reasoning quality to the large model experiments on both the qwen and llama models demonstrate that specsearch significantly outperforms stateoftheart approaches achieving up to 212 speedup with comparable reasoning quality
http://arxiv.org/abs/2505.01800v1,2025-05-03T12:06:53Z,Chidimma Opara,distinguishing aigenerated and humanwritten text through psycholinguistic analysis,the increasing sophistication of aigenerated texts highlights the urgent need for accurate and transparent detection tools especially in educational settings where verifying authorship is essential existing literature has demonstrated that the application of stylometric features with machine learning classifiers can yield excellent results building on this foundation this study proposes a comprehensive framework that integrates stylometric analysis with psycholinguistic theories offering a clear and interpretable approach to distinguishing between aigenerated and humanwritten texts this research specifically maps 31 distinct stylometric features to cognitive processes such as lexical retrieval discourse planning cognitive load management and metacognitive selfmonitoring in doing so it highlights the unique psycholinguistic patterns found in human writing through the intersection of computational linguistics and cognitive science this framework contributes to the development of reliable tools aimed at preserving academic integrity in the era of generative ai
http://arxiv.org/abs/2505.01794v1,2025-05-03T11:54:35Z,"Jared D. T. Guerrero-Sosa, Francisco P. Romero, Víctor Hugo Menéndez-Domínguez, Jesus Serrano-Guerrero, Andres Montoro-Montarroso, Jose A. Olivas",a multimodal framework for explainable evaluation of soft skills in educational environments,in the rapidly evolving educational landscape the unbiased assessment of soft skills is a significant challenge particularly in higher education this paper presents a fuzzy logic approach that employs a granular linguistic model of phenomena integrated with multimodal analysis to evaluate soft skills in undergraduate students by leveraging computational perceptions this approach enables a structured breakdown of complex soft skill expressions capturing nuanced behaviours with high granularity and addressing their inherent uncertainties thereby enhancing interpretability and reliability experiments were conducted with undergraduate students using a developed tool that assesses soft skills such as decisionmaking communication and creativity this tool identifies and quantifies subtle aspects of human interaction such as facial expressions and gesture recognition the findings reveal that the framework effectively consolidates multiple data inputs to produce meaningful and consistent assessments of soft skills showing that integrating multiple modalities into the evaluation process significantly improves the quality of soft skills scores making the assessment work transparent and understandable to educational stakeholders
http://arxiv.org/abs/2505.01790v1,2025-05-03T11:37:31Z,"Markos Stamatakis, Joshua Berger, Christian Wartena, Ralph Ewerth, Anett Hoppe",enhancing the learning experience using visionlanguage models to generate questions for educational videos,webbased educational videos offer flexible learning opportunities and are becoming increasingly popular however improving user engagement and knowledge retention remains a challenge automatically generated questions can activate learners and support their knowledge acquisition further they can help teachers and learners assess their understanding while large language and visionlanguage models have been employed in various tasks their application to question generation for educational videos remains underexplored in this paper we investigate the capabilities of current visionlanguage models for generating learningoriented questions for educational video content we assess 1 outofthebox models performance 2 finetuning effects on contentspecific question generation 3 the impact of different video modalities on question quality and 4 in a qualitative study question relevance answerability and difficulty levels of generated questions our findings delineate the capabilities of current visionlanguage models highlighting the need for finetuning and addressing challenges in question diversity and relevance we identify requirements for future multimodal datasets and outline promising research directions
http://arxiv.org/abs/2505.01761v1,2025-05-03T09:30:26Z,"Tobias Domhan, Dawei Zhu",same evaluation more tokens on the effect of input length for machine translation evaluation using large language models,accurately evaluating machinetranslated text remains a longstanding challenge particularly for long documents recent work has shown that large language models llms can serve as reliable and interpretable sentencelevel translation evaluators via mqm error span annotations with modern llms supporting larger context windows a natural question arises can we feed entire document translations into an llm for quality assessment ideally evaluation should be invariant to text length producing consistent error spans regardless of input granularity however our analysis shows that text length significantly impacts evaluation longer texts lead to fewer error spans and reduced system ranking accuracy to address this limitation we evaluate several strategies including granularityaligned prompting focus sentence prompting fsp and a finetuning approach to better align llms with the evaluation task the latter two methods largely mitigate this length bias making llms more reliable for longform translation evaluation
http://arxiv.org/abs/2505.04637v1,2025-05-03T09:14:24Z,Dongxing Yu,adaptive token boundaries integrating human chunking mechanisms into multimodal llms,recent advancements in multimodal large language models mllms have demonstrated remarkable capabilities in processing diverse data types yet significant disparities persist between human cognitive processes and computational approaches to multimodal information integration this research presents a systematic investigation into the parallels between human crossmodal chunking mechanisms and token representation methodologies in mllms through empirical studies comparing human performance patterns with model behaviors across visuallinguistic tasks we demonstrate that conventional static tokenization schemes fundamentally constrain current models capacity to simulate the dynamic contextsensitive nature of human information processing we propose a novel framework for dynamic crossmodal tokenization that incorporates adaptive boundaries hierarchical representations and alignment mechanisms grounded in cognitive science principles quantitative evaluations demonstrate that our approach yields statistically significant improvements over stateoftheart models on benchmark tasks 78 on visual question answering 53 on complex scene description while exhibiting more humanaligned error patterns and attention distributions these findings contribute to the theoretical understanding of the relationship between human cognition and artificial intelligence while providing empirical evidence for developing more cognitively plausible ai systems
http://arxiv.org/abs/2505.01754v1,2025-05-03T09:09:34Z,"Orlando Jähde, Thorsten Weber, Rüdiger Buchkremer",unraveling media perspectives a comprehensive methodology combining large language models topic modeling sentiment analysis and ontology learning to analyse media bias,biased news reporting poses a significant threat to informed decisionmaking and the functioning of democracies this study introduces a novel methodology for scalable minimally biased analysis of media bias in political news the proposed approach examines event selection labeling word choice and commission and omission biases across news sources by leveraging natural language processing techniques including hierarchical topic modeling sentiment analysis and ontology learning with large language models through three case studies related to current political events we demonstrate the methodologys effectiveness in identifying biases across news sources at various levels of granularity this work represents a significant step towards scalable minimally biased media bias analysis laying the groundwork for tools to help news consumers navigate an increasingly complex media landscape
http://arxiv.org/abs/2505.01731v2,2025-05-03T07:57:02Z,"Chuan Sun, Han Yu, Lizhen Cui, Xiaoxiao Li",efficient shapley valuebased nonuniform pruning of large language models,pruning large language models llms is a promising solution for reducing model sizes and computational complexity while preserving performance traditional layerwise pruning methods often adopt a uniform sparsity approach across all layers which leads to suboptimal performance due to the varying significance of individual transformer layers within the model not being accounted for to this end we propose the shapley valuebased nonuniform pruning svnup method for llms this approach quantifies the contribution of each transformer layer to the overall model performance enabling the assignment of tailored pruning budgets to different layers to retain critical parameters to further improve efficiency we design the sliding windowbased shapley value approximation method it substantially reduces computational overhead compared to exact sv calculation methods extensive experiments on various llms including llamav1 llamav2 and opt demonstrate the effectiveness of the proposed approach the results reveal that nonuniform pruning significantly enhances the performance of pruned models notably svnup achieves a reduction in perplexity ppl of 1801 and 1955 on llama7b and llama13b respectively compared to sparsegpt at 70 sparsity
http://arxiv.org/abs/2505.01706v1,2025-05-03T05:59:13Z,"Sarvesh Shashidhar,  Ritik, Nachiketa Patil, Suraj Racha, Ganesh Ramakrishnan",inducing robustness in a 2 dimensional direct preference optimization paradigm,direct preference optimisation dpo has emerged as a powerful method for aligning large language models llms with human preferences offering a stable and efficient alternative to approaches that use reinforcement learning via human feedback in this work we investigate the performance of dpo using opensource preference datasets one of the major drawbacks of dpo is that it doesnt induce granular scoring and treats all the segments of the responses with equal propensity however this is not practically true for human preferences since even good responses have segments that may not be preferred by the annotator to resolve this a 2dimensional scoring for dpo alignment called 2ddpo was proposed we explore the 2ddpo alignment paradigm and the advantages it provides over the standard dpo by comparing their win rates it is observed that these methods even though effective are not robust to labelscore noise to counter this we propose an approach of incorporating segmentlevel score noise robustness to the 2ddpo algorithm along with theoretical backing we also provide empirical verification in favour of the algorithm and introduce other noise models that can be present
http://arxiv.org/abs/2505.02862v1,2025-05-03T05:28:11Z,"Haoming Yang, Ke Ma, Xiaojun Jia, Yingfei Sun, Qianqian Xu, Qingming Huang",cannot see the forest for the trees invoking heuristics and biases to elicit irrational choices of llms,despite the remarkable performance of large language models llms they remain vulnerable to jailbreak attacks which can compromise their safety mechanisms existing studies often rely on bruteforce optimization or manual design failing to uncover potential risks in realworld scenarios to address this we propose a novel jailbreak attack framework icrt inspired by heuristics and biases in human cognition leveraging the simplicity effect we employ cognitive decomposition to reduce the complexity of malicious prompts simultaneously relevance bias is utilized to reorganize prompts enhancing semantic alignment and inducing harmful outputs effectively furthermore we introduce a rankingbased harmfulness evaluation metric that surpasses the traditional binary successorfailure paradigm by employing ranking aggregation methods such as elo hodgerank and rank centrality to comprehensively quantify the harmfulness of generated content experimental results show that our approach consistently bypasses mainstream llms safety mechanisms and generates highrisk content providing insights into jailbreak attack risks and contributing to stronger defense strategies
http://arxiv.org/abs/2505.01693v1,2025-05-03T04:50:55Z,"Brian Wong, Kaito Tanaka",highfidelity pseudolabel generation by large language models for training robust radiology report classifiers,automated labeling of chest xray reports is essential for enabling downstream tasks such as training imagebased diagnostic models population health studies and clinical decision support however the high variability complexity and prevalence of negation and uncertainty in these freetext reports pose significant challenges for traditional natural language processing methods while large language models llms demonstrate strong text understanding their direct application for largescale efficient labeling is limited by computational cost and speed this paper introduces debertarad a novel twostage framework that combines the power of stateoftheart llm pseudolabeling with efficient debertabased knowledge distillation for accurate and fast chest xray report labeling we leverage an advanced llm to generate highquality pseudolabels including certainty statuses for a large corpus of reports subsequently a debertabase model is trained on this pseudolabeled data using a tailored knowledge distillation strategy evaluated on the expertannotated mimic500 benchmark debertarad achieves a stateoftheart macro f1 score of 09120 significantly outperforming established rulebased systems finetuned transformer models and direct llm inference while maintaining a practical inference speed suitable for highthroughput applications our analysis shows particular strength in handling uncertain findings this work demonstrates a promising path to overcome data annotation bottlenecks and achieve highperformance medical text processing through the strategic combination of llm capabilities and efficient student models trained via distillation
http://arxiv.org/abs/2505.01658v2,2025-05-03T02:47:43Z,"Sihyeong Park, Sungryeol Jeon, Chaelyn Lee, Seokhun Jeon, Byung-Soo Kim, Jemin Lee",a survey on inference engines for large language models perspectives on optimization and efficiency,large language models llms are widely applied in chatbots code generators and search engines workloads such as chainofthought complex reasoning and agent services significantly increase the inference cost by invoking the model repeatedly optimization methods such as parallelism compression and caching have been adopted to reduce costs but the diverse service requirements make it hard to select the right method recently specialized llm inference engines have emerged as a key component for integrating the optimization methods into serviceoriented infrastructures however a systematic study on inference engines is still lacking this paper provides a comprehensive evaluation of 25 opensource and commercial inference engines we examine each inference engine in terms of easeofuse easeofdeployment generalpurpose support scalability and suitability for throughput and latencyaware computation furthermore we explore the design goals of each inference engine by investigating the optimization techniques it supports in addition we assess the ecosystem maturity of open source inference engines and handle the performance and cost policy of commercial solutions we outline future research directions that include support for complex llmbased services support of various hardware and enhanced security offering practical guidance to researchers and developers in selecting and designing optimized llm inference engines we also provide a public repository to continually track developments in this fastevolving field httpsgithubcomsihyeongawesomellminferenceengine
http://arxiv.org/abs/2505.01636v1,2025-05-03T00:05:01Z,Amit Rath,structured prompting and feedbackguided reasoning with llms for data interpretation,large language models llms have demonstrated remarkable capabilities in natural language understanding and task generalization however their application to structured data analysis remains fragile due to inconsistencies in schema interpretation misalignment between user intent and model output and limited mechanisms for selfcorrection when failures occur this paper introduces the strot framework structured task reasoning and output transformation a method for structured prompting and feedbackdriven transformation logic generation aimed at improving the reliability and semantic alignment of llmbased analytical workflows strot begins with lightweight schema introspection and samplebased field classification enabling dynamic context construction that captures both the structure and statistical profile of the input data this contextual information is embedded in structured prompts that guide the model toward generating taskspecific interpretable outputs to address common failure modes in complex queries strot incorporates a refinement mechanism in which the model iteratively revises its outputs based on execution feedback and validation signals unlike conventional approaches that rely on static prompts or singleshot inference strot treats the llm as a reasoning agent embedded within a controlled analysis loop capable of adjusting its output trajectory through planning and correction the result is a robust and reproducible framework for reasoning over structured data with llms applicable to diverse data exploration and analysis tasks where interpretability stability and correctness are essential
http://arxiv.org/abs/2505.01595v1,2025-05-02T21:33:18Z,"Liaoyaqi Wang, Zhengping Jiang, Anqi Liu, Benjamin Van Durme",always tell me the odds finegrained conditional probability estimation,we present a stateoftheart model for finegrained probability estimation of propositions conditioned on context recent advances in large language models llms have significantly enhanced their reasoning capabilities particularly on welldefined tasks with complete information however llms continue to struggle with making accurate and wellcalibrated probabilistic predictions under uncertainty or partial information while incorporating uncertainty into model predictions often boosts performance obtaining reliable estimates of that uncertainty remains understudied in particular llm probability estimates tend to be coarse and biased towards more frequent numbers through a combination of human and synthetic data creation and assessment scaling to larger models and better supervision we propose a set of strong and precise probability estimation models we conduct systematic evaluations across tasks that rely on conditional probability estimation and show that our approach consistently outperforms existing finetuned and promptingbased methods by a large margin
http://arxiv.org/abs/2505.01592v1,2025-05-02T21:27:10Z,"Takyoung Kim, Janvijay Singh, Shuhaib Mehri, Emre Can Acikgoz, Sagnik Mukherjee, Nimet Beyza Bozdag, Sumuk Shashidhar, Gokhan Tur, Dilek Hakkani-Tür",pipa a unified evaluation protocol for diagnosing interactive planning agents,the growing capabilities of large language models llms in instructionfollowing and contextunderstanding lead to the era of agents with numerous applications among these task planning agents have become especially prominent in realistic scenarios involving complex internal pipelines such as context understanding tool management and response generation however existing benchmarks predominantly evaluate agent performance based on task completion as a proxy for overall effectiveness we hypothesize that merely improving task completion is misaligned with maximizing user satisfaction as users interact with the entire agentic process and not only the end result to address this gap we propose pipa a unified evaluation protocol that conceptualizes the behavioral process of interactive task planning agents within a partially observable markov decision process pomdp paradigm the proposed protocol offers a comprehensive assessment of agent performance through a set of atomic evaluation criteria allowing researchers and practitioners to diagnose specific strengths and weaknesses within the agents decisionmaking pipeline our analyses show that agents excel in different behavioral stages with user satisfaction shaped by both outcomes and intermediate behaviors we also highlight future directions including systems that leverage multiple agents and the limitations of user simulators in task planning
http://arxiv.org/abs/2505.02859v1,2025-05-02T20:57:55Z,"Jonas Bokstaller, Julia Altheimer, Julian Dormehl, Alina Buss, Jasper Wiltfang, Johannes Schneider, Maximilian Röglinger",enhancing ml model interpretability leveraging finetuned large language models for better understanding of ai,across various sectors applications of explainableai xai gained momentum as the increasing blackboxedness of prevailing machine learning ml models became apparent in parallel large language models llms significantly developed in their abilities to understand human language and complex patterns by combining both this paper presents a novel reference architecture for the interpretation of xai through an interactive chatbot powered by a finetuned llm we instantiate the reference architecture in the context of stateofhealth soh prediction for batteries and validate its design in multiple evaluation and demonstration rounds the evaluation indicates that the implemented prototype enhances the human interpretability of ml especially for users with less experience with xai
http://arxiv.org/abs/2505.01560v1,2025-05-02T20:02:13Z,"Vicent Briva Iglesias, Gokhan Dogru",ai agents may be worth the hype but not the resources yet an initial exploration of machine translation quality and costs in three language pairs in the legal and news domains,large language models llms and multiagent orchestration are touted as the next leap in machine translation mt but their benefits relative to conventional neural mt nmt remain unclear this paper offers an empirical reality check we benchmark five paradigms google translate strong nmt baseline gpt4o generalpurpose llm o1preview reasoningenhanced llm and two gpt4opowered agentic workflows sequential threestage and iterative refinement on test data drawn from a legal contract and news prose in three englishsource pairs spanish catalan and turkish automatic evaluation is performed with comet bleu chrf2 and ter human evaluation is conducted with expert ratings of adequacy and fluency efficiency with total inputplusoutput token counts mapped to april 2025 pricing automatic scores still favour the mature nmt system which ranks first in seven of twelve metriclanguage combinations o1preview ties or places second in most remaining cases while both multiagent workflows trail human evaluation reverses part of this narrative o1preview produces the most adequate and fluent output in five of six comparisons and the iterative agent edges ahead once indicating that reasoning layers capture semantic nuance undervalued by surface metrics yet these qualitative gains carry steep costs the sequential agent consumes roughly five times and the iterative agent fifteen times the tokens used by nmt or singlepass llms we advocate multidimensional costaware evaluation protocols and highlight research directions that could tip the balance leaner coordination strategies selective agent activation and hybrid pipelines combining singlepass llms with targeted agent intervention
http://arxiv.org/abs/2505.01559v1,2025-05-02T19:59:56Z,"Daniele Grandi, Fabian Riquelme",on the effectiveness of large language models in the mechanical design domain,in this work we seek to understand the performance of large language models in the mechanical engineering domain we leverage the semantic data found in the abc dataset specifically the assembly names that designers assigned to the overall assemblies and the individual semantic part names that were assigned to each part after preprocessing the data we developed two unsupervised tasks to evaluate how different model architectures perform on domainspecific data a binary sentencepair classification task and a zeroshot classification task we achieved a 062 accuracy for the binary sentencepair classification task with a finetuned model that focuses on fighting overfitting 1 modifying learning rates 2 dropout values 3 sequence length and 4 adding a multihead attention layer our model on the zeroshot classification task outperforms the baselines by a wide margin and achieves a top1 classification accuracy of 0386 the results shed some light on the specific failure modes that arise when learning from language in this domain
http://arxiv.org/abs/2505.02858v1,2025-05-02T18:56:01Z,"Henry Tari, Nojus Sereiva, Rishabh Kaushal, Thales Bertaglia, Adriana Iamnitchi",towards highfidelity synthetic multiplatform social media datasets via large language models,social media datasets are essential for research on a variety of topics such as disinformation influence operations hate speech detection or influencer marketing practices however access to social media datasets is often constrained due to costs and platform restrictions acquiring datasets that span multiple platforms which is crucial for understanding the digital ecosystem is particularly challenging this paper explores the potential of large language models to create lexically and semantically relevant social media datasets across multiple platforms aiming to match the quality of real data we propose multiplatform topicbased prompting and employ various language models to generate synthetic data from two real datasets each consisting of posts from three different social media platforms we assess the lexical and semantic properties of the synthetic data and compare them with those of the real data our empirical findings show that using large language models to generate synthetic multiplatform social media data is promising different language models perform differently in terms of fidelity and a postprocessing approach might be needed for generating highfidelity synthetic datasets for research in addition to the empirical evaluation of three state of the art large language models our contributions include new fidelity metrics specific to multiplatform social media datasets
http://arxiv.org/abs/2505.03814v1,2025-05-02T17:05:01Z,"Ganghua Wang, Zhaorun Chen, Bo Li, Haifeng Xu",cereval certifiable and costefficient evaluation framework for llms,as foundation models continue to scale the size of trained models grows exponentially presenting significant challenges for their evaluation current evaluation practices involve curating increasingly large datasets to assess the performance of large language models llms however there is a lack of systematic analysis and guidance on determining the sufficiency of test data or selecting informative samples for evaluation this paper introduces a certifiable and costefficient evaluation framework for llms our framework adapts to different evaluation objectives and outputs confidence intervals that contain true values with high probability we use test sample complexity to quantify the number of test points needed for a certifiable evaluation and derive tight bounds on test sample complexity based on the developed theory we develop a partitionbased algorithm named cereval that adaptively selects test points to minimize the cost of llm evaluation realworld experiments demonstrate that cereval can save 20 to 40 test points across various benchmarks while maintaining an estimation error level comparable to the current evaluation process and providing a 95 confidence guarantee
http://arxiv.org/abs/2505.01485v1,2025-05-02T16:36:57Z,"Tasnim Ahmed, Salimur Choudhury",chorus zeroshot hierarchical retrieval and orchestration for generating linear programming code,linear programming lp problems aim to find the optimal solution to an objective under constraints these problems typically require domain knowledge mathematical skills and programming ability presenting significant challenges for nonexperts this study explores the efficiency of large language models llms in generating solverspecific lp code we propose chorus a retrievalaugmented generation rag framework for synthesizing gurobibased lp code from natural language problem statements chorus incorporates a hierarchical treelike chunking strategy for theoretical contents and generates additional metadata based on code examples from documentation to facilitate selfcontained semantically coherent retrieval twostage retrieval approach of chorus followed by crossencoder reranking further ensures contextual relevance finally expertly crafted prompt and structured parser with reasoning steps improve code generation performance significantly experiments on the nl4optcode benchmark show that chorus improves the performance of opensource llms such as llama31 8b llama33 70b phi4 14b deepseekr1 32b and qwen25coder 32b by a significant margin compared to baseline and conventional rag it also allows these opensource llms to outperform or match the performance of much stronger baselinesgpt35 and gpt4 while requiring far fewer computational resources ablation studies further demonstrate the importance of expert prompting hierarchical chunking and structured reasoning
http://arxiv.org/abs/2505.01372v1,2025-05-02T16:18:40Z,"Kola Ayonrinde, Louis Jaburi",evaluating explanations an explanatory virtues framework for mechanistic interpretability the strange science part iii,mechanistic interpretability mi aims to understand neural networks through causal explanations though mi has many explanationgenerating methods progress has been limited by the lack of a universal approach to evaluating explanations here we analyse the fundamental question what makes a good explanation we introduce a pluralist explanatory virtues framework drawing on four perspectives from the philosophy of science the bayesian kuhnian deutschian and nomological to systematically evaluate and improve explanations in mi we find that compact proofs consider many explanatory virtues and are hence a promising approach fruitful research directions implied by our framework include 1 clearly defining explanatory simplicity 2 focusing on unifying explanations and 3 deriving universal principles for neural networks improved mi methods enhance our ability to monitor predict and steer ai systems
http://arxiv.org/abs/2505.01479v1,2025-05-02T15:18:03Z,"Siheng Xiong, Jieyu Zhou, Zhangding Liu, Yusen Su",symplanner deliberate planning in language models with symbolic representation,planning remains a core challenge for language models lms particularly in domains that require coherent multistep action sequences grounded in external constraints we introduce symplanner a novel framework that equips lms with structured planning capabilities by interfacing them with a symbolic environment that serves as an explicit world model rather than relying purely on natural language reasoning symplanner grounds the planning process in a symbolic state space where a policy model proposes actions and a symbolic environment deterministically executes and verifies their effects to enhance exploration and improve robustness we introduce iterative correction ic which refines previously proposed actions by leveraging feedback from the symbolic environment to eliminate invalid decisions and guide the model toward valid alternatives additionally contrastive ranking cr enables finegrained comparison of candidate plans by evaluating them jointly we evaluate symplanner on planbench demonstrating that it produces more coherent diverse and verifiable plans than pure natural language baselines
http://arxiv.org/abs/2505.01325v1,2025-05-02T14:56:50Z,"Svenja Kenneweg, Jörg Deigmöller, Philipp Cimiano, Julian Eggert",traveler a benchmark for evaluating temporal reasoning across vague implicit and explicit references,understanding and resolving temporal references is essential in natural language understanding as we often refer to the past or future in daily communication although existing benchmarks address a systems ability to reason about and resolve temporal references systematic evaluation of specific temporal references remains limited towards closing this gap we introduce traveler a novel synthetic benchmark dataset that follows a question answering paradigm and consists of questions involving temporal references with the corresponding correct answers traveler assesses models abilities to resolve explicit implicit relative to speech time and vague temporal references beyond investigating the performance of stateoftheart llms depending on the type of temporal reference our benchmark also allows evaluation of performance in relation to the length of the set of events for the category of vague temporal references groundtruth answers were established via human surveys on prolific following a procedure similar to the one from kenneweg et al to demonstrate the benchmarks applicability we evaluate four stateoftheart llms using a questionanswering task encompassing 3300 questions our findings show that while the benchmarked llms can answer questions over event sets with a handful of events and explicit temporal references successfully performance clearly deteriorates with larger event set length and when temporal references get less explicit notably the vague question category exhibits the lowest performance across all models the benchmark is publicly available at httpsgitlabubunibielefelddeskennewegtraveler
http://arxiv.org/abs/2505.01315v2,2025-05-02T14:42:26Z,"Sheikh Samit Muhaimin, Spyridon Mastorakis",helping large language models protect themselves an enhanced filtering and summarization system,the recent growth in the use of large language models has made them vulnerable to sophisticated adversarial assaults manipulative prompts and encoded malicious inputs existing countermeasures frequently necessitate retraining models which is computationally costly and impracticable for deployment without the need for retraining or finetuning this study presents a unique defense paradigm that allows llms to recognize filter and defend against adversarial or malicious inputs on their own there are two main parts to the suggested framework 1 a prompt filtering module that uses sophisticated natural language processing nlp techniques including zeroshot classification keyword analysis and encoded content detection eg base64 hexadecimal url encoding to detect decode and classify harmful inputs and 2 a summarization module that processes and summarizes adversarial research literature to give the llm contextaware defense knowledge this approach strengthens llms resistance to adversarial exploitation by fusing text extraction summarization and harmful prompt analysis according to experimental results this integrated technique has a 9871 success rate in identifying harmful patterns manipulative language structures and encoded prompts by employing a modest amount of adversarial research literature as context the methodology also allows the model to react correctly to harmful inputs with a larger percentage of jailbreak resistance and refusal rate while maintaining the quality of llm responses the framework dramatically increases llms resistance to hostile misuse demonstrating its efficacy as a quick and easy substitute for timeconsuming retrainingbased defenses
http://arxiv.org/abs/2505.01314v1,2025-05-02T14:40:16Z,"Shang Wang, Huanrong Tang, Jianquan Ouyang",a transformerbased neural architecture search method,this paper presents a neural architecture search method based on transformer architecture searching cross multihead attention computation ways for different number of encoder and decoder combinations in order to search for neural network structures with better translation results we considered perplexity as an auxiliary evaluation metric for the algorithm in addition to bleu scores and iteratively improved each individual neural network within the population by a multiobjective genetic algorithm experimental results show that the neural network structures searched by the algorithm outperform all the baseline models and that the introduction of the auxiliary evaluation metric can find better models than considering only the bleu score as an evaluation metric
http://arxiv.org/abs/2505.01311v1,2025-05-02T14:39:04Z,"Svenja Kenneweg, Jörg Deigmöller, Julian Eggert, Philipp Cimiano",a factorized probabilistic model of the semantics of vague temporal adverbials relative to different event types,vague temporal adverbials such as recently just and a long time ago describe the temporal distance between a past event and the utterance time but leave the exact duration underspecified in this paper we introduce a factorized model that captures the semantics of these adverbials as probabilistic distributions these distributions are composed with eventspecific distributions to yield a contextualized meaning for an adverbial applied to a specific event we fit the models parameters using existing data capturing judgments of native speakers regarding the applicability of these vague temporal adverbials to events that took place a given time ago comparing our approach to a nonfactorized model based on a single gaussian distribution for each pair of event and temporal adverbial we find that while both models have similar predictive power our model is preferable in terms of occams razor as it is simpler and has better extendability
http://arxiv.org/abs/2505.01255v1,2025-05-02T13:23:13Z,"Wei Han, Hui Chen, Soujanya Poria",premise matchingbased prediction for accurate review recommendation,we present premise predict with matching scores a new architecture for the matchingbased learning in the multimodal fields for the multimodal review helpfulness mrhp task distinct to previous fusionbased methods which obtains multimodal representations via crossmodal attention for downstream tasks premise computes the multiscale and multifield representations filters duplicated semantics and then obtained a set of matching scores as feature vectors for the downstream recommendation task this new architecture significantly boosts the performance for such multimodal tasks whose context matching content are highly correlated to the targets of that task compared to the stateoftheart fusionbased methods experimental results on two publicly available datasets show that premise achieves promising performance with less computational cost
http://arxiv.org/abs/2505.01238v1,2025-05-02T13:00:05Z,"Mahdi Dhaini, Kafaite Zahra Hussain, Efstratios Zaradoukas, Gjergji Kasneci",evalxnlp a framework for benchmarking posthoc explainability methods on nlp models,as natural language processing nlp models continue to evolve and become integral to highstakes applications ensuring their interpretability remains a critical challenge given the growing variety of explainability methods and diverse stakeholder requirements frameworks that help stakeholders select appropriate explanations tailored to their specific use cases are increasingly important to address this need we introduce evalxnlp a python framework for benchmarking stateoftheart feature attribution methods for transformerbased nlp models evalxnlp integrates eight widely recognized explainability techniques from the explainable ai xai literature enabling users to generate and evaluate explanations based on key properties such as faithfulness plausibility and complexity our framework also provides interactive llmbased textual explanations facilitating user understanding of the generated explanations and evaluation outcomes human evaluation results indicate high user satisfaction with evalxnlp suggesting it is a promising framework for benchmarking explanation methods across diverse user groups by offering a userfriendly and extensible platform evalxnlp aims at democratizing explainability tools and supporting the systematic comparison and advancement of xai techniques in nlp
http://arxiv.org/abs/2505.02854v1,2025-05-02T12:31:43Z,"Masumi Morishige, Ryo Koshihara",ensuring reproducibility in generative ai systems for general use cases a framework for regression testing and open datasets,reproducibility and reliability remain pressing challenges for generative ai systems whose behavior can drift with each model update or prompt revision we introduce gprbench a lightweight extensible benchmark that operationalizes regression testing for general purpose use cases gprbench couples an open bilingual english and japanese dataset covering eight task categories eg text generation code generation and information retrieval and 10 scenarios in each task categories 80 total test cases for each language with an automated evaluation pipeline that employs llmasajudge scoring of correctness and conciseness experiments across three recent model versions gpt4omini o3mini and o4mini and two prompt configurations default versus concisewriting instruction reveal heterogeneous quality our results show that newer models generally improve correctness but the differences are modest and not statistically significant suggesting that gprbench may not be sufficiently challenging to differentiate between recent model versions in contrast the concisewriting instruction significantly enhances conciseness 1237 pp mannwhitney u test p 0001 effect size r 02995 with minimal degradations on accuracy 17 pp demonstrating the effectiveness of prompt engineering released under the mit license gpr bench lowers the barrier to initiating reproducibility monitoring and provides a foundation for communitydriven extensions while also raising important considerations about benchmark design for rapidly evolving language models
http://arxiv.org/abs/2505.03810v1,2025-05-02T11:51:29Z,"Euntae Choi, Sumin Song, Woosang Lim, Sungjoo Yoo",grouped sequencyarranged rotation optimizing rotation transformation for quantization for free,large language models llms face deployment challenges due to high computational costs and while posttraining quantization ptq offers a solution existing rotationbased methods struggle at very low bitwidths like 2bit we introduce a novel trainingfree approach to construct an improved rotation matrix addressing the limitations of current methods the key contributions include leveraging the walshhadamard transform with sequency ordering which clusters similar frequency components to reduce quantization error compared to standard hadamard matrices significantly improving performance furthermore we propose a grouped sequencyarranged rotation gsr using blockdiagonal matrices with smaller walsh blocks effectively isolating outlier impacts and achieving performance comparable to optimizationbased methods without requiring any training our method demonstrates robust performance on reasoning tasks and perplexity ppl score on wikitext2 our method also enhances results even when applied over existing learned rotation techniques
http://arxiv.org/abs/2505.01198v1,2025-05-02T11:41:25Z,"Mahdi Dhaini, Ege Erdogan, Nils Feldhus, Gjergji Kasneci",gender bias in explainability investigating performance disparity in posthoc methods,while research on applications and evaluations of explanation methods continues to expand fairness of the explanation methods concerning disparities in their performance across subgroups remains an often overlooked aspect in this paper we address this gap by showing that across three tasks and five language models widely used posthoc feature attribution methods exhibit significant gender disparity with respect to their faithfulness robustness and complexity these disparities persist even when the models are pretrained or finetuned on particularly unbiased datasets indicating that the disparities we observe are not merely consequences of biased training data our results highlight the importance of addressing disparities in explanations when developing and applying explainability methods as these can lead to biased outcomes against certain subgroups with particularly critical implications in highstakes contexts furthermore our findings underscore the importance of incorporating the fairness of explanations alongside overall model fairness and explainability as a requirement in regulatory frameworks
http://arxiv.org/abs/2505.01162v1,2025-05-02T10:08:34Z,"Chebrolu Niranjan, Kokil Jaidka, Gerard Christopher Yeo",on the limitations of steering in language model alignment,steering vectors are a promising approach to aligning language model behavior at inference time in this paper we propose a framework to assess the limitations of steering vectors as alignment mechanisms using a framework of transformer hook interventions and antonymbased function vectors we evaluate the role of prompt structure and context complexity in steering effectiveness our findings indicate that steering vectors are promising for specific alignment tasks such as value alignment but may not provide a robust foundation for generalpurpose alignment in llms particularly in complex scenarios we establish a methodological foundation for future investigations into steering capabilities of reasoning models
http://arxiv.org/abs/2505.02851v1,2025-05-02T08:53:27Z,"Franklin Zhang, Sonya Zhang, Alon Halevy",30daygen leveraging llms to create a content corpus for habit formation,in this paper we present 30 day me a habit formation application that leverages large language models llms to help users break down their goals into manageable actionable steps and track their progress central to the app is the 30daygen system which generates 3531 unique 30day challenges sourced from over 15k webpages and enables runtime search of challenge ideas aligned with userdefined goals we showcase how llms can be harnessed to rapidly construct domain specific content corpora for behavioral and educational purposes and propose a practical pipeline that incorporates effective llm enhanced approaches for content generation and semantic deduplication
http://arxiv.org/abs/2505.01110v1,2025-05-02T08:45:45Z,"Murtadha Ahmed,  Wenbo, Liu yunfeng",mateicl mitigating attention dispersion in largescale incontext learning,large language models llms have demonstrated remarkable capabilities in incontext learning icl however the fixed position length constraints in pretrained models limit the number of demonstration examples recent efforts to extend context suffer from attention dispersion as the number of demonstrations increases in this paper we introduce mitigating attention dispersion in largescale icl mateicl that enables llms to maintain effective selfattention as the context size grows we first split the context into multiple windows each filled to the models context capacity which are processed separately then we introduce an additional layer to recalibrate the attention weights prioritizing the query tokens as the number of demonstrations increases our empirical results show that mateicl can effectively leverage larger contexts to improve icl performance compared to retrievalbased baselines mateicl consistently achieves better performance without requiring an externally trained retrieval model despite recent advances in inference strategies eg 32k token contexts our results demonstrate that mateicl remains beneficial in computationally resourceconstrained settings the code is publicly available at httpsgithubcomamurtadhamateicl
http://arxiv.org/abs/2505.01096v1,2025-05-02T08:14:03Z,"Marco Salmè, Rosa Sicilia, Paolo Soda, Valerio Guarrasi",evaluating vision language model adaptations for radiology report generation in lowresource languages,the integration of artificial intelligence in healthcare has opened new horizons for improving medical diagnostics and patient care however challenges persist in developing systems capable of generating accurate and contextually relevant radiology reports particularly in lowresource languages in this study we present a comprehensive benchmark to evaluate the performance of instructiontuned visionlanguage models vlms in the specialized task of radiology report generation across three lowresource languages italian german and spanish employing the llava architectural framework we conducted a systematic evaluation of pretrained models utilizing general datasets domainspecific datasets and lowresource languagespecific datasets in light of the unavailability of models that possess prior knowledge of both the medical domain and lowresource languages we analyzed various adaptations to determine the most effective approach for these contexts the results revealed that languagespecific models substantially outperformed both general and domainspecific models in generating radiology reports emphasizing the critical role of linguistic adaptation additionally models finetuned with medical terminology exhibited enhanced performance across all languages compared to models with generic knowledge highlighting the importance of domainspecific training we also explored the influence of the temperature parameter on the coherence of report generation providing insights for optimal model settings our findings highlight the importance of tailored language and domainspecific training for improving the quality and accuracy of radiological reports in multilingual settings this research not only advances our understanding of vlms adaptability in healthcare but also points to significant avenues for future investigations into model tuning and languagespecific adaptations
http://arxiv.org/abs/2505.01068v1,2025-05-02T07:18:00Z,"Yijie Jin, Junjie Peng, Xuanchao Lin, Haochen Yuan, Lan Wang, Cangzhi Zheng",multimodal transformers are hierarchical modalwise heterogeneous graphs,multimodal sentiment analysis msa is a rapidly developing field that integrates multimodal information to recognize sentiments and existing models have made significant progress in this area the central challenge in msa is multimodal fusion which is predominantly addressed by multimodal transformers mults although act as the paradigm mults suffer from efficiency concerns in this work from the perspective of efficiency optimization we propose and prove that mults are hierarchical modalwise heterogeneous graphs hmhgs and we introduce the graphstructured representation pattern of mults based on this pattern we propose an interlaced mask im mechanism to design the graphstructured and interlacedmasked multimodal transformer gsit it is formally equivalent to mults which achieves an efficient weightsharing mechanism without information disorder through im enabling allmodalinone fusion with only 13 of the parameters of pure mults a triton kernel called decomposition is implemented to ensure avoiding additional computational overhead moreover it achieves significantly higher performance than traditional mults to further validate the effectiveness of gsit itself and the hmhg concept we integrate them into multiple stateoftheart models and demonstrate notable performance improvements and parameter reduction on widely used msa datasets
http://arxiv.org/abs/2505.02850v1,2025-05-02T06:36:06Z,"Nicy Scaria, Silvester John Joseph Kennedy, Diksha Seth, Ananya Thakur, Deepak Subramani",harnessing structured knowledge a concept mapbased approach for highquality multiple choice question generation with effective distractors,generating highquality mcqs especially those targeting diverse cognitive levels and incorporating common misconceptions into distractor design is timeconsuming and expertiseintensive making manual creation impractical at scale current automated approaches typically generate questions at lower cognitive levels and fail to incorporate domainspecific misconceptions this paper presents a hierarchical concept mapbased framework that provides structured knowledge to guide llms in generating mcqs with distractors we chose highschool physics as our test domain and began by developing a hierarchical concept map covering major physics topics and their interconnections with an efficient database design next through an automated pipeline topicrelevant sections of these concept maps are retrieved to serve as a structured context for the llm to generate questions and distractors that specifically target common misconceptions lastly an automated validation is completed to ensure that the generated mcqs meet the requirements provided we evaluate our framework against two baseline approaches a base llm and a ragbased generation we conducted expert evaluations and student assessments of the generated mcqs expert evaluation shows that our method significantly outperforms the baseline approaches achieving a success rate of 7520 in meeting all quality criteria compared to approximately 37 for both baseline methods student assessment data reveal that our concept mapdriven approach achieved a significantly lower guess success rate of 2805 compared to 3710 for the baselines indicating a more effective assessment of conceptual understanding the results demonstrate that our concept mapbased approach enables robust assessment across cognitive levels and instant identification of conceptual gaps facilitating faster feedback loops and targeted interventions at scale
http://arxiv.org/abs/2505.01035v1,2025-05-02T06:17:51Z,Lui Yoshida,do we need a detailed rubric for automated essay scoring using large language models,this study investigates the necessity and impact of a detailed rubric in automated essay scoring aes using large language models llms while using rubrics are standard in llmbased aes creating detailed rubrics requires substantial effort and increases token usage we examined how different levels of rubric detail affect scoring accuracy across multiple llms using the toefl11 dataset our experiments compared three conditions a full rubric a simplified rubric and no rubric using four different llms claude 35 haiku gemini 15 flash gpt4omini and llama 3 70b instruct results showed that three out of four models maintained similar scoring accuracy with the simplified rubric compared to the detailed one while significantly reducing token usage however one model gemini 15 flash showed decreased performance with more detailed rubrics the findings suggest that simplified rubrics may be sufficient for most llmbased aes applications offering a more efficient alternative without compromising scoring accuracy however modelspecific evaluation remains crucial as performance patterns vary across different llms
http://arxiv.org/abs/2505.03799v1,2025-05-02T06:08:21Z,"Hyun Lee, Chris Yi, Maminur Islam, B. D. S. Aritra",scalability matters overcoming challenges in instructglm with similaritydegreebased sampling,large language models llms have demonstrated strong capabilities in various natural language processing tasks however their application to graphrelated problems remains limited primarily due to scalability constraints and the absence of dedicated mechanisms for processing graph structures existing approaches predominantly integrate llms with graph neural networks gnns using gnns as feature encoders or auxiliary components however directly encoding graph structures within llms has been underexplored particularly in the context of largescale graphs where token limitations hinder effective representation to address these challenges we propose sdminstructglm a novel instructiontuned graph language model instructglm framework that enhances scalability and efficiency without relying on gnns our method introduces a similaritydegreebased biased random walk mechanism which selectively samples and encodes graph information based on nodefeature similarity and degree centrality ensuring an adaptive and structured representation within the llm this approach significantly improves token efficiency mitigates information loss due to random sampling and enhances performance on graphbased tasks such as node classification and link prediction furthermore our results demonstrate the feasibility of llmonly graph processing enabling scalable and interpretable graph language models glms optimized through instructionbased finetuning this work paves the way for gnnfree approaches to graph learning leveraging llms as standalone graph reasoning models our source code is available on github
http://arxiv.org/abs/2505.01015v1,2025-05-02T05:26:50Z,"Jongwook Han, Dongmin Choi, Woojung Song, Eun-Ju Lee, Yohan Jo",value portrait understanding values of llms with humanaligned benchmark,the importance of benchmarks for assessing the values of language models has been pronounced due to the growing need of more authentic humanaligned responses however existing benchmarks rely on human or machine annotations that are vulnerable to valuerelated biases furthermore the tested scenarios often diverge from realworld contexts in which models are commonly used to generate text and express values to address these issues we propose the value portrait benchmark a reliable framework for evaluating llms value orientations with two key characteristics first the benchmark consists of items that capture reallife userllm interactions enhancing the relevance of assessment results to realworld llm usage and thus ecological validity second each item is rated by human subjects based on its similarity to their own thoughts and correlations between these ratings and the subjects actual value scores are derived this psychometrically validated approach ensures that items strongly correlated with specific values serve as reliable items for assessing those values through evaluating 27 llms with our benchmark we find that these models prioritize benevolence security and selfdirection values while placing less emphasis on tradition power and achievement values also our analysis reveals biases in how llms perceive various demographic groups deviating from real human data
http://arxiv.org/abs/2505.01007v1,2025-05-02T05:11:17Z,"Ling Tang, Yuefeng Chen, Hui Xue, Quanshi Zhang",towards the resistance of neural network watermarking to finetuning,this paper proves a new watermarking method to embed the ownership information into a deep neural network dnn which is robust to finetuning specifically we prove that when the input feature of a convolutional layer only contains lowfrequency components specific frequency components of the convolutional filter will not be changed by gradient descent during the finetuning process where we propose a revised fourier transform to extract frequency components from the convolutional filter additionally we also prove that these frequency components are equivariant to weight scaling and weight permutations in this way we design a watermark module to encode the watermark information to specific frequency components in a convolutional filter preliminary experiments demonstrate the effectiveness of our method
http://arxiv.org/abs/2505.01006v1,2025-05-02T05:04:41Z,"Sumit Mamtani, Maitreya Sonawane, Kanika Agarwal, Nishanth Sanjeev",tokenfree models for sarcasm detection,tokenization is a foundational step in most natural language processing nlp pipelines yet it introduces challenges such as vocabulary mismatch and outofvocabulary issues recent work has shown that models operating directly on raw text at the byte or character level can mitigate these limitations in this paper we evaluate two tokenfree models byt5 and canine on the task of sarcasm detection in both social media twitter and nonsocial media news headlines domains we finetune and benchmark these models against tokenbased baselines and stateoftheart approaches our results show that byt5small and canine outperform tokenbased counterparts and achieve new stateoftheart performance improving accuracy by 077 and 049 on the news headlines and twitter sarcasm datasets respectively these findings underscore the potential of tokenfree models for robust nlp in noisy and informal domains such as social media
http://arxiv.org/abs/2505.00989v1,2025-05-02T04:27:50Z,"Sijin Sun, Liangbin Zhao, Ming Deng, Xiuju Fu",vtsllm domainadaptive llm agent for enhancing awareness in vessel traffic services through natural language,vessel traffic services vts are essential for maritime safety and regulatory compliance through realtime traffic management however with increasing traffic complexity and the prevalence of heterogeneous multimodal data existing vts systems face limitations in spatiotemporal reasoning and intuitive human interaction in this work we propose vtsllm agent the first domainadaptive large llm agent tailored for interactive decision support in vts operations we formalize riskprone vessel identification as a knowledgeaugmented texttosql task combining structured vessel databases with external maritime knowledge to support this we construct a curated benchmark dataset consisting of a custom schema domainspecific corpus and a querysql test set in multiple linguistic styles our framework incorporates nerbased relational reasoning agentbased domain knowledge injection semantic algebra intermediate representation and query rethink mechanisms to enhance domain grounding and contextaware understanding experimental results show that vtsllm outperforms both generalpurpose and sqlfocused baselines under commandstyle operationalstyle and formal natural language queries respectively moreover our analysis provides the first empirical evidence that linguistic style variation introduces systematic performance challenges in texttosql modeling this work lays the foundation for natural language interfaces in vessel traffic services and opens new opportunities for proactive llmdriven maritime realtime traffic management
http://arxiv.org/abs/2505.00985v2,2025-05-02T04:13:27Z,"Ayan Sengupta, Yash Goel, Tanmoy Chakraborty",position enough of scaling llms lets focus on downscaling,we challenge the dominant focus on neural scaling laws and advocate for a paradigm shift toward downscaling in the development of large language models llms while scaling laws have provided critical insights into performance improvements through increasing model and dataset size we emphasize the significant limitations of this approach particularly in terms of computational inefficiency environmental impact and deployment constraints to address these challenges we propose a holistic framework for downscaling llms that seeks to maintain performance while drastically reducing resource demands this paper outlines practical strategies for transitioning away from traditional scaling paradigms advocating for a more sustainable efficient and accessible approach to llm development
http://arxiv.org/abs/2505.00979v2,2025-05-02T03:40:39Z,"Xuhui Jiang, Shengjie Ma, Chengjin Xu, Cehao Yang, Liyu Zhang, Jian Guo",synthesizeongraph knowledgeable synthetic data generation for continue pretraining of large language models,large language models llms have achieved remarkable success but remain datainefficient especially when learning from small specialized corpora with limited and proprietary data existing synthetic data generation methods for continue pretraining focus on intradocument content and overlook crossdocument knowledge associations limiting content diversity and depth we propose syntheticongraph sog a synthetic data generation framework that incorporates crossdocument knowledge associations for efficient corpus expansion sog constructs a context graph by extracting entities and concepts from the original corpus representing crossdocument associations and employing a graph walk strategy for knowledgeassociated sampling this enhances synthetic data diversity and coherence enabling models to learn complex knowledge structures and handle rare knowledge to further improve synthetic data quality we integrate chainofthought cot and contrastive clarifying cc synthetic enhancing reasoning processes and discriminative power experiments show that sog outperforms the stateoftheart sota method in a multihop document qa dataset while performing comparably to the sota method on the reading comprehension task datasets which also underscores the better generalization capability of sog our work advances synthetic data generation and provides practical solutions for efficient knowledge acquisition in llms especially in domains with limited data availability
http://arxiv.org/abs/2505.00977v2,2025-05-02T03:39:49Z,"Yingquan Chen, Qianmu Li, Xiaocong Wu, Huifeng Li, Qing Chang",a characterbased diffusion embedding algorithm for enhancing the generation quality of generative linguistic steganographic texts,generating highquality steganographic text is a fundamental challenge in the field of generative linguistic steganography this challenge arises primarily from two aspects firstly the capabilities of existing models in text generation are limited secondly embedding algorithms fail to effectively mitigate the negative impacts of sensitive informations properties such as semantic content or randomness specifically to ensure that the recipient can accurately extract hidden information embedding algorithms often have to consider selecting candidate words with relatively low probabilities this phenomenon leads to a decrease in the number of highprobability candidate words and an increase in lowprobability candidate words thereby compromising the semantic coherence and logical fluency of the steganographic text and diminishing the overall quality of the generated steganographic material to address this issue this paper proposes a novel embedding algorithm characterbased diffusion embedding algorithm cdea unlike existing embedding algorithms that strive to eliminate the impact of sensitive informations properties on the generation process cdea leverages sensitive informations properties it enhances the selection frequency of highprobability candidate words in the candidate pool based on general statistical properties at the character level and grouping methods based on powerlaw distributions while reducing the selection frequency of lowprobability candidate words in the candidate pool furthermore to ensure the effective transformation of sensitive information in long sequences we also introduce the xlnet model experimental results demonstrate that the combination of cdea and xlnet significantly improves the quality of generated steganographic text particularly in terms of perceptualimperceptibility
http://arxiv.org/abs/2505.00976v1,2025-05-02T03:37:52Z,"Zhiyu Liao, Kang Chen, Yuanguo Lin, Kangkang Li, Yunxuan Liu, Hefeng Chen, Xingwang Huang, Yuanhui Yu",attack and defense techniques in large language models a survey and new perspectives,large language models llms have become central to numerous natural language processing tasks but their vulnerabilities present significant security and ethical challenges this systematic survey explores the evolving landscape of attack and defense techniques in llms we classify attacks into adversarial prompt attack optimized attacks model theft as well as attacks on application of llms detailing their mechanisms and implications consequently we analyze defense strategies including preventionbased and detectionbased defense methods although advances have been made challenges remain to adapt to the dynamic threat landscape balance usability with robustness and address resource constraints in defense implementation we highlight open problems including the need for adaptive scalable defenses explainable security techniques and standardized evaluation frameworks this survey provides actionable insights and directions for developing secure and resilient llms emphasizing the importance of interdisciplinary collaboration and ethical considerations to mitigate risks in realworld applications
http://arxiv.org/abs/2505.00949v3,2025-05-02T01:35:35Z,"Akhiad Bercovich, Itay Levy, Izik Golan, Mohammad Dabbah, Ran El-Yaniv, Omri Puny, Ido Galil, Zach Moshe, Tomer Ronen, Najeeb Nabwani, Ido Shahaf, Oren Tropp, Ehud Karpas, Ran Zilberstein, Jiaqi Zeng, Soumye Singhal, Alexander Bukharin, Yian Zhang, Tugrul Konuk, Gerald Shen, Ameya Sunil Mahabaleshwarkar, Bilal Kartal, Yoshi Suhara, Olivier Delalleau, Zijia Chen, Zhilin Wang, David Mosallanezhad, Adi Renduchintala, Haifeng Qian, Dima Rekesh, Fei Jia, Somshubra Majumdar, Vahid Noroozi, Wasi Uddin Ahmad, Sean Narenthiran, Aleksander Ficek, Mehrzad Samadi, Jocelyn Huang, Siddhartha Jain, Igor Gitman, Ivan Moshkov, Wei Du, Shubham Toshniwal, George Armstrong, Branislav Kisacanin, Matvei Novikov, Daria Gitman, Evelina Bakhturina, Jane Polak Scowcroft, John Kamalu, Dan Su, Kezhi Kong, Markus Kliegl, Rabeeh Karimi, Ying Lin, Sanjeev Satheesh, Jupinder Parmar, Pritam Gundecha, Brandon Norick, Joseph Jennings, Shrimai Prabhumoye, Syeda Nahida Akter, Mostofa Patwary, Abhinav Khattar, Deepak Narayanan, Roger Waleffe, Jimmy Zhang, Bor-Yiing Su, Guyue Huang, Terry Kong, Parth Chadha, Sahil Jain, Christine Harvey, Elad Segal, Jining Huang, Sergey Kashirsky, Robert McQueen, Izzy Putterman, George Lam, Arun Venkatesan, Sherry Wu, Vinh Nguyen, Manoj Kilaru, Andrew Wang, Anna Warno, Abhilash Somasamudramath, Sandip Bhaskar, Maka Dong, Nave Assaf, Shahar Mor, Omer Ullman Argov, Scot Junkin, Oleksandr Romanenko, Pedro Larroy, Monika Katariya, Marco Rovinelli, Viji Balas, Nicholas Edelman, Anahita Bhiwandiwalla, Muthu Subramaniam, Smita Ithape, Karthik Ramamoorthy, Yuting Wu, Suguna Varshini Velury, Omri Almog, Joyjit Daw, Denys Fridman, Erick Galinkin, Michael Evans, Shaona Ghosh, Katherine Luna, Leon Derczynski, Nikki Pope, Eileen Long, Seth Schneider, Guillermo Siman, Tomasz Grzegorzek, Pablo Ribalta, Monika Katariya, Chris Alexiuk, Joey Conway, Trisha Saar, Ann Guan, Krzysztof Pawelec, Shyamala Prayaga, Oleksii Kuchaiev, Boris Ginsburg, Oluwatobi Olabiyi, Kari Briski, Jonathan Cohen, Bryan Catanzaro, Jonah Alben, Yonatan Geifman, Eric Chung",llamanemotron efficient reasoning models,we introduce the llamanemotron series of models an open family of heterogeneous reasoning models that deliver exceptional reasoning capabilities inference efficiency and an open license for enterprise use the family comes in three sizes nano 8b super 49b and ultra 253b and performs competitively with stateoftheart reasoning models such as deepseekr1 while offering superior inference throughput and memory efficiency in this report we discuss the training procedure for these models which entails using neural architecture search from llama 3 models for accelerated inference knowledge distillation and continued pretraining followed by a reasoningfocused posttraining stage consisting of two main parts supervised finetuning and large scale reinforcement learning llamanemotron models are the first opensource models to support a dynamic reasoning toggle allowing users to switch between standard chat and reasoning modes during inference to further support open research and facilitate model development we provide the following resources 1 we release the llamanemotron reasoning models lnnano lnsuper and lnultra under the commercially permissive nvidia open model license agreement 2 we release the complete posttraining dataset llamanemotronposttrainingdataset 3 we also release our training codebases nemo nemoaligner and megatronlm
http://arxiv.org/abs/2505.02848v1,2025-05-02T00:59:49Z,"Kexin Ding, Mu Zhou, Akshay Chaudhari, Shaoting Zhang, Dimitris N. Metaxas",aligning large language models with healthcare stakeholders a pathway to trustworthy ai integration,the wide exploration of large language models llms raises the awareness of alignment between healthcare stakeholder preferences and model outputs this alignment becomes a crucial foundation to empower the healthcare workflow effectively safely and responsibly yet the varying behaviors of llms may not always match with healthcare stakeholders knowledge demands and values to enable a humanai alignment healthcare stakeholders will need to perform essential roles in guiding and enhancing the performance of llms human professionals must participate in the entire life cycle of adopting llm in healthcare including training data curation model training and inference in this review we discuss the approaches tools and applications of alignments between healthcare stakeholders and llms we demonstrate that llms can better follow human values by properly enhancing healthcare knowledge integration task understanding and human guidance we provide outlooks on enhancing the alignment between humans and llms to build trustworthy realworld healthcare applications
http://arxiv.org/abs/2505.00931v1,2025-05-02T00:19:50Z,"Timur Jaganov, John Blake, Julián Villegas, Nicholas Carr",large language modeldriven dynamic assessment of grammatical accuracy in english language learner writing,this study investigates the potential for large language models llms to scaleup dynamic assessment da to facilitate such an investigation we first developed dynawritea modular microservicesbased grammatical tutoring application which supports multiple llms to generate dynamic feedback to learners of english initial testing of 21 llms revealed gpt4o and neural chat to have the most potential to scaleup da in the language learning classroom further testing of these two candidates found both models performed similarly in their ability to accurately identify grammatical errors in user sentences however gpt4o consistently outperformed neural chat in the quality of its da by generating clear consistent and progressively explicit hints realtime responsiveness and system stability were also confirmed through detailed performance testing with gpt4o exhibiting sufficient speed and stability this study shows that llms can be used to scaleup dynamic assessment and thus enable dynamic assessment to be delivered to larger groups than possible in traditional teacherlearner settings
http://arxiv.org/abs/2505.00926v2,2025-05-02T00:07:35Z,"Ruiquan Huang, Yingbin Liang, Jing Yang",how transformers learn regular language recognition a theoretical study on training dynamics and implicit bias,language recognition tasks are fundamental in natural language processing nlp and have been widely used to benchmark the performance of large language models llms these tasks also play a crucial role in explaining the working mechanisms of transformers in this work we focus on two representative tasks in the category of regular language recognition known as even pairs and parity check the aim of which is to determine whether the occurrences of certain subsequences in a given sequence are even our goal is to explore how a onelayer transformer consisting of an attention layer followed by a linear layer learns to solve these tasks by theoretically analyzing its training dynamics under gradient descent while even pairs can be solved directly by a onelayer transformer parity check need to be solved by integrating chainofthought cot either into the inference stage of a transformer welltrained for the even pairs task or into the training of a onelayer transformer for both problems our analysis shows that the joint training of attention and linear layers exhibits two distinct phases in the first phase the attention layer grows rapidly mapping data sequences into separable vectors in the second phase the attention layer becomes stable while the linear layer grows logarithmically and approaches in direction to a maxmargin hyperplane that correctly separates the attention layer outputs into positive and negative samples and the loss decreases at a rate of our experiments validate those theoretical results
http://arxiv.org/abs/2505.00903v1,2025-05-01T22:47:06Z,"Daria Gitman, Igor Gitman, Evelina Bakhturina",nemoinspector a visualization tool for llm generation analysis,adapting large language models llms to novel tasks and enhancing their overall capabilities often requires large highquality training datasets synthetic data generated at scale serves a valuable alternative when realworld data is scarce or difficult to obtain however ensuring the quality of synthetic datasets is challenging as developers must manually inspect and refine numerous samples to identify errors and areas for improvement this process is timeconsuming and requires specialized tools we introduce nemoinspector an opensource tool designed to simplify the analysis of synthetic datasets with integrated inference capabilities we demonstrate its effectiveness through two realworld cases analysis and cleaning of the synthetically generated gsmplus dataset with nemoinspector led to a significant decrease in lowquality samples from 4699 to 1951 the tool also helped identify and correct generation errors in openmath models improving accuracy by 192 on the math dataset and by 417 on the gsm8k dataset for a metallama38b model finetuned on synthetic data generated from nemotron4340b
http://arxiv.org/abs/2505.00831v4,2025-05-01T19:44:36Z,"Quang P. M. Pham, Khoi T. N. Nguyen, Nhi H. Doan, Cuong A. Pham, Kentaro Inui, Dezhen Song",smallplan leverage small language models for sequential path planning with simulationpowered llmguided distillation,efficient path planning in robotics particularly within largescale dynamic environments remains a significant hurdle while large language models llms offer strong reasoning capabilities their high computational cost and limited adaptability in dynamic scenarios hinder realtime deployment on edge devices we present smallplan a novel framework leveraging llms as teacher models to train lightweight small language models slms for highlevel path planning tasks in smallplan the slms provide optimal action sequences to navigate across scene graphs that compactly represent fullscaled 3d scenes the slms are trained in a simulationpowered interleaved manner with llmguided supervised finetuning sft and reinforcement learning rl this strategy not only enables slms to successfully complete navigation tasks but also makes them aware of important factors like travel distance and number of trials through experiments we demonstrate that the finetuned slms perform competitively with larger models like gpt4o on sequential path planning without suffering from hallucination and overfitting smallplan is resourceefficient making it wellsuited for edgedevice deployment and advancing practical autonomous robotics our source code is available here httpsgithubcomquangpham2006smallplan
http://arxiv.org/abs/2505.00814v1,2025-05-01T19:16:18Z,"Mario Sänger, Ulf Leser",knowledgeaugmented pretrained language models for biomedical relation extraction,automatic relationship extraction re from biomedical literature is critical for managing the vast amount of scientific knowledge produced each year in recent years utilizing pretrained language models plms has become the prevalent approach in re several studies report improved performance when incorporating additional context information while finetuning plms for re however variations in the plms applied the databases used for augmentation hyperparameter optimization and evaluation methods complicate direct comparisons between studies and raise questions about the generalizability of these findings our study addresses this research gap by evaluating plms enhanced with contextual information on five datasets spanning four relation scenarios within a consistent evaluation framework we evaluate three baseline plms and first conduct extensive hyperparameter optimization after selecting the topperforming model we enhance it with additional data including textual entity descriptions relational information from knowledge graphs and molecular structure encodings our findings illustrate the importance of i the choice of the underlying language model and ii a comprehensive hyperparameter optimization for achieving strong extraction performance although inclusion of context information yield only minor overall improvements an ablation study reveals substantial benefits for smaller plms when such external data was included during finetuning
http://arxiv.org/abs/2505.00808v1,2025-05-01T19:08:34Z,"Kola Ayonrinde, Louis Jaburi",a mathematical philosophy of explanations in mechanistic interpretability the strange science part ii,mechanistic interpretability aims to understand neural networks through causal explanations we argue for the explanatory view hypothesis that mechanistic interpretability research is a principled approach to understanding models because neural networks contain implicit explanations which can be extracted and understood we hence show that explanatory faithfulness an assessment of how well an explanation fits a model is welldefined we propose a definition of mechanistic interpretability mi as the practice of producing modellevel ontic causalmechanistic and falsifiable explanations of neural networks allowing us to distinguish mi from other interpretability paradigms and detail mis inherent limits we formulate the principle of explanatory optimism a conjecture which we argue is a necessary precondition for the success of mechanistic interpretability
http://arxiv.org/abs/2505.02847v2,2025-05-01T19:06:10Z,"Bang Zhang, Ruotian Ma, Qingxuan Jiang, Peisong Wang, Jiaqi Chen, Zheng Xie, Xingyu Chen, Yue Wang, Fanghua Ye, Jian Li, Yifan Yang, Zhaopeng Tu, Xiaolong Li",sentient agent as a judge evaluating higherorder social cognition in large language models,assessing how well a large language model llm understands human rather than merely text remains an open challenge to bridge the gap we introduce sentient agent as a judge sage an automated evaluation framework that measures an llms higherorder social cognition sage instantiates a sentient agent that simulates humanlike emotional changes and inner thoughts during interaction providing a more realistic evaluation of the tested model in multiturn conversations at every turn the agent reasons about i how its emotion changes ii how it feels and iii how it should reply yielding a numerical emotion trajectory and interpretable inner thoughts experiments on 100 supportivedialogue scenarios show that the final sentient emotion score correlates strongly with barrettlennard relationship inventory blri ratings and utterancelevel empathy metrics validating psychological fidelity we also build a public sentient leaderboard covering 18 commercial and opensource models that uncovers substantial gaps up to 4x between frontier systems gpt4olatest gemini25pro and earlier baselines gaps not reflected in conventional leaderboards eg arena sage thus provides a principled scalable and interpretable tool for tracking progress toward genuinely empathetic and socially adept language agents
http://arxiv.org/abs/2505.00776v1,2025-05-01T18:12:30Z,"Alessandro Raganato, Rafael Peñaloza, Marco Viviani, Gabriella Pasi",reasoning capabilities and invariability of large language models,large language models llms have shown remarkable capabilities in manipulating natural language across multiple applications but their ability to handle simple reasoning tasks is often questioned in this work we aim to provide a comprehensive analysis of llms reasoning competence specifically focusing on their prompt dependency in particular we introduce a new benchmark dataset with a series of simple reasoning questions demanding shallow logical reasoning aligned with cognitive psychology standards the questions are confined to a basic domain revolving around geometric figures ensuring that responses are independent of any preexisting intuition about the world and rely solely on deduction an empirical analysis involving zeroshot and fewshot prompting across 24 llms of different sizes reveals that while llms with over 70 billion parameters perform better in the zeroshot setting there is still a large room for improvement an additional test with chainofthought prompting over 22 llms shows that this additional prompt can aid or damage the performance of models depending on whether the rationale is required before or after the answer
http://arxiv.org/abs/2505.00703v1,2025-05-01T17:59:46Z,"Dongzhi Jiang, Ziyu Guo, Renrui Zhang, Zhuofan Zong, Hao Li, Le Zhuo, Shilin Yan, Pheng-Ann Heng, Hongsheng Li",t2ir1 reinforcing image generation with collaborative semanticlevel and tokenlevel cot,recent advancements in large language models have demonstrated how chainofthought cot and reinforcement learning rl can improve performance however applying such reasoning strategies to the visual generation domain remains largely unexplored in this paper we present t2ir1 a novel reasoningenhanced texttoimage generation model powered by rl with a bilevel cot reasoning process specifically we identify two levels of cot that can be utilized to enhance different stages of generation 1 the semanticlevel cot for highlevel planning of the prompt and 2 the tokenlevel cot for lowlevel pixel processing during patchbypatch generation to better coordinate these two levels of cot we introduce bicotgrpo with an ensemble of generation rewards which seamlessly optimizes both generation cots within the same training step by applying our reasoning strategies to the baseline model januspro we achieve superior performance with 13 improvement on t2icompbench and 19 improvement on the wise benchmark even surpassing the stateoftheart model flux1 code is available at httpsgithubcomcaraj7t2ir1
http://arxiv.org/abs/2505.00759v2,2025-05-01T17:47:55Z,"Jiahui Chen, Candace Ross, Reyhane Askari-Hemmat, Koustuv Sinha, Melissa Hall, Michal Drozdzal, Adriana Romero-Soriano",multimodal language models as texttoimage model evaluators,the steady improvements of texttoimage t2i generative models lead to slow deprecation of automatic evaluation benchmarks that rely on static datasets motivating researchers to seek alternative ways to evaluate the t2i progress in this paper we explore the potential of multimodal large language models mllms as evaluator agents that interact with a t2i model with the objective of assessing promptgeneration consistency and image aesthetics we present multimodal texttoimage eval mt2ie an evaluation framework that iteratively generates prompts for evaluation scores generated images and matches t2i evaluation of existing benchmarks with a fraction of the prompts used in existing static benchmarks moreover we show that mt2ies promptgeneration consistency scores have higher correlation with human judgment than scores previously introduced in the literature mt2ie generates prompts that are efficient at probing t2i model performance producing the same relative t2i model rankings as existing benchmarks while using only 180th the number of prompts for evaluation
http://arxiv.org/abs/2505.00679v2,2025-05-01T17:39:02Z,"Xinchen Yang, Marine Carpuat",steering large language models with register analysis for arbitrary style transfer,large language models llms have demonstrated strong capabilities in rewriting text across various styles however effectively leveraging this ability for examplebased arbitrary style transfer where an input text is rewritten to match the style of a given exemplar remains an open challenge a key question is how to describe the style of the exemplar to guide llms toward highquality rewrites in this work we propose a prompting method based on register analysis to guide llms to perform this task empirical evaluations across multiple style transfer tasks show that our prompting approach enhances style transfer strength while preserving meaning more effectively than existing prompting strategies
http://arxiv.org/abs/2505.00675v1,2025-05-01T17:31:33Z,"Yiming Du, Wenyu Huang, Danna Zheng, Zhaowei Wang, Sebastien Montella, Mirella Lapata, Kam-Fai Wong, Jeff Z. Pan",rethinking memory in ai taxonomy operations topics and future directions,memory is a fundamental component of ai systems underpinning large language models llms based agents while prior surveys have focused on memory applications with llms they often overlook the atomic operations that underlie memory dynamics in this survey we first categorize memory representations into parametric contextual structured and contextual unstructured and then introduce six fundamental memory operations consolidation updating indexing forgetting retrieval and compression we systematically map these operations to the most relevant research topics across longterm longcontext parametric modification and multisource memory by reframing memory systems through the lens of atomic operations and representation types this survey provides a structured and dynamic perspective on research benchmark datasets and tools related to memory in ai clarifying the functional interplay in llms based agents while outlining promising directions for future researchfootnotethe paper list datasets methods and tools are available at hrefhttpsgithubcomelvinyimingdusurveymemoryinaihttpsgithubcomelvinyimingdusurveymemoryinai
http://arxiv.org/abs/2505.00662v1,2025-05-01T17:03:17Z,"Wenkai Yang, Jingwen Chen, Yankai Lin, Ji-Rong Wen",deepcritic deliberate critique with large language models,as large language models llms are rapidly evolving providing accurate feedback and scalable oversight on their outputs becomes an urgent and critical problem leveraging llms as critique models to achieve automated supervision is a promising solution in this work we focus on studying and enhancing the math critique ability of llms current llm critics provide critiques that are too shallow and superficial on each step leading to low judgment accuracy and struggling to offer sufficient feedback for the llm generator to correct mistakes to tackle this issue we propose a novel and effective twostage framework to develop llm critics that are capable of deliberately critiquing on each reasoning step of math solutions in the first stage we utilize qwen2572binstruct to generate 45k longform critiques as seed data for supervised finetuning each seed critique consists of deliberate stepwise critiques that includes multiperspective verifications as well as indepth critiques of initial critiques for each reasoning step then we perform reinforcement learning on the finetuned model with either existing humanlabeled data from prm800k or our automatically annotated data obtained via monte carlo samplingbased correctness estimation to further incentivize its critique ability our developed critique model built on qwen257binstruct not only significantly outperforms existing llm critics including the samesized deepseekr1distill models and gpt4o on various error identification benchmarks but also more effectively helps the llm generator refine erroneous steps through more detailed feedback
http://arxiv.org/abs/2505.00661v2,2025-05-01T17:02:27Z,"Andrew K. Lampinen, Arslan Chaudhry, Stephanie C. Y. Chan, Cody Wild, Diane Wan, Alex Ku, Jörg Bornschein, Razvan Pascanu, Murray Shanahan, James L. McClelland",on the generalization of language models from incontext learning and finetuning a controlled study,large language models exhibit exciting capabilities yet can show surprisingly narrow generalization from finetuning eg they can fail to generalize to simple reversals of relations they are trained on or fail to make simple logical deductions based on trained information these failures to generalize from finetuning can hinder practical application of these models on the other hand language models incontext learning shows different inductive biases and can generalize better in some cases here we explore these differences in generalization between incontext and finetuningbased learning to do so we constructed several novel datasets to evaluate and improve models abilities to generalize from finetuning data the datasets are designed to create clean tests of generalization by isolating the knowledge in the dataset from that in pretraining we expose pretrained large models to controlled subsets of the information in these datasets either in context or through finetuning and evaluate their performance on test sets that require various types of generalization we find overall that in datamatched settings incontext learning can generalize more flexibly than finetuning though we also find some qualifications of prior findings such as cases when finetuning can generalize to reversals embedded in a larger structure of knowledge we build on these findings to propose a method to enable improved generalization from finetuning adding incontext inferences to finetuning data we show that this method improves generalization across various splits of our datasets and other benchmarks our results have implications for understanding the inductive biases of different modes of learning in language models and practically improving their performance
http://arxiv.org/abs/2505.00654v3,2025-05-01T16:55:44Z,Daniel N. Nissani,large language models understanding an inherent ambiguity barrier,a lively ongoing debate is taking place since the extraordinary emergence of large language models llms with regards to their capability to understand the world and capture the meaning of the dialogues in which they are involved arguments and counterarguments have been proposed based upon thought experiments anecdotal conversations between llms and humans statistical linguistic analysis philosophical considerations and more in this brief paper we present a counterargument based upon a thought experiment and semiformal considerations leading to an inherent ambiguity barrier which prevents llms from having any understanding of what their amazingly fluent dialogues mean
http://arxiv.org/abs/2505.00649v1,2025-05-01T16:48:37Z,"Marco Braga, Pranav Kasela, Alessandro Raganato, Gabriella Pasi",investigating task arithmetic for zeroshot information retrieval,large language models llms have shown impressive zeroshot performance across a variety of natural language processing tasks including document reranking however their effectiveness degrades on unseen tasks and domains largely due to shifts in vocabulary and word distributions in this paper we investigate task arithmetic a technique that combines the weights of llms pretrained on different tasks or domains via simple mathematical operations such as addition or subtraction to adapt retrieval models without requiring additional finetuning our method is able to synthesize diverse tasks and domain knowledge into a single model enabling effective zeroshot adaptation in different retrieval contexts extensive experiments on publicly available scientific biomedical and multilingual datasets show that our method improves stateoftheart reranking performance by up to 18 in ndcg10 and 15 in p10 in addition to these empirical gains our analysis provides insights into the strengths and limitations of task arithmetic as a practical strategy for zeroshot learning and model adaptation we make our code publicly available at httpsgithubcomdetectivembtaskarithmeticforzsir
http://arxiv.org/abs/2505.00626v2,2025-05-01T16:06:16Z,"Zihao Wang, Yibo Jiang, Jiahao Yu, Heqing Huang",the illusion of role separation hidden shortcuts in llm role learning and how to fix them,large language models llms that integrate multiple input roles eg system instructions user queries external tool outputs are increasingly prevalent in practice ensuring that the model accurately distinguishes messages from each role a concept we call emphrole separation is crucial for consistent multirole behavior although recent work often targets stateoftheart prompt injection defenses it remains unclear whether such methods truly teach llms to differentiate roles or merely memorize known triggers in this paper we examine emphroleseparation learning the process of teaching llms to robustly distinguish system and user tokens through a emphsimple controlled experimental framework we find that finetuned models often rely on two proxies for role identification 1 task type exploitation and 2 proximity to beginoftext although data augmentation can partially mitigate these shortcuts it generally leads to iterative patching rather than a deeper fix to address this we propose reinforcing emphinvariant signals that mark role boundaries by adjusting tokenwise cues in the models input encoding in particular manipulating position ids helps the model learn clearer distinctions and reduces reliance on superficial proxies by focusing on this mechanismcentered perspective our work illuminates how llms can more reliably maintain consistent multirole behavior without merely memorizing known prompts or triggers
http://arxiv.org/abs/2505.00624v1,2025-05-01T16:05:08Z,"Chaitali Bhattacharyya, Yeseong Kim",finescope precision pruning for domainspecialized large language models using saeguided selfdata cultivation,training large language models llms from scratch requires significant computational resources driving interest in developing smaller domainspecific llms that maintain both efficiency and strong task performance mediumsized models such as llama llama have served as starting points for domainspecific adaptation but they often suffer from accuracy degradation when tested on specialized datasets we introduce finescope a framework for deriving compact domainoptimized llms from larger pretrained models finescope leverages the sparse autoencoder sae framework inspired by its ability to produce interpretable feature representations to extract domainspecific subsets from large datasets we apply structured pruning with domainspecific constraints ensuring that the resulting pruned models retain essential knowledge for the target domain to further enhance performance these pruned models undergo selfdata distillation leveraging saecurated datasets to restore key domainspecific information lost during pruning extensive experiments and ablation studies demonstrate that finescope achieves highly competitive performance outperforming several largescale stateoftheart llms in domainspecific tasks additionally our results show that finescope enables pruned models to regain a substantial portion of their original performance when finetuned with saecurated datasets furthermore applying these datasets to finetune pretrained llms without pruning also improves their domainspecific accuracy highlighting the robustness of our approach the code will be released
http://arxiv.org/abs/2505.00582v1,2025-05-01T15:14:32Z,"Xinyu Ding, Meiqi Wang, Siyu Liao, Zhongfeng Wang",block circulant adapter for large language models,finetuning large language models llms is difficult due to their huge model size recent fourier domainbased methods show potential for reducing finetuning costs we propose a block circulant matrixbased finetuning method with a stable training heuristic to leverage the properties of circulant matrices and onedimensional fourier transforms to reduce storage and computation costs experiments show that our method uses less number of parameters than vera smaller than lora and less flops than fourierft while maintaining close or better task performance our approach presents a promising way in frequency domain to finetune large models on downstream tasks
http://arxiv.org/abs/2505.00570v2,2025-05-01T14:53:12Z,"Jushi Kai, Boyi Zeng, Yixuan Wang, Haoli Bai, Ziwei He, Bo Jiang, Zhouhan Lin",freqkv frequency domain keyvalue compression for efficient context window extension,frequencydomain compression has proven effective in reducing redundancies for spatial signals in this work we propose freqkv a novel frequency domain keyvalue kv compression technique that enables efficient context window extension for decoderonly large language models llms our approach is motivated by a key observation that in the frequency domain the energy distribution of the kv cache is predominantly concentrated in lowfrequency components by discarding highfrequency components we achieve efficient compression of the kv cache with minimal information loss freqkv iteratively compresses the increasing kv cache to a fixed size in the frequency domain allowing models to process lengthy contexts efficiently introducing no additional parameters or architectural modifications freqkv is applicable to both finetuning and inference with minimal finetuning llms can learn to leverage the limited cache that is compressed in the frequency domain and extend the context window experiments on a range of long context language modeling and understanding tasks demonstrate the efficiency and effectiveness of the proposed method
http://arxiv.org/abs/2505.00557v1,2025-05-01T14:33:47Z,Makoto Sato,triggering hallucinations in llms a quantitative study of promptinduced hallucination in large language models,hallucinations in large language models llms present a growing challenge across realworld applications from healthcare to law where factual reliability is essential despite advances in alignment and instruction tuning llms can still generate outputs that are fluent yet fundamentally untrue understanding the cognitive dynamics that underlie these hallucinations remains an open problem in this study we propose a promptbased framework to systematically trigger and quantify hallucination a hallucinationinducing prompt hip which synthetically fuses semantically distant concepts eg periodic table of elements and tarot divination in a misleading way and a hallucination quantifying prompt hqp which scores the plausibility confidence and coherence of the output controlled experiments across multiple llms revealed that hips consistently produced less coherent and more hallucinated responses than their nullfusion controls these effects varied across models with reasoningoriented llms showing distinct profiles from generalpurpose ones our framework provides a reproducible testbed for studying hallucination vulnerability and opens the door to developing safer more introspective llms that can detect and selfregulate the onset of conceptual instability
http://arxiv.org/abs/2505.00551v3,2025-05-01T14:28:35Z,"Chong Zhang, Yue Deng, Xiang Lin, Bin Wang, Dianwen Ng, Hai Ye, Xingxuan Li, Yao Xiao, Zhanfeng Mo, Qi Zhang, Lidong Bing",100 days after deepseekr1 a survey on replication studies and more directions for reasoning language models,the recent development of reasoning language models rlms represents a novel evolution in large language models in particular the recent release of deepseekr1 has generated widespread social impact and sparked enthusiasm in the research community for exploring the explicit reasoning paradigm of language models however the implementation details of the released models have not been fully opensourced by deepseek including deepseekr1zero deepseekr1 and the distilled small models as a result many replication studies have emerged aiming to reproduce the strong performance achieved by deepseekr1 reaching comparable performance through similar training procedures and fully opensource data resources these works have investigated feasible strategies for supervised finetuning sft and reinforcement learning from verifiable rewards rlvr focusing on data preparation and method design yielding various valuable insights in this report we provide a summary of recent replication studies to inspire future research we primarily focus on sft and rlvr as two main directions introducing the details for data construction method design and training procedure of current replication studies moreover we conclude key findings from the implementation details and experimental results reported by these studies anticipating to inspire future research we also discuss additional techniques of enhancing rlms highlighting the potential of expanding the application scope of these models and discussing the challenges in development by this survey we aim to help researchers and developers of rlms stay updated with the latest advancements and seek to inspire new ideas to further enhance rlms
http://arxiv.org/abs/2505.00506v1,2025-05-01T13:22:45Z,"Deanna Emery, Michael Goitia, Freddie Vargus, Iulia Neagu",hallumix a taskagnostic multidomain benchmark for realworld hallucination detection,as large language models llms are increasingly deployed in highstakes domains detecting hallucinated contenttext that is not grounded in supporting evidencehas become a critical challenge existing benchmarks for hallucination detection are often synthetically generated narrowly focused on extractive question answering and fail to capture the complexity of realworld scenarios involving multidocument contexts and fullsentence outputs we introduce the hallumix benchmark a diverse taskagnostic dataset that includes examples from a range of domains and formats using this benchmark we evaluate seven hallucination detection systemsboth open and closed sourcehighlighting differences in performance across tasks document lengths and input representations our analysis highlights substantial performance disparities between short and long contexts with critical implications for realworld retrieval augmented generation rag implementations quotient detections achieves the best overall performance with an accuracy of 082 and an f1 score of 084
http://arxiv.org/abs/2505.00479v1,2025-05-01T12:11:32Z,"Gijs Jan Brandsma, Jens Blom-Hansen, Christiaan Meijer, Kody Moodley",computational identification of regulatory statements in eu legislation,identifying regulatory statements in legislation is useful for developing metrics to measure the regulatory density and strictness of legislation a computational method is valuable for scaling the identification of such statements from a growing body of eu legislation constituting approximately 180000 published legal acts between 1952 and 2023 past work on extraction of these statements varies in the permissiveness of their definitions for what constitutes a regulatory statement in this work we provide a specific definition for our purposes based on the institutional grammar tool we develop and compare two contrasting approaches for automatically identifying such statements in eu legislation one based on dependency parsing and the other on a transformerbased machine learning model we found both approaches performed similarly well with accuracies of 80 and 84 respectively and a k alpha of 058 the high accuracies and not exceedingly high agreement suggests potential for combining strengths of both approaches
http://arxiv.org/abs/2505.01459v1,2025-05-01T12:06:39Z,"Abdoul Majid O. Thiombiano, Brahim Hnich, Ali Ben Mrad, Mohamed Wiem Mkaouer",moxe mixture of xlstm experts with entropyaware routing for efficient language modeling,this paper introduces moxe a novel architecture that synergistically combines the extended long shortterm memory xlstm with the mixture of experts moe framework to address critical scalability and efficiency challenges in large language models llms the proposed method effectively leverages xlstms innovative memory structures while strategically introducing sparsity through moe to substantially reduce computational overhead at the heart of our approach is a novel entropybased routing mechanism designed to dynamically route tokens to specialized experts thereby ensuring efficient and balanced resource utilization this entropy awareness enables the architecture to effectively manage both rare and common tokens with mlstm blocks being favored to handle rare tokens to further enhance generalization we introduce a suite of auxiliary losses including entropybased and groupwise balancing losses ensuring robust performance and efficient training theoretical analysis and empirical evaluations rigorously demonstrate that moxe achieves significant efficiency gains and enhanced effectiveness compared to existing approaches marking a notable advancement in scalable llm architectures
http://arxiv.org/abs/2505.00467v1,2025-05-01T11:43:27Z,"Vahid Balazadeh, Michael Cooper, David Pellow, Atousa Assadi, Jennifer Bell, Jim Fackler, Gabriel Funingana, Spencer Gable-Cook, Anirudh Gangadhar, Abhishek Jaiswal, Sumanth Kaja, Christopher Khoury, Randy Lin, Kaden McKeen, Sara Naimimohasses, Khashayar Namdar, Aviraj Newatia, Allan Pang, Anshul Pattoo, Sameer Peesapati, Diana Prepelita, Bogdana Rakova, Saba Sadatamin, Rafael Schulman, Ajay Shah, Syed Azhar Shah, Syed Ahmar Shah, Babak Taati, Balagopal Unnikrishnan, Stephanie Williams, Rahul G Krishnan",red teaming large language models for healthcare,we present the design process and findings of the preconference workshop at the machine learning for healthcare conference 2024 entitled red teaming large language models for healthcare which took place on august 15 2024 conference participants comprising a mix of computational and clinical expertise attempted to discover vulnerabilities realistic clinical prompts for which a large language model llm outputs a response that could cause clinical harm redteaming with clinicians enables the identification of llm vulnerabilities that may not be recognised by llm developers lacking clinical expertise we report the vulnerabilities found categorise them and present the results of a replication study assessing the vulnerabilities across all llms provided
http://arxiv.org/abs/2505.00422v1,2025-05-01T09:41:41Z,"Yu Han, Aaron Ceross, Jeroen H. M. Bergmann",toward automated regulatory decisionmaking trustworthy medical device risk classification with multimodal transformers and selftraining,accurate classification of medical device risk levels is essential for regulatory oversight and clinical safety we present a transformerbased multimodal framework that integrates textual descriptions and visual information to predict device regulatory classification the model incorporates a crossattention mechanism to capture intermodal dependencies and employs a selftraining strategy for improved generalization under limited supervision experiments on a realworld regulatory dataset demonstrate that our approach achieves up to 904 accuracy and 979 auroc significantly outperforming textonly 772 and imageonly 548 baselines compared to standard multimodal fusion the selftraining mechanism improved svm performance by 33 percentage points in accuracy from 871 to 904 and 14 points in macrof1 suggesting that pseudolabeling can effectively enhance generalization under limited supervision ablation studies further confirm the complementary benefits of both crossmodal attention and selftraining
http://arxiv.org/abs/2505.00753v1,2025-05-01T08:29:26Z,"Henry Peng Zou, Wei-Chieh Huang, Yaozu Wu, Yankai Chen, Chunyu Miao, Hoang Nguyen, Yue Zhou, Weizhi Zhang, Liancheng Fang, Langzhou He, Yangning Li, Yuwei Cao, Dongyuan Li, Renhe Jiang, Philip S. Yu",a survey on large language model based humanagent systems,recent advances in large language models llms have sparked growing interest in building fully autonomous agents however fully autonomous llmbased agents still face significant challenges including limited reliability due to hallucinations difficulty in handling complex tasks and substantial safety and ethical risks all of which limit their feasibility and trustworthiness in realworld applications to overcome these limitations llmbased humanagent systems llmhas incorporate humanprovided information feedback or control into the agent system to enhance system performance reliability and safety this paper provides the first comprehensive and structured survey of llmhas it clarifies fundamental concepts systematically presents core components shaping these systems including environment profiling human feedback interaction types orchestration and communication explores emerging applications and discusses unique challenges and opportunities by consolidating current knowledge and offering a structured overview we aim to foster further research and innovation in this rapidly evolving interdisciplinary field paper lists and resources are available at httpsgithubcomhenrypengzouawesomellmbasedhumanagentsystempapers
http://arxiv.org/abs/2505.00389v1,2025-05-01T08:27:14Z,"Bowen Zhang, Zixin Song, Chunping Li",csesfp enabling unsupervised sentence representation learning via a single forward pass,as a fundamental task in information retrieval and computational linguistics sentence representation has profound implications for a wide range of practical applications such as text clustering content analysis questionanswering systems and web search recent advances in pretrained language models plms have driven remarkable progress in this field particularly through unsupervised embedding derivation methods centered on discriminative plms like bert however due to time and computational constraints few efforts have attempted to integrate unsupervised sentence representation with generative plms which typically possess much larger parameter sizes given that stateoftheart models in both academia and industry are predominantly based on generative architectures there is a pressing need for an efficient unsupervised text representation framework tailored to decoderonly plms to address this concern we propose csesfp an innovative method that exploits the structural characteristics of generative models compared to existing strategies csesfp requires only a single forward pass to perform effective unsupervised contrastive learning rigorous experimentation demonstrates that csesfp not only produces higherquality embeddings but also significantly reduces both training time and memory consumption furthermore we introduce two ratio metrics that jointly assess alignment and uniformity thereby providing a more robust means for evaluating the semantic spatial properties of encoding models
http://arxiv.org/abs/2505.00367v1,2025-05-01T07:37:18Z,"JunSeo Kim, HyeHyeon Kim",koacd the first korean adolescent dataset for cognitive distortion analysis,cognitive distortion refers to negative thinking patterns that can lead to mental health issues like depression and anxiety in adolescents previous studies using natural language processing nlp have focused mainly on smallscale adult datasets with limited research on adolescents this study introduces koacd the first largescale dataset of cognitive distortions in korean adolescents containing 108717 instances we applied a multilarge language model llm negotiation method to refine distortion classification and generate synthetic data using two approaches cognitive clarification for textual clarity and cognitive balancing for diverse distortion representation validation through llms and expert evaluations showed that while llms classified distortions with explicit markers they struggled with contextdependent reasoning where human evaluators demonstrated higher accuracy koacd aims to enhance future research on cognitive distortion detection
http://arxiv.org/abs/2505.00358v1,2025-05-01T07:08:19Z,"Albert Ge, Tzu-Heng Huang, John Cooper, Avi Trost, Ziyi Chu, Satya Sai Srinath Namburi GNVV, Ziyang Cai, Kendall Park, Nicholas Roberts, Frederic Sala",rb domain regrouping and data mixture balancing for efficient foundation model training,data mixing strategies have successfully reduced the costs involved in training language models while promising such methods suffer from two flaws first they rely on predetermined data domains eg data sources task types which may fail to capture critical semantic nuances leaving performance on the table second these methods scale with the number of domains in a computationally prohibitive way we address these challenges via rb a framework that repartitions training data based on semantic similarity regroup to create finergrained domains and efficiently optimizes the data composition balance by leveraging a gram matrix induced by domain gradients obtained throughout training unlike prior works it removes the need for additional compute to obtain evaluation information such as losses or gradients we analyze this technique under standard regularity conditions and provide theoretical insights that justify rbs effectiveness compared to nonadaptive mixing approaches empirically we demonstrate the effectiveness of rb on five diverse datasets ranging from natural language to reasoning and multimodal tasks with as little as 001 additional compute overhead rb matches or exceeds the performance of stateoftheart data mixing strategies
http://arxiv.org/abs/2505.00339v1,2025-05-01T06:36:21Z,"Antoun Yaacoub, Sansiri Tarnpradab, Phattara Khumprom, Zainab Assaghir, Lionel Prevost, Jérôme Da-Rugna",enhancing aidriven education integrating cognitive frameworks linguistic feedback analysis and ethical considerations for improved content generation,artificial intelligence ai is rapidly transforming education presenting unprecedented opportunities for personalized learning and streamlined content creation however realizing the full potential of ai in educational settings necessitates careful consideration of the quality cognitive depth and ethical implications of aigenerated materials this paper synthesizes insights from four related studies to propose a comprehensive framework for enhancing aidriven educational tools we integrate cognitive assessment frameworks blooms taxonomy and solo taxonomy linguistic analysis of aigenerated feedback and ethical design principles to guide the development of effective and responsible ai tools we outline a structured threephase approach encompassing cognitive alignment linguistic feedback integration and ethical safeguards the practical application of this framework is demonstrated through its integration into oneclickquiz an aipowered moodle plugin for quiz generation this work contributes a comprehensive and actionable guide for educators researchers and developers aiming to harness ais potential while upholding pedagogical and ethical standards in educational content generation
http://arxiv.org/abs/2505.00337v1,2025-05-01T06:34:55Z,"Xuyang Guo, Jiayan Huo, Zhenmei Shi, Zhao Song, Jiahao Zhang, Jiale Zhao",t2vphysbench a firstprinciples benchmark for physical consistency in texttovideo generation,texttovideo generative models have made significant strides in recent years producing highquality videos that excel in both aesthetic appeal and accurate instruction following and have become central to digital art creation and user engagement online yet despite these advancements their ability to respect fundamental physical laws remains largely untested many outputs still violate basic constraints such as rigidbody collisions energy conservation and gravitational dynamics resulting in unrealistic or even misleading content existing physicalevaluation benchmarks typically rely on automatic pixellevel metrics applied to simplistic lifescenario prompts and thus overlook both human judgment and firstprinciples physics to fill this gap we introduce textbft2vphysbench a firstprincipled benchmark that systematically evaluates whether stateoftheart texttovideo systems both opensource and commercial obey twelve core physical laws including newtonian mechanics conservation principles and phenomenological effects our benchmark employs a rigorous human evaluation protocol and includes three targeted studies 1 an overall compliance assessment showing that all models score below 060 on average in each law category 2 a prompthint ablation revealing that even detailed lawspecific hints fail to remedy physics violations and 3 a counterfactual robustness test demonstrating that models often generate videos that explicitly break physical rules when so instructed the results expose persistent limitations in current architectures and offer concrete insights for guiding future research toward truly physicsaware video generation
http://arxiv.org/abs/2505.00315v1,2025-05-01T05:22:11Z,"Piotr Piękos, Róbert Csordás, Jürgen Schmidhuber",mixture of sparse attention contentbased learnable sparse attention via expertchoice routing,recent advances in large language models highlighted the excessive quadratic cost of selfattention despite the significant research efforts subquadratic attention methods still suffer from inferior performance in practice we hypothesize that dynamic learned contentbased sparsity can lead to more efficient attention mechanisms we present mixture of sparse attention mosa a novel approach inspired by mixture of experts moe with expert choice routing mosa dynamically selects tokens for each attention head allowing arbitrary sparse attention patterns by selecting tokens from a sequence of length mosa reduces the computational complexity of each attention head from to this enables using more heads within the same computational budget allowing higher specialization we show that among the tested sparse attention variants mosa is the only one that can outperform the dense baseline sometimes with up to 27 better perplexity for an identical compute budget mosa can also reduce the resource usage compared to dense selfattention despite using torch implementation without an optimized kernel perplexitymatched mosa models are simultaneously faster in wallclock time require less memory for training and drastically reduce the size of the kvcache compared to the dense transformer baselines
http://arxiv.org/abs/2505.00268v1,2025-05-01T03:25:25Z,"Jekaterina Novikova, Carol Anderson, Borhane Blili-Hamelin, Subhabrata Majumdar",consistency in language models current landscape challenges and future directions,the hallmark of effective language use lies in consistency expressing similar meanings in similar contexts and avoiding contradictions while human communication naturally demonstrates this principle stateoftheart language models struggle to maintain reliable consistency across different scenarios this paper examines the landscape of consistency research in ai language systems exploring both formal consistency including logical rule adherence and informal consistency such as moral and factual coherence we analyze current approaches to measure aspects of consistency identify critical research gaps in standardization of definitions multilingual assessment and methods to improve consistency our findings point to an urgent need for robust benchmarks to measure and interdisciplinary approaches to ensure consistency in the application of language models on domainspecific tasks while preserving the utility and adaptability
http://arxiv.org/abs/2505.00263v1,2025-05-01T03:07:30Z,"Michael J. Ryan, Danmei Xu, Chris Nivera, Daniel Campos",enronqa towards personalized rag over private documents,retrieval augmented generation rag has become one of the most popular methods for bringing knowledgeintensive context to large language models llm because of its ability to bring local context at inference time without the cost or data leakage risks associated with finetuning a clear separation of private information from the llm training has made rag the basis for many enterprise llm workloads as it allows the company to augment llms understanding using customers private documents despite its popularity for private documents in enterprise deployments current rag benchmarks for validating and optimizing rag pipelines draw their corpora from public data such as wikipedia or generic web pages and offer little to no personal context seeking to empower more personal and private rag we release the enronqa benchmark a dataset of 103638 emails with 528304 questionanswer pairs across 150 different user inboxes enronqa enables better benchmarking of rag pipelines over private data and allows for experimentation on the introduction of personalized retrieval settings over realistic data finally we use enronqa to explore the tradeoff in memorization and retrieval when reasoning over private documents
http://arxiv.org/abs/2505.00261v1,2025-05-01T03:04:07Z,"Jayoung Song, KyungTae Lim, Jungyeul Park",enriching the korean learner corpus with multireference annotations and rubricbased scoring,despite growing global interest in korean language education there remains a significant lack of learner corpora tailored to korean l2 writing to address this gap we enhance the kolla korean learner corpus by adding multiple grammatical error correction gec references thereby enabling more nuanced and flexible evaluation of gec systems and reflects the variability of human language additionally we enrich the corpus with rubricbased scores aligned with guidelines from the korean national language institute capturing grammatical accuracy coherence and lexical diversity these enhancements make kolla a robust and standardized resource for research in korean l2 education supporting advancements in language learning assessment and automated error correction
http://arxiv.org/abs/2505.01456v1,2025-05-01T01:54:00Z,"Vaidehi Patil, Yi-Lin Sung, Peter Hase, Jie Peng, Tianlong Chen, Mohit Bansal",unlearning sensitive information in multimodal llms benchmark and attackdefense evaluation,llms trained on massive datasets may inadvertently acquire sensitive information such as personal details and potentially harmful content this risk is further heightened in multimodal llms as they integrate information from multiple modalities image and text adversaries can exploit this knowledge through multimodal prompts to extract sensitive details evaluating how effectively mllms can forget such information targeted unlearning necessitates the creation of highquality wellannotated imagetext pairs while prior work on unlearning has focused on text multimodal unlearning remains underexplored to address this gap we first introduce a multimodal unlearning benchmark unlokvqa unlearning outside knowledge vqa as well as an attackanddefense framework to evaluate methods for deleting specific multimodal knowledge from mllms we extend a visual questionanswering dataset using an automated pipeline that generates varyingproximity samples for testing generalization and specificity followed by manual filtering for maintaining high quality we then evaluate six defense objectives against seven attacks four whitebox three blackbox including a novel whitebox method leveraging interpretability of hidden states our results show multimodal attacks outperform text or imageonly ones and that the most effective defense removes answer information from internal model states additionally larger models exhibit greater postediting robustness suggesting that scale enhances safety unlokvqa provides a rigorous benchmark for advancing unlearning in mllms
http://arxiv.org/abs/2505.00234v3,2025-05-01T00:48:12Z,"Vishnu Sarukkai, Zhiqiang Xie, Kayvon Fatahalian",selfgenerated incontext examples improve llm agents for sequential decisionmaking tasks,improving large language model llm agents for sequential decisionmaking tasks typically requires extensive taskspecific knowledge engineeringcustom prompts curated examples and specialized observationaction spaces we investigate a different approach where agents automatically improve by learning from their own successful experiences without human intervention our method constructs and refines a database of selfgenerated trajectories that serve as incontext examples for future tasks even naive accumulation of successful trajectories yields substantial performance gains across three diverse benchmarks alfworld 73 to 89 wordcraft 55 to 64 and intercodesql 75 to 79 these improvements exceed those achieved by upgrading from gpt4omini to gpt4o and match the performance of allowing multiple attempts per task we further enhance this approach with two innovations databaselevel curation using populationbased training to propagate highperforming example collections and exemplarlevel curation that selectively retains trajectories based on their empirical utility as incontext examples with these enhancements our method achieves 93 success on alfworldsurpassing approaches that use more powerful llms and handcrafted components our trajectory bootstrapping technique demonstrates that agents can autonomously improve through experience offering a scalable alternative to laborintensive knowledge engineering
http://arxiv.org/abs/2505.00212v1,2025-04-30T23:09:44Z,"Shaokun Zhang, Ming Yin, Jieyu Zhang, Jiale Liu, Zhiguang Han, Jingyang Zhang, Beibin Li, Chi Wang, Huazheng Wang, Yiran Chen, Qingyun Wu",which agent causes task failures and when on automated failure attribution of llm multiagent systems,failure attribution in llm multiagent systemsidentifying the agent and step responsible for task failuresprovides crucial clues for systems debugging but remains underexplored and laborintensive in this paper we propose and formulate a new research area automated failure attribution for llm multiagent systems to support this initiative we introduce the whowhen dataset comprising extensive failure logs from 127 llm multiagent systems with finegrained annotations linking failures to specific agents and decisive error steps using the whowhen we develop and evaluate three automated failure attribution methods summarizing their corresponding pros and cons the best method achieves 535 accuracy in identifying failureresponsible agents but only 142 in pinpointing failure steps with some methods performing below random even sota reasoning models such as openai o1 and deepseek r1 fail to achieve practical usability these results highlight the tasks complexity and the need for further research in this area code and dataset are available at httpsgithubcommingyin1agentsfailureattribution
http://arxiv.org/abs/2505.00191v1,2025-04-30T21:20:05Z,"Yuyan Ge, Kwan Ho Ryan Chan, Pablo Messina, René Vidal",ipcrr information pursuit for interpretable classification of chest radiology reports,the development of aibased methods for analyzing radiology reports could lead to significant advances in medical diagnosisfrom improving diagnostic accuracy to enhancing efficiency and reducing workload however the lack of interpretability in these methods has hindered their adoption in clinical settings in this paper we propose an interpretablebydesign framework for classifying radiology reports the key idea is to extract a set of most informative queries from a large set of reports and use these queries and their corresponding answers to predict a diagnosis thus the explanation for a prediction is by construction the set of selected queries and answers we use the information pursuit framework to select informative queries the flant5 model to determine if facts are present in the report and a classifier to predict the disease experiments on the mimiccxr dataset demonstrate the effectiveness of the proposed method highlighting its potential to enhance trust and usability in medical ai
http://arxiv.org/abs/2505.00150v1,2025-04-30T19:48:12Z,"Minh-Hao Van, Xintao Wu",detecting and mitigating hateful content in multimodal memes with visionlanguage models,the rapid evolution of social media has provided enhanced communication channels for individuals to create online content enabling them to express their thoughts and opinions multimodal memes often utilized for playful or humorous expressions with visual and textual elements are sometimes misused to disseminate hate speech against individuals or groups while the detection of hateful memes is wellresearched developing effective methods to transform hateful content in memes remains a significant challenge leveraging the powerful generation and reasoning capabilities of visionlanguage models vlms we address the tasks of detecting and mitigating hateful content this paper presents two key contributions first a definitionguided prompting technique for detecting hateful memes and second a unified framework for mitigating hateful content in memes named unhatememe which works by replacing hateful textual andor visual components with our definitionguided prompts vlms achieve impressive performance on hateful memes detection task furthermore our unhatememe framework integrated with vlms demonstrates a strong capability to convert hateful memes into nonhateful forms that meet humanlevel criteria for hate speech and maintain multimodal coherence between image and text through empirical experiments we show the effectiveness of stateoftheart pretrained vlms such as llava gemini and gpt4o on the proposed tasks providing a comprehensive analysis of their respective strengths and limitations for these tasks this paper aims to shed light on important applications of vlms for ensuring safe and respectful online environments
http://arxiv.org/abs/2505.00147v1,2025-04-30T19:35:46Z,"Yinghui He, Abhishek Panigrahi, Yong Lin, Sanjeev Arora",adaptmi adaptive skillbased incontext math instruction for small language models,incontext learning icl allows a language model to improve its problemsolving capability when provided with suitable information in context since the choice of incontext information can be determined based on the problem itself incontext learning is analogous to human learning from teachers in a classroom recent works didolkar et al 2024a 2024b show that icl performance can be improved by leveraging a frontier large language models llm ability to predict required skills to solve a problem popularly referred to as an llms metacognition and using the recommended skills to construct necessary incontext examples while this skillbased strategy boosts icl performance in larger models its gains on small language models slms have been minimal highlighting a performance gap in icl capabilities we investigate this gap and show that skillbased prompting can hurt slm performance on easy questions by introducing unnecessary information akin to cognitive overload to address this we introduce adaptmi an adaptive approach to selecting skillbased incontext math instructions for slms inspired by cognitive load theory from human pedagogy our method only introduces skillbased examples when the model performs poorly we further propose adaptmi which adds examples targeted to the specific skills missing from the models responses on 5shot evaluations across popular math benchmarks and five slms 1b7b qwen llama adaptmi improves accuracy by up to 6 over naive skillbased strategies
http://arxiv.org/abs/2505.03788v1,2025-04-30T19:19:21Z,"Trilok Padhi, Ramneet Kaur, Adam D. Cobb, Manoj Acharya, Anirban Roy, Colin Samplawski, Brian Matejek, Alexander M. Berenbeim, Nathaniel D. Bastian, Susmit Jha",calibrating uncertainty quantification of multimodal llms using grounding,we introduce a novel approach for calibrating uncertainty quantification uq tailored for multimodal large language models llms existing stateoftheart uq methods rely on consistency among multiple responses generated by the llm on an input query under diverse settings however these approaches often report higher confidence in scenarios where the llm is consistently incorrect this leads to a poorly calibrated confidence with respect to accuracy to address this we leverage crossmodal consistency in addition to selfconsistency to improve the calibration of the multimodal models specifically we ground the textual responses to the visual inputs the confidence from the grounding model is used to calibrate the overall confidence given that using a grounding model adds its own uncertainty in the pipeline we apply temperature scaling a widely accepted parametric calibration technique to calibrate the grounding models confidence in the accuracy of generated responses we evaluate the proposed approach across multiple multimodal tasks such as medical question answering slake and visual question answering vqav2 considering multimodal models such as llavamed and llava the experiments demonstrate that the proposed framework achieves significantly improved calibration on both tasks
http://arxiv.org/abs/2505.00127v1,2025-04-30T18:48:06Z,"Jinyan Su, Jennifer Healey, Preslav Nakov, Claire Cardie",between underthinking and overthinking an empirical study of reasoning length and correctness in llms,large language models llms are increasingly optimized for long reasoning under the assumption that more reasoning leads to better performance however emerging evidence suggests that longer responses can sometimes degrade accuracy rather than improve it in this paper we conduct a systematic empirical study of the relationship between reasoning length and answer correctness we find that llms tend to overthink simple problems generating unnecessarily long outputs and underthink harder ones failing to extend their reasoning when it is most needed this indicates that models might misjudge problem difficulty and fail to calibrate their response length appropriately furthermore we investigate the effects of length reduction with a preference optimization algorithm when simply preferring the shorter responses regardless of answer correctness experiments show that the generation length can be significantly reduced while maintaining acceptable accuracy our findings highlight generation length as a meaningful signal for reasoning behavior and motivate further exploration into llms selfawareness in reasoning length adaptation
http://arxiv.org/abs/2505.00114v1,2025-04-30T18:33:53Z,"Silvana Yakhni, Ali Chehab",finetuning llms for lowresource dialect translation the case of lebanese,this paper examines the effectiveness of large language models llms in translating the lowresource lebanese dialect focusing on the impact of culturally authentic data versus larger translated datasets we compare three finetuning approaches basic contrastive and grammarhint tuning using opensource aya23 models experiments reveal that models finetuned on a smaller but culturally aware lebanese dataset lw consistently outperform those trained on larger nonnative data the best results were achieved through contrastive finetuning paired with contrastive prompting which indicates the benefits of exposing translation models to bad examples in addition to ensure authentic evaluation we introduce lebeval a new benchmark derived from native lebanese content and compare it to the existing flores benchmark our findings challenge the more data is better paradigm and emphasize the crucial role of cultural authenticity in dialectal translation we made our datasets and code available on github
http://arxiv.org/abs/2505.00105v1,2025-04-30T18:20:16Z,"Naamán Huerga-Pérez, Rubén Álvarez, Rubén Ferrero-Guillén, Alberto Martínez-Gutiérrez, Javier Díez-González",optimization of embeddings storage for rag systems using quantization and dimensionality reduction techniques,retrievalaugmented generation enhances language models by retrieving relevant information from external knowledge bases relying on highdimensional vector embeddings typically stored in float32 precision however storing these embeddings at scale presents significant memory challenges to address this issue we systematically investigate on mteb benchmark two complementary optimization strategies quantization evaluating standard formats float16 int8 binary and lowbit floatingpoint types float8 and dimensionality reduction assessing methods like pca kernel pca umap random projections and autoencoders our results show that float8 quantization achieves a 4x storage reduction with minimal performance degradation 03 significantly outperforming int8 quantization at the same compression level being simpler to implement pca emerges as the most effective dimensionality reduction technique crucially combining moderate pca eg retaining 50 dimensions with float8 quantization offers an excellent tradeoff achieving 8x total compression with less performance impact than using int8 alone which provides only 4x compression to facilitate practical application we propose a methodology based on visualizing the performancestorage tradeoff space to identify the optimal configuration that maximizes performance within their specific memory constraints
http://arxiv.org/abs/2504.21851v1,2025-04-30T17:58:06Z,"Sichang Tu, Abigail Powers, Stephen Doogan, Jinho D. Choi",trust an llmbased dialogue system for trauma understanding and structured assessments,objectives while large language models llms have been widely used to assist clinicians and support patients no existing work has explored dialogue systems for standard diagnostic interviews and assessments this study aims to bridge the gap in mental healthcare accessibility by developing an llmpowered dialogue system that replicates clinician behavior materials and methods we introduce trust a framework of cooperative llm modules capable of conducting formal diagnostic interviews and assessments for posttraumatic stress disorder ptsd to guide the generation of appropriate clinical responses we propose a dialogue acts schema specifically designed for clinical interviews additionally we develop a patient simulation approach based on reallife interview transcripts to replace timeconsuming and costly manual testing by clinicians results a comprehensive set of evaluation metrics is designed to assess the dialogue system from both the agent and patient simulation perspectives expert evaluations by conversation and clinical specialists show that trust performs comparably to reallife clinical interviews discussion our system performs at the level of average clinicians with room for future enhancements in communication styles and response appropriateness conclusions our trust framework shows its potential to facilitate mental healthcare availability
http://arxiv.org/abs/2505.03786v1,2025-04-30T17:27:13Z,Md Fahim Anjum,when reasoning beats scale a 15b reasoning model outranks 13b llms as discriminator,large language models llm with reasoning capabilities offer a promising path for improving candidate evaluation in planning frameworks but their relative performance against traditional nonreasoning models remains largely underexplored in this study we benchmark a distilled 15b parameter reasoning model deepseekr1 against several stateoftheart nonreasoning llms within a generatordiscriminator llm planning framework for the texttosql task for this we introduce a novel method for extracting soft scores from the chainofthought cot outputs from reasoning that enables finegrained ranking of candidates our central hypothesis is that reasoning models are more effective discriminators than nonreasoning llms our results show that distilled deepseekr115b achieves up to higher f1 and better discrimination accuracy than codellama7b as well as higher execution accuracy than codellama13b despite having significantly fewer parameters furthermore we find that there is a limit to the logical capabilities of reasoning models and only providing more context or allowing more compute budget for reasoning is not enough to improve their discrimination performance finally we demonstrate that unlike nonreasoning llms reasoning models find generation more challenging than discrimination and may underperform as generators compared to smaller nonreasoning llms our work highlights the potential of reasoning models as discriminators in agentic frameworks far outweighing their capabilities as generators offering insights into their optimal role within llm planning infrastructures
http://arxiv.org/abs/2504.21801v1,2025-04-30T16:57:48Z,"Z. Z. Ren, Zhihong Shao, Junxiao Song, Huajian Xin, Haocheng Wang, Wanjia Zhao, Liyue Zhang, Zhe Fu, Qihao Zhu, Dejian Yang, Z. F. Wu, Zhibin Gou, Shirong Ma, Hongxuan Tang, Yuxuan Liu, Wenjun Gao, Daya Guo, Chong Ruan",deepseekproverv2 advancing formal mathematical reasoning via reinforcement learning for subgoal decomposition,we introduce deepseekproverv2 an opensource large language model designed for formal theorem proving in lean 4 with initialization data collected through a recursive theorem proving pipeline powered by deepseekv3 the coldstart training procedure begins by prompting deepseekv3 to decompose complex problems into a series of subgoals the proofs of resolved subgoals are synthesized into a chainofthought process combined with deepseekv3s stepbystep reasoning to create an initial cold start for reinforcement learning this process enables us to integrate both informal and formal mathematical reasoning into a unified model the resulting model deepseekproverv2671b achieves stateoftheart performance in neural theorem proving reaching 889 pass ratio on the minif2ftest and solving 49 out of 658 problems from putnambench in addition to standard benchmarks we introduce proverbench a collection of 325 formalized problems to enrich our evaluation including 15 selected problems from the recent aime competitions years 2425 further evaluation on these 15 aime problems shows that the model successfully solves 6 of them in comparison deepseekv3 solves 8 of these problems using majority voting highlighting that the gap between formal and informal mathematical reasoning in large language models is substantially narrowing
http://arxiv.org/abs/2504.21800v2,2025-04-30T16:56:56Z,"Suhas BN, Dominik Mattioli, Saeed Abdullah, Rosa I. Arriaga, Chris W. Wiese, Andrew M. Sherrill",how real are synthetic therapy conversations evaluating fidelity in prolonged exposure dialogues,the growing adoption of synthetic data in healthcare is driven by privacy concerns limited access to realworld data and the high cost of annotation this work explores the use of synthetic prolonged exposure pe therapeutic conversations for posttraumatic stress disorder ptsd as a scalable alternative for training and evaluating clinical models we systematically compare real and synthetic dialogues using linguistic structural and protocolspecific metrics including turntaking patterns and treatment fidelity we also introduce and evaluate pespecific metrics derived from linguistic analysis and semantic modeling offering a novel framework for assessing clinical fidelity beyond surface fluency our findings show that although synthetic data holds promise for mitigating data scarcity and protecting patient privacy it can struggle to capture the subtle dynamics of therapeutic interactions synthetic therapy dialogues closely match structural features of realworld conversations eg speaker switch ratio 098 vs 099 however they may not adequately reflect key fidelity markers eg distress monitoring we highlight gaps in existing evaluation frameworks and advocate for fidelityaware metrics that go beyond surface fluency to uncover clinically significant failures our findings clarify where synthetic data can effectively complement realworld datasets and where critical limitations remain
http://arxiv.org/abs/2504.21798v1,2025-04-30T16:56:06Z,"John Yang, Kilian Leret, Carlos E. Jimenez, Alexander Wettig, Kabir Khandpur, Yanzhe Zhang, Binyuan Hui, Ofir Press, Ludwig Schmidt, Diyi Yang",swesmith scaling data for software engineering agents,despite recent progress in language models lms for software engineering collecting training data remains a significant pain point existing datasets are small with at most 1000s of training instances from 11 or fewer github repositories the procedures to curate such datasets are often complex necessitating hundreds of hours of human labor companion execution environments also take up several terabytes of storage severely limiting their scalability and usability to address this pain point we introduce swesmith a novel pipeline for generating software engineering training data at scale given any python codebase swesmith constructs a corresponding execution environment then automatically synthesizes 100s to 1000s of task instances that break existing tests in the codebase using swesmith we create a dataset of 50k instances sourced from 128 github repositories an order of magnitude larger than all previous works we train sweagentlm32b achieving 402 pass1 resolve rate on the swebench verified benchmark state of the art among open source models we open source swesmith collection procedure task instances trajectories models to lower the barrier of entry for research in lm systems for automated software engineering all assets available at httpsswesmithcom
http://arxiv.org/abs/2504.21776v1,2025-04-30T16:25:25Z,"Xiaoxi Li, Jiajie Jin, Guanting Dong, Hongjin Qian, Yutao Zhu, Yongkang Wu, Ji-Rong Wen, Zhicheng Dou",webthinker empowering large reasoning models with deep research capability,large reasoning models lrms such as openaio1 and deepseekr1 demonstrate impressive longhorizon reasoning capabilities however their reliance on static internal knowledge limits their performance on complex knowledgeintensive tasks and hinders their ability to produce comprehensive research reports requiring synthesis of diverse web information to address this we propose textbfwebthinker a deep research agent that empowers lrms to autonomously search the web navigate web pages and draft research reports during the reasoning process webthinker integrates a textbfdeep web explorer module enabling lrms to dynamically search navigate and extract information from the web when encountering knowledge gaps it also employs an textbfautonomous thinksearchanddraft strategy allowing the model to seamlessly interleave reasoning information gathering and report writing in real time to further enhance research tool utilization we introduce an textbfrlbased training strategy via iterative online direct preference optimization dpo extensive experiments on complex reasoning benchmarks gpqa gaia webwalkerqa hle and scientific report generation tasks glaive demonstrate that webthinker significantly outperforms existing methods and strong proprietary systems our approach enhances lrm reliability and applicability in complex scenarios paving the way for more capable and versatile deep research systems the code is available at httpsgithubcomrucnlpirwebthinker
http://arxiv.org/abs/2505.00065v1,2025-04-30T16:23:15Z,"Ivan Vankov, Matyo Ivanov, Adriana Correia, Victor Botev",consens assessing context grounding in openbook question answering,large language models llms have demonstrated considerable success in openbook question answering qa where the task requires generating answers grounded in a provided external context a critical challenge in openbook qa is to ensure that model responses are based on the provided context rather than its parametric knowledge which can be outdated incomplete or incorrect existing evaluation methods primarily based on the llmasajudge approach face significant limitations including biases scalability issues and dependence on costly external systems to address these challenges we propose a novel metric that contrasts the perplexity of the model response under two conditions when the context is provided and when it is not the resulting score quantifies the extent to which the models answer relies on the provided context the validity of this metric is demonstrated through a series of experiments that show its effectiveness in identifying whether a given answer is grounded in the provided context unlike existing approaches this metric is computationally efficient interpretable and adaptable to various use cases offering a scalable and practical solution to assess context utilization in openbook qa systems
http://arxiv.org/abs/2504.21773v1,2025-04-30T16:17:53Z,"Junsheng Huang, Zhitao He, Sandeep Polisetty, Qingyun Wang, May Fung",mactuning llm multicompositional problem reasoning with enhanced knowledge boundary awareness,with the widespread application of large language models llms the issue of generating nonexisting facts known as hallucination has garnered increasing attention previous research in enhancing llm confidence estimation mainly focuses on the single problem setting however llm awareness of its internal parameterized knowledge boundary under the more challenging multiproblem setting which requires answering multiple problems accurately simultaneously remains underexplored to bridge this gap we introduce a novel method multiple answers and confidence stepwise tuning mactuning that separates the learning of answer prediction and confidence estimation during finetuning on instruction data extensive experiments demonstrate that our method outperforms baselines by up to 25 in average precision
http://arxiv.org/abs/2505.00063v1,2025-04-30T15:46:46Z,"Siqi Li, Yufan Shen, Xiangnan Chen, Jiayi Chen, Hengwei Ju, Haodong Duan, Song Mao, Hongbin Zhou, Bo Zhang, Pinlong Cai, Licheng Wen, Botian Shi, Yong Liu, Xinyu Cai, Yu Qiao",gdibench a benchmark for general document intelligence with vision and reasoning decoupling,the rapid advancement of multimodal large language models mllms has profoundly impacted the document domain creating a wide array of application scenarios this progress highlights the need for a comprehensive benchmark to evaluate these models capabilities across various documentspecific tasks however existing benchmarks often fail to locate specific model weaknesses or guide systematic improvements to bridge this gap we introduce a general document intelligence benchmark gdibench featuring 19k images across 9 key scenarios and 19 documentspecific tasks by decoupling visual complexity and reasoning complexity the gdibench structures graded tasks that allow performance assessment by difficulty aiding in model weakness identification and optimization guidance we evaluate the gdibench on various opensource and closedsource models conducting decoupled analyses in the visual and reasoning domains for instance the gpt4o model excels in reasoning tasks but exhibits limitations in visual capabilities to address the diverse tasks and domains in the gdibench we propose a gdi model that mitigates the issue of catastrophic forgetting during the supervised finetuning sft process through a intelligencepreserving training strategy our model achieves stateoftheart performance on previous benchmarks and the gdibench both our benchmark and model will be open source
http://arxiv.org/abs/2504.21751v1,2025-04-30T15:45:28Z,"Sizhe Wang, Zhengren Wang, Dongsheng Ma, Yongan Yu, Rui Ling, Zhiyu Li, Feiyu Xiong, Wentao Zhang",codeflowbench a multiturn iterative benchmark for complex code generation,real world development demands code that is readable extensible and testable by organizing the implementation into modular components and iteratively reuse preimplemented code we term this iterative multiturn process codeflow and introduce codeflowbench the first benchmark designed for comprehensively evaluating llms ability to perform codeflow namely to implement new functionality by reusing existing functions over multiple turns codeflowbench comprises 5258 problems drawn from codeforces and is continuously updated via an automated pipeline that decomposes each problem into a series of functionlevel subproblems based on its dependency tree and each subproblem is paired with unit tests we further propose a novel evaluation framework with tasks and metrics tailored to multiturn code reuse to assess model performance in experiments across various llms under both multiturn and singleturn patterns we observe models poor performance on codeflowbench with a substantial performance drop in the iterative codeflow scenario for instance o1mini achieves a pass1 of 208 in multiturn pattern versus 378 in singleturn pattern further analysis shows that different models excel at different dependency depths yet all struggle to correctly solve structurally complex problems highlighting challenges for current llms to serve as code generation tools when performing codeflow overall codeflowbench offers a comprehensive benchmark and new insights into llm capabilities for multiturn iterative code generation guiding future advances in code generation tasks
http://arxiv.org/abs/2504.21747v1,2025-04-30T15:41:03Z,"Maxime Bouthors, Josep Crego, François Yvon",improving retrievalaugmented neural machine translation with monolingual data,conventional retrievalaugmented neural machine translation ranmt systems leverage bilingual corpora eg translation memories tms yet in many settings indomain monolingual targetside corpora are often available this work explores ways to take advantage of such resources by retrieving relevant segments directly in the target language based on a sourceside query for this we design improved crosslingual retrieval systems trained with both sentence level and wordlevel matching objectives in our experiments with two ranmt architectures we first demonstrate the benefits of such crosslingual objectives in a controlled setting obtaining translation performances that surpass standard tmbased models we then showcase our method on a realworld setup where the target monolingual resources far exceed the amount of parallel data and observe large improvements of our new techniques which outperform both the baseline setting and generalpurpose crosslingual retrievers
http://arxiv.org/abs/2504.21742v1,2025-04-30T15:39:06Z,Emelie Hallenberg,investigating literary motifs in ancient and medieval novels with large language models,the greek fictional narratives often termed love novels or romances ranging from the first century ce to the middle of the 15th century have long been considered as similar in many ways not least in the use of particular literary motifs by applying the use of finetuned large language models this study aims to investigate which motifs exactly that the texts in this corpus have in common and in which ways they differ from each other the results show that while some motifs persist throughout the corpus others fluctuate in frequency indicating certain trends or external influences conclusively the method proves to adequately extract literary motifs according to a set definition providing data for both quantitative and qualitative analyses
http://arxiv.org/abs/2504.21716v1,2025-04-30T15:00:20Z,"Marc Glocker, Peter Hönig, Matthias Hirschmanner, Markus Vincze",llmempowered embodied agent for memoryaugmented task planning in household robotics,we present an embodied robotic system with an llmdriven agentorchestration architecture for autonomous household object management the system integrates memoryaugmented task planning enabling robots to execute highlevel user commands while tracking past actions it employs three specialized agents a routing agent a task planning agent and a knowledge base agent each powered by taskspecific llms by leveraging incontext learning our system avoids the need for explicit model training rag enables the system to retrieve context from past interactions enhancing longterm object tracking a combination of grounded sam and llama32vision provides robust object detection facilitating semantic scene understanding for task planning evaluation across three household scenarios demonstrates high task planning accuracy and an improvement in memory recall due to rag specifically qwen25 yields best performance for specialized agents while llama31 excels in routing tasks the source code is available at httpsgithubcommarc1198chathsr
http://arxiv.org/abs/2505.00061v1,2025-04-30T14:53:09Z,"Sahar Yarmohammadtoosky, Yiyun Zhou, Victoria Yaneva, Peter Baldwin, Saed Rezayi, Brian Clauser, Polina Harikeo",enhancing security and strengthening defenses in automated shortanswer grading systems,this study examines vulnerabilities in transformerbased automated shortanswer grading systems used in medical education with a focus on how these systems can be manipulated through adversarial gaming strategies our research identifies three main types of gaming strategies that exploit the systems weaknesses potentially leading to false positives to counteract these vulnerabilities we implement several adversarial training methods designed to enhance the systems robustness our results indicate that these methods significantly reduce the susceptibility of grading systems to such manipulations especially when combined with ensemble techniques like majority voting and ridge regression which further improve the systems defense against sophisticated adversarial inputs additionally employing large language models such as gpt4 with varied prompting techniques has shown promise in recognizing and scoring gaming strategies effectively the findings underscore the importance of continuous improvements in aidriven educational tools to ensure their reliability and fairness in highstakes settings
http://arxiv.org/abs/2505.00060v1,2025-04-30T14:42:18Z,Jeho Choi,factconsistency evaluation of texttosql generation for business intelligence using exaone 35,large language models llms have shown promise in enabling natural language interfaces for structured data querying through texttosql generation however their application in realworld business intelligence bi contexts remains limited due to semantic hallucinations structural errors and a lack of domainspecific evaluation frameworks in this study we propose a factconsistency evaluation framework for assessing the semantic accuracy of llmgenerated sql outputs using exaone 35an instructiontuned bilingual llm optimized for enterprise tasks we construct a domainspecific benchmark comprising 219 natural language business questions across five sql complexity levels derived from actual sales data in lg electronics internal bigquery environment each question is paired with a goldstandard sql query and a validated groundtruth answer we evaluate model performance using answer accuracy execution success rate semantic error rate and nonresponse rate experimental results show that while exaone 35 performs well on simple aggregation tasks 93 accuracy in l1 it exhibits substantial degradation in arithmetic reasoning 4 accuracy in h1 and grouped ranking tasks 31 in h4 with semantic errors and nonresponses concentrated in complex cases qualitative error analysis further identifies common failure types such as misapplied arithmetic logic incomplete filtering and incorrect grouping operations our findings highlight the current limitations of llms in businesscritical environments and underscore the need for factconsistency validation layers and hybrid reasoning approaches this work contributes a reproducible benchmark and evaluation methodology for advancing reliable natural language interfaces to structured enterprise data systems
http://arxiv.org/abs/2504.21685v1,2025-04-30T14:21:54Z,"Reem Abdel-Salam, Mary Adewunmi",enhancing health mention classification performance a study on advancements in parameter efficient tuning,health mention classification hmc plays a critical role in leveraging social media posts for realtime tracking and public health monitoring nevertheless the process of hmc presents significant challenges due to its intricate nature primarily stemming from the contextual aspects of health mentions such as figurative language and descriptive terminology rather than explicitly reflecting a personal ailment to address this problem we argue that clearer mentions can be achieved through conventional finetuning with enhanced parameters of biomedical natural language methods nlp in this study we explore different techniques such as the utilisation of partofspeech pos tagger information improving on peft techniques and different combinations thereof extensive experiments are conducted on three widely used datasets rhdm phm and illness the results incorporated pos tagger information and leveraging peft techniques significantly improves performance in terms of f1score compared to stateoftheart methods across all three datasets by utilising smaller models and efficient training furthermore the findings highlight the effectiveness of incorporating pos tagger information and leveraging peft techniques for hmc in conclusion the proposed methodology presents a potentially effective approach to accurately classifying health mentions in social media posts while optimising the model size and training efficiency
http://arxiv.org/abs/2504.21681v1,2025-04-30T14:19:15Z,"Andrei-Alexandru Manea, Jindřich Libovický",investigating the effect of parallel data in the crosslingual transfer for visionlanguage encoders,most pretrained visionlanguage vl models and training data for the downstream tasks are only available in english therefore multilingual vl tasks are solved using crosslingual transfer finetune a multilingual pretrained model or transfer the text encoder using parallel data we study the alternative approach transferring an already trained encoder using parallel data we investigate the effect of parallel data domain and the number of languages which were out of focus in previous work our results show that even machinetranslated task data are the best on average captionlike authentic parallel data outperformed it in some languages further we show that most languages benefit from multilingual training
http://arxiv.org/abs/2504.21677v1,2025-04-30T14:16:08Z,"Michelle Wastl, Jannis Vamvas, Selena Calleri, Rico Sennrich",20minxd a comparable corpus of swiss news articles,we present 20minxd 20 minuten crosslingual documentlevel a frenchgerman documentlevel comparable corpus of news articles sourced from the swiss online news outlet 20 minuten20 minutes our dataset comprises around 15000 article pairs spanning 2015 to 2024 automatically aligned based on semantic similarity we detail the data collection process and alignment methodology furthermore we provide a qualitative and quantitative analysis of the corpus the resulting dataset exhibits a broad spectrum of crosslingual similarity ranging from neartranslations to loosely related articles making it valuable for various nlp applications and broad linguistically motivated studies we publicly release the dataset in document and sentencealigned versions and code for the described experiments
http://arxiv.org/abs/2505.00059v1,2025-04-30T14:08:14Z,"Paige Tuttösí, Mantaj Dhillon, Luna Sang, Shane Eastwood, Poorvi Bhatia, Quang Minh Dinh, Avni Kapoor, Yewon Jin, Angelica Lim",bersting at the screams a benchmark for distanced emotional and shouted speech recognition,some speech recognition tasks such as automatic speech recognition asr are approaching or have reached human performance in many reported metrics yet they continue to struggle in complex realworld situations such as with distanced speech previous challenges have released datasets to address the issue of distanced asr however the focus remains primarily on distance specifically relying on multimicrophone array systems here we present the basic emotion random phrase shouts berst dataset the dataset contains almost 4 hours of english speech from 98 actors with varying regional and nonnative accents the data was collected on smartphones in the actors homes and therefore includes at least 98 different acoustic environments the data also includes 7 different emotion prompts and both shouted and spoken utterances the smartphones were places in 19 different positions including obstructions and being in a different room than the actor this data is publicly available for use and can be used to evaluate a variety of speech recognition tasks including asr shout detection and speech emotion recognition ser we provide initial benchmarks for asr and ser tasks and find that asr degrades both with an increase in distance and shout level and shows varied performance depending on the intended emotion our results show that the berst dataset is challenging for both asr and ser tasks and continued work is needed to improve the robustness of such systems for more accurate realworld use
http://arxiv.org/abs/2504.21659v1,2025-04-30T14:01:45Z,"Haotian Luo, Haiying He, Yibo Wang, Jinluan Yang, Rui Liu, Naiqiang Tan, Xiaochun Cao, Dacheng Tao, Li Shen",adar1 from longcot to hybridcot via bilevel adaptive reasoning optimization,recently longthought reasoning models achieve strong performance on complex reasoning tasks but often incur substantial inference overhead making efficiency a critical concern our empirical analysis reveals that the benefit of using longcot varies across problems while some problems require elaborate reasoning others show no improvement or even degraded accuracy this motivates adaptive reasoning strategies that tailor reasoning depth to the input however prior work primarily reduces redundancy within long reasoning paths limiting exploration of more efficient strategies beyond the longcot paradigm to address this we propose a novel twostage framework for adaptive and efficient reasoning first we construct a hybrid reasoning model by merging long and short cot models to enable diverse reasoning styles second we apply bilevel preference training to guide the model to select suitable reasoning styles grouplevel and prefer concise and correct reasoning within each style group instancelevel experiments demonstrate that our method significantly reduces inference costs compared to other baseline approaches while maintaining performance notably on five mathematical datasets the average length of reasoning is reduced by more than 50 highlighting the potential of adaptive strategies to optimize reasoning efficiency in large language models our code is coming soon at httpsgithubcomstardewxxxadar1
http://arxiv.org/abs/2504.21635v1,2025-04-30T13:37:24Z,"Zeina Aldallal, Sara Chrouf, Khalil Hennara, Mohamed Motaism Hamed, Muhammad Hreden, Safwan AlModhayan",sadeed advancing arabic diacritization through small language model,arabic text diacritization remains a persistent challenge in natural language processing due to the languages morphological richness in this paper we introduce sadeed a novel approach based on a finetuned decoderonly language model adapted from kuwain 15b hennara et al 2025 a compact model originally trained on diverse arabic corpora sadeed is finetuned on carefully curated highquality diacritized datasets constructed through a rigorous datacleaning and normalization pipeline despite utilizing modest computational resources sadeed achieves competitive results compared to proprietary large language models and outperforms traditional models trained on similar domains additionally we highlight key limitations in current benchmarking practices for arabic diacritization to address these issues we introduce sadeeddiac25 a new benchmark designed to enable fairer and more comprehensive evaluation across diverse text genres and complexity levels together sadeed and sadeeddiac25 provide a robust foundation for advancing arabic nlp applications including machine translation texttospeech and language learning tools
http://arxiv.org/abs/2504.21625v2,2025-04-30T13:28:19Z,"Jiaming Wang, Yunke Zhao, Peng Ding, Jun Kuang, Zongyu Wang, Xuezhi Cao, Xunliang Cai",ask fail repeat meeseeks an iterative feedback benchmark for llms multiturn instructionfollowing ability,the ability to follow instructions accurately is fundamental for large language models llms to serve as reliable agents in realworld applications for complex instructions llms often struggle to fulfill all requirements in a single attempt in practice users typically provide iterative feedback until the llm generates a response that meets all requirements however existing instructionfollowing benchmarks are either singleturn or introduce new requirements in each turn without allowing selfcorrection to address this gap we propose textbfmeeseeks named after mr meeseeks from textitrick and mortyfootnoterick and morty is an american adult animated science fiction sitcom created by justin roiland and dan harmon for cartoon networks nighttime programming block adult swim meeseeks simulates realistic humanllm interactions through an iterative feedback framework which enables models to selfcorrect based on specific requirement failures in each turn better reflecting realworld userend usage patterns meanwhile the benchmark implements a comprehensive evaluation system with 38 capability tags organized across three dimensions intent recognition granular content validation and output structure validation through rigorous evaluation across llms meeseeks provides valuable insights into llms instructionfollowing capabilities in multiturn scenarios
http://arxiv.org/abs/2504.21605v1,2025-04-30T13:06:40Z,"Jonas Gwozdz, Andreas Both",rdfbased structured quality assessment representation of multilingual llm evaluations,large language models llms increasingly serve as knowledge interfaces yet systematically assessing their reliability with conflicting information remains difficult we propose an rdfbased framework to assess multilingual llm quality focusing on knowledge conflicts our approach captures model responses across four distinct context conditions complete incomplete conflicting and nocontext information in german and english this structured representation enables the comprehensive analysis of knowledge leakagewhere models favor training data over provided contexterror detection and multilingual consistency we demonstrate the framework through a fire safety domain experiment revealing critical patterns in context prioritization and languagespecific performance and demonstrating that our vocabulary was sufficient to express every assessment facet encountered in the 28question study
http://arxiv.org/abs/2504.21604v1,2025-04-30T13:03:17Z,"Bing Wang, Ximing Li, Changchun Li, Bingrui Zhao, Bo Fu, Renchu Guan, Shengsheng Wang",robust misinformation detection by visiting potential commonsense conflict,the development of internet technology has led to an increased prevalence of misinformation causing severe negative effects across diverse domains to mitigate this challenge misinformation detection md aiming to detect online misinformation automatically emerges as a rapidly growing research topic in the community in this paper we propose a novel plugandplay augmentation method for the md task namely misinformation detection with potential commonsense conflict mdpcc we take inspiration from the prior studies indicating that fake articles are more likely to involve commonsense conflict accordingly we construct commonsense expressions for articles serving to express potential commonsense conflicts inferred by the difference between extracted commonsense triplet and golden ones inferred by the wellestablished commonsense reasoning tool comet these expressions are then specified for each article as augmentation any specific md methods can be then trained on those commonsenseaugmented articles besides we also collect a novel commonsenseoriented dataset named comis whose all fake articles are caused by commonsense conflict we integrate mdpcc with various existing md backbones and compare them across both 4 public benchmark datasets and comis empirical results demonstrate that mdpcc can consistently outperform the existing md baselines
http://arxiv.org/abs/2504.21589v1,2025-04-30T12:47:09Z,"Lisa Kluge, Maximilian Kähler",dnbaiproject at semeval2025 task 5 an llmensemble approach for automated subject indexing,this paper presents our system developed for the semeval2025 task 5 llms4subjects llmbased automated subject tagging for a national technical librarys openaccess catalog our system relies on prompting a selection of llms with varying examples of intellectually annotated records and asking the llms to similarly suggest keywords for new records this fewshot prompting technique is combined with a series of postprocessing steps that map the generated keywords to the target vocabulary aggregate the resulting subject terms to an ensemble vote and finally rank them as to their relevance to the record our system is fourth in the quantitative ranking in the allsubjects track but achieves the best result in the qualitative ranking conducted by subject indexing experts
http://arxiv.org/abs/2504.21578v1,2025-04-30T12:36:02Z,"Kamila Barylska, Frank Delaplace, Anna Gogolińska, Ewa Pańkowska",glucagon and insulin production in pancreatic cells modeled using petri nets and boolean networks,diabetes is a civilization chronic disease characterized by a constant elevated concentration of glucose in the blood many processes are involved in the glucose regulation and their interactions are very complex to better understand those processes we set ourselves a goal to create a petri net model of the glucose regulation in the whole body so far we have managed to create a model of glycolysis and synthesis of glucose in the liver and the general overview models of the glucose regulation in a healthy and diabetic person in this paper we introduce petri nets models of insulin secretion in beta cell of the pancreas and glucagon in the pancreas alpha cells those two hormones have mutually opposite effects insulin preventing hyperglycemia and glucagon preventing hypoglycemia understanding the mechanisms of insulin and glucagon secretion constitutes the basis for understanding diabetes we also present a model in which both processes occur together depending on the blood glucose level the dynamics of each model is analysed additionally we transform the overall insulin and glucagon secretion system to a boolean network following standard transformation rules
http://arxiv.org/abs/2505.07831v1,2025-04-30T12:33:28Z,"Michael Pichat, William Pogrund, Paloma Pichat, Judicael Poumay, Armanouche Gasparian, Samuel Demarchi, Martin Corbet, Alois Georgeon, Michael Veillet-Guillem",polysemy of synthetic neurons towards a new type of explanatory categorical vector spaces,the polysemantic nature of synthetic neurons in artificial intelligence language models is currently understood as the result of a necessary superposition of distributed features within the latent space we propose an alternative approach geometrically defining a neuron in layer n as a categorical vector space with a nonorthogonal basis composed of categorical subdimensions extracted from preceding neurons in layer n1 this categorical vector space is structured by the activation space of each neuron and enables via an intraneuronal attention process the identification and utilization of a critical categorical zone for the efficiency of the language model more homogeneous and located at the intersection of these different categorical subdimensions
http://arxiv.org/abs/2504.21559v1,2025-04-30T11:58:30Z,"Sangmin Woo, Kang Zhou, Yun Zhou, Shuai Wang, Sheng Guan, Haibo Ding, Lin Lee Cheong",blackbox visual prompt engineering for mitigating object hallucination in large vision language models,large vision language models lvlms often suffer from object hallucination which undermines their reliability surprisingly we find that simple objectbased visual prompting overlaying visual cues eg bounding box circle on images can significantly mitigate such hallucination however different visual prompts vps vary in effectiveness to address this we propose blackbox visual prompt engineering bbvpe a framework to identify optimal vps that enhance lvlm responses without needing access to model internals our approach employs a pool of candidate vps and trains a router model to dynamically select the most effective vp for a given input image this blackbox approach is modelagnostic making it applicable to both opensource and proprietary lvlms evaluations on benchmarks such as pope and chair demonstrate that bbvpe effectively reduces object hallucination
http://arxiv.org/abs/2505.00057v1,2025-04-30T11:54:23Z,"Zhu Jiawei, Chen Wei",a report on the llms evaluating the high school questions,this report aims to evaluate the performance of large language models llms in solving high school science questions and to explore their potential applications in the educational field with the rapid development of llms in the field of natural language processing their application in education has attracted widespread attention this study selected mathematics exam questions from the college entrance examinations 20192023 as evaluation data and utilized at least eight llm apis to provide answers a comprehensive assessment was conducted based on metrics such as accuracy response time logical reasoning and creativity through an indepth analysis of the evaluation results this report reveals the strengths and weaknesses of llms in handling high school science questions and discusses their implications for educational practice the findings indicate that although llms perform excellently in certain aspects there is still room for improvement in logical reasoning and creative problemsolving this report provides an empirical foundation for further research and application of llms in the educational field and offers suggestions for improvement
http://arxiv.org/abs/2504.21553v1,2025-04-30T11:52:18Z,"Lucas Maisonnave, Cyril Moineau, Olivier Bichler, Fabrice Rastello",precision where it matters a novel spike aware mixedprecision quantization strategy for llamabased language models,large language models llms have demonstrated remarkable capabilities in various natural language processing tasks however their size presents significant challenges for deployment and inference this paper investigates the quantization of llms focusing on the llama architecture and its derivatives we challenge existing assumptions about activation outliers in llms and propose a novel mixedprecision quantization approach tailored for llamalike models our method leverages the observation that activation spikes in llama architectures are predominantly concentrated in specific projection layers by applying higher precision fp16 or fp8 to these layers while quantizing the rest of the model to lower bitwidths we achieve superior performance compared to existing quantization techniques experimental results on llama2 llama3 and mistral models demonstrate significant improvements in perplexity and zeroshot accuracy particularly for 8bit pertensor quantization our approach outperforms generalpurpose methods designed to handle outliers across all architecture types highlighting the benefits of architecturespecific quantization strategies this research contributes to the ongoing efforts to make llms more efficient and deployable potentially enabling their use in resourceconstrained environments our findings emphasize the importance of considering modelspecific characteristics in developing effective quantization pipelines for stateoftheart language models by identifying and targeting a small number of projections that concentrate activation spikes
http://arxiv.org/abs/2504.21547v1,2025-04-30T11:44:08Z,"Aleksei Dorkin, Kairit Sirts",tartunlp at semeval2025 task 5 subject tagging as twostage information retrieval,we present our submission to the task 5 of semeval2025 that aims to aid librarians in assigning subject tags to the library records by producing a list of likely relevant tags for a given document we frame the task as an information retrieval problem where the document content is used to retrieve subject tags from a large subject taxonomy we leverage two types of encoder models to build a twostage information retrieval system a biencoder for coarsegrained candidate extraction at the first stage and a crossencoder for finegrained reranking at the second stage this approach proved effective demonstrating significant improvements in recall compared to singlestage methods and showing competitive results according to qualitative evaluation
http://arxiv.org/abs/2504.21540v1,2025-04-30T11:36:28Z,"Adrian Benton, Alexander Gutkin, Christo Kirov, Brian Roark",improving informally romanized language identification,the latin script is often used to informally write languages with nonlatin native scripts in many cases eg most languages in india there is no conventional spelling of words in the latin script hence there will be high spelling variability in written text such romanization renders languages that are normally easily distinguished based on script highly confusable such as hindi and urdu in this work we increase language identification lid accuracy for romanized text by improving the methods used to synthesize training sets we find that training on synthetic samples which incorporate natural spelling variation yields higher lid system accuracy than including available naturally occurring examples in the training set or even training higher capacity models we demonstrate new stateoftheart lid performance on romanized text from 20 indic languages in the bhashaabhijnaanam evaluation set madhani et al 2023a improving test f1 from the reported 747 using a pretrained neural model to 854 using a linear classifier trained solely on synthetic data and 882 when also training on available harvested text
http://arxiv.org/abs/2505.00056v2,2025-04-30T11:25:30Z,"Tygo Bloem, Filip Ilievski",clustering internet memes through template matching and multidimensional similarity,meme clustering is critical for toxicity detection virality modeling and typing but it has received little attention in previous research clustering similar internet memes is challenging due to their multimodality cultural context and adaptability existing approaches rely on databases overlook semantics and struggle to handle diverse dimensions of similarity this paper introduces a novel method that uses templatebased matching with multidimensional similarity features thus eliminating the need for predefined databases and supporting adaptive matching memes are clustered using local and global features across similarity categories such as form visual content text and identity our combined approach outperforms existing clustering methods producing more consistent and coherent clusters while similaritybased feature sets enable adaptability and align with human intuition we make all supporting code publicly available to support subsequent research
http://arxiv.org/abs/2504.21475v1,2025-04-30T09:56:36Z,"Serry Sibaee, Samar Ahmed, Abdullah Al Harbi, Omer Nacar, Adel Ammar, Yasser Habashi, Wadii Boulila",advancing arabic reverse dictionary systems a transformerbased approach with dataset construction guidelines,this study addresses the critical gap in arabic natural language processing by developing an effective arabic reverse dictionary rd system that enables users to find words based on their descriptions or meanings we present a novel transformerbased approach with a semiencoder neural network architecture featuring geometrically decreasing layers that achieves stateoftheart results for arabic rd tasks our methodology incorporates a comprehensive dataset construction process and establishes formal quality standards for arabic lexicographic definitions experiments with various pretrained models demonstrate that arabicspecific models significantly outperform general multilingual embeddings with arbertv2 achieving the best ranking score 00644 additionally we provide a formal abstraction of the reverse dictionary task that enhances theoretical understanding and develop a modular extensible python library rdtl with configurable training pipelines our analysis of dataset quality reveals important insights for improving arabic definition construction leading to eight specific standards for building highquality reverse dictionary resources this work contributes significantly to arabic computational linguistics and provides valuable tools for language learning academic writing and professional communication in arabic
http://arxiv.org/abs/2504.21474v1,2025-04-30T09:52:51Z,"Hadi Bayrami Asl Tekanlou, Jafar Razmara, Mahsa Sanaei, Mostafa Rahgouy, Hamed Babaei Giglou",homa at semeval2025 task 5 aligning librarian records with ontoaligner for subject tagging,this paper presents our system homa for semeval2025 task 5 subject tagging which focuses on automatically assigning subject labels to technical records from tibkat using the gemeinsame normdatei gnd taxonomy we leverage ontoaligner a modular ontology alignment toolkit to address this task by integrating retrievalaugmented generation rag techniques our approach formulates the subject tagging problem as an alignment task where records are matched to gnd categories based on semantic similarity we evaluate ontoaligners adaptability for subject indexing and analyze its effectiveness in handling multilingual records experimental results demonstrate the strengths and limitations of this method highlighting the potential of alignment techniques for improving subject tagging in digital libraries
http://arxiv.org/abs/2504.21463v2,2025-04-30T09:38:17Z,"Haowen Hou, Zhiyi Huang, Kaifeng Tan, Rongchang Lu, Fei Richard Yu",rwkvx a linear complexity hybrid language model,in this paper we introduce rwkvx a novel hybrid architecture that combines the efficiency of rwkv for shortrange modeling with a sparse attention mechanism designed to capture longrange context unlike previous hybrid approaches that rely on full attention layers and retain quadratic complexity rwkvx achieves lineartime complexity in training and constanttime complexity in inference decoding we demonstrate that rwkvx when continually pretrained on 64ktoken sequences achieves nearperfect accuracy on the 64k passkey retrieval benchmark it consistently outperforms prior rwkv7 models on longcontext benchmarks while maintaining strong performance on shortcontext tasks these results highlight rwkvx as a scalable and efficient backbone for generalpurpose language modeling capable of decoding sequences up to 1 million tokens with stable speed and memory usage to facilitate further research and analysis we have made the checkpoints and the associated code publicly accessible at httpsgithubcomhowardhourwkvx
http://arxiv.org/abs/2504.21435v3,2025-04-30T08:48:21Z,"Chenkai Zhang, Yiming Lei, Zeming Liu, Haitao Leng, Shaoguo Liu, Tingting Gao, Qingjie Liu, Yunhong Wang",seriesbench a benchmark for narrativedriven drama series understanding,with the rapid development of multimodal large language models mllms an increasing number of benchmarks have been established to evaluate the video understanding capabilities of these models however these benchmarks focus on standalone videos and mainly assess visual elements like human actions and object states in reality contemporary videos often encompass complex and continuous narratives typically presented as a series to address this challenge we propose seriesbench a benchmark consisting of 105 carefully curated narrativedriven series covering 28 specialized tasks that require deep narrative understanding specifically we first select a diverse set of drama series spanning various genres then we introduce a novel longspan narrative annotation method combined with a fullinformation transformation approach to convert manual annotations into diverse task formats to further enhance model capacity for detailed analysis of plot structures and character relationships within series we propose a novel narrative reasoning framework pcdcot extensive results on seriesbench indicate that existing mllms still face significant challenges in understanding narrativedriven series while pcdcot enables these mllms to achieve performance improvements overall our seriesbench and pcdcot highlight the critical necessity of advancing model capabilities to understand narrativedriven series guiding the future development of mllms seriesbench is publicly available at httpsgithubcomzackhxnseriesbenchcvpr2025
http://arxiv.org/abs/2504.21421v1,2025-04-30T08:27:33Z,"Linxuan Wang, Shuiyuan Yu",the distribution of dependency distance and hierarchical distance in contemporary written japanese and its influencing factors,to explore the relationship between dependency distance dd and hierarchical distance hd in japanese we compared the probability distributions of dd and hd with and without sentence length fixed and analyzed the changes in mean dependency distance mdd and mean hierarchical distance mhd as sentence length increases along with their correlation coefficient based on the balanced corpus of contemporary written japanese it was found that the valency of the predicates is the underlying factor behind the tradeoff relation between mdd and mhd in japanese native speakers of japanese regulate the linear complexity and hierarchical complexity through the valency of the predicates and the relative sizes of mdd and mhd depend on whether the threshold of valency has been reached apart from the cognitive load the valency of the predicates also affects the probability distributions of dd and hd the effect of the valency of the predicates on the distribution of hd is greater than on that of dd which leads to differences in their probability distributions and causes the mean of mdd to be lower than that of mhd
http://arxiv.org/abs/2504.21400v1,2025-04-30T07:55:52Z,"Sugat Chaturvedi, Rochana Chaturvedi",who gets the callback generative ai and gender bias,generative artificial intelligence ai particularly large language models llms is being rapidly deployed in recruitment and for candidate shortlisting we audit several midsized opensource llms for gender bias using a dataset of 332044 realworld online job postings for each posting we prompt the model to recommend whether an equally qualified male or female candidate should receive an interview callback we find that most models tend to favor men especially for higherwage roles mapping job descriptions to the standard occupational classification system we find lower callback rates for women in maledominated occupations and higher rates in femaleassociated ones indicating occupational segregation a comprehensive analysis of linguistic features in job ads reveals strong alignment of model recommendations with traditional gender stereotypes to examine the role of recruiter identity we steer model behavior by infusing big five personality traits and simulating the perspectives of historical figures we find that less agreeable personas reduce stereotyping consistent with an agreeableness bias in llms our findings highlight how aidriven hiring may perpetuate biases in the labor market and have implications for fairness and diversity within firms
http://arxiv.org/abs/2505.00050v1,2025-04-30T07:27:06Z,"Aayam Bansal, Agneya Tharun",emotional analysis of fashion trends using social media and ai sentiment analysis on twitter for fashion trend forecasting,this study explores the intersection of fashion trends and social media sentiment through computational analysis of twitter data using the t4sa twitter for sentiment analysis dataset by applying natural language processing and machine learning techniques we examine how sentiment patterns in fashionrelated social media conversations can serve as predictors for emerging fashion trends our analysis involves the identification and categorization of fashionrelated content sentiment classification with improved normalization techniques time series decomposition statistically validated causal relationship modeling crossplatform sentiment comparison and brandspecific sentiment analysis results indicate correlations between sentiment patterns and fashion theme popularity with accessories and streetwear themes showing statistically significant rising trends the granger causality analysis establishes sustainability and streetwear as primary trend drivers showing bidirectional relationships with several other themes the findings demonstrate that social media sentiment analysis can serve as an effective early indicator of fashion trend trajectories when proper statistical validation is applied our improved predictive model achieved 7835 balanced accuracy in sentiment classification establishing a reliable foundation for trend prediction across positive neutral and negative sentiment categories
http://arxiv.org/abs/2504.21372v1,2025-04-30T07:10:10Z,Máté Gedeon,retrievalenhanced fewshot prompting for speech event extraction,speech event extraction speechee is a challenging task that lies at the intersection of automatic speech recognition asr and natural language processing nlp requiring the identification of structured event information from spoken language in this work we present a modular pipelinebased speechee framework that integrates highperformance asr with semantic searchenhanced prompting of large language models llms our system first classifies speech segments likely to contain events using a hybrid filtering mechanism including rulebased bertbased and llmbased models it then employs fewshot llm prompting dynamically enriched via semantic similarity retrieval to identify event triggers and extract corresponding arguments we evaluate the pipeline using multiple llms llama38b gpt4omini and o1mini highlighting significant performance gains with o1mini which achieves 633 f1 on trigger classification and 278 f1 on argument classification outperforming prior benchmarks our results demonstrate that pipeline approaches when empowered by retrievalaugmented llms can rival or exceed endtoend systems while maintaining interpretability and modularity this work provides practical insights into llmdriven event extraction and opens pathways for future hybrid models combining textual and acoustic features
http://arxiv.org/abs/2505.00049v1,2025-04-30T06:09:40Z,"Wenhan Dong, Yuemeng Zhao, Zhen Sun, Yule Liu, Zifan Peng, Jingyi Zheng, Zongmin Zhang, Ziyi Zhang, Jun Wu, Ruiming Wang, Shengmin Xu, Xinyi Huang, Xinlei He",humanizing llms a survey of psychological measurements with tools datasets and humanagent applications,as large language models llms are increasingly used in humancentered tasks assessing their psychological traits is crucial for understanding their social impact and ensuring trustworthy ai alignment while existing reviews have covered some aspects of related research several important areas have not been systematically discussed including detailed discussions of diverse psychological tests llmspecific psychological datasets and the applications of llms with psychological traits to address this gap we systematically review six key dimensions of applying psychological theories to llms 1 assessment tools 2 llmspecific datasets 3 evaluation metrics consistency and stability 4 empirical findings 5 personality simulation methods and 6 llmbased behavior simulation our analysis highlights both the strengths and limitations of current methods while some llms exhibit reproducible personality patterns under specific prompting schemes significant variability remains across tasks and settings recognizing methodological challenges such as mismatches between psychological tools and llms capabilities as well as inconsistencies in evaluation practices this study aims to propose future directions for developing more interpretable robust and generalizable psychological assessment frameworks for llms
http://arxiv.org/abs/2504.21330v1,2025-04-30T05:36:28Z,"Kaixun Yang, Mladen Raković, Dragan Gašević, Guanliang Chen",does the promptbased large language model recognize students demographics and introduce bias in essay scoring,large language models llms are widely used in automated essay scoring aes due to their ability to capture semantic meaning traditional finetuning approaches required technical expertise limiting accessibility for educators with limited technical backgrounds however promptbased tools like chatgpt have made aes more accessible enabling educators to obtain machinegenerated scores using naturallanguage prompts ie the promptbased paradigm despite advancements prior studies have shown bias in finetuned llms particularly against disadvantaged groups it remains unclear whether such biases persist or are amplified in the promptbased paradigm with cuttingedge tools since such biases are believed to stem from the demographic information embedded in pretrained models ie the ability of llms text embeddings to predict demographic attributes this study explores the relationship between the models predictive power of students demographic attributes based on their written works and its predictive bias in the scoring task in the promptbased paradigm using a publicly available dataset of over 25000 students argumentative essays we designed prompts to elicit demographic inferences ie gender firstlanguage background from gpt4o and assessed fairness in automated scoring then we conducted multivariate regression analysis to explore the impact of the models ability to predict demographics on its scoring outcomes our findings revealed that i promptbased llms can somewhat infer students demographics particularly their firstlanguage backgrounds from their essays ii scoring biases are more pronounced when the llm correctly predicts students firstlanguage background than when it does not and iii scoring error for nonnative english speakers increases when the llm correctly identifies them as nonnative
http://arxiv.org/abs/2504.21318v1,2025-04-30T05:05:09Z,"Marah Abdin, Sahaj Agarwal, Ahmed Awadallah, Vidhisha Balachandran, Harkirat Behl, Lingjiao Chen, Gustavo de Rosa, Suriya Gunasekar, Mojan Javaheripi, Neel Joshi, Piero Kauffmann, Yash Lara, Caio César Teodoro Mendes, Arindam Mitra, Besmira Nushi, Dimitris Papailiopoulos, Olli Saarikivi, Shital Shah, Vaishnavi Shrivastava, Vibhav Vineet, Yue Wu, Safoora Yousefi, Guoqing Zheng",phi4reasoning technical report,we introduce phi4reasoning a 14billion parameter reasoning model that achieves strong performance on complex reasoning tasks trained via supervised finetuning of phi4 on carefully curated set of teachable promptsselected for the right level of complexity and diversityand reasoning demonstrations generated using o3mini phi4reasoning generates detailed reasoning chains that effectively leverage inferencetime compute we further develop phi4reasoningplus a variant enhanced through a short phase of outcomebased reinforcement learning that offers higher performance by generating longer reasoning traces across a wide range of reasoning tasks both models outperform significantly larger openweight models such as deepseekr1distillllama70b model and approach the performance levels of full deepseekr1 model our comprehensive evaluations span benchmarks in math and scientific reasoning coding algorithmic problem solving planning and spatial understanding interestingly we observe a nontrivial transfer of improvements to generalpurpose benchmarks as well in this report we provide insights into our training data our training methodologies and our evaluations we show that the benefit of careful data curation for supervised finetuning sft extends to reasoning language models and can be further amplified by reinforcement learning rl finally our evaluation points to opportunities for improving how we assess the performance and robustness of reasoning models
http://arxiv.org/abs/2504.21303v1,2025-04-30T04:24:50Z,"Xiao Xiao, Yu Su, Sijing Zhang, Zhang Chen, Yadong Chen, Tian Liu",confidence in large language model evaluation a bayesian approach to limitedsample challenges,large language models llms exhibit probabilistic output characteristics yet conventional evaluation frameworks rely on deterministic scalar metrics this study introduces a bayesian approach for llm capability assessment that integrates prior knowledge through probabilistic inference addressing limitations under limitedsample regimes by treating model capabilities as latent variables and leveraging a curated query set to induce discriminative responses we formalize model ranking as a bayesian hypothesis testing problem over mutually exclusive capability intervals experimental evaluations with gptseries models demonstrate that the proposed method achieves superior discrimination compared to conventional evaluation methods results indicate that even with reduced sample sizes the approach maintains statistical robustness while providing actionable insights such as probabilistic statements about a models likelihood of surpassing specific baselines this work advances llm evaluation methodologies by bridging bayesian inference with practical constraints in realworld deployment scenarios
http://arxiv.org/abs/2504.21299v1,2025-04-30T04:13:03Z,"Zhiting Fan, Ruizhe Chen, Zuozhu Liu",biasguard a reasoningenhanced bias detection tool for large language models,identifying bias in llmgenerated content is a crucial prerequisite for ensuring fairness in llms existing methods such as fairness classifiers and llmbased judges face limitations related to difficulties in understanding underlying intentions and the lack of criteria for fairness judgment in this paper we introduce biasguard a novel bias detection tool that explicitly analyzes inputs and reasons through fairness specifications to provide accurate judgments biasguard is implemented through a twostage approach the first stage initializes the model to explicitly reason based on fairness specifications while the second stage leverages reinforcement learning to enhance its reasoning and judgment capabilities our experiments conducted across five datasets demonstrate that biasguard outperforms existing tools improving accuracy and reducing overfairness misjudgments we also highlight the importance of reasoningenhanced decisionmaking and provide evidence for the effectiveness of our twostage optimization pipeline
http://arxiv.org/abs/2505.00047v1,2025-04-30T03:41:55Z,"Peter West, Christopher Potts",base models beat aligned models at randomness and creativity,alignment has quickly become a default ingredient in llm development with techniques such as reinforcement learning from human feedback making models act safely follow instructions and perform everbetter on complex tasks while these techniques are certainly useful we propose that they should not be universally applied and demonstrate a range of tasks on which base language models consistently outperform their popular aligned forms particularly we study tasks that require unpredictable outputs such as random number generation mixed strategy games rockpaperscissors and hideandseek and creative writing in each case aligned models tend towards narrow behaviors that result in distinct disadvantages for instance preferring to generate 7 over other uniformly random numbers becoming almost fully predictable in some game states or prioritizing pleasant writing over creative originality across models tested better performance on common benchmarks tends to correlate with worse performance on our tasks suggesting an effective tradeoff in the required capabilities
http://arxiv.org/abs/2504.21252v1,2025-04-30T01:37:44Z,"Xuanzhao Dong, Wenhui Zhu, Hao Wang, Xiwen Chen, Peijie Qiu, Rui Yin, Yi Su, Yalin Wang",talk before you retrieve agentled discussions for better rag in medical qa,medical question answering qa is a reasoningintensive task that remains challenging for large language models llms due to hallucinations and outdated domain knowledge retrievalaugmented generation rag provides a promising posttraining solution by leveraging external knowledge however existing medical rag systems suffer from two key limitations 1 a lack of modeling for humanlike reasoning behaviors during information retrieval and 2 reliance on suboptimal medical corpora which often results in the retrieval of irrelevant or noisy snippets to overcome these challenges we propose discussrag a plugandplay module designed to enhance the medical qa rag system through collaborative agentbased reasoning our method introduces a summarizer agent that orchestrates a team of medical experts to emulate multiturn brainstorming thereby improving the relevance of retrieved content additionally a decisionmaking agent evaluates the retrieved snippets before their final integration experimental results on four benchmark medical qa datasets show that discussrag consistently outperforms medrag especially significantly improving answer accuracy by up to 1667 on bioasq and 1220 on pubmedqa the code is available at httpsgithubcomllmvlmgsldiscussrag
http://arxiv.org/abs/2504.21239v1,2025-04-30T00:28:32Z,"Xu Pan, Ely Hahami, Zechen Zhang, Haim Sompolinsky",memorization and knowledge injection in gated llms,large language models llms currently struggle to sequentially add new memories and integrate new knowledge these limitations contrast with the human ability to continuously learn from new experiences and acquire knowledge throughout life most existing approaches add memories either through large context windows or external memory buffers eg retrievalaugmented generation and studies on knowledge injection rarely test scenarios resembling everyday life events in this work we introduce a continual learning framework memory embedded in gated llms mega which injects event memories directly into the weights of llms each memory is stored in a dedicated set of gated lowrank weights during inference a gating mechanism activates relevant memory weights by matching query embeddings to stored memory embeddings this enables the model to both recall entire memories and answer related questions on two datasets fictional characters and wikipedia events mega outperforms baseline approaches in mitigating catastrophic forgetting our model draws inspiration from the complementary memory system of the human brain
http://arxiv.org/abs/2504.21233v1,2025-04-30T00:04:35Z,"Haoran Xu, Baolin Peng, Hany Awadalla, Dongdong Chen, Yen-Chun Chen, Mei Gao, Young Jin Kim, Yunsheng Li, Liliang Ren, Yelong Shen, Shuohang Wang, Weijian Xu, Jianfeng Gao, Weizhu Chen",phi4minireasoning exploring the limits of small reasoning language models in math,chainofthought cot significantly enhances formal reasoning capabilities in large language models llms by training them to explicitly generate intermediate reasoning steps while llms readily benefit from such techniques improving reasoning in small language models slms remains challenging due to their limited model capacity recent work by deepseekr1 demonstrates that distillation from llmgenerated synthetic data can substantially improve the reasoning ability of slm however the detailed modeling recipe is not disclosed in this work we present a systematic training recipe for slms that consists of four steps 1 largescale midtraining on diverse distilled longcot data 2 supervised finetuning on highquality longcot data 3 rollout dpo leveraging a carefully curated preference dataset and 4 reinforcement learning rl with verifiable reward we apply our method on phi4mini a compact 38bparameter model the resulting phi4minireasoning model exceeds on math reasoning tasks much larger reasoning models eg outperforming deepseekr1distillqwen7b by 32 points and deepseekr1distillllama8b by 77 points on math500 our results validate that a carefully designed training recipe with largescale highquality cot data is effective to unlock strong reasoning capabilities even in resourceconstrained small models
http://arxiv.org/abs/2504.21214v2,2025-04-29T22:48:27Z,"Jinzhao Zhou, Zehong Cao, Yiqun Duan, Connor Barkley, Daniel Leong, Xiaowei Jiang, Quoc-Toan Nguyen, Ziyi Zhao, Thomas Do, Yu-Cheng Chang, Sheng-Fu Liang, Chin-teng Lin",pretraining large brain language model for active bci silent speech,this paper explores silent speech decoding in active braincomputer interface bci systems which offer more natural and flexible communication than traditional bci applications we collected a new silent speech dataset of over 120 hours of electroencephalogram eeg recordings from 12 subjects capturing 24 commonly used english words for language model pretraining and decoding following the recent success of pretraining large models with selfsupervised paradigms to enhance eeg classification performance we propose large brain language model lblm pretrained to decode silent speech for active bci to pretrain lblm we propose future spectrotemporal prediction fstp pretraining paradigm to learn effective representations from unlabeled eeg data unlike existing eeg pretraining methods that mainly follow a maskedreconstruction paradigm our proposed fstp method employs autoregressive modeling in temporal and frequency domains to capture both temporal and spectral dependencies from eeg signals after pretraining we finetune our lblm on downstream tasks including wordlevel and semanticlevel classification extensive experiments demonstrate significant performance gains of the lblm over fullysupervised and pretrained baseline models for instance in the difficult crosssession setting our model achieves 470 accuracy on semanticlevel classification and 396 in wordlevel classification outperforming baseline methods by 54 and 73 respectively our research advances silent speech decoding in active bci systems offering an innovative solution for eeg language model pretraining and a new dataset for fundamental research
http://arxiv.org/abs/2504.21202v1,2025-04-29T22:16:39Z,"Ramon Pires, Roseval Malaquias Junior, Rodrigo Nogueira",automatic legal writing evaluation of llms,despite the recent advances in large language models benchmarks for evaluating legal writing remain scarce due to the inherent complexity of assessing openended responses in this domain one of the key challenges in evaluating language models on domainspecific tasks is finding test datasets that are public frequently updated and contain comprehensive evaluation guidelines the brazilian bar examination meets these requirements we introduce oabbench a benchmark comprising 105 questions across seven areas of law from recent editions of the exam the benchmark includes comprehensive evaluation guidelines and reference materials used by human examiners to ensure consistent grading we evaluate the performance of four llms on oabbench finding that claude35 sonnet achieves the best results with an average score of 793 out of 10 passing all 21 exams we also investigated whether llms can serve as reliable automated judges for evaluating legal writing our experiments show that frontier models like openais o1 achieve a strong correlation with human scores when evaluating approved exams suggesting their potential as reliable automated evaluators despite the inherently subjective nature of legal writing assessment the source code and the benchmark containing questions evaluation guidelines modelgenerated responses and their respective automated evaluations are publicly available
http://arxiv.org/abs/2504.21191v1,2025-04-29T21:50:06Z,"Lovedeep Gondara, Jonathan Simkin, Graham Sayle, Shebnum Devji, Gregory Arbour, Raymond Ng",small or large zeroshot or finetuned guiding language model choice for specialized applications in healthcare,this study aims to guide language model selection by investigating 1 the necessity of finetuning versus zeroshot usage 2 the benefits of domainadjacent versus generic pretrained models 3 the value of further domainspecific pretraining and 4 the continued relevance of small language models slms compared to large language models llms for specific tasks using electronic pathology reports from the british columbia cancer registry bccr three classification scenarios with varying difficulty and data size are evaluated models include various slms and an llm slms are evaluated both zeroshot and finetuned the llm is evaluated zeroshot only finetuning significantly improved slm performance across all scenarios compared to their zeroshot results the zeroshot llm outperformed zeroshot slms but was consistently outperformed by finetuned slms domainadjacent slms generally performed better than the generic slm after finetuning especially on harder tasks further domainspecific pretraining yielded modest gains on easier tasks but significant improvements on the complex datascarce task the results highlight the critical role of finetuning for slms in specialized domains enabling them to surpass zeroshot llm performance on targeted classification tasks pretraining on domainadjacent or domainspecific data provides further advantages particularly for complex problems or limited finetuning data while llms offer strong zeroshot capabilities their performance on these specific tasks did not match that of appropriately finetuned slms in the era of llms slms remain relevant and effective offering a potentially superior performanceresource tradeoff compared to llms
http://arxiv.org/abs/2504.21165v1,2025-04-29T20:33:54Z,"Mark Huasong Meng, Ruizhe Wang, Meng Xu, Chuan Yan, Guangdong Bai",detecting manipulated contents using knowledgegrounded inference,the detection of manipulated content a prevalent form of fake news has been widely studied in recent years while existing solutions have been proven effective in factchecking and analyzing fake news based on historical events the reliance on either intrinsic knowledge obtained during training or manually curated context hinders them from tackling zeroday manipulated content which can only be recognized with realtime contextual information in this work we propose manicod a tool designed for detecting zeroday manipulated content manicod first sources contextual information about the input claim from mainstream search engines and subsequently vectorizes the context for the large language model llm through retrievalaugmented generation rag the llmbased inference can produce a truthful or manipulated decision and offer a textual explanation for the decision to validate the effectiveness of manicod we also propose a dataset comprising 4270 pieces of manipulated fake news derived from 2500 recent realworld news headlines manicod achieves an overall f1 score of 0856 on this dataset and outperforms existing methods by up to 19x in f1 score on their benchmarks on factchecking and claim verification
http://arxiv.org/abs/2504.21132v1,2025-04-29T19:27:04Z,"Naheed Rayhan, Md. Ashrafuzzaman",llm enhancer merged approach using vector embedding for reducing large language model hallucinations with external knowledge,large language models llms such as chatgpt have demonstrated the capability to generate human like natural responses across a range of tasks including task oriented dialogue and question answering however their application in real world critical scenarios is often hindered by a tendency to produce inaccurate information and a limited ability to leverage external knowledge sources this paper introduces the llm enhancer system designed to integrate multiple online sources such as google wikipedia and duckduckgo to enhance data accuracy the llms employed within this system are open source the data acquisition process for the llm enhancer system operates in parallel utilizing custom agent tools to manage the flow of information vector embeddings are used to identify the most pertinent information which is subsequently supplied to the llm for user interaction the llm enhancer system mitigates hallucinations in chat based llms while preserving response naturalness and accuracy
http://arxiv.org/abs/2504.21117v1,2025-04-29T18:56:12Z,"Hanhua Hong, Chenghao Xiao, Yang Wang, Yiqi Liu, Wenge Rong, Chenghua Lin",beyond onesizefitsall inversion learning for highly effective nlg evaluation prompts,evaluating natural language generation nlg systems is challenging due to the diversity of valid outputs while human evaluation is the gold standard it suffers from inconsistencies lack of standardisation and demographic biases limiting reproducibility llmbased evaluation offers a scalable alternative but is highly sensitive to prompt design where small variations can lead to significant discrepancies in this work we propose an inversion learning method that learns effective reverse mappings from model outputs back to their input instructions enabling the automatic generation of highly effective modelspecific evaluation prompts our method requires only a single evaluation sample and eliminates the need for timeconsuming manual prompt engineering thereby improving both efficiency and robustness our work contributes toward a new direction for more robust and efficient llmbased evaluation
http://arxiv.org/abs/2505.00039v2,2025-04-29T18:36:57Z,Hudson de Martim,graph rag for legal norms a hierarchical and temporal approach,this article proposes an adaptation of graph retrieval augmented generation graph rag specifically designed for the analysis and comprehension of legal norms which are characterized by their predefined hierarchical structure extensive network of internal and external references and multiple temporal versions by combining structured knowledge graphs with contextually enriched text segments graph rag offers a promising solution to address the inherent complexity and vast volume of legal data the integration of hierarchical structure and temporal evolution into knowledge graphs along with the concept of comprehensive text units facilitates the construction of richer interconnected representations of legal knowledge through a detailed analysis of graph rag and its application to legal norm datasets this article aims to advance the field of artificial intelligence applied to law creating opportunities for more effective systems in legal research legislative analysis and decision support
http://arxiv.org/abs/2505.00038v1,2025-04-29T18:01:46Z,"Cristina Garbacea, Chenhao Tan",hyperalign hypothesesdriven personalized alignment,alignment algorithms are widely used to align large language models llms to human users based on preference annotations that reflect their intended realworld use cases typically these often divergent preferences are aggregated over a diverse set of users resulting in finetuned models that are aligned to the averageuser preference nevertheless current models are used by individual users in very specific contexts and situations emphasizing the need for userdependent preference control in this work we address the problem of personalizing llm outputs to their users aiming to generate customized responses tailored to individual users instead of generic outputs that emulate the collective voices of diverse populations we propose a novel interpretable and sampleefficient hypothesesdriven personalization approach hyperalign where given fewshot examples written by a particular user we first infer hypotheses about their communication strategies personality and writing style then prompt llm models with these hypotheses and user specific attributes to generate customized outputs we conduct experiments on two different personalization tasks authorship attribution and deliberative alignment with datasets from diverse domains news articles blog posts emails jailbreaking benchmarks and demonstrate the superiority of hypothesesdriven personalization approach when compared to preferencebased finetuning methods for deliberative alignment the helpfulness of llm models is improved by up to on average for authorship attribution results indicate consistently high winrates commonly against stateoftheart preference finetuning approaches for llm personalization across diverse user profiles and llm models overall our approach represents an interpretable and sampleefficient strategy for the personalization of llm models to individual users
http://arxiv.org/abs/2504.20972v1,2025-04-29T17:40:29Z,"Yifan Wei, Xiaoyan Yu, Ran Song, Hao Peng, Angsheng Li",setke knowledge editing for knowledge elements overlap,large language models llms excel in tasks such as retrieval and question answering but require updates to incorporate new knowledge and reduce inaccuracies and hallucinations traditional updating methods like finetuning and incremental learning face challenges such as overfitting and high computational costs knowledge editing ke provides a promising alternative but often overlooks the knowledge element overlap keo phenomenon where multiple triplets share common elements leading to editing conflicts we identify the prevalence of keo in existing ke datasets and show its significant impact on current ke methods causing performance degradation in handling such triplets to address this we propose a new formulation knowledge set editing kse and introduce setke a method that edits sets of triplets simultaneously experimental results demonstrate that setke outperforms existing methods in keo scenarios on mainstream llms additionally we introduce editset a dataset containing keo triplets providing a comprehensive benchmark
http://arxiv.org/abs/2504.20964v1,2025-04-29T17:34:49Z,"Shangyu Li, Juyong Jiang, Tiancheng Zhao, Jiasi Shen",osvbench benchmarking llms on specification generation tasks for operating system verification,we introduce osvbench a new benchmark for evaluating large language models llms in generating complete specification code pertaining to operating system kernel verification tasks the benchmark first defines the specification generation problem into a program synthesis problem within a confined scope of syntax and semantics by providing llms with the programming model the llms are required to understand the provided verification assumption and the potential syntax and semantics space to search for then generate the complete specification for the potentially buggy operating system code implementation under the guidance of the highlevel functional description of the operating system this benchmark is built upon a realworld operating system kernel hyperkernel and consists of 245 complex specification generation tasks in total each is a long context task of about 20k30k tokens our comprehensive evaluation of 12 llms exhibits the limited performance of the current llms on the specification generation tasks for operating system verification significant disparities in their performance on the benchmark highlight differences in their ability to handle longcontext code generation tasks the evaluation toolkit and benchmark are available at httpsgithubcomlishangyuhkustosvbench
http://arxiv.org/abs/2504.20951v1,2025-04-29T17:21:20Z,Maryna Vyshnyvetska,information gravity a fieldtheoretic model for token selection in large language models,we propose a theoretical model called information gravity to describe the text generation process in large language models llms the model uses physical apparatus from field theory and spacetime geometry to formalize the interaction between user queries and the probability distribution of generated tokens a query is viewed as an object with information mass that curves the semantic space of the model creating gravitational potential wells that attract tokens during generation this model offers a mechanism to explain several observed phenomena in llm behavior including hallucinations emerging from lowdensity semantic voids sensitivity to query formulation due to semantic field curvature changes and the influence of sampling temperature on output diversity
http://arxiv.org/abs/2504.20946v2,2025-04-29T17:14:54Z,"Tyler McDonald, Ali Emami",traceofthought prompting investigating promptbased knowledge distillation through question decomposition,knowledge distillation allows smaller neural networks to emulate the performance of larger teacher models with reduced computational demands traditional methods for large language models llms often necessitate extensive finetuning which limits their accessibility to address this we introduce traceofthought prompting a novel framework designed to distill critical reasoning capabilities from highresource teacher models over 8 billion parameters to lowresource student models up to 8 billion parameters this approach leverages problem decomposition to enhance interpretability and facilitate humanintheloop interventions empirical evaluations on the gsm8k and math datasets show that student models achieve accuracy gains of up to 113 on gsm8k and 21 on math with significant improvements particularly notable in smaller models like llama 2 and zephyr our results suggest a promising pathway for opensource lowresource models to eventually serve both as both students and teachers potentially reducing our reliance on highresource proprietary models
http://arxiv.org/abs/2504.20938v1,2025-04-29T17:03:03Z,"Zhengfu He, Junxuan Wang, Rui Lin, Xuyang Ge, Wentao Shu, Qiong Tang, Junping Zhang, Xipeng Qiu",towards understanding the nature of attention with lowrank sparse decomposition,we propose lowrank sparse attention lorsa a sparse replacement model of transformer attention layers to disentangle original multi head self attention mhsa into individually comprehensible components lorsa is designed to address the challenge of attention superposition to understand attentionmediated interaction between features in different token positions we show that lorsa heads find cleaner and finergrained versions of previously discovered mhsa behaviors like induction heads successor heads and attention sink behavior ie heavily attending to the first token lorsa and sparse autoencoder sae are both sparse dictionary learning methods applied to different transformer components and lead to consistent findings in many ways for instance we discover a comprehensive family of arithmeticspecific lorsa heads each corresponding to an atomic operation in llama318b automated interpretability analysis indicates that lorsa achieves parity with sae in interpretability while lorsa exhibits superior circuit discovery properties especially for features computed collectively by multiple mhsa heads we also conduct extensive experiments on architectural design ablation lorsa scaling law and error analysis
http://arxiv.org/abs/2504.20930v1,2025-04-29T16:48:23Z,"Ziqing Fan, Cheng Liang, Chaoyi Wu, Ya Zhang, Yanfeng Wang, Weidi Xie",chestxreasoner advancing radiology foundation models with reasoning through stepbystep verification,recent advances in reasoningenhanced large language models llms and multimodal llms mllms have significantly improved performance in complex tasks yet medical ai models often overlook the structured reasoning processes inherent in clinical practice in this work we present chestxreasoner a radiology diagnosis mllm designed to leverage process supervision mined directly from clinical reports reflecting the stepbystep reasoning followed by radiologists we construct a large dataset by extracting and refining reasoning chains from routine radiology reports our twostage training framework combines supervised finetuning and reinforcement learning guided by process rewards to better align model reasoning with clinical standards we introduce radrbenchcxr a comprehensive benchmark featuring 59k visual question answering samples with 301k clinically validated reasoning steps and propose radrscore a metric evaluating reasoning factuality completeness and effectiveness chestxreasoner outperforms existing medical and generaldomain mllms in both diagnostic accuracy and reasoning ability achieving 16 59 and 18 improvements in reasoning ability compared to the best medical mllm the best general mllm and its base model respectively as well as 33 24 and 27 improvements in outcome accuracy all resources are opensourced to facilitate further research in medical reasoning mllms
http://arxiv.org/abs/2504.20922v1,2025-04-29T16:38:15Z,"Miguel Nogales, Matteo Gambella, Manuel Roveri",dynamax dynamic computing for transformers and mamba based architectures,early exits ees offer a promising approach to reducing computational costs and latency by dynamically terminating inference once a satisfactory prediction confidence on a data sample is achieved although many works integrate ees into encoderonly transformers their application to decoderonly architectures and more importantly mamba models a novel family of statespace architectures in the llm realm remains insufficiently explored this work introduces dynamax the first framework to exploit the unique properties of mamba architectures for early exit mechanisms we not only integrate ees into mamba but also repurpose mamba as an efficient ee classifier for both mambabased and transformerbased llms showcasing its versatility our experiments employ the mistral 7b transformer compared to the codestral 7b mamba model using data sets such as truthfulqa coqa and triviaqa to evaluate computational savings accuracy and consistency the results highlight the adaptability of mamba as a powerful ee classifier and its efficiency in balancing computational cost and performance quality across nlp tasks by leveraging mambas inherent design for dynamic processing we open pathways for scalable and efficient inference in embedded applications and resourceconstrained environments this study underscores the transformative potential of mamba in redefining dynamic computing paradigms for llms
http://arxiv.org/abs/2505.00036v1,2025-04-29T16:02:51Z,"Zhongren Chen, Joshua Kalla, Quan Le, Shinpei Nakamura-Sakai, Jasjeet Sekhon, Ruixiao Wang",a framework to assess the persuasion risks large language model chatbots pose to democratic societies,in recent years significant concern has emerged regarding the potential threat that large language models llms pose to democratic societies through their persuasive capabilities we expand upon existing research by conducting two survey experiments and a realworld simulation exercise to determine whether it is more cost effective to persuade a large number of voters using llm chatbots compared to standard political campaign practice taking into account both the receive and accept steps in the persuasion process zaller 1992 these experiments improve upon previous work by assessing extended interactions between humans and llms instead of using singleshot interactions and by assessing both short and longrun persuasive effects rather than simply asking users to rate the persuasiveness of llmproduced content in two survey experiments n 10417 across three distinct political domains we find that while llms are about as persuasive as actual campaign ads once voters are exposed to them political persuasion in the realworld depends on both exposure to a persuasive message and its impact conditional on exposure through simulations based on realworld parameters we estimate that llmbased persuasion costs between 74 per persuaded voter compared to 100 for traditional campaign methods when accounting for the costs of exposure however it is currently much easier to scale traditional campaign persuasion methods than llmbased persuasion while llms do not currently appear to have substantially greater potential for largescale political persuasion than existing nonllm methods this may change as llm capabilities continue to improve and it becomes easier to scalably encourage exposure to persuasive llms
http://arxiv.org/abs/2504.20879v2,2025-04-29T15:48:49Z,"Shivalika Singh, Yiyang Nan, Alex Wang, Daniel D'Souza, Sayash Kapoor, Ahmet Üstün, Sanmi Koyejo, Yuntian Deng, Shayne Longpre, Noah A. Smith, Beyza Ermis, Marzieh Fadaee, Sara Hooker",the leaderboard illusion,measuring progress is fundamental to the advancement of any scientific field as benchmarks play an increasingly central role they also grow more susceptible to distortion chatbot arena has emerged as the goto leaderboard for ranking the most capable ai systems yet in this work we identify systematic issues that have resulted in a distorted playing field we find that undisclosed private testing practices benefit a handful of providers who are able to test multiple variants before public release and retract scores if desired we establish that the ability of these providers to choose the best score leads to biased arena scores due to selective disclosure of performance results at an extreme we identify 27 private llm variants tested by meta in the leadup to the llama4 release we also establish that proprietary closed models are sampled at higher rates number of battles and have fewer models removed from the arena than openweight and opensource alternatives both these policies lead to large data access asymmetries over time providers like google and openai have received an estimated 192 and 204 of all data on the arena respectively in contrast a combined 83 openweight models have only received an estimated 297 of the total data we show that access to chatbot arena data yields substantial benefits even limited additional data can result in relative performance gains of up to 112 on the arena distribution based on our conservative estimates together these dynamics result in overfitting to arenaspecific dynamics rather than general model quality the arena builds on the substantial efforts of both the organizers and an open community that maintains this valuable evaluation platform we offer actionable recommendations to reform the chatbot arenas evaluation framework and promote fairer more transparent benchmarking for the field
http://arxiv.org/abs/2504.20859v1,2025-04-29T15:33:20Z,"Guy Hadad, Haggai Roitman, Yotam Eshel, Bracha Shapira, Lior Rokach",xcross dynamic integration of language models for crossdomain sequential recommendation,as new products are emerging daily recommendation systems are required to quickly adapt to possible new domains without needing extensive retraining this work presents xcross a novel crossdomain sequentialrecommendation model that recommends products in new domains by integrating several domainspecific language models each model is finetuned with lowrank adapters lora given a recommendation prompt operating layer by layer xcross dynamically refines the representation of each source language model by integrating knowledge from all other models these refined representations are propagated from one layer to the next leveraging the activations from each domain adapter to ensure domainspecific nuances are preserved while enabling adaptability across domains using amazon datasets for sequential recommendation xcross achieves performance comparable to a model that is finetuned with lora while using only 25 of the additional parameters in crossdomain tasks such as adapting from toys domain to tools electronics or sports xcross demonstrates robust performance while requiring about 5075 less finetuning data than lora to make finetuning effective furthermore xcross achieves significant improvement in accuracy over alternative crossdomain baselines overall xcross enables scalable and adaptive crossdomain recommendations reducing computational overhead and providing an efficient solution for dataconstrained environments
http://arxiv.org/abs/2504.20849v1,2025-04-29T15:19:06Z,"Anum Afzal, Alexandre Mercier, Florian Matthes",jaccdiv a metric and benchmark for quantifying diversity of generated marketing text in the music industry,online platforms are increasingly interested in using datatotext technologies to generate content and help their users unfortunately traditional generative methods often fall into repetitive patterns resulting in monotonous galleries of texts after only a few iterations in this paper we investigate llmbased datatotext approaches to automatically generate marketing texts that are of sufficient quality and diverse enough for broad adoption we leverage language models such as t5 gpt35 gpt4 and llama2 in conjunction with finetuning fewshot and zeroshot approaches to set a baseline for diverse marketing texts we also introduce a metric jaccdiv to evaluate the diversity of a set of texts this research extends its relevance beyond the music industry proving beneficial in various fields where repetitive automated content generation is prevalent
http://arxiv.org/abs/2504.20839v1,2025-04-29T15:02:30Z,D. -F. Qin,universal language model with the intervention of quantum theory,this paper examines language modeling based on the theory of quantum mechanics it focuses on the introduction of quantum mechanics into the symbolmeaning pairs of language in order to build a representation model of natural language at the same time it is realized that word embedding which is widely used as a basic technique for statistical language modeling can be explained and improved by the mathematical framework of quantum mechanics on this basis this paper continues to try to use quantum statistics and other related theories to study the mathematical representation natural evolution and statistical properties of natural language it is also assumed that the source of such quantum properties is the physicality of information the feasibility of using quantum theory to model natural language is pointed out through the construction of a experimental code the paper discusses in terms of applications the possible help of the theory in constructing generative models that are popular nowadays a preliminary discussion of future applications of the theory to quantum computers is also presented
http://arxiv.org/abs/2505.00035v1,2025-04-29T15:01:23Z,"Aayam Bansal, Raghav Agarwal, Kaashvi Jain",linguistic complexity and sociocultural patterns in hiphop lyrics,this paper presents a comprehensive computational framework for analyzing linguistic complexity and sociocultural trends in hiphop lyrics using a dataset of 3814 songs from 146 influential artists spanning four decades 19802020 we employ natural language processing techniques to quantify multiple dimensions of lyrical complexity our analysis reveals a 237 increase in vocabulary diversity over the study period with east coast artists demonstrating 173 higher lexical variation than other regions rhyme density increased by 342 across all regions with midwest artists exhibiting the highest technical complexity 304 rhymes per line topic modeling identified significant shifts in thematic content with social justice themes decreasing from 285 to 138 of content while introspective themes increased from 76 to 263 sentiment analysis demon strated that lyrics became significantly more negative during sociopolitical crises with polarity decreasing by 031 following major social unrest multidimensional analysis revealed four dis tinct stylistic approaches that correlate strongly with geographic origin r068 p0001 and time period r059 p0001 these findings establish quantitative evidence for the evolution of hip hop as both an art form and a reflection of societal dynamics providing insights into the interplay between linguistic innovation and cultural context in popular music
